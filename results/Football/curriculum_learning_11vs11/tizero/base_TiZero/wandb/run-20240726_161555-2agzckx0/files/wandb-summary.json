{"value_loss": 0.7062474716703097, "_timestamp": 1721995144.3670125, "policy_loss": -0.0017907728630234486, "dist_entropy": 2.8687907552719114, "actor_grad_norm": 0.40043240785598755, "critic_grad_norm": 0.8343106508255005, "ratio": 0.9994338154792786, "total_episode_rewards": -170.0, "Difficulty_level": 1, "Episode_Time": 81.17947316169739, "train_goal_diff": -1.0, "train_goal": 0.0, "train_WDL": -1.0, "_runtime": 16989.029640436172, "_step": 196928}