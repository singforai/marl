{"value_loss": 0.057100260828932124, "_timestamp": 1722017749.0109422, "policy_loss": 0.11567032353331645, "dist_entropy": 2.9387257639567057, "actor_grad_norm": 0.21493007242679596, "critic_grad_norm": 0.08056716620922089, "ratio": 0.5121233463287354, "total_episode_rewards": 0.0, "Difficulty_level": 1, "Episode_Time": 86.42518067359924, "train_goal_diff": -0.6803891160298886, "train_goal": 0.1598054419850557, "train_WDL": -0.6803891160298886, "_runtime": 310.78940320014954, "_step": 3277}