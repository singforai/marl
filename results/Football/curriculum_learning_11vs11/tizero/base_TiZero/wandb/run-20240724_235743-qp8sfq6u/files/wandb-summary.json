{"value_loss": 0.4708267628401518, "_timestamp": 1721888258.148771, "policy_loss": -0.008607482574880122, "dist_entropy": 2.8439754660924277, "actor_grad_norm": 0.2087647020816803, "critic_grad_norm": 0.26114994287490845, "ratio": 1.0007396936416626, "total_episode_rewards": 0.0, "Episode_Time": 40.30723476409912, "Difficulty_level": 1, "train_goal_diff": -0.3557297019527235, "train_goal": 0.0, "train_WDL": -0.3557297019527235, "_runtime": 55194.967393159866, "_step": 17970000, "eval_goal": 0.3, "eval_WDL": -0.1, "eval_goal_diff": -0.1}