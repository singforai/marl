{"value_loss": 0.12148999178575953, "_timestamp": 1722060185.6442835, "policy_loss": 0.012669689041213133, "dist_entropy": 2.891364016532898, "actor_grad_norm": 0.08998198062181473, "critic_grad_norm": 0.06257423758506775, "ratio": 0.5049842596054077, "total_episode_rewards": -40.0, "Difficulty_level": 1, "Episode_Time": 101.32781863212585, "train_goal_diff": -1.0, "train_goal": 0.0, "train_WDL": -1.0, "_runtime": 41708.47902750969, "_step": 465439}