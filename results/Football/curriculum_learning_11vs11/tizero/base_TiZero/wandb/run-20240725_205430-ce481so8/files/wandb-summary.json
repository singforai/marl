{"value_loss": 0.3255924121787151, "_timestamp": 1721929894.6651804, "policy_loss": -0.0011464177027422314, "dist_entropy": 2.900614306131999, "actor_grad_norm": 0.28663143515586853, "critic_grad_norm": 0.3667060136795044, "ratio": 1.0000865459442139, "total_episode_rewards": -130.0, "Difficulty_level": 1, "Episode_Time": 140.2130823135376, "train_goal_diff": -1.0, "train_goal": 0.0, "train_WDL": -1.0, "_runtime": 21424.156393527985, "_step": 24951}