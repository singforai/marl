
사용 가능한 CPU Thread: 128
Env Football Algo jrpo Exp base_JRPO updates 6794/100000000000.0 steps in 78.20
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 4995/100000000000.0 steps in 52.92
total episode rewards is -100.0
wandb: WARNING Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'value_loss': 0.8459592741727829, '_timestamp': 1721910387.2049713}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'policy_loss': -0.015474456613495325, '_timestamp': 1721910387.2051709}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.9374517520268757, '_timestamp': 1721910387.2052412}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 1.63307523727417, '_timestamp': 1721910387.2053463}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 2.614898443222046, '_timestamp': 1721910387.2056434}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'ratio': 1.0157912969589233, '_timestamp': 1721910387.2057493}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721910387.2058876}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910387.2059891}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'Episode_Time': 52.923126459121704, '_timestamp': 1721910387.206049}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910387.2064471}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910387.2067277}).
wandb: WARNING (User provided step: 4995 is less than current step: 6794. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910387.2070057}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'value_loss': 0.26315635345876215, '_timestamp': 1721910480.5100093}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'policy_loss': -0.0035430657863616943, '_timestamp': 1721910480.5101767}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.933106150627136, '_timestamp': 1721910480.5102487}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 0.6511568427085876, '_timestamp': 1721910480.5103474}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 0.9852355122566223, '_timestamp': 1721910480.510549}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'ratio': 1.0013058185577393, '_timestamp': 1721910480.5106535}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721910480.5107849}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910480.5108836}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'Episode_Time': 93.30205750465393, '_timestamp': 1721910480.5109448}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910480.5115805}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910480.5121217}).
wandb: WARNING (User provided step: 6018 is less than current step: 6794. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910480.5126746}).
Env Football Algo jrpo Exp base_JRPO updates 6018/100000000000.0 steps in 93.30
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4868/100000000000.0 steps in 78.61
total episode rewards is -60.0
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'value_loss': 0.5097750071436167, '_timestamp': 1721910559.1259348}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'policy_loss': -0.003998638753996602, '_timestamp': 1721910559.126099}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.91279038588206, '_timestamp': 1721910559.1261673}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 0.9271206855773926, '_timestamp': 1721910559.1262677}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 1.5447341203689575, '_timestamp': 1721910559.1264968}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'ratio': 1.0082690715789795, '_timestamp': 1721910559.1266003}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721910559.1267376}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910559.1268315}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'Episode_Time': 78.61245131492615, '_timestamp': 1721910559.1268914}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'train_goal_diff': -0.3328717806701745, '_timestamp': 1721910559.1274707}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'train_goal': 0.3335641096649128, '_timestamp': 1721910559.1279123}).
wandb: WARNING (User provided step: 4868 is less than current step: 6794. Dropping entry: {'train_WDL': -0.3328717806701745, '_timestamp': 1721910559.1283767}).
Env Football Algo jrpo Exp base_JRPO updates 3900/100000000000.0 steps in 38.67
total episode rewards is -140.0
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'value_loss': 0.8583805295204123, '_timestamp': 1721910597.8027945}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'policy_loss': 0.0271103223048461, '_timestamp': 1721910597.802948}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.9096605014801025, '_timestamp': 1721910597.8030148}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 1.6069884300231934, '_timestamp': 1721910597.8031077}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 2.103358745574951, '_timestamp': 1721910597.803351}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'ratio': 1.0067296028137207, '_timestamp': 1721910597.8034537}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721910597.80359}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910597.8036828}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'Episode_Time': 38.673749685287476, '_timestamp': 1721910597.8037422}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910597.8040304}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910597.804802}).
wandb: WARNING (User provided step: 3900 is less than current step: 6794. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910597.8049905}).
Env Football Algo jrpo Exp base_JRPO updates 4512/100000000000.0 steps in 94.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'value_loss': 0.2222120884169514, '_timestamp': 1721910692.0304878}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'policy_loss': 0.00999155332450755, '_timestamp': 1721910692.0306425}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.914210548400879, '_timestamp': 1721910692.0307095}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 0.5973855257034302, '_timestamp': 1721910692.0308046}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 0.4103451371192932, '_timestamp': 1721910692.0310378}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'ratio': 1.0029453039169312, '_timestamp': 1721910692.0311408}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721910692.0312731}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910692.0313616}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'Episode_Time': 94.22481989860535, '_timestamp': 1721910692.03142}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910692.0321448}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910692.0327377}).
wandb: WARNING (User provided step: 4512 is less than current step: 6794. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910692.0333545}).
Env Football Algo jrpo Exp base_JRPO updates 4834/100000000000.0 steps in 69.95
total episode rewards is -70.0
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'value_loss': 0.4177166959255313, '_timestamp': 1721910761.9799957}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'policy_loss': -0.006002443633624352, '_timestamp': 1721910761.98015}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'dist_entropy': 2.9177478790283202, '_timestamp': 1721910761.9802177}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'actor_grad_norm': 0.7246911525726318, '_timestamp': 1721910761.980315}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'critic_grad_norm': 1.285283088684082, '_timestamp': 1721910761.9805546}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'ratio': 1.0078809261322021, '_timestamp': 1721910761.9806635}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721910761.9808052}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910761.980899}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'Episode_Time': 69.94587469100952, '_timestamp': 1721910761.9809625}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910761.981426}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910761.9817896}).
wandb: WARNING (User provided step: 4834 is less than current step: 6794. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910761.982163}).
Env Football Algo jrpo Exp base_JRPO updates 8272/100000000000.0 steps in 79.25
total episode rewards is -30.0
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'value_loss': 0.6378209713101387, '_timestamp': 1721910866.7633529}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'policy_loss': 0.0029765567125286906, '_timestamp': 1721910866.7635207}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9177056248982747, '_timestamp': 1721910866.7635906}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 1.1273263692855835, '_timestamp': 1721910866.7636967}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 2.1860029697418213, '_timestamp': 1721910866.7639275}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'ratio': 1.0013169050216675, '_timestamp': 1721910866.7640636}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721910866.764192}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910866.76429}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'Episode_Time': 25.522886037826538, '_timestamp': 1721910866.764354}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.09327548806941431, '_timestamp': 1721910866.764619}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'train_goal': 0.45336225596529284, '_timestamp': 1721910866.7647817}).
wandb: WARNING (User provided step: 1832 is less than current step: 8272. Dropping entry: {'train_WDL': -0.09327548806941431, '_timestamp': 1721910866.7649508}).
Env Football Algo jrpo Exp base_JRPO updates 1832/100000000000.0 steps in 25.52
total episode rewards is -70.0
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'value_loss': 0.2682441295256528, '_timestamp': 1721910961.4850612}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'policy_loss': -0.007161999538075179, '_timestamp': 1721910961.4852145}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.909788827896118, '_timestamp': 1721910961.485283}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.536612331867218, '_timestamp': 1721910961.4853742}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.5446891784667969, '_timestamp': 1721910961.485602}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'ratio': 1.007908582687378, '_timestamp': 1721910961.4857042}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721910961.4858336}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910961.4859238}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'Episode_Time': 94.71946668624878, '_timestamp': 1721910961.4859838}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910961.4865963}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910961.4870973}).
wandb: WARNING (User provided step: 6356 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910961.4876223}).
Env Football Algo jrpo Exp base_JRPO updates 6356/100000000000.0 steps in 94.72
total episode rewards is -40.0
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'value_loss': 0.46214186545461416, '_timestamp': 1721911031.009998}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'policy_loss': -0.011597600621171296, '_timestamp': 1721911031.0101616}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9097917445500694, '_timestamp': 1721911031.0102382}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7916794419288635, '_timestamp': 1721911031.0103376}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.3148669004440308, '_timestamp': 1721911031.0105648}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'ratio': 1.0121419429779053, '_timestamp': 1721911031.010671}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721911031.0108104}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911031.0109057}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'Episode_Time': 69.52157545089722, '_timestamp': 1721911031.0109673}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911031.0114028}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911031.0117652}).
wandb: WARNING (User provided step: 7247 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911031.0121443}).
Env Football Algo jrpo Exp base_JRPO updates 7247/100000000000.0 steps in 69.52
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 2452/100000000000.0 steps in 46.80
total episode rewards is -100.0
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'value_loss': 0.5680998232091466, '_timestamp': 1721911077.8175578}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'policy_loss': -0.004084000820294023, '_timestamp': 1721911077.8177192}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.908364281654358, '_timestamp': 1721911077.8177907}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 1.0141490697860718, '_timestamp': 1721911077.8178864}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.5973206758499146, '_timestamp': 1721911077.8181274}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'ratio': 1.0050768852233887, '_timestamp': 1721911077.8182335}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721911077.8183718}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911077.818467}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'Episode_Time': 46.80471444129944, '_timestamp': 1721911077.8185291}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911077.8188834}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911077.8191311}).
wandb: WARNING (User provided step: 2452 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911077.8193762}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'value_loss': 0.4480406118184328, '_timestamp': 1721911154.731126}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'policy_loss': -0.01096908884937875, '_timestamp': 1721911154.7312791}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.904573976198832, '_timestamp': 1721911154.7313504}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.5459860563278198, '_timestamp': 1721911154.7314472}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.9577996134757996, '_timestamp': 1721911154.731682}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'ratio': 1.007280945777893, '_timestamp': 1721911154.7317975}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721911154.7319314}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911154.7320569}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'Episode_Time': 76.91107559204102, '_timestamp': 1721911154.732122}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.23215846198660064, '_timestamp': 1721911154.732651}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'train_goal': 0.3839207690066997, '_timestamp': 1721911154.7330682}).
wandb: WARNING (User provided step: 6044 is less than current step: 8272. Dropping entry: {'train_WDL': -0.23215846198660064, '_timestamp': 1721911154.7334976}).
Env Football Algo jrpo Exp base_JRPO updates 6044/100000000000.0 steps in 76.91
total episode rewards is -30.0
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'value_loss': 0.5189395459927618, '_timestamp': 1721911223.659414}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'policy_loss': -0.005121489369921619, '_timestamp': 1721911223.6595757}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9098332945505776, '_timestamp': 1721911223.6596522}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.8758645057678223, '_timestamp': 1721911223.6597507}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.6364338397979736, '_timestamp': 1721911223.6600125}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'ratio': 1.0076944828033447, '_timestamp': 1721911223.6601214}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721911223.6602519}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911223.6603394}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'Episode_Time': 68.92522048950195, '_timestamp': 1721911223.6604013}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911223.661097}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911223.6614444}).
wandb: WARNING (User provided step: 5084 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911223.661789}).
Env Football Algo jrpo Exp base_JRPO updates 5084/100000000000.0 steps in 68.93
total episode rewards is -70.0
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'value_loss': 0.5022771966084838, '_timestamp': 1721911274.109945}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'policy_loss': 0.0007502508124647041, '_timestamp': 1721911274.1101067}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.916793794631958, '_timestamp': 1721911274.1101773}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9570100903511047, '_timestamp': 1721911274.1102755}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.3870911598205566, '_timestamp': 1721911274.1104946}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'ratio': 1.0062724351882935, '_timestamp': 1721911274.1106071}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721911274.1107352}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911274.110827}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'Episode_Time': 50.447415351867676, '_timestamp': 1721911274.110889}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'train_goal_diff': 0.2461085401766933, '_timestamp': 1721911274.1112747}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'train_goal': 0.6230542700883467, '_timestamp': 1721911274.1114864}).
wandb: WARNING (User provided step: 5278 is less than current step: 8272. Dropping entry: {'train_WDL': 0.2461085401766933, '_timestamp': 1721911274.1116943}).
Env Football Algo jrpo Exp base_JRPO updates 5278/100000000000.0 steps in 50.45
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 2246/100000000000.0 steps in 36.63
total episode rewards is -110.0
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'value_loss': 0.7183373204121987, '_timestamp': 1721911310.742342}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'policy_loss': -0.002204136260940383, '_timestamp': 1721911310.7424963}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9179541142781575, '_timestamp': 1721911310.7425675}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9794800281524658, '_timestamp': 1721911310.7426612}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.6441787481307983, '_timestamp': 1721911310.7428977}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'ratio': 1.003423810005188, '_timestamp': 1721911310.7430038}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721911310.7431443}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911310.743237}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'Episode_Time': 36.63000226020813, '_timestamp': 1721911310.7432983}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911310.7435684}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911310.743764}).
wandb: WARNING (User provided step: 2246 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911310.7439659}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'value_loss': 0.8758319845298926, '_timestamp': 1721911333.9587944}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'policy_loss': 0.004438452113342161, '_timestamp': 1721911333.9589195}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.918671236038208, '_timestamp': 1721911333.9589903}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9792667627334595, '_timestamp': 1721911333.9590745}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 2.1672112941741943, '_timestamp': 1721911333.9593089}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'ratio': 1.0048326253890991, '_timestamp': 1721911333.9594152}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721911333.959541}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911333.959632}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'Episode_Time': 23.21430540084839, '_timestamp': 1721911333.9596946}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911333.9598837}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911333.960045}).
wandb: WARNING (User provided step: 1882 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911333.9601824}).
Env Football Algo jrpo Exp base_JRPO updates 1882/100000000000.0 steps in 23.21
total episode rewards is -150.0
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'value_loss': 0.7739664410799741, '_timestamp': 1721911399.6642363}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'policy_loss': -0.002772092072215552, '_timestamp': 1721911399.6643908}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.915832306543986, '_timestamp': 1721911399.6644588}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9321227073669434, '_timestamp': 1721911399.664551}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.7639522552490234, '_timestamp': 1721911399.664769}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'ratio': 1.0090900659561157, '_timestamp': 1721911399.664873}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721911399.6650045}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911399.6650949}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'Episode_Time': 65.70321989059448, '_timestamp': 1721911399.6651533}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'train_goal_diff': 0.41719389653889094, '_timestamp': 1721911399.6656435}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'train_goal': 0.7085969482694455, '_timestamp': 1721911399.6659906}).
wandb: WARNING (User provided step: 4211 is less than current step: 8272. Dropping entry: {'train_WDL': 0.41719389653889094, '_timestamp': 1721911399.6663368}).
Env Football Algo jrpo Exp base_JRPO updates 4211/100000000000.0 steps in 65.70
total episode rewards is -100.0
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'value_loss': 0.7411131083965301, '_timestamp': 1721911442.0294101}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'policy_loss': -0.005416250691826766, '_timestamp': 1721911442.0295722}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9119049978256224, '_timestamp': 1721911442.0296395}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9464617371559143, '_timestamp': 1721911442.0297372}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.5472577810287476, '_timestamp': 1721911442.0299695}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'ratio': 1.011244535446167, '_timestamp': 1721911442.0300708}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721911442.030206}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911442.0303001}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'Episode_Time': 42.362340211868286, '_timestamp': 1721911442.0303593}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911442.030616}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911442.0307984}).
wandb: WARNING (User provided step: 4432 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911442.0309782}).
Env Football Algo jrpo Exp base_JRPO updates 4432/100000000000.0 steps in 42.36
total episode rewards is -130.0
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'value_loss': 0.22583400533534587, '_timestamp': 1721911531.8147802}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'policy_loss': 0.02957648269754524, '_timestamp': 1721911531.8149345}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.908430002530416, '_timestamp': 1721911531.8150032}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.44772136211395264, '_timestamp': 1721911531.8150976}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.6024362444877625, '_timestamp': 1721911531.8153381}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'ratio': 0.9882514476776123, '_timestamp': 1721911531.8154418}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721911531.8155746}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911531.8156686}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'Episode_Time': 89.77778196334839, '_timestamp': 1721911531.8157263}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.3668178872326636, '_timestamp': 1721911531.8164127}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'train_goal': 0.3165910563836682, '_timestamp': 1721911531.8169444}).
wandb: WARNING (User provided step: 5742 is less than current step: 8272. Dropping entry: {'train_WDL': -0.3668178872326636, '_timestamp': 1721911531.8174927}).
Env Football Algo jrpo Exp base_JRPO updates 5742/100000000000.0 steps in 89.78
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6210/100000000000.0 steps in 92.80
total episode rewards is -40.0
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'value_loss': 0.2531029158302893, '_timestamp': 1721911624.6153476}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'policy_loss': 0.0076810165929297606, '_timestamp': 1721911624.6155028}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9153958320617677, '_timestamp': 1721911624.615572}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.3784412741661072, '_timestamp': 1721911624.6156666}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.5091978311538696, '_timestamp': 1721911624.6158981}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'ratio': 1.0033373832702637, '_timestamp': 1721911624.6160262}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721911624.6161687}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911624.6162605}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'Episode_Time': 92.79713988304138, '_timestamp': 1721911624.6163216}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911624.616953}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911624.617458}).
wandb: WARNING (User provided step: 6210 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911624.6179898}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'value_loss': 0.5936633281658094, '_timestamp': 1721911690.2909498}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'policy_loss': 0.004977799874419968, '_timestamp': 1721911690.2911136}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.915518283843994, '_timestamp': 1721911690.2911909}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7173552513122559, '_timestamp': 1721911690.2912881}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.4206664562225342, '_timestamp': 1721911690.2915123}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'ratio': 1.0110299587249756, '_timestamp': 1721911690.291614}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721911690.2917414}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911690.2918293}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'Episode_Time': 65.6721043586731, '_timestamp': 1721911690.2918866}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911690.292371}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911690.292761}).
wandb: WARNING (User provided step: 3343 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911690.2931674}).
Env Football Algo jrpo Exp base_JRPO updates 3343/100000000000.0 steps in 65.67
total episode rewards is -100.0
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'value_loss': 0.8539232221742471, '_timestamp': 1721911728.2643228}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'policy_loss': 0.005057749060069909, '_timestamp': 1721911728.2644882}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9095214080810545, '_timestamp': 1721911728.2645578}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 1.0190867185592651, '_timestamp': 1721911728.2646554}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.7993319034576416, '_timestamp': 1721911728.264899}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'ratio': 1.01779043674469, '_timestamp': 1721911728.2650032}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721911728.265134}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911728.265225}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'Episode_Time': 37.97029209136963, '_timestamp': 1721911728.2652836}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.2092130518234165, '_timestamp': 1721911728.2656112}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'train_goal': 0.39539347408829173, '_timestamp': 1721911728.2658503}).
wandb: WARNING (User provided step: 3124 is less than current step: 8272. Dropping entry: {'train_WDL': -0.2092130518234165, '_timestamp': 1721911728.2660935}).
Env Football Algo jrpo Exp base_JRPO updates 3124/100000000000.0 steps in 37.97
total episode rewards is -150.0
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'value_loss': 0.9283798514306545, '_timestamp': 1721911760.394375}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'policy_loss': 0.008163045396407446, '_timestamp': 1721911760.3945549}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.9067352644602455, '_timestamp': 1721911760.3946218}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.9812169671058655, '_timestamp': 1721911760.3947217}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 2.080552101135254, '_timestamp': 1721911760.3949518}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'ratio': 1.0125043392181396, '_timestamp': 1721911760.3950548}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -170.0, '_timestamp': 1721911760.3951933}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911760.395284}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'Episode_Time': 32.12748837471008, '_timestamp': 1721911760.3953445}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911760.395632}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911760.39581}).
wandb: WARNING (User provided step: 2371 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911760.4063497}).
Env Football Algo jrpo Exp base_JRPO updates 2371/100000000000.0 steps in 32.13
total episode rewards is -170.0
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'value_loss': 0.32623107625481984, '_timestamp': 1721911854.532685}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'policy_loss': -0.008821655552019365, '_timestamp': 1721911854.5328667}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.905880529085795, '_timestamp': 1721911854.5329506}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.4750049412250519, '_timestamp': 1721911854.5330505}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.6602829098701477, '_timestamp': 1721911854.534105}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'ratio': 1.013923168182373, '_timestamp': 1721911854.5388927}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721911854.5394888}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911854.5397933}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'Episode_Time': 94.12510967254639, '_timestamp': 1721911854.5400372}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911854.540907}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911854.5415995}).
wandb: WARNING (User provided step: 5799 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911854.5423114}).
Env Football Algo jrpo Exp base_JRPO updates 5799/100000000000.0 steps in 94.13
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 4680/100000000000.0 steps in 46.17
total episode rewards is -70.0
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'value_loss': 0.34817842243239283, '_timestamp': 1721911900.7210255}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'policy_loss': -0.012815633390224927, '_timestamp': 1721911900.7212021}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8830263090133665, '_timestamp': 1721911900.7212718}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.6007685661315918, '_timestamp': 1721911900.7213752}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.6287302374839783, '_timestamp': 1721911900.7216458}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'ratio': 1.011296272277832, '_timestamp': 1721911900.7217546}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721911900.7219028}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911900.7220147}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'Episode_Time': 46.173643350601196, '_timestamp': 1721911900.7220767}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911900.7224932}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911900.7227714}).
wandb: WARNING (User provided step: 4680 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911900.7230306}).
Env Football Algo jrpo Exp base_JRPO updates 4084/100000000000.0 steps in 58.76
total episode rewards is -80.0
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'value_loss': 0.6533185572798054, '_timestamp': 1721911959.4840388}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'policy_loss': -0.0048591740737902005, '_timestamp': 1721911959.4842086}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8821084054311115, '_timestamp': 1721911959.48429}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.8283621072769165, '_timestamp': 1721911959.4843955}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.6452234983444214, '_timestamp': 1721911959.4846385}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'ratio': 1.0088900327682495, '_timestamp': 1721911959.4847553}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721911959.484901}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911959.4850018}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'Episode_Time': 58.76026368141174, '_timestamp': 1721911959.4850738}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911959.485451}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911959.4857385}).
wandb: WARNING (User provided step: 4084 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911959.4860342}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'value_loss': 0.5855527761826913, '_timestamp': 1721912008.5945265}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'policy_loss': -0.014709099619455325, '_timestamp': 1721912008.5946906}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8815361483891806, '_timestamp': 1721912008.5947592}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7052744030952454, '_timestamp': 1721912008.594857}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.3901089429855347, '_timestamp': 1721912008.595087}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'ratio': 1.020874261856079, '_timestamp': 1721912008.595193}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721912008.5953288}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912008.59542}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'Episode_Time': 49.10776686668396, '_timestamp': 1721912008.595481}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912008.5957735}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912008.5959964}).
wandb: WARNING (User provided step: 6317 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912008.59621}).
Env Football Algo jrpo Exp base_JRPO updates 6317/100000000000.0 steps in 49.11
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 6270/100000000000.0 steps in 85.10
total episode rewards is -80.0
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'value_loss': 0.3838585852831602, '_timestamp': 1721912093.693981}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'policy_loss': -0.00019763959775445983, '_timestamp': 1721912093.6941485}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8843767340977986, '_timestamp': 1721912093.6942282}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.4501335322856903, '_timestamp': 1721912093.6943297}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.9553667306900024, '_timestamp': 1721912093.6945782}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'ratio': 1.014931082725525, '_timestamp': 1721912093.6946833}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721912093.6948113}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912093.694901}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'Episode_Time': 85.09703803062439, '_timestamp': 1721912093.694958}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912093.6955013}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912093.695938}).
wandb: WARNING (User provided step: 6270 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912093.696435}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'value_loss': 0.33646113156030577, '_timestamp': 1721912161.496187}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'policy_loss': -0.010682832483823101, '_timestamp': 1721912161.4963849}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8877977609634398, '_timestamp': 1721912161.496455}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.477197527885437, '_timestamp': 1721912161.496572}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.9565562009811401, '_timestamp': 1721912161.4968576}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'ratio': 1.025359869003296, '_timestamp': 1721912161.4969592}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721912161.4971044}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912161.4972043}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'Episode_Time': 67.79877758026123, '_timestamp': 1721912161.4972646}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912161.4978}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912161.4981868}).
wandb: WARNING (User provided step: 5185 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912161.4985776}).
Env Football Algo jrpo Exp base_JRPO updates 5185/100000000000.0 steps in 67.80
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 2162/100000000000.0 steps in 36.40
total episode rewards is -120.0
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'value_loss': 0.5986233582595984, '_timestamp': 1721912197.9015408}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'policy_loss': -0.008498858655026803, '_timestamp': 1721912197.902885}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8905840269724528, '_timestamp': 1721912197.9030209}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7907156348228455, '_timestamp': 1721912197.9037037}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.4634191989898682, '_timestamp': 1721912197.9040942}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'ratio': 1.0174667835235596, '_timestamp': 1721912197.9042213}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721912197.9045105}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912197.904719}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'Episode_Time': 36.396464586257935, '_timestamp': 1721912197.9047854}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912197.9059813}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912197.906289}).
wandb: WARNING (User provided step: 2162 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912197.9065928}).
Env Football Algo jrpo Exp base_JRPO updates 3457/100000000000.0 steps in 44.11
total episode rewards is -120.0
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'value_loss': 0.6915502455582221, '_timestamp': 1721912242.013339}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'policy_loss': -0.009132700573536568, '_timestamp': 1721912242.0135345}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8901340564092, '_timestamp': 1721912242.0203803}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7819162011146545, '_timestamp': 1721912242.0205715}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.7258217334747314, '_timestamp': 1721912242.0208392}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'ratio': 1.0301003456115723, '_timestamp': 1721912242.0209608}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721912242.0212104}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912242.0213115}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'Episode_Time': 44.105809926986694, '_timestamp': 1721912242.0213711}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.1324599708879185, '_timestamp': 1721912242.0218432}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'train_goal': 0.43377001455604075, '_timestamp': 1721912242.0220766}).
wandb: WARNING (User provided step: 3457 is less than current step: 8272. Dropping entry: {'train_WDL': -0.1324599708879185, '_timestamp': 1721912242.0223682}).
Env Football Algo jrpo Exp base_JRPO updates 4421/100000000000.0 steps in 91.23
total episode rewards is -30.0
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'value_loss': 0.23647475228955347, '_timestamp': 1721912333.2591796}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'policy_loss': -0.01793235124554485, '_timestamp': 1721912333.2602422}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8878884919484458, '_timestamp': 1721912333.260326}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.4828801155090332, '_timestamp': 1721912333.260833}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 0.2513430714607239, '_timestamp': 1721912333.2611494}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'ratio': 0.9917080998420715, '_timestamp': 1721912333.26127}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721912333.2614255}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912333.2616057}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'Episode_Time': 91.23205351829529, '_timestamp': 1721912333.2616727}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.4373759334530674, '_timestamp': 1721912333.262905}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'train_goal': 0.2813120332734663, '_timestamp': 1721912333.26353}).
wandb: WARNING (User provided step: 4421 is less than current step: 8272. Dropping entry: {'train_WDL': -0.4373759334530674, '_timestamp': 1721912333.2642064}).
Env Football Algo jrpo Exp base_JRPO updates 4465/100000000000.0 steps in 64.93
total episode rewards is -60.0
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'value_loss': 0.4225047035018603, '_timestamp': 1721912398.1919055}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'policy_loss': -0.01469502938988929, '_timestamp': 1721912398.1921105}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8900381263097126, '_timestamp': 1721912398.1921828}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.6136921644210815, '_timestamp': 1721912398.1922925}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.2392009496688843, '_timestamp': 1721912398.1925633}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'ratio': 1.0132558345794678, '_timestamp': 1721912398.1926692}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721912398.192804}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912398.1928983}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'Episode_Time': 64.92651629447937, '_timestamp': 1721912398.1929562}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'train_goal_diff': -0.31118530884808016, '_timestamp': 1721912398.1935406}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'train_goal': 0.3444073455759599, '_timestamp': 1721912398.1939235}).
wandb: WARNING (User provided step: 4465 is less than current step: 8272. Dropping entry: {'train_WDL': -0.31118530884808016, '_timestamp': 1721912398.194318}).
Env Football Algo jrpo Exp base_JRPO updates 2060/100000000000.0 steps in 40.93
total episode rewards is -80.0
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'value_loss': 0.7897057569026947, '_timestamp': 1721912439.12574}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'policy_loss': -0.0061357586460265645, '_timestamp': 1721912439.1259286}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.890313345591227, '_timestamp': 1721912439.1260161}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.7711538076400757, '_timestamp': 1721912439.1261306}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.7572180032730103, '_timestamp': 1721912439.1264005}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'ratio': 1.0173802375793457, '_timestamp': 1721912439.1265318}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721912439.1266954}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912439.1268048}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'Episode_Time': 40.93064618110657, '_timestamp': 1721912439.1268785}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'train_goal_diff': 0.013602015113350126, '_timestamp': 1721912439.127227}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'train_goal': 0.506801007556675, '_timestamp': 1721912439.1274579}).
wandb: WARNING (User provided step: 2060 is less than current step: 8272. Dropping entry: {'train_WDL': 0.013602015113350126, '_timestamp': 1721912439.1276867}).
Env Football Algo jrpo Exp base_JRPO updates 6383/100000000000.0 steps in 66.38
total episode rewards is -80.0
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'value_loss': 0.5858324986944596, '_timestamp': 1721912505.5135415}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'policy_loss': 0.0003015049171517603, '_timestamp': 1721912505.5136967}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8909414275487264, '_timestamp': 1721912505.5137663}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.650336742401123, '_timestamp': 1721912505.5138605}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.496921181678772, '_timestamp': 1721912505.5140967}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'ratio': 1.0207422971725464, '_timestamp': 1721912505.514199}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721912505.5143354}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912505.5144265}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'Episode_Time': 66.38493967056274, '_timestamp': 1721912505.5144858}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912505.514912}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912505.515245}).
wandb: WARNING (User provided step: 6383 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912505.5155883}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'value_loss': 0.6259405263513327, '_timestamp': 1721912563.6160393}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'policy_loss': -0.0067557572992518545, '_timestamp': 1721912563.6162047}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'dist_entropy': 2.8873211193084716, '_timestamp': 1721912563.616274}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'actor_grad_norm': 0.631131649017334, '_timestamp': 1721912563.616372}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'critic_grad_norm': 1.477187156677246, '_timestamp': 1721912563.6166055}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'ratio': 1.027836799621582, '_timestamp': 1721912563.6167088}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721912563.616842}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912563.616934}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'Episode_Time': 58.09967064857483, '_timestamp': 1721912563.6169927}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912563.61735}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912563.6175854}).
wandb: WARNING (User provided step: 6233 is less than current step: 8272. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912563.6178238}).
Env Football Algo jrpo Exp base_JRPO updates 6233/100000000000.0 steps in 58.10
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 8502/100000000000.0 steps in 84.20
total episode rewards is -40.0
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'value_loss': 0.31822999984025957, '_timestamp': 1721912743.4189937}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'policy_loss': -0.03700512088403533, '_timestamp': 1721912743.41918}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'dist_entropy': 2.8836262957255046, '_timestamp': 1721912743.4192488}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'actor_grad_norm': 0.51197350025177, '_timestamp': 1721912743.4193535}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'critic_grad_norm': 0.39111751317977905, '_timestamp': 1721912743.4196217}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'ratio': 1.016896367073059, '_timestamp': 1721912743.4197307}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912743.41988}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912743.420018}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'Episode_Time': 95.59188842773438, '_timestamp': 1721912743.4200816}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912743.4208724}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912743.4214509}).
wandb: WARNING (User provided step: 5120 is less than current step: 8502. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912743.4220552}).
Env Football Algo jrpo Exp base_JRPO updates 5120/100000000000.0 steps in 95.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'value_loss': 0.5436785533527533, '_timestamp': 1721912786.6305485}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'policy_loss': -0.029350456471632546, '_timestamp': 1721912786.6307364}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'dist_entropy': 2.8831456518173217, '_timestamp': 1721912786.6308048}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'actor_grad_norm': 0.6173605918884277, '_timestamp': 1721912786.6308985}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'critic_grad_norm': 1.2675801515579224, '_timestamp': 1721912786.6311274}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'ratio': 1.0390217304229736, '_timestamp': 1721912786.631228}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721912786.63136}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912786.631448}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'Episode_Time': 43.207719802856445, '_timestamp': 1721912786.631506}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'train_goal_diff': -0.2831905781584582, '_timestamp': 1721912786.6318939}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'train_goal': 0.35840471092077086, '_timestamp': 1721912786.6321924}).
wandb: WARNING (User provided step: 3619 is less than current step: 8502. Dropping entry: {'train_WDL': -0.2831905781584582, '_timestamp': 1721912786.6324677}).
Env Football Algo jrpo Exp base_JRPO updates 3619/100000000000.0 steps in 43.21
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 8962/100000000000.0 steps in 92.70
total episode rewards is -30.0
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'value_loss': 0.2015607367704312, '_timestamp': 1721912975.124392}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'policy_loss': -0.01434876245756944, '_timestamp': 1721912975.1246579}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8784238862991334, '_timestamp': 1721912975.1247282}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.41278883814811707, '_timestamp': 1721912975.1248286}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.327246755361557, '_timestamp': 1721912975.125078}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'ratio': 1.0026018619537354, '_timestamp': 1721912975.1251812}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912975.1255}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912975.1256027}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'Episode_Time': 95.79135990142822, '_timestamp': 1721912975.1256626}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912975.126897}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912975.1275978}).
wandb: WARNING (User provided step: 4853 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912975.1284854}).
Env Football Algo jrpo Exp base_JRPO updates 4853/100000000000.0 steps in 95.79
total episode rewards is -40.0
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'value_loss': 0.25872683300947147, '_timestamp': 1721913053.6025093}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'policy_loss': -0.011672636184375734, '_timestamp': 1721913053.6027286}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.882708969116211, '_timestamp': 1721913053.6028147}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.3650590479373932, '_timestamp': 1721913053.6029174}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.5590662360191345, '_timestamp': 1721913053.603171}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'ratio': 1.0159549713134766, '_timestamp': 1721913053.6032956}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721913053.6034706}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913053.6035693}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'Episode_Time': 78.4729733467102, '_timestamp': 1721913053.6036327}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913053.6042469}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913053.604716}).
wandb: WARNING (User provided step: 7163 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913053.605195}).
Env Football Algo jrpo Exp base_JRPO updates 7163/100000000000.0 steps in 78.47
total episode rewards is -50.0
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'value_loss': 0.22860240830108525, '_timestamp': 1721913148.1266072}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'policy_loss': -0.012589853732691458, '_timestamp': 1721913148.12677}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.87028470993042, '_timestamp': 1721913148.1268382}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.30379655957221985, '_timestamp': 1721913148.1269393}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.5263824462890625, '_timestamp': 1721913148.1271946}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'ratio': 1.008675217628479, '_timestamp': 1721913148.127303}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913148.127445}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913148.1275373}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'Episode_Time': 94.5206663608551, '_timestamp': 1721913148.1276}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913148.1283011}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913148.1288314}).
wandb: WARNING (User provided step: 5909 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913148.1293814}).
Env Football Algo jrpo Exp base_JRPO updates 5909/100000000000.0 steps in 94.52
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5463/100000000000.0 steps in 90.86
total episode rewards is 0.0
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'value_loss': 0.23173123843599266, '_timestamp': 1721913238.9946306}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'policy_loss': -0.009937411337450613, '_timestamp': 1721913238.9948785}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.876804755528768, '_timestamp': 1721913238.9949563}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.25691771507263184, '_timestamp': 1721913238.9950838}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.35617923736572266, '_timestamp': 1721913238.995347}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'ratio': 0.9986797571182251, '_timestamp': 1721913238.9954553}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721913238.9956806}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913238.9958014}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'Episode_Time': 90.86380362510681, '_timestamp': 1721913238.9958682}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'train_goal_diff': 0.23980287302086611, '_timestamp': 1721913238.997006}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'train_goal': 0.6199014365104331, '_timestamp': 1721913238.997588}).
wandb: WARNING (User provided step: 5463 is less than current step: 8962. Dropping entry: {'train_WDL': 0.23980287302086611, '_timestamp': 1721913238.9981637}).
Env Football Algo jrpo Exp base_JRPO updates 3813/100000000000.0 steps in 59.56
total episode rewards is -50.0
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'value_loss': 0.43017676202269894, '_timestamp': 1721913298.5639274}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'policy_loss': -0.011574639061582275, '_timestamp': 1721913298.565249}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.879274106025696, '_timestamp': 1721913298.5653224}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.434244841337204, '_timestamp': 1721913298.5659564}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 1.2753338813781738, '_timestamp': 1721913298.5662699}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'ratio': 1.0115491151809692, '_timestamp': 1721913298.5663762}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721913298.5665216}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913298.5667286}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'Episode_Time': 59.55966877937317, '_timestamp': 1721913298.566789}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.32748538011695905, '_timestamp': 1721913298.5678496}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'train_goal': 0.3362573099415205, '_timestamp': 1721913298.5682669}).
wandb: WARNING (User provided step: 3813 is less than current step: 8962. Dropping entry: {'train_WDL': -0.32748538011695905, '_timestamp': 1721913298.568689}).
Env Football Algo jrpo Exp base_JRPO updates 6084/100000000000.0 steps in 84.52
total episode rewards is -50.0
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'value_loss': 0.32299369279450424, '_timestamp': 1721913383.0947773}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'policy_loss': -0.014068564038413266, '_timestamp': 1721913383.09506}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.880662965774536, '_timestamp': 1721913383.0951614}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.33008241653442383, '_timestamp': 1721913383.0953455}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.8404519557952881, '_timestamp': 1721913383.0957541}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'ratio': 1.0141369104385376, '_timestamp': 1721913383.0959842}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721913383.0962284}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913383.0963376}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'Episode_Time': 84.52480220794678, '_timestamp': 1721913383.0963993}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.2577348850411581, '_timestamp': 1721913383.0971484}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'train_goal': 0.3711325574794209, '_timestamp': 1721913383.0975873}).
wandb: WARNING (User provided step: 6084 is less than current step: 8962. Dropping entry: {'train_WDL': -0.2577348850411581, '_timestamp': 1721913383.098036}).
Env Football Algo jrpo Exp base_JRPO updates 5420/100000000000.0 steps in 86.33
total episode rewards is -40.0
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'value_loss': 0.22682337422758186, '_timestamp': 1721913469.4319055}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'policy_loss': -0.014860567581296587, '_timestamp': 1721913469.4321089}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.889752100308736, '_timestamp': 1721913469.432179}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.25294896960258484, '_timestamp': 1721913469.4322877}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.4012833833694458, '_timestamp': 1721913469.4325497}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'ratio': 1.0071494579315186, '_timestamp': 1721913469.432653}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913469.4327915}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913469.4328895}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'Episode_Time': 86.33292937278748, '_timestamp': 1721913469.4329462}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913469.4336817}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913469.4343016}).
wandb: WARNING (User provided step: 5420 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913469.4349308}).
Env Football Algo jrpo Exp base_JRPO updates 8822/100000000000.0 steps in 89.52
total episode rewards is -20.0
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'value_loss': 0.21029158941775677, '_timestamp': 1721913558.9594111}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'policy_loss': -0.011925171999416003, '_timestamp': 1721913558.9596276}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.894156896273295, '_timestamp': 1721913558.959695}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.2589539885520935, '_timestamp': 1721913558.959793}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.3576006293296814, '_timestamp': 1721913558.9600663}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'ratio': 0.997808039188385, '_timestamp': 1721913558.9601743}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721913558.9603572}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913558.960454}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'Episode_Time': 89.52352857589722, '_timestamp': 1721913558.960514}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.06280349627711233, '_timestamp': 1721913558.9610977}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'train_goal': 0.4685982518614438, '_timestamp': 1721913558.9615033}).
wandb: WARNING (User provided step: 8822 is less than current step: 8962. Dropping entry: {'train_WDL': -0.06280349627711233, '_timestamp': 1721913558.9619157}).
Env Football Algo jrpo Exp base_JRPO updates 2845/100000000000.0 steps in 38.78
total episode rewards is -60.0
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'value_loss': 0.4101053967575232, '_timestamp': 1721913597.741796}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'policy_loss': -0.012000697775899122, '_timestamp': 1721913597.7427344}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8973494736353556, '_timestamp': 1721913597.7428129}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.5232187509536743, '_timestamp': 1721913597.7432933}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 1.4780924320220947, '_timestamp': 1721913597.7435343}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'ratio': 1.0086064338684082, '_timestamp': 1721913597.743643}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721913597.7437844}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913597.7480075}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'Episode_Time': 38.775413513183594, '_timestamp': 1721913597.7481236}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.27919655667144905, '_timestamp': 1721913597.7489672}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'train_goal': 0.3604017216642755, '_timestamp': 1721913597.7492428}).
wandb: WARNING (User provided step: 2845 is less than current step: 8962. Dropping entry: {'train_WDL': -0.27919655667144905, '_timestamp': 1721913597.7495058}).
Env Football Algo jrpo Exp base_JRPO updates 6433/100000000000.0 steps in 93.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'value_loss': 0.2511493327903251, '_timestamp': 1721913691.2898035}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'policy_loss': -0.007373463751282543, '_timestamp': 1721913691.289959}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.893365357716878, '_timestamp': 1721913691.290029}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.22267383337020874, '_timestamp': 1721913691.290125}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.3413693904876709, '_timestamp': 1721913691.2903585}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'ratio': 0.9987819790840149, '_timestamp': 1721913691.2904603}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721913691.2905946}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913691.2906866}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'Episode_Time': 93.53958058357239, '_timestamp': 1721913691.290748}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.3031399556437493, '_timestamp': 1721913691.2913895}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'train_goal': 0.34843002217812535, '_timestamp': 1721913691.2918854}).
wandb: WARNING (User provided step: 6433 is less than current step: 8962. Dropping entry: {'train_WDL': -0.3031399556437493, '_timestamp': 1721913691.292422}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'value_loss': 0.24582281261410874, '_timestamp': 1721913781.8479614}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'policy_loss': -0.010959634188717851, '_timestamp': 1721913781.8481705}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.890924340883891, '_timestamp': 1721913781.8482447}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.21621450781822205, '_timestamp': 1721913781.8483672}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.46407049894332886, '_timestamp': 1721913781.8486564}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'ratio': 1.0084023475646973, '_timestamp': 1721913781.8487716}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913781.8489163}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913781.8490164}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'Episode_Time': 90.55431866645813, '_timestamp': 1721913781.8490896}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913781.8499458}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913781.8505595}).
wandb: WARNING (User provided step: 4915 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913781.851188}).
Env Football Algo jrpo Exp base_JRPO updates 4915/100000000000.0 steps in 90.55
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8200/100000000000.0 steps in 79.43
total episode rewards is -20.0
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'value_loss': 0.2263845352413288, '_timestamp': 1721913861.2842665}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'policy_loss': -0.0029104844355606475, '_timestamp': 1721913861.2844107}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8890707683563233, '_timestamp': 1721913861.2844772}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.2700921297073364, '_timestamp': 1721913861.2845683}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.4415384531021118, '_timestamp': 1721913861.2847888}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'ratio': 1.0028150081634521, '_timestamp': 1721913861.2848854}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721913861.2850206}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913861.2851129}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'Episode_Time': 79.4323525428772, '_timestamp': 1721913861.2851717}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.1261764705882353, '_timestamp': 1721913861.2857249}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'train_goal': 0.43691176470588233, '_timestamp': 1721913861.2861378}).
wandb: WARNING (User provided step: 8200 is less than current step: 8962. Dropping entry: {'train_WDL': -0.1261764705882353, '_timestamp': 1721913861.2865605}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'value_loss': 0.5694532516722878, '_timestamp': 1721913896.8001602}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'policy_loss': -0.009054209175907697, '_timestamp': 1721913896.8003125}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8876854515075685, '_timestamp': 1721913896.800382}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.5590215921401978, '_timestamp': 1721913896.8004746}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 1.7208665609359741, '_timestamp': 1721913896.8006952}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'ratio': 1.0091187953948975, '_timestamp': 1721913896.8007977}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721913896.8009288}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913896.801019}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'Episode_Time': 35.512718200683594, '_timestamp': 1721913896.8010788}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913896.8013732}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913896.8015804}).
wandb: WARNING (User provided step: 2834 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913896.801788}).
Env Football Algo jrpo Exp base_JRPO updates 2834/100000000000.0 steps in 35.51
total episode rewards is -110.0
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'value_loss': 0.24059159515270342, '_timestamp': 1721913985.682114}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'policy_loss': 0.0035254279420284243, '_timestamp': 1721913985.6823225}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8890107456843057, '_timestamp': 1721913985.6823933}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.2093319594860077, '_timestamp': 1721913985.6825073}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.5186419486999512, '_timestamp': 1721913985.6828253}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'ratio': 1.006894826889038, '_timestamp': 1721913985.6829383}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913985.683088}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913985.6831946}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'Episode_Time': 88.87870573997498, '_timestamp': 1721913985.6832547}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913985.6839147}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913985.6844108}).
wandb: WARNING (User provided step: 7365 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913985.6852653}).
Env Football Algo jrpo Exp base_JRPO updates 7365/100000000000.0 steps in 88.88
total episode rewards is -40.0
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'value_loss': 0.2283651890679418, '_timestamp': 1721914080.4413884}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'policy_loss': -0.013656391416055461, '_timestamp': 1721914080.4418306}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.889212096532186, '_timestamp': 1721914080.441903}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.23544663190841675, '_timestamp': 1721914080.4421055}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 0.4433704614639282, '_timestamp': 1721914080.4423864}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'ratio': 1.0094949007034302, '_timestamp': 1721914080.4424973}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914080.4426455}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914080.4427795}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'Episode_Time': 94.75373196601868, '_timestamp': 1721914080.442842}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914080.4435494}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914080.4439719}).
wandb: WARNING (User provided step: 8873 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914080.444385}).
Env Football Algo jrpo Exp base_JRPO updates 8873/100000000000.0 steps in 94.75
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 2671/100000000000.0 steps in 39.66
total episode rewards is -100.0
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'value_loss': 0.6416630240778128, '_timestamp': 1721914120.1090631}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'policy_loss': -0.010519880570548897, '_timestamp': 1721914120.109229}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.8871440521876015, '_timestamp': 1721914120.109298}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.5535575747489929, '_timestamp': 1721914120.1093957}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 2.3960459232330322, '_timestamp': 1721914120.1096318}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'ratio': 1.0095211267471313, '_timestamp': 1721914120.1097336}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721914120.109868}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914120.109959}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'Episode_Time': 39.66381049156189, '_timestamp': 1721914120.110016}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'train_goal_diff': -0.3107940446650124, '_timestamp': 1721914120.1103623}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'train_goal': 0.3446029776674938, '_timestamp': 1721914120.1107256}).
wandb: WARNING (User provided step: 2671 is less than current step: 8962. Dropping entry: {'train_WDL': -0.3107940446650124, '_timestamp': 1721914120.1109724}).
Env Football Algo jrpo Exp base_JRPO updates 5356/100000000000.0 steps in 58.23
total episode rewards is -80.0
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'value_loss': 0.503802167524894, '_timestamp': 1721914178.34461}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'policy_loss': -0.008818256448721513, '_timestamp': 1721914178.345714}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'dist_entropy': 2.886249532699585, '_timestamp': 1721914178.345806}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'actor_grad_norm': 0.4476719796657562, '_timestamp': 1721914178.3463626}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'critic_grad_norm': 1.233985185623169, '_timestamp': 1721914178.346674}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'ratio': 1.0073022842407227, '_timestamp': 1721914178.3467913}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721914178.3469415}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914178.3471284}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'Episode_Time': 58.229905128479004, '_timestamp': 1721914178.3472028}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914178.3481305}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914178.348483}).
wandb: WARNING (User provided step: 5356 is less than current step: 8962. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914178.3488317}).
Env Football Algo jrpo Exp base_JRPO updates 10652/100000000000.0 steps in 90.80
total episode rewards is -40.0
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'value_loss': 0.7496785420676072, '_timestamp': 1721914314.0452666}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'policy_loss': -0.011154199428080271, '_timestamp': 1721914314.0454369}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.885552668571472, '_timestamp': 1721914314.0455136}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.6231630444526672, '_timestamp': 1721914314.045615}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.7276654243469238, '_timestamp': 1721914314.045844}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'ratio': 1.020982265472412, '_timestamp': 1721914314.0459473}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721914314.046082}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914314.0461767}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'Episode_Time': 44.89085793495178, '_timestamp': 1721914314.0462363}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914314.046534}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914314.046746}).
wandb: WARNING (User provided step: 3946 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914314.0469637}).
Env Football Algo jrpo Exp base_JRPO updates 3946/100000000000.0 steps in 44.89
total episode rewards is -130.0
Env Football Algo jrpo Exp base_JRPO updates 6840/100000000000.0 steps in 88.68
total episode rewards is -20.0
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'value_loss': 0.2389151252992451, '_timestamp': 1721914402.7295508}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'policy_loss': -0.012341713221200432, '_timestamp': 1721914402.729738}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8826104990641275, '_timestamp': 1721914402.7298107}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.229665145277977, '_timestamp': 1721914402.729919}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.5985779762268066, '_timestamp': 1721914402.730192}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'ratio': 1.0064430236816406, '_timestamp': 1721914402.7302985}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721914402.7304406}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914402.7305434}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'Episode_Time': 88.68157124519348, '_timestamp': 1721914402.7306187}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.27034313725490194, '_timestamp': 1721914402.731725}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'train_goal': 0.364828431372549, '_timestamp': 1721914402.7322557}).
wandb: WARNING (User provided step: 6840 is less than current step: 10652. Dropping entry: {'train_WDL': -0.27034313725490194, '_timestamp': 1721914402.7327652}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'value_loss': 0.20965283802788084, '_timestamp': 1721914505.2516842}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'policy_loss': 0.002465754169194649, '_timestamp': 1721914505.253084}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.882225308418274, '_timestamp': 1721914505.25316}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.21864718198776245, '_timestamp': 1721914505.2537854}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.5548271536827087, '_timestamp': 1721914505.2541294}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'ratio': 1.0088658332824707, '_timestamp': 1721914505.2542398}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914505.2543905}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914505.2545938}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'Episode_Time': 102.51293015480042, '_timestamp': 1721914505.2547355}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914505.25599}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914505.2565079}).
wandb: WARNING (User provided step: 6632 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914505.2570422}).
Env Football Algo jrpo Exp base_JRPO updates 6632/100000000000.0 steps in 102.51
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5136/100000000000.0 steps in 71.37
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'value_loss': 0.28807654678511124, '_timestamp': 1721914576.6253827}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'policy_loss': -0.01424139270442538, '_timestamp': 1721914576.625553}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.884616103172302, '_timestamp': 1721914576.6256218}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.2534013092517853, '_timestamp': 1721914576.6257195}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.31475532054901123, '_timestamp': 1721914576.625959}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'ratio': 1.0071139335632324, '_timestamp': 1721914576.6260655}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721914576.626202}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914576.6262934}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'Episode_Time': 71.36750769615173, '_timestamp': 1721914576.626377}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.3608878683505549, '_timestamp': 1721914576.62701}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'train_goal': 0.31955606582472257, '_timestamp': 1721914576.6274712}).
wandb: WARNING (User provided step: 5136 is less than current step: 10652. Dropping entry: {'train_WDL': -0.3608878683505549, '_timestamp': 1721914576.6279447}).
total episode rewards is -30.0
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'value_loss': 0.3130218559247442, '_timestamp': 1721914661.0261245}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'policy_loss': -0.01313325299260517, '_timestamp': 1721914661.0272298}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8823193359375, '_timestamp': 1721914661.0273018}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.22810189425945282, '_timestamp': 1721914661.0278513}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.5047826766967773, '_timestamp': 1721914661.0281928}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'ratio': 1.0100232362747192, '_timestamp': 1721914661.028298}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914661.0284727}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914661.02866}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'Episode_Time': 84.39290356636047, '_timestamp': 1721914661.0287247}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.3244822092405735, '_timestamp': 1721914661.0299084}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'train_goal': 0.3377588953797132, '_timestamp': 1721914661.0303695}).
wandb: WARNING (User provided step: 5268 is less than current step: 10652. Dropping entry: {'train_WDL': -0.3244822092405735, '_timestamp': 1721914661.030836}).
Env Football Algo jrpo Exp base_JRPO updates 5268/100000000000.0 steps in 84.39
total episode rewards is -40.0
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'value_loss': 0.5380931158984701, '_timestamp': 1721914709.5148242}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007129916889025481, '_timestamp': 1721914709.5150287}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.881786665916443, '_timestamp': 1721914709.5151007}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.4227447807788849, '_timestamp': 1721914709.515216}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.3962210416793823, '_timestamp': 1721914709.5154736}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'ratio': 1.0056108236312866, '_timestamp': 1721914709.5155797}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721914709.5157301}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914709.5158298}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'Episode_Time': 48.48286962509155, '_timestamp': 1721914709.5159178}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914709.5163584}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914709.5166476}).
wandb: WARNING (User provided step: 4818 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914709.5169327}).
Env Football Algo jrpo Exp base_JRPO updates 4818/100000000000.0 steps in 48.48
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 9999/100000000000.0 steps in 93.23
total episode rewards is -40.0
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'value_loss': 0.226339223497392, '_timestamp': 1721914802.751337}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'policy_loss': -0.004927434448230391, '_timestamp': 1721914802.751491}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8851247056325278, '_timestamp': 1721914802.751561}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.20602913200855255, '_timestamp': 1721914802.7516556}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.24512606859207153, '_timestamp': 1721914802.7518997}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'ratio': 1.0087647438049316, '_timestamp': 1721914802.7520401}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914802.752189}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914802.7522814}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'Episode_Time': 93.23373556137085, '_timestamp': 1721914802.7523415}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914802.7530427}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914802.7533815}).
wandb: WARNING (User provided step: 9999 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914802.7537258}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'value_loss': 0.26055315918521954, '_timestamp': 1721914894.3487422}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007436616035362628, '_timestamp': 1721914894.3489172}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8862664874394737, '_timestamp': 1721914894.3489845}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.2349010705947876, '_timestamp': 1721914894.3490949}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.2931097447872162, '_timestamp': 1721914894.3493605}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'ratio': 1.0030947923660278, '_timestamp': 1721914894.3494616}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721914894.3495967}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914894.3496933}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'Episode_Time': 91.59412932395935, '_timestamp': 1721914894.349751}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.42667188111067655, '_timestamp': 1721914894.3505552}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'train_goal': 0.2866640594446617, '_timestamp': 1721914894.3511698}).
wandb: WARNING (User provided step: 4772 is less than current step: 10652. Dropping entry: {'train_WDL': -0.42667188111067655, '_timestamp': 1721914894.351771}).
Env Football Algo jrpo Exp base_JRPO updates 4772/100000000000.0 steps in 91.59
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 7628/100000000000.0 steps in 86.38
total episode rewards is -40.0
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'value_loss': 0.25347916601303344, '_timestamp': 1721914980.7373338}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'policy_loss': -0.008729736601623395, '_timestamp': 1721914980.7374923}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.89086243947347, '_timestamp': 1721914980.7375705}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.22987547516822815, '_timestamp': 1721914980.7376685}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.3080276548862457, '_timestamp': 1721914980.737909}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'ratio': 1.0086863040924072, '_timestamp': 1721914980.7380137}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914980.7381513}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914980.738242}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'Episode_Time': 86.38479614257812, '_timestamp': 1721914980.7383018}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914980.7389667}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914980.7394166}).
wandb: WARNING (User provided step: 7628 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914980.7398756}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'value_loss': 0.18721424649547164, '_timestamp': 1721915071.9708993}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007528655135150378, '_timestamp': 1721915071.971047}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.887204219500224, '_timestamp': 1721915071.9711185}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.17916268110275269, '_timestamp': 1721915071.9712112}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.5145870447158813, '_timestamp': 1721915071.9714391}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'ratio': 1.0054230690002441, '_timestamp': 1721915071.9715393}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721915071.9716716}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915071.9717607}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'Episode_Time': 91.2302839756012, '_timestamp': 1721915071.9718451}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915071.9726305}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915071.9730284}).
wandb: WARNING (User provided step: 8618 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915071.9734354}).
Env Football Algo jrpo Exp base_JRPO updates 8618/100000000000.0 steps in 91.23
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 5649/100000000000.0 steps in 82.99
total episode rewards is -40.0
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'value_loss': 0.24678016901753533, '_timestamp': 1721915154.960574}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'policy_loss': -0.0036346143470533812, '_timestamp': 1721915154.9607306}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8879116694132487, '_timestamp': 1721915154.9607964}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.19019047915935516, '_timestamp': 1721915154.9608967}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.34719833731651306, '_timestamp': 1721915154.9611628}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'ratio': 1.0027692317962646, '_timestamp': 1721915154.9612668}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915154.9614034}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915154.9614995}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'Episode_Time': 82.9864330291748, '_timestamp': 1721915154.9615557}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915154.962259}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915154.9627867}).
wandb: WARNING (User provided step: 5649 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915154.9633448}).
Env Football Algo jrpo Exp base_JRPO updates 3802/100000000000.0 steps in 66.72
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'value_loss': 0.4841550373503317, '_timestamp': 1721915221.6811087}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'policy_loss': -0.010219809698076763, '_timestamp': 1721915221.6812644}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.888234713872274, '_timestamp': 1721915221.6813328}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.34819135069847107, '_timestamp': 1721915221.6814246}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.4574772119522095, '_timestamp': 1721915221.681654}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'ratio': 1.003688931465149, '_timestamp': 1721915221.6817555}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721915221.6818871}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915221.681975}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'Episode_Time': 66.71706485748291, '_timestamp': 1721915221.6820338}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915221.6826227}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915221.683034}).
wandb: WARNING (User provided step: 3802 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915221.6834555}).
total episode rewards is -80.0
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'value_loss': 0.9780824248492718, '_timestamp': 1721915258.1996017}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'policy_loss': -0.004418099441336381, '_timestamp': 1721915258.199764}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.886169974009196, '_timestamp': 1721915258.1998386}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.5161156058311462, '_timestamp': 1721915258.199936}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 2.5670299530029297, '_timestamp': 1721915258.2001784}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'ratio': 1.0068933963775635, '_timestamp': 1721915258.200284}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721915258.200423}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915258.2005217}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'Episode_Time': 36.51541996002197, '_timestamp': 1721915258.2005837}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.12148760330578512, '_timestamp': 1721915258.200914}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'train_goal': 0.43925619834710744, '_timestamp': 1721915258.201124}).
wandb: WARNING (User provided step: 2955 is less than current step: 10652. Dropping entry: {'train_WDL': -0.12148760330578512, '_timestamp': 1721915258.2013268}).
Env Football Algo jrpo Exp base_JRPO updates 2955/100000000000.0 steps in 36.52
total episode rewards is -160.0
Env Football Algo jrpo Exp base_JRPO updates 7524/100000000000.0 steps in 87.42
total episode rewards is -30.0
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'value_loss': 0.17215498949633912, '_timestamp': 1721915345.6218936}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'policy_loss': -0.013513073381618597, '_timestamp': 1721915345.622053}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.886288129488627, '_timestamp': 1721915345.6221197}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.19728244841098785, '_timestamp': 1721915345.6222134}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.24808457493782043, '_timestamp': 1721915345.6224473}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'ratio': 1.0028188228607178, '_timestamp': 1721915345.6225474}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721915345.6226778}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915345.6227672}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'Episode_Time': 87.41966080665588, '_timestamp': 1721915345.622825}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915345.6234252}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915345.6238787}).
wandb: WARNING (User provided step: 7524 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915345.6243832}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'value_loss': 0.4382549896991501, '_timestamp': 1721915385.2001193}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'policy_loss': -0.013380659849693378, '_timestamp': 1721915385.2002938}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.888626427650452, '_timestamp': 1721915385.2003734}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.3386051654815674, '_timestamp': 1721915385.2004817}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.9236412644386292, '_timestamp': 1721915385.200747}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'ratio': 1.0067553520202637, '_timestamp': 1721915385.2008705}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721915385.2010102}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915385.201102}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'Episode_Time': 39.57501578330994, '_timestamp': 1721915385.2012358}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915385.2015605}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915385.2017958}).
wandb: WARNING (User provided step: 2863 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915385.2020342}).
Env Football Algo jrpo Exp base_JRPO updates 2863/100000000000.0 steps in 39.58
total episode rewards is -80.0
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'value_loss': 0.2549534646980465, '_timestamp': 1721915471.4961774}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'policy_loss': -0.01520594077417627, '_timestamp': 1721915471.496385}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8890981690088906, '_timestamp': 1721915471.4964564}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.2246709167957306, '_timestamp': 1721915471.496643}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.18868811428546906, '_timestamp': 1721915471.4972286}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'ratio': 1.0019539594650269, '_timestamp': 1721915471.4973562}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915471.4975176}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915471.497628}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'Episode_Time': 86.29305005073547, '_timestamp': 1721915471.4976969}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915471.4988344}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915471.499403}).
wandb: WARNING (User provided step: 5170 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915471.5000062}).
Env Football Algo jrpo Exp base_JRPO updates 5170/100000000000.0 steps in 86.29
total episode rewards is -40.0
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'value_loss': 0.4424491037117938, '_timestamp': 1721915543.4821577}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'policy_loss': -0.012075998217333107, '_timestamp': 1721915543.482335}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.88866761525472, '_timestamp': 1721915543.4824166}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.40905165672302246, '_timestamp': 1721915543.4825213}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.7882463932037354, '_timestamp': 1721915543.4827788}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'ratio': 1.0061450004577637, '_timestamp': 1721915543.4828882}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721915543.4830267}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915543.4831216}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'Episode_Time': 71.98133444786072, '_timestamp': 1721915543.483393}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915543.4838438}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915543.4842067}).
wandb: WARNING (User provided step: 4976 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915543.4845624}).
Env Football Algo jrpo Exp base_JRPO updates 4976/100000000000.0 steps in 71.98
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 4973/100000000000.0 steps in 78.82
total episode rewards is -20.0
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'value_loss': 0.2699196805812729, '_timestamp': 1721915622.3060403}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'policy_loss': -0.0064961446131928825, '_timestamp': 1721915622.3061972}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.884233667055766, '_timestamp': 1721915622.3062644}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.23515605926513672, '_timestamp': 1721915622.3063564}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.32454484701156616, '_timestamp': 1721915622.3065524}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'ratio': 0.9997383952140808, '_timestamp': 1721915622.3066568}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721915622.3067856}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915622.3068762}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'Episode_Time': 78.820796251297, '_timestamp': 1721915622.3069353}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.4044080981350354, '_timestamp': 1721915622.307688}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'train_goal': 0.2977959509324823, '_timestamp': 1721915622.3082778}).
wandb: WARNING (User provided step: 4973 is less than current step: 10652. Dropping entry: {'train_WDL': -0.4044080981350354, '_timestamp': 1721915622.3090684}).
Env Football Algo jrpo Exp base_JRPO updates 3910/100000000000.0 steps in 79.69
total episode rewards is -50.0
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'value_loss': 0.42022430764511226, '_timestamp': 1721915702.0004706}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'policy_loss': -0.012022528266340184, '_timestamp': 1721915702.0006945}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.879954277674357, '_timestamp': 1721915702.000768}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.3119705319404602, '_timestamp': 1721915702.0008655}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.7782813906669617, '_timestamp': 1721915702.001209}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'ratio': 1.0018724203109741, '_timestamp': 1721915702.0013154}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721915702.0014567}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915702.001554}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'Episode_Time': 79.69042825698853, '_timestamp': 1721915702.0016136}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.4185696361355082, '_timestamp': 1721915702.0027328}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'train_goal': 0.29071518193224594, '_timestamp': 1721915702.0032253}).
wandb: WARNING (User provided step: 3910 is less than current step: 10652. Dropping entry: {'train_WDL': -0.4185696361355082, '_timestamp': 1721915702.003712}).
Env Football Algo jrpo Exp base_JRPO updates 3134/100000000000.0 steps in 33.49
total episode rewards is -90.0
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'value_loss': 0.7025666840809087, '_timestamp': 1721915735.497418}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'policy_loss': -0.008562661335260296, '_timestamp': 1721915735.4975767}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8839468145370484, '_timestamp': 1721915735.49765}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.4121350049972534, '_timestamp': 1721915735.4977431}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.8849328756332397, '_timestamp': 1721915735.4979863}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'ratio': 1.0020931959152222, '_timestamp': 1721915735.4980907}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721915735.4982247}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915735.4983156}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'Episode_Time': 33.49289870262146, '_timestamp': 1721915735.498375}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.057904411764705885, '_timestamp': 1721915735.4987884}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'train_goal': 0.4710477941176471, '_timestamp': 1721915735.4989936}).
wandb: WARNING (User provided step: 3134 is less than current step: 10652. Dropping entry: {'train_WDL': -0.057904411764705885, '_timestamp': 1721915735.4991844}).
Env Football Algo jrpo Exp base_JRPO updates 5933/100000000000.0 steps in 88.29
total episode rewards is -40.0
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'value_loss': 0.2579766901675612, '_timestamp': 1721915823.788032}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'policy_loss': -0.0036481134504235038, '_timestamp': 1721915823.788194}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.886814592679342, '_timestamp': 1721915823.7882633}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.229872927069664, '_timestamp': 1721915823.7883596}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.43138545751571655, '_timestamp': 1721915823.7886016}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'ratio': 0.9993248581886292, '_timestamp': 1721915823.788709}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915823.7888446}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915823.7889376}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'Episode_Time': 88.2881371974945, '_timestamp': 1721915823.7891462}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915823.790146}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915823.7910128}).
wandb: WARNING (User provided step: 5933 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915823.7915642}).
Env Football Algo jrpo Exp base_JRPO updates 4080/100000000000.0 steps in 70.87
total episode rewards is -40.0
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'value_loss': 0.3634027370500068, '_timestamp': 1721915894.6604955}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'policy_loss': -0.009998319509904832, '_timestamp': 1721915894.6606753}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8901969734827677, '_timestamp': 1721915894.6607435}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.2899776101112366, '_timestamp': 1721915894.6608455}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.5775899887084961, '_timestamp': 1721915894.6610956}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'ratio': 1.000624418258667, '_timestamp': 1721915894.6612005}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915894.6613393}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915894.661438}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'Episode_Time': 70.8680248260498, '_timestamp': 1721915894.661497}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.4165998855180309, '_timestamp': 1721915894.662307}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'train_goal': 0.2917000572409845, '_timestamp': 1721915894.662821}).
wandb: WARNING (User provided step: 4080 is less than current step: 10652. Dropping entry: {'train_WDL': -0.4165998855180309, '_timestamp': 1721915894.6633494}).
Env Football Algo jrpo Exp base_JRPO updates 4188/100000000000.0 steps in 87.03
total episode rewards is 0.0
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'value_loss': 0.25640071178631235, '_timestamp': 1721915981.6911478}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007739913481576271, '_timestamp': 1721915981.6913078}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8854142649968466, '_timestamp': 1721915981.691378}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.226501926779747, '_timestamp': 1721915981.6914735}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.3796965479850769, '_timestamp': 1721915981.6916945}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'ratio': 0.9956979751586914, '_timestamp': 1721915981.6917975}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721915981.6919303}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915981.6920319}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'Episode_Time': 87.02703905105591, '_timestamp': 1721915981.6920896}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'train_goal_diff': 0.08823529411764706, '_timestamp': 1721915981.692897}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'train_goal': 0.5441176470588235, '_timestamp': 1721915981.6935096}).
wandb: WARNING (User provided step: 4188 is less than current step: 10652. Dropping entry: {'train_WDL': 0.08823529411764706, '_timestamp': 1721915981.6941273}).
Env Football Algo jrpo Exp base_JRPO updates 4399/100000000000.0 steps in 72.19
total episode rewards is -50.0
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'value_loss': 0.42189774035631367, '_timestamp': 1721916053.8878496}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'policy_loss': -0.012849619404684442, '_timestamp': 1721916053.8882365}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.880025788942973, '_timestamp': 1721916053.8883407}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.25639674067497253, '_timestamp': 1721916053.8884656}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.0248432159423828, '_timestamp': 1721916053.889051}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'ratio': 1.0015865564346313, '_timestamp': 1721916053.8891876}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721916053.88961}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916053.889749}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'Episode_Time': 72.19232034683228, '_timestamp': 1721916053.889817}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.27487795719113783, '_timestamp': 1721916053.8909454}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'train_goal': 0.3625610214044311, '_timestamp': 1721916053.8914254}).
wandb: WARNING (User provided step: 4399 is less than current step: 10652. Dropping entry: {'train_WDL': -0.27487795719113783, '_timestamp': 1721916053.8918881}).
Env Football Algo jrpo Exp base_JRPO updates 3974/100000000000.0 steps in 40.60
total episode rewards is -130.0
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'value_loss': 0.7839004601041476, '_timestamp': 1721916094.5004456}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'policy_loss': -0.008260723116109148, '_timestamp': 1721916094.5014024}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8819395399093626, '_timestamp': 1721916094.5014777}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.4311889708042145, '_timestamp': 1721916094.5019083}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.7487127780914307, '_timestamp': 1721916094.5022247}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'ratio': 1.0014400482177734, '_timestamp': 1721916094.5023322}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721916094.5024786}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916094.5029852}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'Episode_Time': 40.60340237617493, '_timestamp': 1721916094.5030453}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916094.5037508}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916094.5039735}).
wandb: WARNING (User provided step: 3974 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916094.5041683}).
Env Football Algo jrpo Exp base_JRPO updates 8205/100000000000.0 steps in 93.51
total episode rewards is -40.0
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'value_loss': 0.29742127857015777, '_timestamp': 1721916188.0107746}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'policy_loss': -0.003082179087990274, '_timestamp': 1721916188.0109525}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8856370385487873, '_timestamp': 1721916188.0110247}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.21681992709636688, '_timestamp': 1721916188.0111294}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.373748242855072, '_timestamp': 1721916188.011391}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'ratio': 1.0029597282409668, '_timestamp': 1721916188.0114963}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916188.0116346}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916188.011741}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'Episode_Time': 93.50573682785034, '_timestamp': 1721916188.0121586}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916188.012705}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916188.013139}).
wandb: WARNING (User provided step: 8205 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916188.0135949}).
Env Football Algo jrpo Exp base_JRPO updates 8188/100000000000.0 steps in 86.30
total episode rewards is -40.0
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'value_loss': 0.2471220459928736, '_timestamp': 1721916274.312656}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'policy_loss': -0.011862773045431823, '_timestamp': 1721916274.3128233}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8885906648635866, '_timestamp': 1721916274.3128915}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.21891891956329346, '_timestamp': 1721916274.3131263}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.3179829716682434, '_timestamp': 1721916274.3133972}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'ratio': 0.9979153871536255, '_timestamp': 1721916274.3135023}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916274.313643}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916274.3137405}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'Episode_Time': 86.29805850982666, '_timestamp': 1721916274.313799}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916274.314467}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916274.314894}).
wandb: WARNING (User provided step: 8188 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916274.3153253}).
Env Football Algo jrpo Exp base_JRPO updates 3853/100000000000.0 steps in 57.71
total episode rewards is -40.0
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'value_loss': 0.5718068903063734, '_timestamp': 1721916332.0262063}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'policy_loss': -0.010258234387244254, '_timestamp': 1721916332.026511}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8866628885269163, '_timestamp': 1721916332.0265923}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.34015998244285583, '_timestamp': 1721916332.0266955}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.2158738374710083, '_timestamp': 1721916332.026958}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'ratio': 1.0060131549835205, '_timestamp': 1721916332.027072}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916332.0273237}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916332.0274227}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'Episode_Time': 57.70979881286621, '_timestamp': 1721916332.0278106}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.3073959938366718, '_timestamp': 1721916332.0287387}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'train_goal': 0.3463020030816641, '_timestamp': 1721916332.029101}).
wandb: WARNING (User provided step: 3853 is less than current step: 10652. Dropping entry: {'train_WDL': -0.3073959938366718, '_timestamp': 1721916332.0294554}).
Env Football Algo jrpo Exp base_JRPO updates 4158/100000000000.0 steps in 55.65
total episode rewards is -50.0
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'value_loss': 0.3938398458637918, '_timestamp': 1721916387.6860876}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007693005473508189, '_timestamp': 1721916387.6873565}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8880061674118043, '_timestamp': 1721916387.6874297}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.228313148021698, '_timestamp': 1721916387.6881044}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.9130571484565735, '_timestamp': 1721916387.6884232}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'ratio': 1.003232479095459, '_timestamp': 1721916387.6885276}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721916387.6886775}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916387.6888695}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'Episode_Time': 55.65051770210266, '_timestamp': 1721916387.6892493}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.23455664463186687, '_timestamp': 1721916387.6902895}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'train_goal': 0.38272167768406656, '_timestamp': 1721916387.690629}).
wandb: WARNING (User provided step: 4158 is less than current step: 10652. Dropping entry: {'train_WDL': -0.23455664463186687, '_timestamp': 1721916387.6909645}).
Env Football Algo jrpo Exp base_JRPO updates 6957/100000000000.0 steps in 74.01
total episode rewards is -70.0
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'value_loss': 0.6175339603920778, '_timestamp': 1721916461.7048979}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'policy_loss': -0.009782330411641548, '_timestamp': 1721916461.7050495}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.883730525970459, '_timestamp': 1721916461.7051156}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.34997525811195374, '_timestamp': 1721916461.7052104}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.0659615993499756, '_timestamp': 1721916461.7054436}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'ratio': 1.0060386657714844, '_timestamp': 1721916461.705549}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721916461.705667}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916461.7058284}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'Episode_Time': 74.01321792602539, '_timestamp': 1721916461.7058887}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'train_goal_diff': 0.06718408925539655, '_timestamp': 1721916461.7063303}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'train_goal': 0.5335920446276983, '_timestamp': 1721916461.7066147}).
wandb: WARNING (User provided step: 6957 is less than current step: 10652. Dropping entry: {'train_WDL': 0.06718408925539655, '_timestamp': 1721916461.7069018}).
Env Football Algo jrpo Exp base_JRPO updates 3180/100000000000.0 steps in 48.37
total episode rewards is -70.0
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'value_loss': 0.7886781683688362, '_timestamp': 1721916510.0799828}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'policy_loss': -0.008295515335521485, '_timestamp': 1721916510.0801332}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8796450662612916, '_timestamp': 1721916510.0801992}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.43136754631996155, '_timestamp': 1721916510.0802937}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.8650636672973633, '_timestamp': 1721916510.08053}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'ratio': 1.004303216934204, '_timestamp': 1721916510.0806305}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721916510.0807629}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916510.080855}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'Episode_Time': 48.37234306335449, '_timestamp': 1721916510.0809126}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'train_goal_diff': 0.35426621160409555, '_timestamp': 1721916510.0814867}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'train_goal': 0.6771331058020478, '_timestamp': 1721916510.081783}).
wandb: WARNING (User provided step: 3180 is less than current step: 10652. Dropping entry: {'train_WDL': 0.35426621160409555, '_timestamp': 1721916510.0820785}).
Env Football Algo jrpo Exp base_JRPO updates 5359/100000000000.0 steps in 69.47
total episode rewards is -60.0
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'value_loss': 0.42124776015679044, '_timestamp': 1721916579.5561385}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'policy_loss': -0.008320706102531404, '_timestamp': 1721916579.5562956}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8663627672195435, '_timestamp': 1721916579.5563622}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.28883033990859985, '_timestamp': 1721916579.5564528}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.023328423500061, '_timestamp': 1721916579.5566816}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'ratio': 1.0006816387176514, '_timestamp': 1721916579.5567834}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721916579.5569901}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916579.5570798}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'Episode_Time': 69.47334790229797, '_timestamp': 1721916579.5571365}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.2559125754363073, '_timestamp': 1721916579.557624}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'train_goal': 0.37204371228184635, '_timestamp': 1721916579.5580084}).
wandb: WARNING (User provided step: 5359 is less than current step: 10652. Dropping entry: {'train_WDL': -0.2559125754363073, '_timestamp': 1721916579.5583963}).
Env Football Algo jrpo Exp base_JRPO updates 5438/100000000000.0 steps in 83.82
total episode rewards is -20.0
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'value_loss': 0.252630671877414, '_timestamp': 1721916663.3822503}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'policy_loss': -0.011133661764518668, '_timestamp': 1721916663.382411}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8832232777277627, '_timestamp': 1721916663.3824754}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.19487738609313965, '_timestamp': 1721916663.3825703}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.4106968641281128, '_timestamp': 1721916663.3827982}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'ratio': 0.9988129734992981, '_timestamp': 1721916663.3828983}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721916663.3830333}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916663.3832228}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'Episode_Time': 83.82309341430664, '_timestamp': 1721916663.3832815}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.37502614515791677, '_timestamp': 1721916663.3840218}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'train_goal': 0.3124869274210416, '_timestamp': 1721916663.384571}).
wandb: WARNING (User provided step: 5438 is less than current step: 10652. Dropping entry: {'train_WDL': -0.37502614515791677, '_timestamp': 1721916663.3851347}).
Env Football Algo jrpo Exp base_JRPO updates 3211/100000000000.0 steps in 64.39
total episode rewards is -40.0
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'value_loss': 0.4632295599517723, '_timestamp': 1721916727.7754407}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'policy_loss': -0.012273976403909426, '_timestamp': 1721916727.7755938}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8795375696818035, '_timestamp': 1721916727.7756617}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.3066367208957672, '_timestamp': 1721916727.7757554}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.9082006812095642, '_timestamp': 1721916727.7760196}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'ratio': 1.000811219215393, '_timestamp': 1721916727.7761269}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916727.776247}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916727.7764661}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'Episode_Time': 64.38955664634705, '_timestamp': 1721916727.7765226}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'train_goal_diff': 0.15594995635728834, '_timestamp': 1721916727.7770882}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'train_goal': 0.5779749781786442, '_timestamp': 1721916727.7775004}).
wandb: WARNING (User provided step: 3211 is less than current step: 10652. Dropping entry: {'train_WDL': 0.15594995635728834, '_timestamp': 1721916727.7779198}).
Env Football Algo jrpo Exp base_JRPO updates 3995/100000000000.0 steps in 37.61
total episode rewards is -80.0
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'value_loss': 0.6425502847507596, '_timestamp': 1721916765.3892894}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'policy_loss': -0.011574581879540347, '_timestamp': 1721916765.3894348}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8776194794972736, '_timestamp': 1721916765.389502}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.33720529079437256, '_timestamp': 1721916765.3895912}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.3878408670425415, '_timestamp': 1721916765.389822}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'ratio': 1.0015954971313477, '_timestamp': 1721916765.3899941}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721916765.3901281}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916765.3902135}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'Episode_Time': 37.610698223114014, '_timestamp': 1721916765.3902705}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916765.3904757}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916765.3906107}).
wandb: WARNING (User provided step: 3995 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916765.3907406}).
Env Football Algo jrpo Exp base_JRPO updates 7164/100000000000.0 steps in 85.10
total episode rewards is -40.0
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'value_loss': 0.25245240205277997, '_timestamp': 1721916850.4961753}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'policy_loss': -0.015796257097196453, '_timestamp': 1721916850.496331}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8742485094070434, '_timestamp': 1721916850.496408}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.19867052137851715, '_timestamp': 1721916850.4965012}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.3392173647880554, '_timestamp': 1721916850.4967413}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'ratio': 0.9966414570808411, '_timestamp': 1721916850.4968412}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916850.4969754}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916850.4970658}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'Episode_Time': 85.10475659370422, '_timestamp': 1721916850.4973135}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916850.4979284}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916850.4983947}).
wandb: WARNING (User provided step: 7164 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916850.4988778}).
Env Football Algo jrpo Exp base_JRPO updates 7475/100000000000.0 steps in 82.40
total episode rewards is -20.0
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'value_loss': 0.2598294880799949, '_timestamp': 1721916932.9019806}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'policy_loss': -0.015122285917119976, '_timestamp': 1721916932.902142}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8642916965484617, '_timestamp': 1721916932.9022095}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.21415813267230988, '_timestamp': 1721916932.9023056}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.41517651081085205, '_timestamp': 1721916932.9025233}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'ratio': 0.997774064540863, '_timestamp': 1721916932.902624}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721916932.9028487}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916932.9029412}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'Episode_Time': 82.40231466293335, '_timestamp': 1721916932.9029994}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.20691029900332225, '_timestamp': 1721916932.9035692}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'train_goal': 0.3965448504983389, '_timestamp': 1721916932.904054}).
wandb: WARNING (User provided step: 7475 is less than current step: 10652. Dropping entry: {'train_WDL': -0.20691029900332225, '_timestamp': 1721916932.9045208}).
Env Football Algo jrpo Exp base_JRPO updates 6679/100000000000.0 steps in 66.94
total episode rewards is -90.0
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'value_loss': 0.529165826489528, '_timestamp': 1721916999.8488197}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'policy_loss': -0.014835166058862039, '_timestamp': 1721916999.8489723}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.858364545504252, '_timestamp': 1721916999.84904}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.331599622964859, '_timestamp': 1721916999.8491333}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.8812116980552673, '_timestamp': 1721916999.849365}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'ratio': 1.0057860612869263, '_timestamp': 1721916999.8494668}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721916999.8496022}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916999.8496907}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'Episode_Time': 66.94358277320862, '_timestamp': 1721916999.84982}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916999.8501804}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916999.8504477}).
wandb: WARNING (User provided step: 6679 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916999.850724}).
Env Football Algo jrpo Exp base_JRPO updates 6212/100000000000.0 steps in 79.36
total episode rewards is -40.0
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'value_loss': 0.268202538844198, '_timestamp': 1721917079.2083762}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'policy_loss': -0.00681520225169758, '_timestamp': 1721917079.2085297}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8545120684305827, '_timestamp': 1721917079.208597}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.20888514816761017, '_timestamp': 1721917079.2086873}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.21710291504859924, '_timestamp': 1721917079.208937}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'ratio': 1.0013564825057983, '_timestamp': 1721917079.2090392}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917079.2094646}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917079.2095578}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'Episode_Time': 79.35693573951721, '_timestamp': 1721917079.2096157}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917079.2102516}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917079.2107646}).
wandb: WARNING (User provided step: 6212 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917079.2112966}).
Env Football Algo jrpo Exp base_JRPO updates 6835/100000000000.0 steps in 92.85
total episode rewards is -20.0
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'value_loss': 0.25443356117544075, '_timestamp': 1721917172.0619457}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'policy_loss': -0.011240261900238692, '_timestamp': 1721917172.0621223}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.845536060333252, '_timestamp': 1721917172.062189}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.17210392653942108, '_timestamp': 1721917172.0622935}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.28952786326408386, '_timestamp': 1721917172.0625544}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'ratio': 0.9812198877334595, '_timestamp': 1721917172.0626585}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721917172.062797}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917172.0629883}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'Episode_Time': 92.84979343414307, '_timestamp': 1721917172.063047}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.2685854255970606, '_timestamp': 1721917172.063755}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'train_goal': 0.36570728720146967, '_timestamp': 1721917172.0642662}).
wandb: WARNING (User provided step: 6835 is less than current step: 10652. Dropping entry: {'train_WDL': -0.2685854255970606, '_timestamp': 1721917172.0647721}).
Env Football Algo jrpo Exp base_JRPO updates 5045/100000000000.0 steps in 88.01
total episode rewards is -40.0
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'value_loss': 0.27481513227025667, '_timestamp': 1721917260.0738516}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'policy_loss': -0.007280896431184374, '_timestamp': 1721917260.074009}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8378087107340493, '_timestamp': 1721917260.0740762}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.14805012941360474, '_timestamp': 1721917260.0741713}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.32445451617240906, '_timestamp': 1721917260.0744104}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'ratio': 0.9797261953353882, '_timestamp': 1721917260.0745099}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917260.074627}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917260.0747159}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'Episode_Time': 88.0082471370697, '_timestamp': 1721917260.0747745}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917260.0754595}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917260.0760543}).
wandb: WARNING (User provided step: 5045 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917260.0825958}).
Env Football Algo jrpo Exp base_JRPO updates 9537/100000000000.0 steps in 83.92
total episode rewards is -40.0
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'value_loss': 0.23875981436421473, '_timestamp': 1721917344.0030153}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'policy_loss': 0.012128501141754289, '_timestamp': 1721917344.0031812}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8359891096750895, '_timestamp': 1721917344.0032601}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.23057620227336884, '_timestamp': 1721917344.0033634}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 0.376727432012558, '_timestamp': 1721917344.0036154}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'ratio': 0.9964405298233032, '_timestamp': 1721917344.0037284}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917344.003863}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917344.0041027}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'Episode_Time': 83.919508934021, '_timestamp': 1721917344.0041664}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917344.0046287}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917344.004981}).
wandb: WARNING (User provided step: 9537 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917344.0053601}).
Env Football Algo jrpo Exp base_JRPO updates 2901/100000000000.0 steps in 59.21
total episode rewards is -80.0
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'value_loss': 0.5931679923956593, '_timestamp': 1721917403.2137182}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'policy_loss': -0.0061830961590749215, '_timestamp': 1721917403.2139432}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8333110364278156, '_timestamp': 1721917403.2140768}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.3192715346813202, '_timestamp': 1721917403.214248}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.0038275718688965, '_timestamp': 1721917403.2145882}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'ratio': 0.9986904859542847, '_timestamp': 1721917403.2147586}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721917403.2153232}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917403.2154872}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'Episode_Time': 59.206891775131226, '_timestamp': 1721917403.2156055}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.37167343256653135, '_timestamp': 1721917403.2162845}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'train_goal': 0.3141632837167343, '_timestamp': 1721917403.2167344}).
wandb: WARNING (User provided step: 2901 is less than current step: 10652. Dropping entry: {'train_WDL': -0.37167343256653135, '_timestamp': 1721917403.217216}).
Env Football Algo jrpo Exp base_JRPO updates 5948/100000000000.0 steps in 58.45
total episode rewards is -70.0
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'value_loss': 0.532085410815974, '_timestamp': 1721917461.6636767}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'policy_loss': -0.010655762897804379, '_timestamp': 1721917461.663832}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.8337060022354126, '_timestamp': 1721917461.6638987}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.35690775513648987, '_timestamp': 1721917461.6652808}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.061837911605835, '_timestamp': 1721917461.6655073}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'ratio': 1.0019370317459106, '_timestamp': 1721917461.665607}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721917461.6657383}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917461.6658258}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'Episode_Time': 58.44553756713867, '_timestamp': 1721917461.66601}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'train_goal_diff': -0.13642756680731363, '_timestamp': 1721917461.6665025}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'train_goal': 0.4317862165963432, '_timestamp': 1721917461.666848}).
wandb: WARNING (User provided step: 5948 is less than current step: 10652. Dropping entry: {'train_WDL': -0.13642756680731363, '_timestamp': 1721917461.6671898}).
Env Football Algo jrpo Exp base_JRPO updates 7426/100000000000.0 steps in 82.84
total episode rewards is -70.0
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'value_loss': 0.39154379699379205, '_timestamp': 1721917544.5086393}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'policy_loss': -0.010655003464392698, '_timestamp': 1721917544.5087867}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'dist_entropy': 2.833174500465393, '_timestamp': 1721917544.5088503}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'actor_grad_norm': 0.2729049623012543, '_timestamp': 1721917544.5089383}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'critic_grad_norm': 1.078852653503418, '_timestamp': 1721917544.5091617}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'ratio': 0.9985218644142151, '_timestamp': 1721917544.50926}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721917544.5094593}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917544.5095465}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'Episode_Time': 82.84080982208252, '_timestamp': 1721917544.509604}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917544.5100486}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917544.5104127}).
wandb: WARNING (User provided step: 7426 is less than current step: 10652. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917544.5107865}).
Env Football Algo jrpo Exp base_JRPO updates 10854/100000000000.0 steps in 80.22
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8185/100000000000.0 steps in 79.37
total episode rewards is -60.0
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'value_loss': 0.34439578612645466, '_timestamp': 1721917704.096917}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'policy_loss': -0.01424186060942399, '_timestamp': 1721917704.097318}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8340629720687867, '_timestamp': 1721917704.0975358}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.25871139764785767, '_timestamp': 1721917704.0977707}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.41427499055862427, '_timestamp': 1721917704.0981798}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'ratio': 1.0047439336776733, '_timestamp': 1721917704.0984364}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721917704.0986977}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917704.0994475}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'Episode_Time': 79.36637783050537, '_timestamp': 1721917704.0996127}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917704.100274}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917704.1007037}).
wandb: WARNING (User provided step: 8185 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917704.1011033}).
Env Football Algo jrpo Exp base_JRPO updates 7376/100000000000.0 steps in 84.68
total episode rewards is -20.0
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'value_loss': 0.23004487692688902, '_timestamp': 1721917788.7812574}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'policy_loss': -0.012408663352640967, '_timestamp': 1721917788.781412}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8234550285339357, '_timestamp': 1721917788.7814765}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.21388481557369232, '_timestamp': 1721917788.781569}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.5595139265060425, '_timestamp': 1721917788.7817903}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'ratio': 1.0018105506896973, '_timestamp': 1721917788.781889}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721917788.7820199}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917788.782108}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'Episode_Time': 84.67920660972595, '_timestamp': 1721917788.7821662}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.2166841552990556, '_timestamp': 1721917788.7828736}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'train_goal': 0.3916579223504722, '_timestamp': 1721917788.7833328}).
wandb: WARNING (User provided step: 7376 is less than current step: 10854. Dropping entry: {'train_WDL': -0.2166841552990556, '_timestamp': 1721917788.7838008}).
Env Football Algo jrpo Exp base_JRPO updates 6444/100000000000.0 steps in 85.57
total episode rewards is -40.0
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'value_loss': 0.24238600215447756, '_timestamp': 1721917874.3591735}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'policy_loss': -0.008776946362534848, '_timestamp': 1721917874.3593447}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.826255470911662, '_timestamp': 1721917874.3594117}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.15472114086151123, '_timestamp': 1721917874.359512}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.1942967027425766, '_timestamp': 1721917874.3597703}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'ratio': 1.006180763244629, '_timestamp': 1721917874.359876}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917874.3600233}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917874.360269}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'Episode_Time': 85.57437205314636, '_timestamp': 1721917874.360327}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917874.361019}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917874.361553}).
wandb: WARNING (User provided step: 6444 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917874.3620827}).
Env Football Algo jrpo Exp base_JRPO updates 4931/100000000000.0 steps in 55.78
total episode rewards is -80.0
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'value_loss': 0.4689102231649061, '_timestamp': 1721917930.1401846}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'policy_loss': -0.00906178292617066, '_timestamp': 1721917930.1403384}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.828837095896403, '_timestamp': 1721917930.1404045}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.29967474937438965, '_timestamp': 1721917930.1404955}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.248884677886963, '_timestamp': 1721917930.1407259}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'ratio': 1.0086700916290283, '_timestamp': 1721917930.1408246}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721917930.1409538}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917930.1410427}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'Episode_Time': 55.777304887771606, '_timestamp': 1721917930.1410992}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917930.1415443}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917930.1418033}).
wandb: WARNING (User provided step: 4931 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917930.1420608}).
Env Football Algo jrpo Exp base_JRPO updates 7328/100000000000.0 steps in 80.57
total episode rewards is -10.0
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'value_loss': 0.17672685911975955, '_timestamp': 1721918010.709119}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'policy_loss': -0.010334664224307441, '_timestamp': 1721918010.7092762}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.840833903948466, '_timestamp': 1721918010.709343}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.17069147527217865, '_timestamp': 1721918010.7094352}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.7334327101707458, '_timestamp': 1721918010.7096643}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'ratio': 0.9996739029884338, '_timestamp': 1721918010.7097707}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721918010.7098944}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918010.7101474}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'Episode_Time': 80.56633281707764, '_timestamp': 1721918010.7102063}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.22393117831074036, '_timestamp': 1721918010.7107992}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'train_goal': 0.3880344108446298, '_timestamp': 1721918010.7112648}).
wandb: WARNING (User provided step: 7328 is less than current step: 10854. Dropping entry: {'train_WDL': -0.22393117831074036, '_timestamp': 1721918010.711732}).
Env Football Algo jrpo Exp base_JRPO updates 8399/100000000000.0 steps in 89.24
total episode rewards is -30.0
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'value_loss': 0.20896062530572332, '_timestamp': 1721918099.9563646}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'policy_loss': -0.013315880253309539, '_timestamp': 1721918099.9565196}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.845420219103495, '_timestamp': 1721918099.9565866}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.1524631381034851, '_timestamp': 1721918099.956682}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.3811618387699127, '_timestamp': 1721918099.9569306}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'ratio': 1.0017024278640747, '_timestamp': 1721918099.9570346}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721918099.957169}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918099.9572608}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'Episode_Time': 89.24384808540344, '_timestamp': 1721918099.9573212}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918099.9580905}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918099.9585035}).
wandb: WARNING (User provided step: 8399 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918099.958928}).
Env Football Algo jrpo Exp base_JRPO updates 9253/100000000000.0 steps in 82.15
total episode rewards is -40.0
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'value_loss': 0.22323209936696609, '_timestamp': 1721918182.106089}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'policy_loss': -0.014191423023197178, '_timestamp': 1721918182.1062782}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.845845112800598, '_timestamp': 1721918182.1063478}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.1591271311044693, '_timestamp': 1721918182.1064563}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.384286493062973, '_timestamp': 1721918182.106733}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'ratio': 0.9994108080863953, '_timestamp': 1721918182.106839}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721918182.1069849}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918182.1073246}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'Episode_Time': 82.14610433578491, '_timestamp': 1721918182.107385}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918182.1082163}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918182.108614}).
wandb: WARNING (User provided step: 9253 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918182.1090112}).
Env Football Algo jrpo Exp base_JRPO updates 3107/100000000000.0 steps in 51.44
total episode rewards is -70.0
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'value_loss': 0.4169122182174275, '_timestamp': 1721918233.552208}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'policy_loss': -0.015221521020284854, '_timestamp': 1721918233.5535235}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8438150389989216, '_timestamp': 1721918233.5536}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.2583548426628113, '_timestamp': 1721918233.5542088}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.0944228172302246, '_timestamp': 1721918233.5545876}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'ratio': 1.0026923418045044, '_timestamp': 1721918233.5546973}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721918233.5548441}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918233.5550473}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'Episode_Time': 51.43692898750305, '_timestamp': 1721918233.555115}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918233.5569932}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918233.5573096}).
wandb: WARNING (User provided step: 3107 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918233.557635}).
Env Football Algo jrpo Exp base_JRPO updates 10372/100000000000.0 steps in 81.47
total episode rewards is -10.0
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'value_loss': 0.1699455677822698, '_timestamp': 1721918315.0260036}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'policy_loss': -0.006228099018335343, '_timestamp': 1721918315.026177}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8525308640797933, '_timestamp': 1721918315.0262418}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.17803147435188293, '_timestamp': 1721918315.0263362}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.5460591912269592, '_timestamp': 1721918315.0265546}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'ratio': 1.0008745193481445, '_timestamp': 1721918315.0266526}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721918315.0267792}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918315.0268674}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'Episode_Time': 81.46755027770996, '_timestamp': 1721918315.0270166}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'train_goal_diff': 0.287381158167675, '_timestamp': 1721918315.0275166}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'train_goal': 0.6436905790838375, '_timestamp': 1721918315.02784}).
wandb: WARNING (User provided step: 10372 is less than current step: 10854. Dropping entry: {'train_WDL': 0.287381158167675, '_timestamp': 1721918315.0281606}).
Env Football Algo jrpo Exp base_JRPO updates 3150/100000000000.0 steps in 95.58
total episode rewards is 40.0
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'value_loss': 0.32016463556016483, '_timestamp': 1721918410.6117442}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'policy_loss': -0.010780487296481928, '_timestamp': 1721918410.6127615}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8500614595413207, '_timestamp': 1721918410.6128352}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.25709450244903564, '_timestamp': 1721918410.6133301}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.2767525613307953, '_timestamp': 1721918410.6136699}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'ratio': 0.99737948179245, '_timestamp': 1721918410.6137736}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'total_episode_rewards': 40.0, '_timestamp': 1721918410.6139174}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918410.6140895}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'Episode_Time': 95.57905673980713, '_timestamp': 1721918410.6141508}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721918410.61643}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721918410.6170921}).
wandb: WARNING (User provided step: 3150 is less than current step: 10854. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721918410.6177433}).
Env Football Algo jrpo Exp base_JRPO updates 7286/100000000000.0 steps in 56.81
total episode rewards is -100.0
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'value_loss': 0.6607061428949237, '_timestamp': 1721918467.4317887}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'policy_loss': -0.0037231181412547207, '_timestamp': 1721918467.4319956}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.851716610590617, '_timestamp': 1721918467.4320667}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.4031798243522644, '_timestamp': 1721918467.4321792}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.8154181241989136, '_timestamp': 1721918467.4324534}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'ratio': 1.00482976436615, '_timestamp': 1721918467.4325588}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721918467.4326954}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918467.4327943}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'Episode_Time': 56.81266927719116, '_timestamp': 1721918467.4328527}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918467.4332216}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918467.4334712}).
wandb: WARNING (User provided step: 7286 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918467.4337184}).
Env Football Algo jrpo Exp base_JRPO updates 5690/100000000000.0 steps in 59.56
total episode rewards is -70.0
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'value_loss': 0.5473762836617728, '_timestamp': 1721918526.9978418}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'policy_loss': -0.010024204986621044, '_timestamp': 1721918526.9979982}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8518311738967896, '_timestamp': 1721918526.998064}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.27577224373817444, '_timestamp': 1721918526.9981556}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.2958213090896606, '_timestamp': 1721918526.9983723}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'ratio': 1.0041875839233398, '_timestamp': 1721918526.9984763}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721918526.9986038}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918526.9986947}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'Episode_Time': 59.563371896743774, '_timestamp': 1721918526.9987524}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.20261723009814614, '_timestamp': 1721918526.999434}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'train_goal': 0.39869138495092693, '_timestamp': 1721918526.9997418}).
wandb: WARNING (User provided step: 5690 is less than current step: 10854. Dropping entry: {'train_WDL': -0.20261723009814614, '_timestamp': 1721918527.0000672}).
Env Football Algo jrpo Exp base_JRPO updates 3832/100000000000.0 steps in 51.47
total episode rewards is -130.0
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'value_loss': 0.7587127498537302, '_timestamp': 1721918578.4734275}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'policy_loss': -0.007712660638305048, '_timestamp': 1721918578.473579}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.861088013648987, '_timestamp': 1721918578.4736447}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.35250502824783325, '_timestamp': 1721918578.473737}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.4759762287139893, '_timestamp': 1721918578.473976}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'ratio': 1.00391685962677, '_timestamp': 1721918578.4740765}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721918578.47421}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918578.4743023}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'Episode_Time': 51.47264242172241, '_timestamp': 1721918578.474504}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918578.4748278}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918578.475054}).
wandb: WARNING (User provided step: 3832 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918578.475287}).
Env Football Algo jrpo Exp base_JRPO updates 2605/100000000000.0 steps in 46.22
total episode rewards is -80.0
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'value_loss': 0.7736164045333862, '_timestamp': 1721918624.6952393}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'policy_loss': -0.006587498311079495, '_timestamp': 1721918624.6953907}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.861815768877665, '_timestamp': 1721918624.695456}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.3370319902896881, '_timestamp': 1721918624.695547}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.712030291557312, '_timestamp': 1721918624.6957877}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'ratio': 1.0019932985305786, '_timestamp': 1721918624.69589}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721918624.6960337}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918624.6963918}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'Episode_Time': 46.2190887928009, '_timestamp': 1721918624.6964557}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'train_goal_diff': 0.20199203187250997, '_timestamp': 1721918624.6969368}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'train_goal': 0.600996015936255, '_timestamp': 1721918624.6972682}).
wandb: WARNING (User provided step: 2605 is less than current step: 10854. Dropping entry: {'train_WDL': 0.20199203187250997, '_timestamp': 1721918624.697599}).
Env Football Algo jrpo Exp base_JRPO updates 7325/100000000000.0 steps in 87.78
total episode rewards is -60.0
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'value_loss': 0.38024948198348285, '_timestamp': 1721918712.476522}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'policy_loss': -0.00918824437908673, '_timestamp': 1721918712.4767103}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8698187176386516, '_timestamp': 1721918712.4767857}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.2727270722389221, '_timestamp': 1721918712.4768913}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.5277875065803528, '_timestamp': 1721918712.4771647}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'ratio': 0.9995373487472534, '_timestamp': 1721918712.4772747}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721918712.4774213}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918712.4780865}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'Episode_Time': 87.77781057357788, '_timestamp': 1721918712.4781508}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918712.4787507}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918712.4793317}).
wandb: WARNING (User provided step: 7325 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918712.4797912}).
Env Football Algo jrpo Exp base_JRPO updates 7332/100000000000.0 steps in 84.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'value_loss': 0.250408654709657, '_timestamp': 1721918796.6960607}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'policy_loss': -0.00966922774326425, '_timestamp': 1721918796.6962101}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8666013209025065, '_timestamp': 1721918796.6962762}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.22845256328582764, '_timestamp': 1721918796.6963673}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.4252319037914276, '_timestamp': 1721918796.6965883}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'ratio': 0.9971988201141357, '_timestamp': 1721918796.6966872}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721918796.696813}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918796.6969936}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'Episode_Time': 84.21555352210999, '_timestamp': 1721918796.697053}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918796.697643}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918796.6980996}).
wandb: WARNING (User provided step: 7332 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918796.698573}).
Env Football Algo jrpo Exp base_JRPO updates 9906/100000000000.0 steps in 76.60
total episode rewards is -30.0
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'value_loss': 0.1799524884019047, '_timestamp': 1721918873.2956614}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'policy_loss': -0.005427913862804417, '_timestamp': 1721918873.2958305}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8657005977630616, '_timestamp': 1721918873.2959049}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.20884539186954498, '_timestamp': 1721918873.2960336}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.2814411222934723, '_timestamp': 1721918873.2962382}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'ratio': 1.0003145933151245, '_timestamp': 1721918873.2963464}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721918873.2966971}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918873.296791}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'Episode_Time': 76.5963146686554, '_timestamp': 1721918873.2968483}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918873.2972887}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918873.2976198}).
wandb: WARNING (User provided step: 9906 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918873.2979627}).
Env Football Algo jrpo Exp base_JRPO updates 9409/100000000000.0 steps in 92.07
total episode rewards is -40.0
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'value_loss': 0.25942438090530534, '_timestamp': 1721918965.3680007}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'policy_loss': -0.013072718062030617, '_timestamp': 1721918965.3681643}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.865578409830729, '_timestamp': 1721918965.3682292}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.19002018868923187, '_timestamp': 1721918965.368319}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.326863557100296, '_timestamp': 1721918965.3685546}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'ratio': 1.0036686658859253, '_timestamp': 1721918965.368655}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721918965.3687866}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918965.3688755}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'Episode_Time': 92.06917119026184, '_timestamp': 1721918965.368931}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918965.369398}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918965.3697593}).
wandb: WARNING (User provided step: 9409 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918965.3701262}).
Env Football Algo jrpo Exp base_JRPO updates 4869/100000000000.0 steps in 58.46
total episode rewards is -70.0
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'value_loss': 0.5220861728085826, '_timestamp': 1721919023.8292124}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'policy_loss': -0.011816496298706625, '_timestamp': 1721919023.829385}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8608901834487916, '_timestamp': 1721919023.8294594}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.2770572602748871, '_timestamp': 1721919023.8295593}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.6999950408935547, '_timestamp': 1721919023.8297908}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'ratio': 1.0046558380126953, '_timestamp': 1721919023.8298926}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721919023.8300195}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919023.8302073}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'Episode_Time': 58.45827507972717, '_timestamp': 1721919023.830265}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.2236584410497454, '_timestamp': 1721919023.830736}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'train_goal': 0.3881707794751273, '_timestamp': 1721919023.8310711}).
wandb: WARNING (User provided step: 4869 is less than current step: 10854. Dropping entry: {'train_WDL': -0.2236584410497454, '_timestamp': 1721919023.8314102}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'value_loss': 0.6161959451685349, '_timestamp': 1721919066.0792065}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'policy_loss': -0.009644892456753951, '_timestamp': 1721919066.0793717}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8614209270477295, '_timestamp': 1721919066.0794387}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.2898390293121338, '_timestamp': 1721919066.0795348}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.3891584873199463, '_timestamp': 1721919066.0797632}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'ratio': 1.0018315315246582, '_timestamp': 1721919066.0798655}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721919066.080014}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919066.080106}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'Episode_Time': 42.246946573257446, '_timestamp': 1721919066.0801709}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.11276164753544902, '_timestamp': 1721919066.080664}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'train_goal': 0.4436191762322755, '_timestamp': 1721919066.080907}).
wandb: WARNING (User provided step: 3718 is less than current step: 10854. Dropping entry: {'train_WDL': -0.11276164753544902, '_timestamp': 1721919066.0811403}).
Env Football Algo jrpo Exp base_JRPO updates 3718/100000000000.0 steps in 42.25
total episode rewards is -90.0
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'value_loss': 0.7104655859867731, '_timestamp': 1721919110.1216533}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'policy_loss': -0.009706277827499435, '_timestamp': 1721919110.1218522}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8561584043502806, '_timestamp': 1721919110.1219213}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.32269561290740967, '_timestamp': 1721919110.1220162}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 1.34689462184906, '_timestamp': 1721919110.1222649}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'ratio': 1.0070825815200806, '_timestamp': 1721919110.1223686}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721919110.1229215}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919110.123023}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'Episode_Time': 44.03376269340515, '_timestamp': 1721919110.12308}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'train_goal_diff': 0.033734005428460646, '_timestamp': 1721919110.123452}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'train_goal': 0.5168670027142304, '_timestamp': 1721919110.1236715}).
wandb: WARNING (User provided step: 4156 is less than current step: 10854. Dropping entry: {'train_WDL': 0.033734005428460646, '_timestamp': 1721919110.1238885}).
Env Football Algo jrpo Exp base_JRPO updates 4156/100000000000.0 steps in 44.03
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 6513/100000000000.0 steps in 88.51
total episode rewards is 10.0
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'value_loss': 0.20575303290194522, '_timestamp': 1721919198.6334422}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'policy_loss': -0.006056046744827957, '_timestamp': 1721919198.6336315}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8579558753967285, '_timestamp': 1721919198.6337118}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.1662411242723465, '_timestamp': 1721919198.6338198}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.39352506399154663, '_timestamp': 1721919198.6341062}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'ratio': 1.000356674194336, '_timestamp': 1721919198.6342275}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721919198.634386}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919198.6349413}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'Episode_Time': 88.50594687461853, '_timestamp': 1721919198.635015}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'train_goal_diff': 0.402851419818546, '_timestamp': 1721919198.6358202}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'train_goal': 0.701425709909273, '_timestamp': 1721919198.636593}).
wandb: WARNING (User provided step: 6513 is less than current step: 10854. Dropping entry: {'train_WDL': 0.402851419818546, '_timestamp': 1721919198.6372213}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'value_loss': 0.3015851288785537, '_timestamp': 1721919280.2590349}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'policy_loss': -0.004001477847729499, '_timestamp': 1721919280.2591949}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.858435535430908, '_timestamp': 1721919280.2592614}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.18168312311172485, '_timestamp': 1721919280.2593513}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.16723276674747467, '_timestamp': 1721919280.2596254}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'ratio': 1.000392198562622, '_timestamp': 1721919280.2597275}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721919280.2599974}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919280.2600915}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'Episode_Time': 81.6209602355957, '_timestamp': 1721919280.2601511}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.3556667391777246, '_timestamp': 1721919280.260788}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'train_goal': 0.3221666304111377, '_timestamp': 1721919280.2613106}).
wandb: WARNING (User provided step: 5806 is less than current step: 10854. Dropping entry: {'train_WDL': -0.3556667391777246, '_timestamp': 1721919280.2618537}).
Env Football Algo jrpo Exp base_JRPO updates 5806/100000000000.0 steps in 81.62
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 4543/100000000000.0 steps in 74.60
total episode rewards is -60.0
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'value_loss': 0.4220578629989177, '_timestamp': 1721919354.8630672}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'policy_loss': -0.009426950949806875, '_timestamp': 1721919354.8632133}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.858497306505839, '_timestamp': 1721919354.8632784}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.19884555041790009, '_timestamp': 1721919354.863366}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.7647979259490967, '_timestamp': 1721919354.8635895}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'ratio': 1.0025256872177124, '_timestamp': 1721919354.863688}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721919354.8638098}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919354.8640294}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'Episode_Time': 74.60052156448364, '_timestamp': 1721919354.8640912}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919354.864595}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919354.8650036}).
wandb: WARNING (User provided step: 4543 is less than current step: 10854. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919354.8654315}).
Env Football Algo jrpo Exp base_JRPO updates 6560/100000000000.0 steps in 82.96
total episode rewards is -20.0
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'value_loss': 0.2897269213059917, '_timestamp': 1721919437.8236816}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'policy_loss': -0.009602735411220541, '_timestamp': 1721919437.8239415}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'dist_entropy': 2.8554260301589967, '_timestamp': 1721919437.8240218}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'actor_grad_norm': 0.2172769457101822, '_timestamp': 1721919437.8241384}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'critic_grad_norm': 0.6656813621520996, '_timestamp': 1721919437.8243997}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'ratio': 0.9995520114898682, '_timestamp': 1721919437.8245056}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721919437.8247104}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919437.8252234}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'Episode_Time': 82.9570164680481, '_timestamp': 1721919437.8252838}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'train_goal_diff': -0.29976303317535546, '_timestamp': 1721919437.8260193}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'train_goal': 0.35011848341232227, '_timestamp': 1721919437.8265228}).
wandb: WARNING (User provided step: 6560 is less than current step: 10854. Dropping entry: {'train_WDL': -0.29976303317535546, '_timestamp': 1721919437.8270514}).
Env Football Algo jrpo Exp base_JRPO updates 12016/100000000000.0 steps in 88.07
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6282/100000000000.0 steps in 91.02
total episode rewards is 10.0
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'value_loss': 0.21334052135314172, '_timestamp': 1721919616.9191704}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010205381786508951, '_timestamp': 1721919616.9193275}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.844436844189962, '_timestamp': 1721919616.9193945}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18332606554031372, '_timestamp': 1721919616.9194894}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.689673662185669, '_timestamp': 1721919616.919742}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'ratio': 0.9976744651794434, '_timestamp': 1721919616.919845}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721919616.9200199}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919616.9203815}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.02229714393616, '_timestamp': 1721919616.9204445}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.3560449644413856, '_timestamp': 1721919616.921083}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'train_goal': 0.6780224822206928, '_timestamp': 1721919616.9215765}).
wandb: WARNING (User provided step: 6282 is less than current step: 12016. Dropping entry: {'train_WDL': 0.3560449644413856, '_timestamp': 1721919616.9220588}).
Env Football Algo jrpo Exp base_JRPO updates 4983/100000000000.0 steps in 55.01
total episode rewards is -40.0
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'value_loss': 0.5164380137249828, '_timestamp': 1721919671.9309642}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009759600803954526, '_timestamp': 1721919671.9311123}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.837885154088338, '_timestamp': 1721919671.9311774}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2765704095363617, '_timestamp': 1721919671.9312685}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0770790576934814, '_timestamp': 1721919671.931496}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'ratio': 1.0017781257629395, '_timestamp': 1721919671.9316027}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919671.9317336}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919671.9319093}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.008179664611816, '_timestamp': 1721919671.9319768}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.5144361721445433, '_timestamp': 1721919671.932566}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'train_goal': 0.7572180860722717, '_timestamp': 1721919671.9329166}).
wandb: WARNING (User provided step: 4983 is less than current step: 12016. Dropping entry: {'train_WDL': 0.5144361721445433, '_timestamp': 1721919671.9332511}).
Env Football Algo jrpo Exp base_JRPO updates 3868/100000000000.0 steps in 83.54
total episode rewards is -40.0
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'value_loss': 0.37971344579942523, '_timestamp': 1721919755.4702997}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'policy_loss': -0.012306217465084045, '_timestamp': 1721919755.4704604}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8328519280751547, '_timestamp': 1721919755.4705265}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1960846483707428, '_timestamp': 1721919755.4706197}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6520586609840393, '_timestamp': 1721919755.4708555}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'ratio': 1.0008469820022583, '_timestamp': 1721919755.470958}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919755.4710894}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919755.4713323}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.53612184524536, '_timestamp': 1721919755.471392}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4512840619486375, '_timestamp': 1721919755.4720788}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'train_goal': 0.2743579690256812, '_timestamp': 1721919755.4726584}).
wandb: WARNING (User provided step: 3868 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4512840619486375, '_timestamp': 1721919755.473223}).
Env Football Algo jrpo Exp base_JRPO updates 5228/100000000000.0 steps in 80.97
total episode rewards is -20.0
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'value_loss': 0.31560094523398824, '_timestamp': 1721919836.4451175}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006687774676635551, '_timestamp': 1721919836.445304}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8288925552368163, '_timestamp': 1721919836.445374}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18136073648929596, '_timestamp': 1721919836.4454796}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3518998920917511, '_timestamp': 1721919836.445706}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'ratio': 1.0041253566741943, '_timestamp': 1721919836.445809}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721919836.445944}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919836.4465735}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.9710168838501, '_timestamp': 1721919836.446633}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3933688088415882, '_timestamp': 1721919836.4473994}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_goal': 0.3033155955792059, '_timestamp': 1721919836.4480135}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3933688088415882, '_timestamp': 1721919836.448608}).
Env Football Algo jrpo Exp base_JRPO updates 11205/100000000000.0 steps in 91.65
total episode rewards is -30.0
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'value_loss': 0.20234091880837998, '_timestamp': 1721919928.100449}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0043976006784942, '_timestamp': 1721919928.1006608}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8260669803619383, '_timestamp': 1721919928.1007302}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16240136325359344, '_timestamp': 1721919928.1008234}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.549901008605957, '_timestamp': 1721919928.101069}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'ratio': 1.001793622970581, '_timestamp': 1721919928.1011665}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721919928.1012971}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919928.1013875}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.65087866783142, '_timestamp': 1721919928.1017437}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919928.1021683}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919928.1024463}).
wandb: WARNING (User provided step: 11205 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919928.1027215}).
Env Football Algo jrpo Exp base_JRPO updates 3588/100000000000.0 steps in 46.92
total episode rewards is -110.0
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'value_loss': 0.6581148508563638, '_timestamp': 1721919975.0266106}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006848268033597075, '_timestamp': 1721919975.0267637}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8204495604832966, '_timestamp': 1721919975.0268307}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.31192776560783386, '_timestamp': 1721919975.0269222}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3807361125946045, '_timestamp': 1721919975.02717}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'ratio': 1.0010024309158325, '_timestamp': 1721919975.0272725}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721919975.0274036}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919975.0274923}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.9232177734375, '_timestamp': 1721919975.0278044}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919975.0282056}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919975.0284884}).
wandb: WARNING (User provided step: 3588 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919975.028764}).
Env Football Algo jrpo Exp base_JRPO updates 5999/100000000000.0 steps in 91.22
total episode rewards is -20.0
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'value_loss': 0.26645000486615267, '_timestamp': 1721920066.2612488}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004931749088767295, '_timestamp': 1721920066.2614243}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.827201806704203, '_timestamp': 1721920066.2614985}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14272843301296234, '_timestamp': 1721920066.2615979}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.16470149159431458, '_timestamp': 1721920066.2618494}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'ratio': 1.0039584636688232, '_timestamp': 1721920066.2619696}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721920066.2620947}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920066.2621896}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.22268486022949, '_timestamp': 1721920066.2625442}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.33607376958115764, '_timestamp': 1721920066.2631748}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'train_goal': 0.3319631152094212, '_timestamp': 1721920066.2637608}).
wandb: WARNING (User provided step: 5999 is less than current step: 12016. Dropping entry: {'train_WDL': -0.33607376958115764, '_timestamp': 1721920066.2643158}).
Env Football Algo jrpo Exp base_JRPO updates 10493/100000000000.0 steps in 87.32
total episode rewards is -40.0
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'value_loss': 0.2581906356916685, '_timestamp': 1721920153.5871959}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0025522771533966686, '_timestamp': 1721920153.5874474}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829133639335632, '_timestamp': 1721920153.5875158}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17141732573509216, '_timestamp': 1721920153.587618}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.36677315831184387, '_timestamp': 1721920153.5878744}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'ratio': 1.0002918243408203, '_timestamp': 1721920153.5879936}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920153.5882084}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920153.58831}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.32164335250854, '_timestamp': 1721920153.5887446}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920153.5892715}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920153.5896003}).
wandb: WARNING (User provided step: 10493 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920153.5899324}).
Env Football Algo jrpo Exp base_JRPO updates 3779/100000000000.0 steps in 57.93
total episode rewards is -90.0
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'value_loss': 0.6730582283064723, '_timestamp': 1721920211.5206215}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0015058460280609628, '_timestamp': 1721920211.5217674}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8277769072850547, '_timestamp': 1721920211.5218375}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.3104475140571594, '_timestamp': 1721920211.522342}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2823331356048584, '_timestamp': 1721920211.5226705}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'ratio': 1.0008363723754883, '_timestamp': 1721920211.5227785}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721920211.5229201}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920211.5231004}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'Episode_Time': 57.9252393245697, '_timestamp': 1721920211.5231612}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2974954184483812, '_timestamp': 1721920211.5241053}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_goal': 0.3512522907758094, '_timestamp': 1721920211.5244515}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2974954184483812, '_timestamp': 1721920211.5247908}).
Env Football Algo jrpo Exp base_JRPO updates 2499/100000000000.0 steps in 47.19
total episode rewards is -80.0
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'value_loss': 0.7185729803144931, '_timestamp': 1721920258.7207797}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008293327042870995, '_timestamp': 1721920258.720975}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.828096389770508, '_timestamp': 1721920258.7210438}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.30995985865592957, '_timestamp': 1721920258.7211714}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.4410655498504639, '_timestamp': 1721920258.7215111}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'ratio': 0.9997735023498535, '_timestamp': 1721920258.7216368}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721920258.721807}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920258.722017}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'Episode_Time': 47.194742918014526, '_timestamp': 1721920258.7227838}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.2444130792754646, '_timestamp': 1721920258.723435}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'train_goal': 0.6222065396377323, '_timestamp': 1721920258.7238116}).
wandb: WARNING (User provided step: 2499 is less than current step: 12016. Dropping entry: {'train_WDL': 0.2444130792754646, '_timestamp': 1721920258.7242024}).
Env Football Algo jrpo Exp base_JRPO updates 7303/100000000000.0 steps in 86.88
total episode rewards is -40.0
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'value_loss': 0.27871992441592736, '_timestamp': 1721920345.6046236}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0029977260382535557, '_timestamp': 1721920345.6047978}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.82500611782074, '_timestamp': 1721920345.6048648}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17906427383422852, '_timestamp': 1721920345.604971}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3589015603065491, '_timestamp': 1721920345.6052487}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'ratio': 0.9997034072875977, '_timestamp': 1721920345.6053526}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920345.605492}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920345.6060627}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.87932205200195, '_timestamp': 1721920345.6061354}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920345.606755}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920345.607235}).
wandb: WARNING (User provided step: 7303 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920345.607722}).
Env Football Algo jrpo Exp base_JRPO updates 8631/100000000000.0 steps in 86.88
total episode rewards is -10.0
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'value_loss': 0.2070129754533991, '_timestamp': 1721920432.4901614}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00010053262871224433, '_timestamp': 1721920432.490398}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829983890851339, '_timestamp': 1721920432.4904692}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19832073152065277, '_timestamp': 1721920432.4905646}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5859343409538269, '_timestamp': 1721920432.490812}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'ratio': 0.9977293014526367, '_timestamp': 1721920432.4909182}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721920432.491142}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920432.4913573}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.8814549446106, '_timestamp': 1721920432.4914174}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.34181190139739365, '_timestamp': 1721920432.4923277}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'train_goal': 0.3290940493013032, '_timestamp': 1721920432.49274}).
wandb: WARNING (User provided step: 8631 is less than current step: 12016. Dropping entry: {'train_WDL': -0.34181190139739365, '_timestamp': 1721920432.4931555}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'value_loss': 0.40542432555463165, '_timestamp': 1721920501.6409426}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004647040895263975, '_timestamp': 1721920501.6419759}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8356955353418987, '_timestamp': 1721920501.6420498}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1991623193025589, '_timestamp': 1721920501.642551}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6192490458488464, '_timestamp': 1721920501.6428485}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'ratio': 0.9995042085647583, '_timestamp': 1721920501.6429548}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721920501.6430922}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920501.6432648}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'Episode_Time': 69.14296960830688, '_timestamp': 1721920501.6437066}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.08783039647577093, '_timestamp': 1721920501.6447194}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'train_goal': 0.5439151982378855, '_timestamp': 1721920501.6452048}).
wandb: WARNING (User provided step: 2721 is less than current step: 12016. Dropping entry: {'train_WDL': 0.08783039647577093, '_timestamp': 1721920501.6456797}).
Env Football Algo jrpo Exp base_JRPO updates 2721/100000000000.0 steps in 69.14
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 3793/100000000000.0 steps in 42.49
total episode rewards is -100.0
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'value_loss': 0.8271605076702933, '_timestamp': 1721920544.1331651}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005200580695212315, '_timestamp': 1721920544.133322}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.82847945690155, '_timestamp': 1721920544.1333873}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.3088904321193695, '_timestamp': 1721920544.1334803}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.708679437637329, '_timestamp': 1721920544.133722}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'ratio': 0.999190092086792, '_timestamp': 1721920544.133824}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721920544.1339543}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920544.134135}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'Episode_Time': 42.48672127723694, '_timestamp': 1721920544.1341913}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.14860480207657364, '_timestamp': 1721920544.1345482}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'train_goal': 0.42569759896171316, '_timestamp': 1721920544.1349194}).
wandb: WARNING (User provided step: 3793 is less than current step: 12016. Dropping entry: {'train_WDL': -0.14860480207657364, '_timestamp': 1721920544.1351562}).
Env Football Algo jrpo Exp base_JRPO updates 4050/100000000000.0 steps in 90.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'value_loss': 0.2919092782245328, '_timestamp': 1721920635.0399437}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0018502478214213625, '_timestamp': 1721920635.0401287}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.833978575070699, '_timestamp': 1721920635.0401976}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15944617986679077, '_timestamp': 1721920635.0402951}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.32817453145980835, '_timestamp': 1721920635.0405507}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'ratio': 0.9979968667030334, '_timestamp': 1721920635.0406532}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920635.0407877}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920635.0408823}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'Episode_Time': 90.90368843078613, '_timestamp': 1721920635.0409398}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920635.041688}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920635.042299}).
wandb: WARNING (User provided step: 4050 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920635.042947}).
Env Football Algo jrpo Exp base_JRPO updates 3169/100000000000.0 steps in 54.96
total episode rewards is -40.0
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'value_loss': 0.5068600982582817, '_timestamp': 1721920689.9989138}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004012928337227398, '_timestamp': 1721920689.9990695}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829703900019328, '_timestamp': 1721920689.9991353}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2724933624267578, '_timestamp': 1721920689.999227}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0515689849853516, '_timestamp': 1721920689.9994586}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'ratio': 1.002166986465454, '_timestamp': 1721920689.9995594}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920689.9996917}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920689.9997814}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'Episode_Time': 54.95520567893982, '_timestamp': 1721920689.999931}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.29634196465269214, '_timestamp': 1721920690.0006702}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'train_goal': 0.6481709823263461, '_timestamp': 1721920690.0009937}).
wandb: WARNING (User provided step: 3169 is less than current step: 12016. Dropping entry: {'train_WDL': 0.29634196465269214, '_timestamp': 1721920690.0013146}).
Env Football Algo jrpo Exp base_JRPO updates 8526/100000000000.0 steps in 81.37
total episode rewards is -30.0
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'value_loss': 0.18841407516447362, '_timestamp': 1721920771.367288}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011052492538583465, '_timestamp': 1721920771.367441}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8336627658208213, '_timestamp': 1721920771.367505}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15888799726963043, '_timestamp': 1721920771.3675952}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3446393311023712, '_timestamp': 1721920771.367824}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'ratio': 1.0014625787734985, '_timestamp': 1721920771.3679228}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721920771.3681755}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920771.368265}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.3652994632721, '_timestamp': 1721920771.3683214}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920771.3688216}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920771.3692238}).
wandb: WARNING (User provided step: 8526 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920771.369631}).
Env Football Algo jrpo Exp base_JRPO updates 7835/100000000000.0 steps in 87.46
total episode rewards is -10.0
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'value_loss': 0.21514436998715003, '_timestamp': 1721920858.8349617}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00948342758541306, '_timestamp': 1721920858.8351152}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8353385432561238, '_timestamp': 1721920858.8351808}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15910327434539795, '_timestamp': 1721920858.8352702}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3032408356666565, '_timestamp': 1721920858.8354542}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'ratio': 1.0000239610671997, '_timestamp': 1721920858.8355558}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721920858.8356812}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920858.8358529}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.46464014053345, '_timestamp': 1721920858.8359108}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.18213538032100487, '_timestamp': 1721920858.8364832}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'train_goal': 0.4089323098394976, '_timestamp': 1721920858.8369164}).
wandb: WARNING (User provided step: 7835 is less than current step: 12016. Dropping entry: {'train_WDL': -0.18213538032100487, '_timestamp': 1721920858.8373554}).
Env Football Algo jrpo Exp base_JRPO updates 3048/100000000000.0 steps in 44.08
total episode rewards is -90.0
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'value_loss': 0.5500070472247899, '_timestamp': 1721920902.919077}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'policy_loss': -0.01106515578314429, '_timestamp': 1721920902.919299}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.833973938624064, '_timestamp': 1721920902.9193683}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24247068166732788, '_timestamp': 1721920902.9194748}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3918375968933105, '_timestamp': 1721920902.91975}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'ratio': 0.9975787401199341, '_timestamp': 1721920902.9198558}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721920902.9206886}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920902.920798}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.08069109916687, '_timestamp': 1721920902.9208593}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920902.921283}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920902.9215114}).
wandb: WARNING (User provided step: 3048 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920902.9217463}).
Env Football Algo jrpo Exp base_JRPO updates 6822/100000000000.0 steps in 79.59
total episode rewards is 0.0
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'value_loss': 0.2632926147442777, '_timestamp': 1721920982.516005}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0018905872367182988, '_timestamp': 1721920982.516229}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839979561169942, '_timestamp': 1721920982.516296}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20055033266544342, '_timestamp': 1721920982.5163908}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2565746009349823, '_timestamp': 1721920982.516628}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'ratio': 0.9981037378311157, '_timestamp': 1721920982.5167282}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721920982.517135}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920982.517233}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.59328007698059, '_timestamp': 1721920982.5172904}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.45634629493763756, '_timestamp': 1721920982.5180717}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'train_goal': 0.7281731474688188, '_timestamp': 1721920982.5185597}).
wandb: WARNING (User provided step: 6822 is less than current step: 12016. Dropping entry: {'train_WDL': 0.45634629493763756, '_timestamp': 1721920982.5190377}).
Env Football Algo jrpo Exp base_JRPO updates 2806/100000000000.0 steps in 37.91
total episode rewards is -90.0
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'value_loss': 0.6375716744052867, '_timestamp': 1721921020.4249542}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005104808908654377, '_timestamp': 1721921020.4251087}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8441542466481526, '_timestamp': 1721921020.4251735}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.26594915986061096, '_timestamp': 1721921020.4252636}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0093679428100586, '_timestamp': 1721921020.425497}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'ratio': 0.9955319166183472, '_timestamp': 1721921020.4257088}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721921020.425845}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921020.425933}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.90516257286072, '_timestamp': 1721921020.425989}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921020.4262562}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921020.426436}).
wandb: WARNING (User provided step: 2806 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921020.4266145}).
Env Football Algo jrpo Exp base_JRPO updates 9278/100000000000.0 steps in 79.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'value_loss': 0.2576034316183844, '_timestamp': 1721921100.2365937}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006521983207397474, '_timestamp': 1721921100.2367687}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839955434799194, '_timestamp': 1721921100.2368402}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19890768826007843, '_timestamp': 1721921100.236935}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3701489269733429, '_timestamp': 1721921100.2371817}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'ratio': 1.0031541585922241, '_timestamp': 1721921100.2376416}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721921100.2377982}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921100.2378895}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.80927610397339, '_timestamp': 1721921100.2379475}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921100.2384593}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921100.2388616}).
wandb: WARNING (User provided step: 9278 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921100.239242}).
Env Football Algo jrpo Exp base_JRPO updates 4547/100000000000.0 steps in 58.62
total episode rewards is -90.0
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'value_loss': 0.5541152726113796, '_timestamp': 1721921158.8564897}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008156548882834614, '_timestamp': 1721921158.856658}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8389445034662883, '_timestamp': 1721921158.8567226}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2666093707084656, '_timestamp': 1721921158.8568184}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.272267460823059, '_timestamp': 1721921158.8570404}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'ratio': 1.0024633407592773, '_timestamp': 1721921158.8571408}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721921158.8573606}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921158.8574498}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'Episode_Time': 58.61644983291626, '_timestamp': 1721921158.8575072}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921158.8579252}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921158.8582377}).
wandb: WARNING (User provided step: 4547 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921158.8585563}).
Env Football Algo jrpo Exp base_JRPO updates 6803/100000000000.0 steps in 78.94
total episode rewards is -40.0
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'value_loss': 0.27635647763032467, '_timestamp': 1721921237.7994678}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0016591666947836832, '_timestamp': 1721921237.7996218}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8451471296946207, '_timestamp': 1721921237.799687}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15909874439239502, '_timestamp': 1721921237.799778}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.26712700724601746, '_timestamp': 1721921237.8000245}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'ratio': 1.0009125471115112, '_timestamp': 1721921237.8001306}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721921237.800266}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921237.800496}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.9402084350586, '_timestamp': 1721921237.8005557}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921237.8011894}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921237.8016677}).
wandb: WARNING (User provided step: 6803 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921237.802172}).
Env Football Algo jrpo Exp base_JRPO updates 8183/100000000000.0 steps in 88.45
total episode rewards is -10.0
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'value_loss': 0.1892605371718916, '_timestamp': 1721921326.2569938}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0018659954816879084, '_timestamp': 1721921326.2571979}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.847348903020223, '_timestamp': 1721921326.2572691}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18489055335521698, '_timestamp': 1721921326.2573807}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4529477059841156, '_timestamp': 1721921326.2576683}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'ratio': 1.0002063512802124, '_timestamp': 1721921326.2577813}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721921326.257927}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921326.2585952}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.44818758964539, '_timestamp': 1721921326.258659}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.12776881326096523, '_timestamp': 1721921326.2593293}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'train_goal': 0.4361155933695174, '_timestamp': 1721921326.2597916}).
wandb: WARNING (User provided step: 8183 is less than current step: 12016. Dropping entry: {'train_WDL': -0.12776881326096523, '_timestamp': 1721921326.2637258}).
Env Football Algo jrpo Exp base_JRPO updates 3850/100000000000.0 steps in 37.26
total episode rewards is -70.0
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'value_loss': 0.4529054357204586, '_timestamp': 1721921363.5235214}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0040706540023287135, '_timestamp': 1721921363.5236776}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8456210533777875, '_timestamp': 1721921363.5237427}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2517988085746765, '_timestamp': 1721921363.5238335}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8632444739341736, '_timestamp': 1721921363.524103}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'ratio': 1.0009723901748657, '_timestamp': 1721921363.5242069}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721921363.5243273}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921363.5245554}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.25902843475342, '_timestamp': 1721921363.5246139}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921363.5248668}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921363.5250354}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921363.5252032}).
Env Football Algo jrpo Exp base_JRPO updates 8557/100000000000.0 steps in 91.08
total episode rewards is -70.0
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'value_loss': 0.39986840908182786, '_timestamp': 1721921454.6101785}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006348462294942389, '_timestamp': 1721921454.6103358}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8570144589742026, '_timestamp': 1721921454.6104023}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2250421941280365, '_timestamp': 1721921454.6104972}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4575960338115692, '_timestamp': 1721921454.6107388}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'ratio': 1.0012627840042114, '_timestamp': 1721921454.6108398}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721921454.6109755}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921454.6110637}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.08413696289062, '_timestamp': 1721921454.6112373}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921454.6117268}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921454.6121366}).
wandb: WARNING (User provided step: 8557 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921454.6125245}).
Env Football Algo jrpo Exp base_JRPO updates 10092/100000000000.0 steps in 82.21
total episode rewards is -40.0
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'value_loss': 0.2440889472483347, '_timestamp': 1721921536.8200707}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005894705625444961, '_timestamp': 1721921536.8202322}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8752250798543293, '_timestamp': 1721921536.8202984}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20706667006015778, '_timestamp': 1721921536.8203924}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.313064843416214, '_timestamp': 1721921536.820639}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'ratio': 1.0000826120376587, '_timestamp': 1721921536.8207388}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721921536.8208716}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921536.821122}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.20679187774658, '_timestamp': 1721921536.821182}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921536.8216164}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921536.821939}).
wandb: WARNING (User provided step: 10092 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921536.8222706}).
Env Football Algo jrpo Exp base_JRPO updates 3741/100000000000.0 steps in 63.31
total episode rewards is -80.0
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'value_loss': 0.5070695183146745, '_timestamp': 1721921600.128497}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011224909118609502, '_timestamp': 1721921600.1286488}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8760626109441123, '_timestamp': 1721921600.1287138}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22383540868759155, '_timestamp': 1721921600.1288054}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9309307932853699, '_timestamp': 1721921600.1290343}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'ratio': 0.9985358119010925, '_timestamp': 1721921600.1291354}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721921600.1292698}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921600.129525}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'Episode_Time': 63.30533409118652, '_timestamp': 1721921600.1295843}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921600.130099}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921600.1305065}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921600.1309302}).
Env Football Algo jrpo Exp base_JRPO updates 7987/100000000000.0 steps in 71.93
total episode rewards is -70.0
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'value_loss': 0.5311698295300206, '_timestamp': 1721921672.0581775}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0036192414880497382, '_timestamp': 1721921672.0583458}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8714880593617758, '_timestamp': 1721921672.058412}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23755818605422974, '_timestamp': 1721921672.0585063}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0427745580673218, '_timestamp': 1721921672.058738}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'ratio': 1.00113046169281, '_timestamp': 1721921672.0588412}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721921672.0591075}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921672.0592003}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'Episode_Time': 71.92647910118103, '_timestamp': 1721921672.0592585}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921672.0597115}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921672.0600765}).
wandb: WARNING (User provided step: 7987 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921672.06043}).
Env Football Algo jrpo Exp base_JRPO updates 9869/100000000000.0 steps in 84.48
total episode rewards is -30.0
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'value_loss': 0.23757619351924708, '_timestamp': 1721921756.5460017}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'policy_loss': -0.01156773384277282, '_timestamp': 1721921756.5461535}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8706314516067506, '_timestamp': 1721921756.546216}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1604742854833603, '_timestamp': 1721921756.5463076}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3405449390411377, '_timestamp': 1721921756.5465338}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'ratio': 1.0031601190567017, '_timestamp': 1721921756.5466821}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721921756.5468743}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921756.546997}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.4848837852478, '_timestamp': 1721921756.5470567}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921756.5474951}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921756.5478234}).
wandb: WARNING (User provided step: 9869 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921756.5481782}).
Env Football Algo jrpo Exp base_JRPO updates 9203/100000000000.0 steps in 89.17
total episode rewards is -10.0
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'value_loss': 0.18724886727170087, '_timestamp': 1721921845.7168071}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007084410773046936, '_timestamp': 1721921845.716998}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8718450689315795, '_timestamp': 1721921845.7170663}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18920041620731354, '_timestamp': 1721921845.717173}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.33981311321258545, '_timestamp': 1721921845.717449}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'ratio': 1.0009371042251587, '_timestamp': 1721921845.7175524}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721921845.717692}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921845.722781}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'Episode_Time': 89.16739988327026, '_timestamp': 1721921845.7229195}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.02742797998964982, '_timestamp': 1721921845.723865}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'train_goal': 0.5137139899948249, '_timestamp': 1721921845.724555}).
wandb: WARNING (User provided step: 9203 is less than current step: 12016. Dropping entry: {'train_WDL': 0.02742797998964982, '_timestamp': 1721921845.724985}).
Env Football Algo jrpo Exp base_JRPO updates 3563/100000000000.0 steps in 41.90
total episode rewards is -60.0
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'value_loss': 0.5035836855539432, '_timestamp': 1721921887.633352}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007741152110199134, '_timestamp': 1721921887.6346176}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8708158604303997, '_timestamp': 1721921887.6346912}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2639421224594116, '_timestamp': 1721921887.6353219}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1036449670791626, '_timestamp': 1721921887.6356924}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'ratio': 0.9998379945755005, '_timestamp': 1721921887.6357982}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721921887.636617}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921887.63683}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'Episode_Time': 41.9020619392395, '_timestamp': 1721921887.63689}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.08501118568232663, '_timestamp': 1721921887.637834}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'train_goal': 0.4574944071588367, '_timestamp': 1721921887.638085}).
wandb: WARNING (User provided step: 3563 is less than current step: 12016. Dropping entry: {'train_WDL': -0.08501118568232663, '_timestamp': 1721921887.6383326}).
Env Football Algo jrpo Exp base_JRPO updates 3696/100000000000.0 steps in 42.68
total episode rewards is -100.0
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'value_loss': 0.8311585419376691, '_timestamp': 1721921930.316169}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008668683107049826, '_timestamp': 1721921930.316388}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8703174591064453, '_timestamp': 1721921930.3164551}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2778984010219574, '_timestamp': 1721921930.3165588}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.5377978086471558, '_timestamp': 1721921930.3168144}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'ratio': 0.9978795647621155, '_timestamp': 1721921930.3169167}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721921930.317056}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921930.3174784}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'Episode_Time': 42.67693018913269, '_timestamp': 1721921930.3175378}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921930.3180852}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921930.3183193}).
wandb: WARNING (User provided step: 3696 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921930.318563}).
Env Football Algo jrpo Exp base_JRPO updates 7183/100000000000.0 steps in 89.06
total episode rewards is -40.0
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'value_loss': 0.2655071295394252, '_timestamp': 1721922019.3797078}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010464382133213802, '_timestamp': 1721922019.3808975}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873397952715556, '_timestamp': 1721922019.3809729}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17974746227264404, '_timestamp': 1721922019.3815093}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3355396091938019, '_timestamp': 1721922019.3818452}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'ratio': 0.9976482391357422, '_timestamp': 1721922019.3819497}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721922019.3820875}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922019.38273}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'Episode_Time': 89.05584406852722, '_timestamp': 1721922019.3827913}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922019.3839164}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922019.384419}).
wandb: WARNING (User provided step: 7183 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922019.3849306}).
Env Football Algo jrpo Exp base_JRPO updates 3803/100000000000.0 steps in 67.68
total episode rewards is -70.0
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'value_loss': 0.47064237512027224, '_timestamp': 1721922087.065062}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'policy_loss': -0.013120814750242668, '_timestamp': 1721922087.06522}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8743370230992635, '_timestamp': 1721922087.0652862}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19838503003120422, '_timestamp': 1721922087.0653796}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5571595430374146, '_timestamp': 1721922087.0656133}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'ratio': 0.9997894763946533, '_timestamp': 1721922087.0657194}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721922087.0658605}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922087.0661113}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.67932224273682, '_timestamp': 1721922087.0661716}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922087.06673}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922087.0672305}).
wandb: WARNING (User provided step: 3803 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922087.0676968}).
Env Football Algo jrpo Exp base_JRPO updates 5366/100000000000.0 steps in 55.92
total episode rewards is -110.0
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'value_loss': 0.6578633742655317, '_timestamp': 1721922142.9849052}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007953632665448821, '_timestamp': 1721922142.985052}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8772815450032554, '_timestamp': 1721922142.9851189}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.29396480321884155, '_timestamp': 1721922142.9852078}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.274574637413025, '_timestamp': 1721922142.985429}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'ratio': 1.0014246702194214, '_timestamp': 1721922142.985528}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721922142.9856575}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922142.9857428}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.91652536392212, '_timestamp': 1721922142.9858904}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922142.9862673}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922142.9865544}).
wandb: WARNING (User provided step: 5366 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922142.9868505}).
Env Football Algo jrpo Exp base_JRPO updates 5228/100000000000.0 steps in 66.37
total episode rewards is -60.0
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'value_loss': 0.5223219130436579, '_timestamp': 1721922209.3608642}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007053421717137098, '_timestamp': 1721922209.3610585}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8749662319819134, '_timestamp': 1721922209.361128}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2734547257423401, '_timestamp': 1721922209.3612368}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0930722951889038, '_timestamp': 1721922209.36151}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'ratio': 1.0005395412445068, '_timestamp': 1721922209.3616138}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721922209.3617563}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922209.3620634}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'Episode_Time': 66.37292313575745, '_timestamp': 1721922209.362124}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.19874312647289866, '_timestamp': 1721922209.3626785}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_goal': 0.40062843676355064, '_timestamp': 1721922209.3630416}).
wandb: WARNING (User provided step: 5228 is less than current step: 12016. Dropping entry: {'train_WDL': -0.19874312647289866, '_timestamp': 1721922209.3633897}).
Env Football Algo jrpo Exp base_JRPO updates 5674/100000000000.0 steps in 83.29
total episode rewards is -20.0
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'value_loss': 0.26416036825627087, '_timestamp': 1721922292.654901}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009821837482353052, '_timestamp': 1721922292.655071}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8744238392512003, '_timestamp': 1721922292.6551356}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19118154048919678, '_timestamp': 1721922292.6552374}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2972983717918396, '_timestamp': 1721922292.6554801}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'ratio': 0.9998966455459595, '_timestamp': 1721922292.6555798}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922292.6557102}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922292.6559014}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.29070734977722, '_timestamp': 1721922292.655994}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3592108084923869, '_timestamp': 1721922292.6566784}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'train_goal': 0.3203945957538066, '_timestamp': 1721922292.6572194}).
wandb: WARNING (User provided step: 5674 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3592108084923869, '_timestamp': 1721922292.657768}).
Env Football Algo jrpo Exp base_JRPO updates 6794/100000000000.0 steps in 91.71
total episode rewards is -40.0
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'value_loss': 0.2835356290390094, '_timestamp': 1721922384.3729286}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009015901621120672, '_timestamp': 1721922384.3730817}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8714139540990193, '_timestamp': 1721922384.3731458}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19257600605487823, '_timestamp': 1721922384.373236}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.41244521737098694, '_timestamp': 1721922384.373465}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'ratio': 0.9972303509712219, '_timestamp': 1721922384.3735638}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721922384.3736923}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922384.373906}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.71420121192932, '_timestamp': 1721922384.373964}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922384.374557}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922384.3750327}).
wandb: WARNING (User provided step: 6794 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922384.375534}).
Env Football Algo jrpo Exp base_JRPO updates 4893/100000000000.0 steps in 76.76
total episode rewards is -50.0
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'value_loss': 0.5135289381196102, '_timestamp': 1721922461.1376853}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'policy_loss': -0.012124138035384627, '_timestamp': 1721922461.137854}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8698437547683717, '_timestamp': 1721922461.137927}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23529472947120667, '_timestamp': 1721922461.1380222}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7489494681358337, '_timestamp': 1721922461.138262}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'ratio': 1.000568151473999, '_timestamp': 1721922461.1383765}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721922461.1388454}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922461.1389441}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.76137661933899, '_timestamp': 1721922461.1390026}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.35361800051137815, '_timestamp': 1721922461.1396449}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'train_goal': 0.3231909997443109, '_timestamp': 1721922461.1477373}).
wandb: WARNING (User provided step: 4893 is less than current step: 12016. Dropping entry: {'train_WDL': -0.35361800051137815, '_timestamp': 1721922461.1488714}).
Env Football Algo jrpo Exp base_JRPO updates 4103/100000000000.0 steps in 45.46
total episode rewards is -80.0
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'value_loss': 0.6969117036958535, '_timestamp': 1721922506.609567}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010289428516989574, '_timestamp': 1721922506.6097927}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.863398798306783, '_timestamp': 1721922506.6098847}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.28373461961746216, '_timestamp': 1721922506.6099966}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.935503363609314, '_timestamp': 1721922506.6102488}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'ratio': 1.0005638599395752, '_timestamp': 1721922506.610377}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721922506.610767}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922506.610872}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'Episode_Time': 45.459484338760376, '_timestamp': 1721922506.610932}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.9994821336095288, '_timestamp': 1721922506.6113827}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'train_goal': 0.0002589331952356292, '_timestamp': 1721922506.6116934}).
wandb: WARNING (User provided step: 4103 is less than current step: 12016. Dropping entry: {'train_WDL': -0.9994821336095288, '_timestamp': 1721922506.6120157}).
Env Football Algo jrpo Exp base_JRPO updates 6899/100000000000.0 steps in 78.92
total episode rewards is -40.0
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'value_loss': 0.38974883628388246, '_timestamp': 1721922585.532552}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0044724151944925935, '_timestamp': 1721922585.5327127}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866313036282857, '_timestamp': 1721922585.5327778}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19372501969337463, '_timestamp': 1721922585.5328703}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5581042170524597, '_timestamp': 1721922585.5330913}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'ratio': 0.9994552731513977, '_timestamp': 1721922585.5331917}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721922585.5334163}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922585.5335042}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.91979646682739, '_timestamp': 1721922585.5335612}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922585.5340545}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922585.5344543}).
wandb: WARNING (User provided step: 6899 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922585.5348635}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'value_loss': 0.274806504920125, '_timestamp': 1721922664.2957258}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006294471389458825, '_timestamp': 1721922664.2958896}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.864394536018372, '_timestamp': 1721922664.2959678}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19990158081054688, '_timestamp': 1721922664.2960618}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4689970910549164, '_timestamp': 1721922664.2963064}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'ratio': 1.0005803108215332, '_timestamp': 1721922664.2964091}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721922664.296668}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922664.29676}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.75999307632446, '_timestamp': 1721922664.2968192}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922664.2972791}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922664.2976437}).
wandb: WARNING (User provided step: 9209 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922664.298022}).
Env Football Algo jrpo Exp base_JRPO updates 9209/100000000000.0 steps in 78.76
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 2545/100000000000.0 steps in 36.47
total episode rewards is -70.0
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'value_loss': 0.734099379008015, '_timestamp': 1721922700.7730794}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00020366128834818179, '_timestamp': 1721922700.773234}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8640883763631186, '_timestamp': 1721922700.7733006}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.29093608260154724, '_timestamp': 1721922700.7733927}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3362833261489868, '_timestamp': 1721922700.7736309}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'ratio': 1.0038753747940063, '_timestamp': 1721922700.773858}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721922700.7739923}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922700.774079}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'Episode_Time': 36.47434377670288, '_timestamp': 1721922700.7741363}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.05795454545454545, '_timestamp': 1721922700.7744114}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'train_goal': 0.47102272727272726, '_timestamp': 1721922700.7745876}).
wandb: WARNING (User provided step: 2545 is less than current step: 12016. Dropping entry: {'train_WDL': -0.05795454545454545, '_timestamp': 1721922700.7747576}).
Env Football Algo jrpo Exp base_JRPO updates 3589/100000000000.0 steps in 53.90
total episode rewards is -60.0
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'value_loss': 0.6526583013683558, '_timestamp': 1721922754.6794467}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006868908422390329, '_timestamp': 1721922754.679606}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.864623303413391, '_timestamp': 1721922754.6796708}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2811740040779114, '_timestamp': 1721922754.6797612}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9724141955375671, '_timestamp': 1721922754.6799946}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'ratio': 1.001879096031189, '_timestamp': 1721922754.680097}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721922754.680325}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922754.6804156}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'Episode_Time': 53.904019832611084, '_timestamp': 1721922754.6804745}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3302629053924391, '_timestamp': 1721922754.6809316}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'train_goal': 0.33486854730378046, '_timestamp': 1721922754.681276}).
wandb: WARNING (User provided step: 3589 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3302629053924391, '_timestamp': 1721922754.6816616}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'value_loss': 0.4521599001561602, '_timestamp': 1721922826.4081242}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00921312067230853, '_timestamp': 1721922826.4084125}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8675622653961184, '_timestamp': 1721922826.4084787}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2382877618074417, '_timestamp': 1721922826.4085805}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7939633727073669, '_timestamp': 1721922826.408986}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'ratio': 0.9982396960258484, '_timestamp': 1721922826.4090898}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721922826.4094067}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922826.409506}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'Episode_Time': 71.72508692741394, '_timestamp': 1721922826.4095654}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922826.4104102}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922826.4110663}).
wandb: WARNING (User provided step: 5809 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922826.4115393}).
Env Football Algo jrpo Exp base_JRPO updates 5809/100000000000.0 steps in 71.73
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 5946/100000000000.0 steps in 91.10
total episode rewards is -40.0
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'value_loss': 0.2629292042180896, '_timestamp': 1721922917.5101485}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00787528945763673, '_timestamp': 1721922917.5103948}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.87214159488678, '_timestamp': 1721922917.510463}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20986512303352356, '_timestamp': 1721922917.510564}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.27818745374679565, '_timestamp': 1721922917.510821}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'ratio': 0.9990227222442627, '_timestamp': 1721922917.5114899}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721922917.5117075}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922917.511802}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.09768629074097, '_timestamp': 1721922917.5118601}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721922917.5126164}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721922917.5131884}).
wandb: WARNING (User provided step: 5946 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721922917.5137577}).
Env Football Algo jrpo Exp base_JRPO updates 6911/100000000000.0 steps in 85.26
total episode rewards is -40.0
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'value_loss': 0.2859661820779244, '_timestamp': 1721923002.7755973}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009397368857947489, '_timestamp': 1721923002.7758086}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8749879709879558, '_timestamp': 1721923002.7758765}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21432925760746002, '_timestamp': 1721923002.7759972}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3004206418991089, '_timestamp': 1721923002.7762535}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'ratio': 0.998374879360199, '_timestamp': 1721923002.7763531}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923002.7766733}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923002.7767673}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.26083827018738, '_timestamp': 1721923002.7768266}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923002.7778506}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923002.7786863}).
wandb: WARNING (User provided step: 6911 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923002.7795808}).
Env Football Algo jrpo Exp base_JRPO updates 8153/100000000000.0 steps in 84.06
total episode rewards is -40.0
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'value_loss': 0.25777210320035615, '_timestamp': 1721923086.8442674}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008985855557645361, '_timestamp': 1721923086.8446279}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8756457360585532, '_timestamp': 1721923086.844695}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19309097528457642, '_timestamp': 1721923086.8447828}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2261039763689041, '_timestamp': 1721923086.8450015}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'ratio': 0.9995596408843994, '_timestamp': 1721923086.8451009}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923086.8453228}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923086.8454108}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.06394219398499, '_timestamp': 1721923086.8454676}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923086.845964}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923086.8463762}).
wandb: WARNING (User provided step: 8153 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923086.8468056}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'value_loss': 0.4826698941489061, '_timestamp': 1721923146.4044504}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00875241645941666, '_timestamp': 1721923146.404611}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874024624824524, '_timestamp': 1721923146.4046776}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.26677656173706055, '_timestamp': 1721923146.4047732}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6231647729873657, '_timestamp': 1721923146.4050183}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'ratio': 1.0001939535140991, '_timestamp': 1721923146.4051192}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721923146.405481}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923146.405587}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'Episode_Time': 59.5566246509552, '_timestamp': 1721923146.4056463}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.1516143431037048, '_timestamp': 1721923146.4062052}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'train_goal': 0.5758071715518523, '_timestamp': 1721923146.4066215}).
wandb: WARNING (User provided step: 3129 is less than current step: 12016. Dropping entry: {'train_WDL': 0.1516143431037048, '_timestamp': 1721923146.4070451}).
Env Football Algo jrpo Exp base_JRPO updates 3129/100000000000.0 steps in 59.56
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 3317/100000000000.0 steps in 46.76
total episode rewards is -110.0
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'value_loss': 0.6680520015830795, '_timestamp': 1721923193.1715324}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007741269718486971, '_timestamp': 1721923193.1716871}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.875213071505229, '_timestamp': 1721923193.171757}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.306087464094162, '_timestamp': 1721923193.1718488}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3446577787399292, '_timestamp': 1721923193.1721075}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'ratio': 1.0002968311309814, '_timestamp': 1721923193.1722102}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721923193.1723292}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923193.1724176}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.76364731788635, '_timestamp': 1721923193.1724746}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923193.1728265}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923193.1731725}).
wandb: WARNING (User provided step: 3317 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923193.1734512}).
Env Football Algo jrpo Exp base_JRPO updates 9111/100000000000.0 steps in 81.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'value_loss': 0.27646737386782966, '_timestamp': 1721923274.9834604}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009442276711342856, '_timestamp': 1721923274.9836211}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8738653310139974, '_timestamp': 1721923274.9836864}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22699107229709625, '_timestamp': 1721923274.9837823}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5138079524040222, '_timestamp': 1721923274.992751}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'ratio': 0.9988955855369568, '_timestamp': 1721923274.9932673}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923274.9939573}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923274.9940681}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.8092839717865, '_timestamp': 1721923274.9941266}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923274.99473}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923274.9951427}).
wandb: WARNING (User provided step: 9111 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923274.9955313}).
Env Football Algo jrpo Exp base_JRPO updates 6449/100000000000.0 steps in 81.12
total episode rewards is -20.0
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'value_loss': 0.31612007175882656, '_timestamp': 1721923356.1130056}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009913125072295467, '_timestamp': 1721923356.1131792}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874675488471985, '_timestamp': 1721923356.113246}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.25779762864112854, '_timestamp': 1721923356.1133456}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.251089483499527, '_timestamp': 1721923356.1136022}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'ratio': 0.9991225600242615, '_timestamp': 1721923356.1137037}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721923356.1140437}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923356.114139}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.11644864082336, '_timestamp': 1721923356.1141958}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.30557829493626476, '_timestamp': 1721923356.11997}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'train_goal': 0.3472108525318676, '_timestamp': 1721923356.1206114}).
wandb: WARNING (User provided step: 6449 is less than current step: 12016. Dropping entry: {'train_WDL': -0.30557829493626476, '_timestamp': 1721923356.1211643}).
Env Football Algo jrpo Exp base_JRPO updates 3697/100000000000.0 steps in 51.95
total episode rewards is -30.0
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'value_loss': 0.4849569198489189, '_timestamp': 1721923408.077721}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009801636971533299, '_timestamp': 1721923408.0789871}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8726327816645303, '_timestamp': 1721923408.0790708}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2852695882320404, '_timestamp': 1721923408.0796127}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8023483753204346, '_timestamp': 1721923408.080029}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'ratio': 1.0011931657791138, '_timestamp': 1721923408.0801468}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721923408.0812104}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923408.0814474}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.95093822479248, '_timestamp': 1721923408.0815094}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.46546830652790916, '_timestamp': 1721923408.0826242}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'train_goal': 0.7327341532639546, '_timestamp': 1721923408.0829713}).
wandb: WARNING (User provided step: 3697 is less than current step: 12016. Dropping entry: {'train_WDL': 0.46546830652790916, '_timestamp': 1721923408.08329}).
Env Football Algo jrpo Exp base_JRPO updates 7341/100000000000.0 steps in 81.09
total episode rewards is -40.0
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'value_loss': 0.2766221816216906, '_timestamp': 1721923489.1775753}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0055220664765996234, '_timestamp': 1721923489.1777437}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8735745509465533, '_timestamp': 1721923489.177814}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21277782320976257, '_timestamp': 1721923489.1779175}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3893279433250427, '_timestamp': 1721923489.178192}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'ratio': 0.996889054775238, '_timestamp': 1721923489.178649}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923489.1787882}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923489.1788852}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.0932252407074, '_timestamp': 1721923489.1789446}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923489.179574}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923489.1801023}).
wandb: WARNING (User provided step: 7341 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923489.1805942}).
Env Football Algo jrpo Exp base_JRPO updates 9167/100000000000.0 steps in 87.33
total episode rewards is -60.0
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'value_loss': 0.385024952845027, '_timestamp': 1721923576.5165105}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00593738832937864, '_timestamp': 1721923576.5166762}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8737512572606403, '_timestamp': 1721923576.5167434}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20464660227298737, '_timestamp': 1721923576.5168402}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5027416348457336, '_timestamp': 1721923576.5171015}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'ratio': 0.9992956519126892, '_timestamp': 1721923576.5172052}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721923576.517485}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923576.5175786}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.33492112159729, '_timestamp': 1721923576.5176368}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923576.5181983}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923576.5185647}).
wandb: WARNING (User provided step: 9167 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923576.518934}).
Env Football Algo jrpo Exp base_JRPO updates 3591/100000000000.0 steps in 60.14
total episode rewards is -90.0
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'value_loss': 0.7141647091507912, '_timestamp': 1721923636.6606574}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004939677888372292, '_timestamp': 1721923636.6608176}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874857063293457, '_timestamp': 1721923636.6608837}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2828063666820526, '_timestamp': 1721923636.6609776}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9398606419563293, '_timestamp': 1721923636.6612275}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'ratio': 1.0036989450454712, '_timestamp': 1721923636.6613276}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721923636.661471}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923636.6615596}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'Episode_Time': 60.140634059906006, '_timestamp': 1721923636.6616182}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.38300611522368844, '_timestamp': 1721923636.6621919}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_goal': 0.3084969423881558, '_timestamp': 1721923636.6625926}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_WDL': -0.38300611522368844, '_timestamp': 1721923636.662995}).
Env Football Algo jrpo Exp base_JRPO updates 1854/100000000000.0 steps in 34.75
total episode rewards is -80.0
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'value_loss': 0.930271603067716, '_timestamp': 1721923671.4156651}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004898246675729752, '_timestamp': 1721923671.4158392}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.879719098409017, '_timestamp': 1721923671.4159093}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.29719090461730957, '_timestamp': 1721923671.4160302}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.4764827489852905, '_timestamp': 1721923671.4163759}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'ratio': 0.9994671940803528, '_timestamp': 1721923671.4164855}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721923671.4173963}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923671.4175076}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.751603841781616, '_timestamp': 1721923671.417568}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.5285565939771547, '_timestamp': 1721923671.4179673}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'train_goal': 0.7642782969885774, '_timestamp': 1721923671.4181633}).
wandb: WARNING (User provided step: 1854 is less than current step: 12016. Dropping entry: {'train_WDL': 0.5285565939771547, '_timestamp': 1721923671.4183536}).
Env Football Algo jrpo Exp base_JRPO updates 3244/100000000000.0 steps in 46.81
total episode rewards is -30.0
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'value_loss': 0.893377024208506, '_timestamp': 1721923718.2301674}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008033802433740979, '_timestamp': 1721923718.2303407}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.882663475672404, '_timestamp': 1721923718.2304075}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2841368615627289, '_timestamp': 1721923718.230506}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3585418462753296, '_timestamp': 1721923718.2307532}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'ratio': 0.9995125532150269, '_timestamp': 1721923718.230853}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721923718.2311156}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923718.2312086}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.811030626297, '_timestamp': 1721923718.2312663}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.29934013197360526, '_timestamp': 1721923718.2317162}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'train_goal': 0.6496700659868027, '_timestamp': 1721923718.2320733}).
wandb: WARNING (User provided step: 3244 is less than current step: 12016. Dropping entry: {'train_WDL': 0.29934013197360526, '_timestamp': 1721923718.2324073}).
Env Football Algo jrpo Exp base_JRPO updates 2556/100000000000.0 steps in 29.47
total episode rewards is -100.0
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'value_loss': 1.1640545937418938, '_timestamp': 1721923747.7102995}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006380448836328772, '_timestamp': 1721923747.7115202}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8789355691274006, '_timestamp': 1721923747.7115903}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.30976152420043945, '_timestamp': 1721923747.7121956}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.6951048374176025, '_timestamp': 1721923747.7125523}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'ratio': 0.9982682466506958, '_timestamp': 1721923747.712655}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721923747.7128372}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923747.7133944}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'Episode_Time': 29.472333908081055, '_timestamp': 1721923747.713455}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923747.7142725}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923747.7144878}).
wandb: WARNING (User provided step: 2556 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923747.7146978}).
Env Football Algo jrpo Exp base_JRPO updates 4902/100000000000.0 steps in 72.79
total episode rewards is -110.0
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'value_loss': 0.6292699917033314, '_timestamp': 1721923820.5033803}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0017706189442348356, '_timestamp': 1721923820.5035596}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8735575834910074, '_timestamp': 1721923820.503629}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2648477554321289, '_timestamp': 1721923820.5037298}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1362833976745605, '_timestamp': 1721923820.5040224}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'ratio': 0.997179388999939, '_timestamp': 1721923820.5041304}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721923820.5045214}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923820.5046184}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.78766393661499, '_timestamp': 1721923820.5046775}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923820.5053046}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923820.5057223}).
wandb: WARNING (User provided step: 4902 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923820.5061486}).
Env Football Algo jrpo Exp base_JRPO updates 7024/100000000000.0 steps in 79.72
total episode rewards is -40.0
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'value_loss': 0.2995273004223903, '_timestamp': 1721923900.2260275}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011956829200595773, '_timestamp': 1721923900.2261894}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8743614753087363, '_timestamp': 1721923900.2262568}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18631857633590698, '_timestamp': 1721923900.2263467}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3908520042896271, '_timestamp': 1721923900.2265697}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'ratio': 0.997628390789032, '_timestamp': 1721923900.2266688}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923900.2267983}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923900.2269976}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.71866178512573, '_timestamp': 1721923900.2270548}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923900.2358792}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923900.236404}).
wandb: WARNING (User provided step: 7024 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923900.236919}).
Env Football Algo jrpo Exp base_JRPO updates 4084/100000000000.0 steps in 51.81
total episode rewards is -120.0
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'value_loss': 0.7268782789508502, '_timestamp': 1721923952.0451813}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008516925666481257, '_timestamp': 1721923952.0454948}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.875469363530477, '_timestamp': 1721923952.0455863}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2514628767967224, '_timestamp': 1721923952.045704}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.250407338142395, '_timestamp': 1721923952.046003}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'ratio': 1.0003074407577515, '_timestamp': 1721923952.04613}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721923952.0463626}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923952.0471468}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.8068323135376, '_timestamp': 1721923952.0472121}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923952.047677}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923952.0479295}).
wandb: WARNING (User provided step: 4084 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923952.0481932}).
Env Football Algo jrpo Exp base_JRPO updates 3591/100000000000.0 steps in 62.74
total episode rewards is -110.0
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'value_loss': 0.7344865915427605, '_timestamp': 1721924014.7982981}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005455168225647261, '_timestamp': 1721924014.7994778}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8738651927312215, '_timestamp': 1721924014.7995486}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.25968027114868164, '_timestamp': 1721924014.800103}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0039345026016235, '_timestamp': 1721924014.8004608}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'ratio': 0.9988839030265808, '_timestamp': 1721924014.8005683}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721924014.800704}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924014.8008838}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'Episode_Time': 62.74453616142273, '_timestamp': 1721924014.802005}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924014.8030508}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924014.8035324}).
wandb: WARNING (User provided step: 3591 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924014.8039918}).
Env Football Algo jrpo Exp base_JRPO updates 2146/100000000000.0 steps in 55.32
total episode rewards is -30.0
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'value_loss': 0.5425252349860966, '_timestamp': 1721924070.1236145}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011616391297138762, '_timestamp': 1721924070.1238594}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8726805384953815, '_timestamp': 1721924070.123928}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23196826875209808, '_timestamp': 1721924070.1240454}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6446681022644043, '_timestamp': 1721924070.1243124}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'ratio': 0.9998076558113098, '_timestamp': 1721924070.1244185}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721924070.1246192}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924070.1252828}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.31845426559448, '_timestamp': 1721924070.1253438}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.045639403524627205, '_timestamp': 1721924070.1267715}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'train_goal': 0.5228197017623136, '_timestamp': 1721924070.1272013}).
wandb: WARNING (User provided step: 2146 is less than current step: 12016. Dropping entry: {'train_WDL': 0.045639403524627205, '_timestamp': 1721924070.1276293}).
Env Football Algo jrpo Exp base_JRPO updates 5857/100000000000.0 steps in 68.92
total episode rewards is -60.0
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'value_loss': 0.4896515674268206, '_timestamp': 1721924139.0524735}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007297364148350122, '_timestamp': 1721924139.052665}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874616837501526, '_timestamp': 1721924139.0527346}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24857386946678162, '_timestamp': 1721924139.0528371}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8591316938400269, '_timestamp': 1721924139.0531266}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'ratio': 1.0014359951019287, '_timestamp': 1721924139.0532353}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721924139.0542018}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924139.054305}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'Episode_Time': 68.92357516288757, '_timestamp': 1721924139.0543635}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924139.0549338}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924139.0553522}).
wandb: WARNING (User provided step: 5857 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924139.0557773}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'value_loss': 0.36367711930846175, '_timestamp': 1721924209.8585045}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005469742156565189, '_timestamp': 1721924209.858671}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8732138029734293, '_timestamp': 1721924209.8587358}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1951422095298767, '_timestamp': 1721924209.858832}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5551489591598511, '_timestamp': 1721924209.8590665}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'ratio': 0.9981294274330139, '_timestamp': 1721924209.859168}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721924209.859302}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924209.8595645}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'Episode_Time': 70.80191326141357, '_timestamp': 1721924209.859624}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924209.860265}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924209.8607082}).
wandb: WARNING (User provided step: 5500 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924209.8611908}).
Env Football Algo jrpo Exp base_JRPO updates 5500/100000000000.0 steps in 70.80
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 2367/100000000000.0 steps in 36.57
total episode rewards is -60.0
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'value_loss': 0.6161523241425554, '_timestamp': 1721924246.4367125}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006242741998285055, '_timestamp': 1721924246.4368906}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8695720799764, '_timestamp': 1721924246.4369588}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2625317871570587, '_timestamp': 1721924246.4370599}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8344077467918396, '_timestamp': 1721924246.4373305}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'ratio': 1.0037673711776733, '_timestamp': 1721924246.4379852}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721924246.438127}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924246.438223}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'Episode_Time': 36.57431650161743, '_timestamp': 1721924246.4382849}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.3505939689308559, '_timestamp': 1721924246.4387474}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'train_goal': 0.675296984465428, '_timestamp': 1721924246.4390256}).
wandb: WARNING (User provided step: 2367 is less than current step: 12016. Dropping entry: {'train_WDL': 0.3505939689308559, '_timestamp': 1721924246.4392836}).
Env Football Algo jrpo Exp base_JRPO updates 5707/100000000000.0 steps in 60.70
total episode rewards is -90.0
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'value_loss': 0.5253727669641376, '_timestamp': 1721924307.1389198}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006678759639520043, '_timestamp': 1721924307.1390975}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.867980275154114, '_timestamp': 1721924307.1391654}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2740342915058136, '_timestamp': 1721924307.1392643}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7625133395195007, '_timestamp': 1721924307.139508}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'ratio': 1.0013031959533691, '_timestamp': 1721924307.1396105}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721924307.1397445}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924307.139981}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'Episode_Time': 60.698782205581665, '_timestamp': 1721924307.1400452}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924307.1404567}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924307.140732}).
wandb: WARNING (User provided step: 5707 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924307.1410139}).
Env Football Algo jrpo Exp base_JRPO updates 6350/100000000000.0 steps in 86.46
total episode rewards is -20.0
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'value_loss': 0.29617006541540225, '_timestamp': 1721924393.6061897}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003000080605537126, '_timestamp': 1721924393.6063852}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873443806966146, '_timestamp': 1721924393.6064558}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19845061004161835, '_timestamp': 1721924393.6065521}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2926155626773834, '_timestamp': 1721924393.6068175}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'ratio': 0.9988414645195007, '_timestamp': 1721924393.6069422}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721924393.6074536}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924393.6075487}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.46431136131287, '_timestamp': 1721924393.6076071}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3160693641618497, '_timestamp': 1721924393.6084573}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'train_goal': 0.34196531791907514, '_timestamp': 1721924393.6089842}).
wandb: WARNING (User provided step: 6350 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3160693641618497, '_timestamp': 1721924393.609519}).
Env Football Algo jrpo Exp base_JRPO updates 7783/100000000000.0 steps in 83.24
total episode rewards is -30.0
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'value_loss': 0.19544723633987207, '_timestamp': 1721924476.848236}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0047527276451486, '_timestamp': 1721924476.8484204}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8665867122014363, '_timestamp': 1721924476.8484888}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16302645206451416, '_timestamp': 1721924476.848592}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3159404695034027, '_timestamp': 1721924476.8488503}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'ratio': 0.9994208216667175, '_timestamp': 1721924476.848952}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721924476.8490908}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924476.849566}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.23746514320374, '_timestamp': 1721924476.8496249}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924476.850264}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924476.8507335}).
wandb: WARNING (User provided step: 7783 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924476.8512108}).
Env Football Algo jrpo Exp base_JRPO updates 4417/100000000000.0 steps in 50.58
total episode rewards is -70.0
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'value_loss': 0.39171875541408857, '_timestamp': 1721924527.4353561}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006056724415830103, '_timestamp': 1721924527.4355314}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8687703736623127, '_timestamp': 1721924527.4355996}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20754516124725342, '_timestamp': 1721924527.435701}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6018198132514954, '_timestamp': 1721924527.4359715}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'ratio': 0.9995259642601013, '_timestamp': 1721924527.4360774}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721924527.4362218}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924527.4367814}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'Episode_Time': 50.58307766914368, '_timestamp': 1721924527.4368405}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924527.4372902}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924527.4375427}).
wandb: WARNING (User provided step: 4417 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924527.4377913}).
Env Football Algo jrpo Exp base_JRPO updates 3968/100000000000.0 steps in 45.43
total episode rewards is -140.0
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'value_loss': 0.830195598800977, '_timestamp': 1721924572.8673003}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'policy_loss': -0.000989402539562434, '_timestamp': 1721924572.867499}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8719835535685223, '_timestamp': 1721924572.8675663}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.291486918926239, '_timestamp': 1721924572.867664}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.345936894416809, '_timestamp': 1721924572.8678935}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'ratio': 0.9986347556114197, '_timestamp': 1721924572.8680177}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721924572.868238}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924572.8684442}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'Episode_Time': 45.42837858200073, '_timestamp': 1721924572.8685043}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924572.8689845}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924572.8691874}).
wandb: WARNING (User provided step: 3968 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924572.8694088}).
Env Football Algo jrpo Exp base_JRPO updates 6097/100000000000.0 steps in 67.87
total episode rewards is -60.0
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'value_loss': 0.4800951412444313, '_timestamp': 1721924640.7414339}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007908629062585533, '_timestamp': 1721924640.741608}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873664081891378, '_timestamp': 1721924640.741683}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.26216816902160645, '_timestamp': 1721924640.7417815}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9373069405555725, '_timestamp': 1721924640.742212}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'ratio': 1.0006321668624878, '_timestamp': 1721924640.7426147}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721924640.7428026}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924640.7428956}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.87094330787659, '_timestamp': 1721924640.7429612}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.14769594328475777, '_timestamp': 1721924640.743554}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_goal': 0.4261520283576211, '_timestamp': 1721924640.7441099}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_WDL': -0.14769594328475777, '_timestamp': 1721924640.744454}).
Env Football Algo jrpo Exp base_JRPO updates 6649/100000000000.0 steps in 85.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'value_loss': 0.26314406130928547, '_timestamp': 1721924725.9292514}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011817358196324979, '_timestamp': 1721924725.9295032}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.871536432902018, '_timestamp': 1721924725.9295735}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16103042662143707, '_timestamp': 1721924725.929674}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.21642442047595978, '_timestamp': 1721924725.9299753}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'ratio': 0.9988209009170532, '_timestamp': 1721924725.9300828}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721924725.930221}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924725.9307108}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.18315029144287, '_timestamp': 1721924725.930772}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924725.931432}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924725.931937}).
wandb: WARNING (User provided step: 6649 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924725.932476}).
Env Football Algo jrpo Exp base_JRPO updates 6423/100000000000.0 steps in 85.52
total episode rewards is -50.0
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'value_loss': 0.3013196170919885, '_timestamp': 1721924811.4546232}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'policy_loss': -0.014439178296403649, '_timestamp': 1721924811.4556446}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.877680481274923, '_timestamp': 1721924811.4557126}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14816667139530182, '_timestamp': 1721924811.4561977}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2352939397096634, '_timestamp': 1721924811.4565246}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'ratio': 0.9968140125274658, '_timestamp': 1721924811.4566267}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721924811.4569554}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924811.4571223}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.51689267158508, '_timestamp': 1721924811.4571807}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924811.4586122}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924811.4591217}).
wandb: WARNING (User provided step: 6423 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924811.4597445}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'value_loss': 0.5441919839009642, '_timestamp': 1721924849.095048}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009139781818181897, '_timestamp': 1721924849.0951943}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.878437457084656, '_timestamp': 1721924849.0952609}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2428392618894577, '_timestamp': 1721924849.09535}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2597525119781494, '_timestamp': 1721924849.0955763}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'ratio': 0.998043954372406, '_timestamp': 1721924849.0956755}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721924849.0958056}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924849.096023}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.63459229469299, '_timestamp': 1721924849.0960832}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.09818481848184818, '_timestamp': 1721924849.0963912}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'train_goal': 0.4509075907590759, '_timestamp': 1721924849.0966022}).
wandb: WARNING (User provided step: 3121 is less than current step: 12016. Dropping entry: {'train_WDL': -0.09818481848184818, '_timestamp': 1721924849.0968084}).
Env Football Algo jrpo Exp base_JRPO updates 3121/100000000000.0 steps in 37.63
total episode rewards is -50.0
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'value_loss': 0.6299465372537573, '_timestamp': 1721924911.1376693}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005455876167106907, '_timestamp': 1721924911.1378293}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8775610478719074, '_timestamp': 1721924911.1378973}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2506331205368042, '_timestamp': 1721924911.1379914}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.080227017402649, '_timestamp': 1721924911.1382418}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'ratio': 0.9992044568061829, '_timestamp': 1721924911.1388052}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721924911.138954}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924911.1390476}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'Episode_Time': 62.04010033607483, '_timestamp': 1721924911.1391065}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924911.139683}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924911.139994}).
wandb: WARNING (User provided step: 6690 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924911.1402779}).
Env Football Algo jrpo Exp base_JRPO updates 6690/100000000000.0 steps in 62.04
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 4223/100000000000.0 steps in 45.16
total episode rewards is -100.0
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'value_loss': 1.0620529980460802, '_timestamp': 1721924956.301359}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002149269840835283, '_timestamp': 1721924956.301517}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874121387799581, '_timestamp': 1721924956.3015854}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.27413687109947205, '_timestamp': 1721924956.3016815}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.5553719997406006, '_timestamp': 1721924956.301931}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'ratio': 0.9987546801567078, '_timestamp': 1721924956.3020425}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721924956.3021798}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924956.302272}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'Episode_Time': 45.16034460067749, '_timestamp': 1721924956.3027153}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721924956.3030581}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721924956.3032844}).
wandb: WARNING (User provided step: 4223 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721924956.3035011}).
Env Football Algo jrpo Exp base_JRPO updates 1272/100000000000.0 steps in 27.87
total episode rewards is -70.0
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'value_loss': 1.1314551504949728, '_timestamp': 1721924984.1735437}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003937968413811177, '_timestamp': 1721924984.173714}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.877204939524333, '_timestamp': 1721924984.173778}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2602303624153137, '_timestamp': 1721924984.173876}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.5612698793411255, '_timestamp': 1721924984.1741245}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'ratio': 0.9998078942298889, '_timestamp': 1721924984.1744072}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721924984.174545}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924984.1746333}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'Episode_Time': 27.86909508705139, '_timestamp': 1721924984.1746886}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.1339421613394216, '_timestamp': 1721924984.1750402}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'train_goal': 0.5669710806697108, '_timestamp': 1721924984.1752713}).
wandb: WARNING (User provided step: 1272 is less than current step: 12016. Dropping entry: {'train_WDL': 0.1339421613394216, '_timestamp': 1721924984.1755004}).
Env Football Algo jrpo Exp base_JRPO updates 6454/100000000000.0 steps in 84.77
total episode rewards is -20.0
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'value_loss': 0.2612872559577227, '_timestamp': 1721925068.9503272}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002378723833244294, '_timestamp': 1721925068.9504788}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.870948255856832, '_timestamp': 1721925068.9505463}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2046339362859726, '_timestamp': 1721925068.9506357}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.21932391822338104, '_timestamp': 1721925068.95087}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'ratio': 0.9994130730628967, '_timestamp': 1721925068.9509687}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925068.9511}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925068.9511888}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.77406930923462, '_timestamp': 1721925068.951245}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3016615960683361, '_timestamp': 1721925068.9518747}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'train_goal': 0.34916920196583195, '_timestamp': 1721925068.9523969}).
wandb: WARNING (User provided step: 6454 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3016615960683361, '_timestamp': 1721925068.9529061}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'value_loss': 0.32296557623893024, '_timestamp': 1721925155.173429}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010580736868749909, '_timestamp': 1721925155.1736097}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8728845914204917, '_timestamp': 1721925155.1736777}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17561818659305573, '_timestamp': 1721925155.1737795}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.293783575296402, '_timestamp': 1721925155.1740553}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'ratio': 0.996895968914032, '_timestamp': 1721925155.1747272}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721925155.1748788}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925155.1749806}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.21938419342041, '_timestamp': 1721925155.1750388}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925155.1756375}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925155.1762505}).
wandb: WARNING (User provided step: 8087 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925155.176694}).
Env Football Algo jrpo Exp base_JRPO updates 8087/100000000000.0 steps in 86.22
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 4666/100000000000.0 steps in 74.39
total episode rewards is -40.0
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'value_loss': 0.4798464533189932, '_timestamp': 1721925229.5697443}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009499384678347269, '_timestamp': 1721925229.5701494}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873765309651693, '_timestamp': 1721925229.5702186}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2197587639093399, '_timestamp': 1721925229.5704384}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6400279998779297, '_timestamp': 1721925229.570722}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'ratio': 0.9960132241249084, '_timestamp': 1721925229.5708258}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721925229.5712953}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925229.571415}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'Episode_Time': 74.39078116416931, '_timestamp': 1721925229.5714726}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.2886173462611237, '_timestamp': 1721925229.5723207}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'train_goal': 0.6443086731305618, '_timestamp': 1721925229.5727975}).
wandb: WARNING (User provided step: 4666 is less than current step: 12016. Dropping entry: {'train_WDL': 0.2886173462611237, '_timestamp': 1721925229.5732594}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'value_loss': 0.5115671471692622, '_timestamp': 1721925288.6054947}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011439874817830665, '_timestamp': 1721925288.6057186}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874095010757446, '_timestamp': 1721925288.6057832}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20050972700119019, '_timestamp': 1721925288.6058803}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9044487476348877, '_timestamp': 1721925288.6060843}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'ratio': 0.9999838471412659, '_timestamp': 1721925288.6063278}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721925288.606544}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925288.6066368}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'Episode_Time': 59.03141903877258, '_timestamp': 1721925288.6066947}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3373239436619718, '_timestamp': 1721925288.607484}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'train_goal': 0.3313380281690141, '_timestamp': 1721925288.6078596}).
wandb: WARNING (User provided step: 3795 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3373239436619718, '_timestamp': 1721925288.6082807}).
Env Football Algo jrpo Exp base_JRPO updates 3795/100000000000.0 steps in 59.03
total episode rewards is -70.0
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'value_loss': 0.4132888621743768, '_timestamp': 1721925365.0560822}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008045372031629085, '_timestamp': 1721925365.056339}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8762459723154703, '_timestamp': 1721925365.0564086}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21529142558574677, '_timestamp': 1721925365.0565095}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.549828827381134, '_timestamp': 1721925365.0567944}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'ratio': 0.9990686178207397, '_timestamp': 1721925365.056901}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721925365.057686}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925365.05779}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.44658303260803, '_timestamp': 1721925365.0578477}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925365.05849}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925365.0589833}).
wandb: WARNING (User provided step: 4575 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925365.0594602}).
Env Football Algo jrpo Exp base_JRPO updates 4575/100000000000.0 steps in 76.45
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 7485/100000000000.0 steps in 89.65
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'value_loss': 0.24859824104700237, '_timestamp': 1721925454.7066119}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010121620212254736, '_timestamp': 1721925454.7067876}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8726963154474894, '_timestamp': 1721925454.7068565}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19970405101776123, '_timestamp': 1721925454.706957}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.23922911286354065, '_timestamp': 1721925454.7072132}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'ratio': 0.9990172386169434, '_timestamp': 1721925454.7073147}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721925454.70779}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925454.7078867}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'Episode_Time': 89.64633274078369, '_timestamp': 1721925454.7079751}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925454.708889}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925454.7096756}).
wandb: WARNING (User provided step: 7485 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925454.7104888}).
total episode rewards is -40.0
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'value_loss': 0.28999069802152616, '_timestamp': 1721925534.990752}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007165388890231649, '_timestamp': 1721925534.9919689}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.875730487505595, '_timestamp': 1721925534.9920406}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19805438816547394, '_timestamp': 1721925534.9926145}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.290240615606308, '_timestamp': 1721925534.9929607}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'ratio': 0.9985222816467285, '_timestamp': 1721925534.9930654}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721925534.9932005}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925534.993412}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.27447772026062, '_timestamp': 1721925534.9934697}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.2605932203389831, '_timestamp': 1721925534.9946675}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'train_goal': 0.6302966101694916, '_timestamp': 1721925534.9952216}).
wandb: WARNING (User provided step: 5560 is less than current step: 12016. Dropping entry: {'train_WDL': 0.2605932203389831, '_timestamp': 1721925534.9957712}).
Env Football Algo jrpo Exp base_JRPO updates 5560/100000000000.0 steps in 80.27
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 5931/100000000000.0 steps in 87.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'value_loss': 0.26750105497427284, '_timestamp': 1721925622.2388334}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010167130639504952, '_timestamp': 1721925622.2389827}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8699408706029255, '_timestamp': 1721925622.2390468}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17505505681037903, '_timestamp': 1721925622.2391331}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.17482224106788635, '_timestamp': 1721925622.2393556}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'ratio': 0.9982677698135376, '_timestamp': 1721925622.2395551}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721925622.239678}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925622.2397616}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.24232006072998, '_timestamp': 1721925622.239818}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925622.2404437}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925622.240959}).
wandb: WARNING (User provided step: 5931 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925622.2415025}).
Env Football Algo jrpo Exp base_JRPO updates 7659/100000000000.0 steps in 77.75
total episode rewards is -60.0
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'value_loss': 0.36479040219448505, '_timestamp': 1721925699.9956274}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011731486450104663, '_timestamp': 1721925699.9958057}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.869566437403361, '_timestamp': 1721925699.9958751}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1921304166316986, '_timestamp': 1721925699.9959807}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4506445825099945, '_timestamp': 1721925699.996237}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'ratio': 0.999820351600647, '_timestamp': 1721925699.9963415}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721925699.996744}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925699.9968364}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'Episode_Time': 77.75332474708557, '_timestamp': 1721925699.9968958}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925699.9973607}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925699.9977403}).
wandb: WARNING (User provided step: 7659 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925699.9983122}).
Env Football Algo jrpo Exp base_JRPO updates 4870/100000000000.0 steps in 77.09
total episode rewards is -70.0
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'value_loss': 0.4178241670752565, '_timestamp': 1721925777.090542}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009602633069735021, '_timestamp': 1721925777.0907135}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866589077313741, '_timestamp': 1721925777.090781}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21025243401527405, '_timestamp': 1721925777.0908756}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6526200175285339, '_timestamp': 1721925777.0911188}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'ratio': 0.9991323947906494, '_timestamp': 1721925777.0912216}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721925777.0917885}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925777.0918844}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'Episode_Time': 77.09139704704285, '_timestamp': 1721925777.091942}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925777.092598}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925777.0931172}).
wandb: WARNING (User provided step: 4870 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925777.0936532}).
Env Football Algo jrpo Exp base_JRPO updates 9095/100000000000.0 steps in 83.79
total episode rewards is -40.0
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'value_loss': 0.22995848446153105, '_timestamp': 1721925860.8815064}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'policy_loss': -0.011345876623721173, '_timestamp': 1721925860.8816648}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.864815107981364, '_timestamp': 1721925860.881732}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.162288099527359, '_timestamp': 1721925860.8818252}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.14433321356773376, '_timestamp': 1721925860.8820574}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'ratio': 0.997890830039978, '_timestamp': 1721925860.8821623}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721925860.8824732}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925860.8825638}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.7869508266449, '_timestamp': 1721925860.8826292}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925860.8831248}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925860.8835084}).
wandb: WARNING (User provided step: 9095 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925860.8838954}).
Env Football Algo jrpo Exp base_JRPO updates 5056/100000000000.0 steps in 85.98
total episode rewards is -20.0
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'value_loss': 0.2546134512685239, '_timestamp': 1721925946.8617926}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007041497688236025, '_timestamp': 1721925946.8620229}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8651749308904013, '_timestamp': 1721925946.8620918}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1784961223602295, '_timestamp': 1721925946.8621986}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.24178723990917206, '_timestamp': 1721925946.8624735}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'ratio': 0.9993782043457031, '_timestamp': 1721925946.8625817}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925946.8630054}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925946.8631024}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.97673225402832, '_timestamp': 1721925946.863161}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3992357200321802, '_timestamp': 1721925946.864095}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'train_goal': 0.3003821399839099, '_timestamp': 1721925946.8647192}).
wandb: WARNING (User provided step: 5056 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3992357200321802, '_timestamp': 1721925946.8653722}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'value_loss': 0.22092853783319394, '_timestamp': 1721926032.073248}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010342143090286603, '_timestamp': 1721926032.0744727}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.863249977429708, '_timestamp': 1721926032.0745459}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1788358837366104, '_timestamp': 1721926032.0751219}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3361336886882782, '_timestamp': 1721926032.0754716}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'ratio': 0.9957841038703918, '_timestamp': 1721926032.0755756}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721926032.0764394}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926032.0766346}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.20181226730347, '_timestamp': 1721926032.0766914}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.24201380015333504, '_timestamp': 1721926032.07785}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'train_goal': 0.37899309992333247, '_timestamp': 1721926032.078357}).
wandb: WARNING (User provided step: 7174 is less than current step: 12016. Dropping entry: {'train_WDL': -0.24201380015333504, '_timestamp': 1721926032.0788534}).
Env Football Algo jrpo Exp base_JRPO updates 7174/100000000000.0 steps in 85.20
total episode rewards is -10.0
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'value_loss': 0.48627189796728393, '_timestamp': 1721926098.5872731}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'policy_loss': -0.01142073192660367, '_timestamp': 1721926098.5874438}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8672005716959634, '_timestamp': 1721926098.5875144}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22324295341968536, '_timestamp': 1721926098.587613}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7081003785133362, '_timestamp': 1721926098.5878794}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'ratio': 0.9971583485603333, '_timestamp': 1721926098.5880153}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721926098.5884347}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926098.5885315}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'Episode_Time': 66.50737071037292, '_timestamp': 1721926098.5885906}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.10642895732036736, '_timestamp': 1721926098.5890517}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'train_goal': 0.5532144786601837, '_timestamp': 1721926098.5894258}).
wandb: WARNING (User provided step: 6743 is less than current step: 12016. Dropping entry: {'train_WDL': 0.10642895732036736, '_timestamp': 1721926098.5897202}).
Env Football Algo jrpo Exp base_JRPO updates 6743/100000000000.0 steps in 66.51
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 4574/100000000000.0 steps in 88.87
total episode rewards is -20.0
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'value_loss': 0.2724227563710883, '_timestamp': 1721926187.4601352}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0030990768770182814, '_timestamp': 1721926187.460316}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.865205683708191, '_timestamp': 1721926187.4603853}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21341416239738464, '_timestamp': 1721926187.4604862}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2536197304725647, '_timestamp': 1721926187.460786}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'ratio': 0.9992265105247498, '_timestamp': 1721926187.4608927}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721926187.4618196}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926187.4619262}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.8691418170929, '_timestamp': 1721926187.4619873}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4287358526760023, '_timestamp': 1721926187.462828}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'train_goal': 0.28563207366199883, '_timestamp': 1721926187.463499}).
wandb: WARNING (User provided step: 4574 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4287358526760023, '_timestamp': 1721926187.4642384}).
Env Football Algo jrpo Exp base_JRPO updates 4350/100000000000.0 steps in 57.57
total episode rewards is -80.0
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'value_loss': 0.478046692982316, '_timestamp': 1721926245.036766}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00853217147445927, '_timestamp': 1721926245.037004}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866511888504028, '_timestamp': 1721926245.0370696}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21640406548976898, '_timestamp': 1721926245.0371668}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.674676239490509, '_timestamp': 1721926245.0374105}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'ratio': 0.9986685514450073, '_timestamp': 1721926245.037513}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721926245.0379066}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926245.0380013}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'Episode_Time': 57.57144737243652, '_timestamp': 1721926245.038058}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926245.0386178}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926245.0389497}).
wandb: WARNING (User provided step: 4350 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926245.0392904}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'value_loss': 0.6258707839498917, '_timestamp': 1721926292.3141136}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005763018395518884, '_timestamp': 1721926292.3143687}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8628627840677896, '_timestamp': 1721926292.3144383}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24566437304019928, '_timestamp': 1721926292.3145416}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.101232886314392, '_timestamp': 1721926292.3148184}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'ratio': 0.9976938366889954, '_timestamp': 1721926292.314934}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721926292.3158364}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926292.3159566}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'Episode_Time': 47.27334117889404, '_timestamp': 1721926292.3160174}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926292.3167326}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926292.317034}).
wandb: WARNING (User provided step: 2869 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926292.3173594}).
Env Football Algo jrpo Exp base_JRPO updates 2869/100000000000.0 steps in 47.27
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 2526/100000000000.0 steps in 35.13
total episode rewards is -130.0
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'value_loss': 0.9127495290338993, '_timestamp': 1721926327.4462805}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006655593382117028, '_timestamp': 1721926327.4465392}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.862998692194621, '_timestamp': 1721926327.4466045}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.25903549790382385, '_timestamp': 1721926327.4467018}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2501822710037231, '_timestamp': 1721926327.4469879}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'ratio': 0.9990573525428772, '_timestamp': 1721926327.4472523}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721926327.447565}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926327.4476595}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'Episode_Time': 35.127817153930664, '_timestamp': 1721926327.4477177}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.21000396982929734, '_timestamp': 1721926327.4485}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'train_goal': 0.3949980150853513, '_timestamp': 1721926327.4487202}).
wandb: WARNING (User provided step: 2526 is less than current step: 12016. Dropping entry: {'train_WDL': -0.21000396982929734, '_timestamp': 1721926327.4489331}).
Env Football Algo jrpo Exp base_JRPO updates 4643/100000000000.0 steps in 55.79
total episode rewards is -90.0
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'value_loss': 0.9352768344183763, '_timestamp': 1721926383.2425373}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0051010257269566255, '_timestamp': 1721926383.243879}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8648071320851645, '_timestamp': 1721926383.2440157}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2719908356666565, '_timestamp': 1721926383.2446544}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.6637542247772217, '_timestamp': 1721926383.2450652}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'ratio': 1.0014511346817017, '_timestamp': 1721926383.2456558}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721926383.245822}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926383.2460217}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.787354946136475, '_timestamp': 1721926383.2460835}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926383.2470963}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926383.247458}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926383.2478192}).
Env Football Algo jrpo Exp base_JRPO updates 3241/100000000000.0 steps in 41.73
total episode rewards is -140.0
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'value_loss': 0.8401602257788181, '_timestamp': 1721926424.9828358}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006527293928447761, '_timestamp': 1721926424.9829874}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866064650217692, '_timestamp': 1721926424.9830515}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2551853060722351, '_timestamp': 1721926424.9831436}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.7736059427261353, '_timestamp': 1721926424.9833598}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'ratio': 0.9978094696998596, '_timestamp': 1721926424.9834626}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721926424.983739}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926424.9838252}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'Episode_Time': 41.73424553871155, '_timestamp': 1721926424.9838827}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926424.9842348}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926424.9844718}).
wandb: WARNING (User provided step: 3241 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926424.9847121}).
Env Football Algo jrpo Exp base_JRPO updates 6107/100000000000.0 steps in 73.79
total episode rewards is -100.0
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'value_loss': 0.6013349267840385, '_timestamp': 1721926498.7747831}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00946624630363658, '_timestamp': 1721926498.7749443}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8657205788294475, '_timestamp': 1721926498.7750113}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24262045323848724, '_timestamp': 1721926498.7751086}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7827794551849365, '_timestamp': 1721926498.7753482}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'ratio': 1.0005435943603516, '_timestamp': 1721926498.7754478}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721926498.7755852}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926498.7756774}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'Episode_Time': 73.78932547569275, '_timestamp': 1721926498.7759356}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926498.7765002}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926498.7769241}).
wandb: WARNING (User provided step: 6107 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926498.7773533}).
Env Football Algo jrpo Exp base_JRPO updates 6892/100000000000.0 steps in 84.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'value_loss': 0.26534851532429454, '_timestamp': 1721926583.2364368}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00541219990584068, '_timestamp': 1721926583.2365868}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866876177787781, '_timestamp': 1721926583.2366517}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.27035078406333923, '_timestamp': 1721926583.2367435}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.26106077432632446, '_timestamp': 1721926583.2371264}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'ratio': 1.0016403198242188, '_timestamp': 1721926583.237231}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721926583.237357}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926583.2374423}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.45834708213806, '_timestamp': 1721926583.237499}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926583.2380812}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926583.2385547}).
wandb: WARNING (User provided step: 6892 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926583.2390504}).
Env Football Algo jrpo Exp base_JRPO updates 7375/100000000000.0 steps in 80.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'value_loss': 0.2593687948087851, '_timestamp': 1721926663.828431}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005383274471969343, '_timestamp': 1721926663.8285818}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8655889336268108, '_timestamp': 1721926663.828647}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21939557790756226, '_timestamp': 1721926663.8287382}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.20444722473621368, '_timestamp': 1721926663.8289766}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'ratio': 0.9991499781608582, '_timestamp': 1721926663.829078}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721926663.8293352}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926663.8294263}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.58867335319519, '_timestamp': 1721926663.829485}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926663.8300326}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926663.8304844}).
wandb: WARNING (User provided step: 7375 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926663.8309567}).
Env Football Algo jrpo Exp base_JRPO updates 3741/100000000000.0 steps in 65.38
total episode rewards is -40.0
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'value_loss': 0.3843907476092378, '_timestamp': 1721926729.2095497}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007892587734386326, '_timestamp': 1721926729.2097325}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8656384642918904, '_timestamp': 1721926729.209812}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21490859985351562, '_timestamp': 1721926729.2099159}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5619300603866577, '_timestamp': 1721926729.2109292}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'ratio': 1.0001370906829834, '_timestamp': 1721926729.2110415}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721926729.2111802}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926729.2112784}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'Episode_Time': 65.37746691703796, '_timestamp': 1721926729.2113395}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.40318844529227416, '_timestamp': 1721926729.2120018}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_goal': 0.2984057773538629, '_timestamp': 1721926729.212481}).
wandb: WARNING (User provided step: 3741 is less than current step: 12016. Dropping entry: {'train_WDL': -0.40318844529227416, '_timestamp': 1721926729.2129438}).
Env Football Algo jrpo Exp base_JRPO updates 2742/100000000000.0 steps in 34.86
total episode rewards is -120.0
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'value_loss': 0.8124690075715383, '_timestamp': 1721926764.076528}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005705228955484927, '_timestamp': 1721926764.0766842}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.869095648129781, '_timestamp': 1721926764.0767496}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.261491596698761, '_timestamp': 1721926764.0768418}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2979543209075928, '_timestamp': 1721926764.0770702}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'ratio': 1.0008924007415771, '_timestamp': 1721926764.0771718}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721926764.077427}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926764.0775146}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.8627769947052, '_timestamp': 1721926764.0775733}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.18923465096719932, '_timestamp': 1721926764.0778615}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'train_goal': 0.4053826745164003, '_timestamp': 1721926764.078066}).
wandb: WARNING (User provided step: 2742 is less than current step: 12016. Dropping entry: {'train_WDL': -0.18923465096719932, '_timestamp': 1721926764.0782666}).
Env Football Algo jrpo Exp base_JRPO updates 6097/100000000000.0 steps in 87.97
total episode rewards is -40.0
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'value_loss': 0.27720246895526846, '_timestamp': 1721926852.0516257}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00779338816801707, '_timestamp': 1721926852.051785}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.87321008682251, '_timestamp': 1721926852.0518527}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18519340455532074, '_timestamp': 1721926852.0519578}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.21930812299251556, '_timestamp': 1721926852.0522146}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'ratio': 1.0002774000167847, '_timestamp': 1721926852.0524826}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721926852.0526218}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926852.052712}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.9674642086029, '_timestamp': 1721926852.0527709}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926852.0534563}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926852.0539703}).
wandb: WARNING (User provided step: 6097 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926852.054507}).
Env Football Algo jrpo Exp base_JRPO updates 9566/100000000000.0 steps in 82.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'value_loss': 0.24858354286601145, '_timestamp': 1721926934.23235}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0074202647409401835, '_timestamp': 1721926934.232505}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873692437807719, '_timestamp': 1721926934.232571}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17654839158058167, '_timestamp': 1721926934.2326627}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3142840266227722, '_timestamp': 1721926934.2328997}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'ratio': 1.0011234283447266, '_timestamp': 1721926934.2331123}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721926934.233248}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926934.233338}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.17709851264954, '_timestamp': 1721926934.233398}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926934.2339435}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926934.2342958}).
wandb: WARNING (User provided step: 9566 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926934.2347612}).
Env Football Algo jrpo Exp base_JRPO updates 3958/100000000000.0 steps in 50.21
total episode rewards is -60.0
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'value_loss': 0.47628229461610316, '_timestamp': 1721926984.4423292}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004762505379815896, '_timestamp': 1721926984.4425926}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8723961162567138, '_timestamp': 1721926984.442661}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2248411327600479, '_timestamp': 1721926984.4427652}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7974379658699036, '_timestamp': 1721926984.443119}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'ratio': 0.9984248876571655, '_timestamp': 1721926984.4432256}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721926984.4438465}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926984.443964}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'Episode_Time': 50.206419229507446, '_timestamp': 1721926984.4440255}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.20423108218063465, '_timestamp': 1721926984.4447443}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'train_goal': 0.39788445890968266, '_timestamp': 1721926984.445135}).
wandb: WARNING (User provided step: 3958 is less than current step: 12016. Dropping entry: {'train_WDL': -0.20423108218063465, '_timestamp': 1721926984.4454303}).
Env Football Algo jrpo Exp base_JRPO updates 3576/100000000000.0 steps in 39.43
total episode rewards is -90.0
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'value_loss': 0.6489725188910961, '_timestamp': 1721927023.8809001}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00756117732070076, '_timestamp': 1721927023.8811038}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.873857865333557, '_timestamp': 1721927023.881172}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21552343666553497, '_timestamp': 1721927023.8812683}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.09883451461792, '_timestamp': 1721927023.88152}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'ratio': 0.996635377407074, '_timestamp': 1721927023.8817735}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721927023.8819308}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927023.8820217}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'Episode_Time': 39.43454837799072, '_timestamp': 1721927023.8820791}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927023.8825269}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927023.8827422}).
wandb: WARNING (User provided step: 3576 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927023.8830507}).
Env Football Algo jrpo Exp base_JRPO updates 4377/100000000000.0 steps in 49.72
total episode rewards is -140.0
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'value_loss': 0.7947775729869803, '_timestamp': 1721927073.6000764}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006582921093601423, '_timestamp': 1721927073.6002488}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8732564544677732, '_timestamp': 1721927073.6003146}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2350601702928543, '_timestamp': 1721927073.6004107}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.49830961227417, '_timestamp': 1721927073.600906}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'ratio': 1.0020101070404053, '_timestamp': 1721927073.6011374}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721927073.6012807}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927073.6013722}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'Episode_Time': 49.71597242355347, '_timestamp': 1721927073.6014287}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927073.6017914}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927073.6020463}).
wandb: WARNING (User provided step: 4377 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927073.6022973}).
Env Football Algo jrpo Exp base_JRPO updates 5557/100000000000.0 steps in 76.77
total episode rewards is -60.0
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'value_loss': 0.49800885358204444, '_timestamp': 1721927150.3761122}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00038381321685543903, '_timestamp': 1721927150.3762589}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.877304377555847, '_timestamp': 1721927150.3763244}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2111150175333023, '_timestamp': 1721927150.3764117}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6490945219993591, '_timestamp': 1721927150.3766277}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'ratio': 1.001893401145935, '_timestamp': 1721927150.3768241}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721927150.3769557}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927150.3770428}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.77315998077393, '_timestamp': 1721927150.377099}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927150.3776548}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927150.3781269}).
wandb: WARNING (User provided step: 5557 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927150.3787737}).
Env Football Algo jrpo Exp base_JRPO updates 5546/100000000000.0 steps in 87.70
total episode rewards is -50.0
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'value_loss': 0.4199776475162556, '_timestamp': 1721927238.0767064}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0022535589438242216, '_timestamp': 1721927238.0769339}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8729577747980755, '_timestamp': 1721927238.0770023}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18543407320976257, '_timestamp': 1721927238.077107}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5268726348876953, '_timestamp': 1721927238.0773742}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'ratio': 1.0002259016036987, '_timestamp': 1721927238.0777748}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721927238.0779245}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927238.0780194}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.69677233695984, '_timestamp': 1721927238.0780776}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3517911628432591, '_timestamp': 1721927238.0792046}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'train_goal': 0.3241044185783704, '_timestamp': 1721927238.0797968}).
wandb: WARNING (User provided step: 5546 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3517911628432591, '_timestamp': 1721927238.0805945}).
Env Football Algo jrpo Exp base_JRPO updates 6550/100000000000.0 steps in 72.52
total episode rewards is -60.0
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'value_loss': 0.3709816031887506, '_timestamp': 1721927310.6059663}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004933920364736271, '_timestamp': 1721927310.6061442}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.874731327692668, '_timestamp': 1721927310.6062098}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1652241349220276, '_timestamp': 1721927310.606321}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.47537121176719666, '_timestamp': 1721927310.6066058}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'ratio': 0.9974712133407593, '_timestamp': 1721927310.6067095}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721927310.607093}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927310.6071885}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.52433228492737, '_timestamp': 1721927310.607245}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927310.6079257}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927310.6083782}).
wandb: WARNING (User provided step: 6550 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927310.6089828}).
Env Football Algo jrpo Exp base_JRPO updates 6458/100000000000.0 steps in 82.19
total episode rewards is -60.0
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'value_loss': 0.3637145450625879, '_timestamp': 1721927392.799696}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0011817776746950888, '_timestamp': 1721927392.7998705}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8695494683583576, '_timestamp': 1721927392.7999387}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17866387963294983, '_timestamp': 1721927392.800059}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.558605432510376, '_timestamp': 1721927392.8003192}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'ratio': 0.9998833537101746, '_timestamp': 1721927392.800423}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721927392.800558}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927392.8006477}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.18941760063171, '_timestamp': 1721927392.8007064}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927392.8013117}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927392.8017354}).
wandb: WARNING (User provided step: 6458 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927392.8021457}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'value_loss': 0.6549339717129866, '_timestamp': 1721927431.160674}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0003152424030122347, '_timestamp': 1721927431.1620522}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.864941207567851, '_timestamp': 1721927431.162125}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20802412927150726, '_timestamp': 1721927431.1627762}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.179303765296936, '_timestamp': 1721927431.1631787}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'ratio': 0.9997310638427734, '_timestamp': 1721927431.16329}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721927431.164119}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927431.164351}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'Episode_Time': 38.352049827575684, '_timestamp': 1721927431.1644094}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.029143105698129623, '_timestamp': 1721927431.1653645}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'train_goal': 0.4854284471509352, '_timestamp': 1721927431.1655965}).
wandb: WARNING (User provided step: 3406 is less than current step: 12016. Dropping entry: {'train_WDL': -0.029143105698129623, '_timestamp': 1721927431.1658204}).
Env Football Algo jrpo Exp base_JRPO updates 3406/100000000000.0 steps in 38.35
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 2171/100000000000.0 steps in 39.47
total episode rewards is -120.0
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'value_loss': 0.8061604008016487, '_timestamp': 1721927470.633403}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0006552291572249184, '_timestamp': 1721927470.6336505}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8607839266459147, '_timestamp': 1721927470.6337185}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2423935830593109, '_timestamp': 1721927470.6338155}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.4586280584335327, '_timestamp': 1721927470.6340802}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'ratio': 0.9997984766960144, '_timestamp': 1721927470.6341813}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721927470.6347702}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927470.634869}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'Episode_Time': 39.46668362617493, '_timestamp': 1721927470.6349287}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927470.6354969}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927470.6357138}).
wandb: WARNING (User provided step: 2171 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927470.6359267}).
Env Football Algo jrpo Exp base_JRPO updates 3938/100000000000.0 steps in 44.17
total episode rewards is -140.0
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'value_loss': 0.8192455058296522, '_timestamp': 1721927514.8064082}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004122118510810348, '_timestamp': 1721927514.8065722}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.857482735315959, '_timestamp': 1721927514.8066394}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24104240536689758, '_timestamp': 1721927514.8067338}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.16902494430542, '_timestamp': 1721927514.806988}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'ratio': 1.0004974603652954, '_timestamp': 1721927514.8070905}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721927514.8075302}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927514.8076265}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.169360876083374, '_timestamp': 1721927514.8076844}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927514.8080258}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927514.8082364}).
wandb: WARNING (User provided step: 3938 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927514.8084426}).
Env Football Algo jrpo Exp base_JRPO updates 6230/100000000000.0 steps in 91.56
total episode rewards is -20.0
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'value_loss': 0.26489859756703177, '_timestamp': 1721927606.3703902}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007691279616362105, '_timestamp': 1721927606.37061}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8613357146581015, '_timestamp': 1721927606.3706794}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19747011363506317, '_timestamp': 1721927606.3707786}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.29032328724861145, '_timestamp': 1721927606.3710406}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'ratio': 1.0001665353775024, '_timestamp': 1721927606.371143}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721927606.371792}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927606.3718896}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.56090950965881, '_timestamp': 1721927606.3719656}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3183580387685291, '_timestamp': 1721927606.3727453}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'train_goal': 0.34082098061573546, '_timestamp': 1721927606.3734643}).
wandb: WARNING (User provided step: 6230 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3183580387685291, '_timestamp': 1721927606.374084}).
Env Football Algo jrpo Exp base_JRPO updates 4020/100000000000.0 steps in 43.95
total episode rewards is -80.0
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'value_loss': 0.6583887001685799, '_timestamp': 1721927650.3254817}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004020165839077284, '_timestamp': 1721927650.3256364}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8627586523691813, '_timestamp': 1721927650.3257036}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2107083648443222, '_timestamp': 1721927650.325797}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9782489538192749, '_timestamp': 1721927650.3260353}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'ratio': 1.0003741979599, '_timestamp': 1721927650.3262584}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721927650.326388}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927650.3264735}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'Episode_Time': 43.95042681694031, '_timestamp': 1721927650.3265293}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.1776536312849162, '_timestamp': 1721927650.326907}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'train_goal': 0.4111731843575419, '_timestamp': 1721927650.327165}).
wandb: WARNING (User provided step: 4020 is less than current step: 12016. Dropping entry: {'train_WDL': -0.1776536312849162, '_timestamp': 1721927650.3274267}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'value_loss': 0.7498210904250542, '_timestamp': 1721927703.3840833}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00870396010344848, '_timestamp': 1721927703.3842463}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8630747763315836, '_timestamp': 1721927703.3843122}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20003406703472137, '_timestamp': 1721927703.3844068}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0071942806243896, '_timestamp': 1721927703.3846579}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'ratio': 0.998043954372406, '_timestamp': 1721927703.3847585}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721927703.3850398}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927703.3851311}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'Episode_Time': 53.055702447891235, '_timestamp': 1721927703.3851874}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927703.3854961}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927703.385706}).
wandb: WARNING (User provided step: 4255 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927703.3859093}).
Env Football Algo jrpo Exp base_JRPO updates 4255/100000000000.0 steps in 53.06
total episode rewards is -100.0
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'value_loss': 0.2490501708847781, '_timestamp': 1721927785.7515593}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00315588100561096, '_timestamp': 1721927785.7517195}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8576410881678265, '_timestamp': 1721927785.751783}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21665433049201965, '_timestamp': 1721927785.751874}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2136830985546112, '_timestamp': 1721927785.7522476}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'ratio': 0.9988505244255066, '_timestamp': 1721927785.7523518}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721927785.752488}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927785.7525783}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.3649275302887, '_timestamp': 1721927785.7526355}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927785.753294}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927785.753821}).
wandb: WARNING (User provided step: 5960 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927785.7544034}).
Env Football Algo jrpo Exp base_JRPO updates 5960/100000000000.0 steps in 82.36
total episode rewards is -40.0
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'value_loss': 0.3857609366066754, '_timestamp': 1721927859.8873277}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0075882824564663075, '_timestamp': 1721927859.8874962}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8417674907048545, '_timestamp': 1721927859.8875604}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19075624644756317, '_timestamp': 1721927859.887655}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.39726346731185913, '_timestamp': 1721927859.8878696}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'ratio': 0.9985213279724121, '_timestamp': 1721927859.8879988}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721927859.8883026}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927859.8883944}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'Episode_Time': 74.13212943077087, '_timestamp': 1721927859.888451}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4518418384589388, '_timestamp': 1721927859.8891313}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'train_goal': 0.27407908077053056, '_timestamp': 1721927859.8896554}).
wandb: WARNING (User provided step: 3483 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4518418384589388, '_timestamp': 1721927859.8901882}).
Env Football Algo jrpo Exp base_JRPO updates 3483/100000000000.0 steps in 74.13
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8223/100000000000.0 steps in 93.58
total episode rewards is -40.0
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'value_loss': 0.2547076936904341, '_timestamp': 1721927953.4679172}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006112586907693185, '_timestamp': 1721927953.4681025}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8465116882324217, '_timestamp': 1721927953.4681702}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17385165393352509, '_timestamp': 1721927953.468274}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.25623100996017456, '_timestamp': 1721927953.46851}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'ratio': 0.9991288781166077, '_timestamp': 1721927953.4686105}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721927953.4689815}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927953.469079}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'Episode_Time': 93.57669639587402, '_timestamp': 1721927953.469148}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927953.46985}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927953.4704683}).
wandb: WARNING (User provided step: 8223 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927953.4709563}).
Env Football Algo jrpo Exp base_JRPO updates 4619/100000000000.0 steps in 83.28
total episode rewards is 0.0
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'value_loss': 0.2667085765923063, '_timestamp': 1721928036.7489016}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004388153185136617, '_timestamp': 1721928036.7490833}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8410158077875773, '_timestamp': 1721928036.7491517}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1925128698348999, '_timestamp': 1721928036.7492523}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.24031169712543488, '_timestamp': 1721928036.7495062}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'ratio': 1.0000531673431396, '_timestamp': 1721928036.7496102}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721928036.7497554}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928036.7498481}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.27668404579163, '_timestamp': 1721928036.749905}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.1409305461901551, '_timestamp': 1721928036.7506895}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'train_goal': 0.5704652730950776, '_timestamp': 1721928036.7512858}).
wandb: WARNING (User provided step: 4619 is less than current step: 12016. Dropping entry: {'train_WDL': 0.1409305461901551, '_timestamp': 1721928036.7518806}).
Env Football Algo jrpo Exp base_JRPO updates 8147/100000000000.0 steps in 88.08
total episode rewards is -40.0
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'value_loss': 0.2547574641555548, '_timestamp': 1721928124.8342865}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005376646211079788, '_timestamp': 1721928124.834457}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.835286250114441, '_timestamp': 1721928124.8345227}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17537172138690948, '_timestamp': 1721928124.8346202}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2561035454273224, '_timestamp': 1721928124.8348744}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'ratio': 1.000744342803955, '_timestamp': 1721928124.8349767}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928124.8353405}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928124.8354344}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.08141040802002, '_timestamp': 1721928124.8354926}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928124.8361409}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928124.8367317}).
wandb: WARNING (User provided step: 8147 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928124.837174}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'value_loss': 0.5963002253696322, '_timestamp': 1721928180.3586195}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005630087079868342, '_timestamp': 1721928180.359472}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8325615803400677, '_timestamp': 1721928180.3595443}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21629321575164795, '_timestamp': 1721928180.3599808}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8246431946754456, '_timestamp': 1721928180.3603249}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'ratio': 1.0019088983535767, '_timestamp': 1721928180.360431}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721928180.3613155}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928180.3614838}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.517418384552, '_timestamp': 1721928180.3615453}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3576760137179746, '_timestamp': 1721928180.362609}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'train_goal': 0.32116199314101274, '_timestamp': 1721928180.362995}).
wandb: WARNING (User provided step: 3043 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3576760137179746, '_timestamp': 1721928180.36336}).
Env Football Algo jrpo Exp base_JRPO updates 3043/100000000000.0 steps in 55.52
total episode rewards is -60.0
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'value_loss': 0.3991639185200135, '_timestamp': 1721928252.5522206}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0026054571192556373, '_timestamp': 1721928252.5523713}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8268310038248696, '_timestamp': 1721928252.5524378}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1993541717529297, '_timestamp': 1721928252.552532}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6210230588912964, '_timestamp': 1721928252.5527704}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'ratio': 1.000813364982605, '_timestamp': 1721928252.5528724}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721928252.5532262}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928252.5533156}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.18812298774719, '_timestamp': 1721928252.553372}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928252.553853}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928252.5542185}).
wandb: WARNING (User provided step: 7676 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928252.554597}).
Env Football Algo jrpo Exp base_JRPO updates 7676/100000000000.0 steps in 72.19
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 6566/100000000000.0 steps in 85.02
total episode rewards is -40.0
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'value_loss': 0.3657264125222961, '_timestamp': 1721928337.5717957}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004104472249843336, '_timestamp': 1721928337.5719578}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.823259784380595, '_timestamp': 1721928337.5720232}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1955558806657791, '_timestamp': 1721928337.572111}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.453946590423584, '_timestamp': 1721928337.5723467}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'ratio': 0.9999497532844543, '_timestamp': 1721928337.5724452}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928337.572749}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928337.5728436}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.01616549491882, '_timestamp': 1721928337.5729015}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.24268360022087246, '_timestamp': 1721928337.573441}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'train_goal': 0.3786581998895638, '_timestamp': 1721928337.5738757}).
wandb: WARNING (User provided step: 6566 is less than current step: 12016. Dropping entry: {'train_WDL': -0.24268360022087246, '_timestamp': 1721928337.5743153}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'value_loss': 0.48485917765647174, '_timestamp': 1721928402.8943152}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'policy_loss': 0.001290718106708179, '_timestamp': 1721928402.894468}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.830366849899292, '_timestamp': 1721928402.8945324}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2119734138250351, '_timestamp': 1721928402.8946233}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7164009809494019, '_timestamp': 1721928402.8948085}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'ratio': 0.9986811280250549, '_timestamp': 1721928402.8950105}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928402.895132}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928402.8952236}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'Episode_Time': 65.31888842582703, '_timestamp': 1721928402.8952806}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.7005368098159509, '_timestamp': 1721928402.8959227}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'train_goal': 0.8502684049079755, '_timestamp': 1721928402.896271}).
wandb: WARNING (User provided step: 6064 is less than current step: 12016. Dropping entry: {'train_WDL': 0.7005368098159509, '_timestamp': 1721928402.8966074}).
Env Football Algo jrpo Exp base_JRPO updates 6064/100000000000.0 steps in 65.32
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 3786/100000000000.0 steps in 59.20
total episode rewards is -90.0
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'value_loss': 0.5468854981660843, '_timestamp': 1721928462.0973697}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005740309913332264, '_timestamp': 1721928462.0975938}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8338759167989096, '_timestamp': 1721928462.0976686}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20718486607074738, '_timestamp': 1721928462.0977762}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9474478363990784, '_timestamp': 1721928462.098048}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'ratio': 0.9962219595909119, '_timestamp': 1721928462.0981507}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721928462.098295}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928462.0983946}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'Episode_Time': 59.19876027107239, '_timestamp': 1721928462.09845}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928462.0990314}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928462.0994117}).
wandb: WARNING (User provided step: 3786 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928462.0998006}).
Env Football Algo jrpo Exp base_JRPO updates 6625/100000000000.0 steps in 83.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'value_loss': 0.2625423738453537, '_timestamp': 1721928546.0774229}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'policy_loss': 0.008293039373626621, '_timestamp': 1721928546.0775807}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8283755668004353, '_timestamp': 1721928546.0776474}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15484751760959625, '_timestamp': 1721928546.0777414}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.32954141497612, '_timestamp': 1721928546.0779333}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'ratio': 0.9976511001586914, '_timestamp': 1721928546.0780334}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928546.0781758}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928546.0782669}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.97688126564026, '_timestamp': 1721928546.0784714}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928546.0790803}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928546.0795724}).
wandb: WARNING (User provided step: 6625 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928546.0801065}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'value_loss': 0.24843678084822993, '_timestamp': 1721928626.654951}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006509652477689087, '_timestamp': 1721928626.655096}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8240866486231484, '_timestamp': 1721928626.6551597}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.178888738155365, '_timestamp': 1721928626.6552472}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2871018648147583, '_timestamp': 1721928626.6554704}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'ratio': 0.9974347352981567, '_timestamp': 1721928626.6555703}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928626.6556966}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928626.6558928}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.57416296005249, '_timestamp': 1721928626.655967}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928626.656534}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928626.6570077}).
wandb: WARNING (User provided step: 6927 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928626.6575024}).
Env Football Algo jrpo Exp base_JRPO updates 6927/100000000000.0 steps in 80.57
total episode rewards is -40.0
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'value_loss': 0.3092502278586229, '_timestamp': 1721928705.4399047}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006528281947903451, '_timestamp': 1721928705.440069}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8310678720474245, '_timestamp': 1721928705.4401348}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21444107592105865, '_timestamp': 1721928705.440224}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2850225269794464, '_timestamp': 1721928705.4404564}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'ratio': 1.0008959770202637, '_timestamp': 1721928705.4405544}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721928705.4406855}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928705.4407718}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.7712287902832, '_timestamp': 1721928705.4410002}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928705.4414544}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928705.441803}).
wandb: WARNING (User provided step: 7966 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928705.4421678}).
Env Football Algo jrpo Exp base_JRPO updates 7966/100000000000.0 steps in 78.77
total episode rewards is -50.0
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'value_loss': 0.18302195855241735, '_timestamp': 1721928783.3471322}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006237422370662292, '_timestamp': 1721928783.3472917}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8290025663375853, '_timestamp': 1721928783.3473577}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19846294820308685, '_timestamp': 1721928783.3474512}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.28478848934173584, '_timestamp': 1721928783.347689}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'ratio': 1.000376582145691, '_timestamp': 1721928783.347905}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721928783.348063}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928783.348154}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'Episode_Time': 77.9040138721466, '_timestamp': 1721928783.348213}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928783.3486319}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928783.3489428}).
wandb: WARNING (User provided step: 10509 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928783.3492575}).
Env Football Algo jrpo Exp base_JRPO updates 10509/100000000000.0 steps in 77.90
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 2160/100000000000.0 steps in 37.04
total episode rewards is -90.0
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'value_loss': 0.5298306390022238, '_timestamp': 1721928820.387894}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0014897464502913256, '_timestamp': 1721928820.3881006}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8277529096603393, '_timestamp': 1721928820.38817}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23591969907283783, '_timestamp': 1721928820.3882742}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0133299827575684, '_timestamp': 1721928820.3885393}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'ratio': 1.0005019903182983, '_timestamp': 1721928820.3886425}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721928820.3887815}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928820.388879}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.03782343864441, '_timestamp': 1721928820.389201}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928820.3895252}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928820.3897178}).
wandb: WARNING (User provided step: 2160 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928820.3899038}).
Env Football Algo jrpo Exp base_JRPO updates 7266/100000000000.0 steps in 71.28
total episode rewards is -70.0
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'value_loss': 0.5115401100274175, '_timestamp': 1721928891.686878}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00454503732403585, '_timestamp': 1721928891.6877458}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8279195833206177, '_timestamp': 1721928891.6878147}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2122398167848587, '_timestamp': 1721928891.688238}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7848188877105713, '_timestamp': 1721928891.6885724}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'ratio': 0.9982613325119019, '_timestamp': 1721928891.6892922}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721928891.689436}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928891.6895988}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'Episode_Time': 71.27718210220337, '_timestamp': 1721928891.6896565}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.043309380462225676, '_timestamp': 1721928891.6904607}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'train_goal': 0.4783453097688872, '_timestamp': 1721928891.690913}).
wandb: WARNING (User provided step: 7266 is less than current step: 12016. Dropping entry: {'train_WDL': -0.043309380462225676, '_timestamp': 1721928891.6912558}).
Env Football Algo jrpo Exp base_JRPO updates 2470/100000000000.0 steps in 46.41
total episode rewards is -60.0
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'value_loss': 0.6692164320871234, '_timestamp': 1721928938.0990846}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006213394756390093, '_timestamp': 1721928938.0992684}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8203241936365764, '_timestamp': 1721928938.099334}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21980227530002594, '_timestamp': 1721928938.0994356}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9541295766830444, '_timestamp': 1721928938.0996838}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'ratio': 0.999203622341156, '_timestamp': 1721928938.099788}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721928938.099928}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928938.1004083}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.406827449798584, '_timestamp': 1721928938.1004682}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.2644848484848485, '_timestamp': 1721928938.1009536}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'train_goal': 0.6322424242424243, '_timestamp': 1721928938.101248}).
wandb: WARNING (User provided step: 2470 is less than current step: 12016. Dropping entry: {'train_WDL': 0.2644848484848485, '_timestamp': 1721928938.1015396}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'value_loss': 0.8083561651781201, '_timestamp': 1721928967.2736106}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006082187225886931, '_timestamp': 1721928967.2747912}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8252198362350462, '_timestamp': 1721928967.274861}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22250956296920776, '_timestamp': 1721928967.275438}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.261794090270996, '_timestamp': 1721928967.2757926}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'ratio': 0.9996593594551086, '_timestamp': 1721928967.2764416}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721928967.2765672}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928967.2767632}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'Episode_Time': 29.166661500930786, '_timestamp': 1721928967.2768219}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928967.2776341}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928967.2778149}).
wandb: WARNING (User provided step: 2052 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928967.2779934}).
Env Football Algo jrpo Exp base_JRPO updates 2052/100000000000.0 steps in 29.17
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5941/100000000000.0 steps in 59.03
total episode rewards is -120.0
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'value_loss': 0.7800724731385708, '_timestamp': 1721929026.3081448}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0008794124447740614, '_timestamp': 1721929026.3082952}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8299392588933308, '_timestamp': 1721929026.3083596}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2183167040348053, '_timestamp': 1721929026.308452}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2601585388183594, '_timestamp': 1721929026.308672}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'ratio': 0.9994932413101196, '_timestamp': 1721929026.3087752}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721929026.3090246}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929026.3091142}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'Episode_Time': 59.029263496398926, '_timestamp': 1721929026.3091698}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929026.3095245}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929026.3097997}).
wandb: WARNING (User provided step: 5941 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929026.310076}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'value_loss': 0.7650964796543122, '_timestamp': 1721929066.8299615}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004385263062237452, '_timestamp': 1721929066.8301213}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.828000431060791, '_timestamp': 1721929066.8301837}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23355746269226074, '_timestamp': 1721929066.8302743}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1507760286331177, '_timestamp': 1721929066.8305929}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'ratio': 0.9979554414749146, '_timestamp': 1721929066.8306954}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721929066.8308246}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929066.8309145}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'Episode_Time': 40.519022703170776, '_timestamp': 1721929066.8309703}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929066.831321}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929066.8315613}).
wandb: WARNING (User provided step: 3857 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929066.8318033}).
Env Football Algo jrpo Exp base_JRPO updates 3857/100000000000.0 steps in 40.52
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5985/100000000000.0 steps in 63.90
total episode rewards is -90.0
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'value_loss': 0.5933569947630167, '_timestamp': 1721929130.734071}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'policy_loss': 0.002729995539363396, '_timestamp': 1721929130.7342277}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829286847114563, '_timestamp': 1721929130.7342908}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22294101119041443, '_timestamp': 1721929130.734382}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9526247382164001, '_timestamp': 1721929130.7346017}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'ratio': 0.9984115958213806, '_timestamp': 1721929130.7348197}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721929130.734945}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929130.7350342}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'Episode_Time': 63.9013934135437, '_timestamp': 1721929130.7350907}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.030156815440289506, '_timestamp': 1721929130.7355156}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'train_goal': 0.48492159227985526, '_timestamp': 1721929130.735811}).
wandb: WARNING (User provided step: 5985 is less than current step: 12016. Dropping entry: {'train_WDL': -0.030156815440289506, '_timestamp': 1721929130.7361143}).
Env Football Algo jrpo Exp base_JRPO updates 3068/100000000000.0 steps in 31.79
total episode rewards is -90.0
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'value_loss': 0.7097517052168647, '_timestamp': 1721929162.5283692}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0038873701375753927, '_timestamp': 1721929162.5286202}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8344845310846964, '_timestamp': 1721929162.5286887}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21524839103221893, '_timestamp': 1721929162.5287933}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.940676212310791, '_timestamp': 1721929162.529053}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'ratio': 0.9988464713096619, '_timestamp': 1721929162.5294883}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721929162.5296934}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929162.529791}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'Episode_Time': 31.791191577911377, '_timestamp': 1721929162.5298483}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.4402917046490428, '_timestamp': 1721929162.5302625}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'train_goal': 0.7201458523245214, '_timestamp': 1721929162.5304115}).
wandb: WARNING (User provided step: 3068 is less than current step: 12016. Dropping entry: {'train_WDL': 0.4402917046490428, '_timestamp': 1721929162.5305545}).
Env Football Algo jrpo Exp base_JRPO updates 6467/100000000000.0 steps in 49.22
total episode rewards is -130.0
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'value_loss': 0.8387442793697119, '_timestamp': 1721929211.7556849}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005423413337363551, '_timestamp': 1721929211.757132}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8336662975947062, '_timestamp': 1721929211.7572064}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20964863896369934, '_timestamp': 1721929211.7578483}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0172511339187622, '_timestamp': 1721929211.7582455}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'ratio': 0.9986331462860107, '_timestamp': 1721929211.7590833}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721929211.7593482}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929211.759558}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'Episode_Time': 49.2188458442688, '_timestamp': 1721929211.7596166}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929211.7606819}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929211.7608614}).
wandb: WARNING (User provided step: 6467 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929211.761058}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'value_loss': 0.27502463608980177, '_timestamp': 1721929303.5496087}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0018611031161465993, '_timestamp': 1721929303.5497816}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8333014345169065, '_timestamp': 1721929303.5498502}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17628052830696106, '_timestamp': 1721929303.5499463}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.28260380029678345, '_timestamp': 1721929303.5501955}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'ratio': 0.9984391331672668, '_timestamp': 1721929303.550481}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721929303.5506186}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929303.5507104}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.78756332397461, '_timestamp': 1721929303.550767}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929303.5514884}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929303.552049}).
wandb: WARNING (User provided step: 5624 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929303.5526214}).
Env Football Algo jrpo Exp base_JRPO updates 5624/100000000000.0 steps in 91.79
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6070/100000000000.0 steps in 86.51
total episode rewards is -50.0
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'value_loss': 0.4442091110721231, '_timestamp': 1721929390.0604498}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0012291426898930998, '_timestamp': 1721929390.0608377}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.834367807706197, '_timestamp': 1721929390.0609097}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22945356369018555, '_timestamp': 1721929390.0611038}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.40243807435035706, '_timestamp': 1721929390.0613678}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'ratio': 1.0004242658615112, '_timestamp': 1721929390.061469}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721929390.0616121}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929390.0617223}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.50578331947327, '_timestamp': 1721929390.0617812}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.32781065088757394, '_timestamp': 1721929390.062519}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'train_goal': 0.336094674556213, '_timestamp': 1721929390.0630229}).
wandb: WARNING (User provided step: 6070 is less than current step: 12016. Dropping entry: {'train_WDL': -0.32781065088757394, '_timestamp': 1721929390.0635295}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'value_loss': 0.6987257189800342, '_timestamp': 1721929441.9370415}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005141990960758752, '_timestamp': 1721929441.9371963}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8347799809773764, '_timestamp': 1721929441.9372628}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22758857905864716, '_timestamp': 1721929441.937357}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1265181303024292, '_timestamp': 1721929441.9375997}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'ratio': 0.9989471435546875, '_timestamp': 1721929441.937702}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721929441.938023}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929441.938117}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.87262034416199, '_timestamp': 1721929441.9381776}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929441.9385483}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929441.9388046}).
wandb: WARNING (User provided step: 4747 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929441.9390588}).
Env Football Algo jrpo Exp base_JRPO updates 4747/100000000000.0 steps in 51.87
total episode rewards is -120.0
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'value_loss': 0.2508898159489036, '_timestamp': 1721929526.6567218}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'policy_loss': 0.01207947023436039, '_timestamp': 1721929526.6568754}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8364440806706748, '_timestamp': 1721929526.6569405}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1832326054573059, '_timestamp': 1721929526.6570299}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.32395070791244507, '_timestamp': 1721929526.6572714}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'ratio': 1.0004947185516357, '_timestamp': 1721929526.6575222}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721929526.6576564}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929526.657745}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.71677613258362, '_timestamp': 1721929526.6578007}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929526.6583157}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929526.6587265}).
wandb: WARNING (User provided step: 8363 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929526.6591465}).
Env Football Algo jrpo Exp base_JRPO updates 8363/100000000000.0 steps in 84.72
total episode rewards is -40.0
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'value_loss': 0.2953402817994356, '_timestamp': 1721929600.4360945}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007647169732081238, '_timestamp': 1721929600.436261}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8312203025817873, '_timestamp': 1721929600.4363267}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18165263533592224, '_timestamp': 1721929600.4364214}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3121480941772461, '_timestamp': 1721929600.436661}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'ratio': 1.0005685091018677, '_timestamp': 1721929600.436758}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721929600.4371028}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929600.437195}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'Episode_Time': 73.7759964466095, '_timestamp': 1721929600.4372525}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929600.4377277}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929600.4380934}).
wandb: WARNING (User provided step: 7227 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929600.4384718}).
Env Football Algo jrpo Exp base_JRPO updates 7227/100000000000.0 steps in 73.78
total episode rewards is -50.0
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'value_loss': 0.6248598448932171, '_timestamp': 1721929647.6835637}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'policy_loss': -0.001685153966730771, '_timestamp': 1721929647.6838226}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.836482357978821, '_timestamp': 1721929647.6838918}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21964702010154724, '_timestamp': 1721929647.6840136}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8203536868095398, '_timestamp': 1721929647.6842835}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'ratio': 1.0004255771636963, '_timestamp': 1721929647.6848752}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721929647.6851103}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929647.6852098}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'Episode_Time': 47.24409747123718, '_timestamp': 1721929647.6852674}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929647.6856277}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929647.685801}).
wandb: WARNING (User provided step: 4782 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929647.6859732}).
Env Football Algo jrpo Exp base_JRPO updates 4782/100000000000.0 steps in 47.24
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 10362/100000000000.0 steps in 87.88
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'value_loss': 0.1776468603654454, '_timestamp': 1721929735.5718572}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003136450005113147, '_timestamp': 1721929735.5723107}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8342341216405234, '_timestamp': 1721929735.5723789}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16864514350891113, '_timestamp': 1721929735.5725594}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.19963592290878296, '_timestamp': 1721929735.5728464}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'ratio': 0.9995092749595642, '_timestamp': 1721929735.572948}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721929735.5730832}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929735.5736299}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.88374495506287, '_timestamp': 1721929735.5736923}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929735.5742917}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929735.5746114}).
wandb: WARNING (User provided step: 10362 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929735.5749774}).
total episode rewards is -30.0
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'value_loss': 0.40086531500021616, '_timestamp': 1721929799.7646832}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002414924459105047, '_timestamp': 1721929799.7648547}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.836833267211914, '_timestamp': 1721929799.7649214}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20043696463108063, '_timestamp': 1721929799.7650223}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6371774077415466, '_timestamp': 1721929799.7652812}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'ratio': 1.0000712871551514, '_timestamp': 1721929799.7653828}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721929799.7656767}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929799.765774}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'Episode_Time': 64.18843674659729, '_timestamp': 1721929799.7658327}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929799.7662468}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929799.7665381}).
wandb: WARNING (User provided step: 6146 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929799.7668333}).
Env Football Algo jrpo Exp base_JRPO updates 6146/100000000000.0 steps in 64.19
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 3928/100000000000.0 steps in 37.61
total episode rewards is -110.0
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'value_loss': 0.6512912280857563, '_timestamp': 1721929837.3854675}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00501725008682115, '_timestamp': 1721929837.3866282}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8366479603449504, '_timestamp': 1721929837.3867006}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21264058351516724, '_timestamp': 1721929837.3872275}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.32968270778656, '_timestamp': 1721929837.3876162}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'ratio': 1.0000734329223633, '_timestamp': 1721929837.3877246}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721929837.3878903}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929837.3882163}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.61332130432129, '_timestamp': 1721929837.3882754}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929837.3892071}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929837.3893847}).
wandb: WARNING (User provided step: 3928 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929837.3896027}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'value_loss': 0.1912294302539279, '_timestamp': 1721929926.341118}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003583336610463448, '_timestamp': 1721929926.3413153}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8387109168370563, '_timestamp': 1721929926.3413835}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14644579589366913, '_timestamp': 1721929926.3414946}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.19591988623142242, '_timestamp': 1721929926.3417702}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'ratio': 0.9983994960784912, '_timestamp': 1721929926.3418756}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721929926.3420212}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929926.3423388}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.9503972530365, '_timestamp': 1721929926.3423998}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721929926.343009}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721929926.343441}).
wandb: WARNING (User provided step: 8714 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721929926.3438613}).
Env Football Algo jrpo Exp base_JRPO updates 8714/100000000000.0 steps in 88.95
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 9312/100000000000.0 steps in 86.94
total episode rewards is -40.0
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'value_loss': 0.2669183737970889, '_timestamp': 1721930013.2829552}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002111364005346938, '_timestamp': 1721930013.2831326}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.842253425916036, '_timestamp': 1721930013.283201}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18911296129226685, '_timestamp': 1721930013.2832925}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3600492477416992, '_timestamp': 1721930013.283528}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'ratio': 1.000343680381775, '_timestamp': 1721930013.2836313}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930013.2837918}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930013.2838864}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.93800139427185, '_timestamp': 1721930013.2839632}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930013.2845988}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930013.2850776}).
wandb: WARNING (User provided step: 9312 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930013.2855723}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'value_loss': 0.2514638468498985, '_timestamp': 1721930098.0681026}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0008988800666217382, '_timestamp': 1721930098.0682585}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8422457790374756, '_timestamp': 1721930098.0683234}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21243241429328918, '_timestamp': 1721930098.0684144}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2889847159385681, '_timestamp': 1721930098.068651}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'ratio': 0.9998281002044678, '_timestamp': 1721930098.0687501}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930098.0690267}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930098.0691524}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.78162336349487, '_timestamp': 1721930098.0692098}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930098.0697758}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930098.0702298}).
wandb: WARNING (User provided step: 7388 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930098.0707018}).
Env Football Algo jrpo Exp base_JRPO updates 7388/100000000000.0 steps in 84.78
total episode rewards is -40.0
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'value_loss': 0.6922184076656898, '_timestamp': 1721930118.0932257}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005464926489706461, '_timestamp': 1721930118.0934005}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8489436864852906, '_timestamp': 1721930118.0934653}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21759651601314545, '_timestamp': 1721930118.093565}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9877685904502869, '_timestamp': 1721930118.0938272}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'ratio': 0.9991656541824341, '_timestamp': 1721930118.0939252}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721930118.0940607}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930118.0941558}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'Episode_Time': 20.021710634231567, '_timestamp': 1721930118.0945194}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.27384615384615385, '_timestamp': 1721930118.0947733}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'train_goal': 0.3630769230769231, '_timestamp': 1721930118.0949097}).
wandb: WARNING (User provided step: 1410 is less than current step: 12016. Dropping entry: {'train_WDL': -0.27384615384615385, '_timestamp': 1721930118.0950444}).
Env Football Algo jrpo Exp base_JRPO updates 1410/100000000000.0 steps in 20.02
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 4830/100000000000.0 steps in 87.26
total episode rewards is -40.0
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'value_loss': 0.30143859659011163, '_timestamp': 1721930205.363195}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00398642879241379, '_timestamp': 1721930205.3642855}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.846530955632528, '_timestamp': 1721930205.3643594}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16512183845043182, '_timestamp': 1721930205.3648498}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2989404499530792, '_timestamp': 1721930205.3651984}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'ratio': 0.9983603954315186, '_timestamp': 1721930205.365305}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930205.3654459}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930205.366597}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.2634003162384, '_timestamp': 1721930205.366657}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930205.3679729}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930205.3686435}).
wandb: WARNING (User provided step: 4830 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930205.3692784}).
Env Football Algo jrpo Exp base_JRPO updates 5980/100000000000.0 steps in 94.19
total episode rewards is -40.0
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'value_loss': 0.24913715759913127, '_timestamp': 1721930299.5563266}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005927773339208215, '_timestamp': 1721930299.5564883}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.844570385615031, '_timestamp': 1721930299.556553}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17643259465694427, '_timestamp': 1721930299.5566475}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.184416264295578, '_timestamp': 1721930299.556891}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'ratio': 0.9996131658554077, '_timestamp': 1721930299.5569966}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930299.5571318}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930299.557223}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'Episode_Time': 94.18593883514404, '_timestamp': 1721930299.5574348}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930299.558135}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930299.5586681}).
wandb: WARNING (User provided step: 5980 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930299.5592184}).
Env Football Algo jrpo Exp base_JRPO updates 6482/100000000000.0 steps in 64.44
total episode rewards is -40.0
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'value_loss': 0.37338635422910255, '_timestamp': 1721930364.000321}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005068182058942814, '_timestamp': 1721930364.0005689}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8490406958262127, '_timestamp': 1721930364.0006392}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21514247357845306, '_timestamp': 1721930364.0007389}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7759360671043396, '_timestamp': 1721930364.0009837}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'ratio': 1.0030206441879272, '_timestamp': 1721930364.0010827}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930364.0012815}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930364.0013778}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'Episode_Time': 64.43976473808289, '_timestamp': 1721930364.001748}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.11419342580277408, '_timestamp': 1721930364.0023203}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_goal': 0.442903287098613, '_timestamp': 1721930364.002865}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_WDL': -0.11419342580277408, '_timestamp': 1721930364.0033965}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'value_loss': 0.44526080107937255, '_timestamp': 1721930440.6739676}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002386867773893755, '_timestamp': 1721930440.675117}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.84931827545166, '_timestamp': 1721930440.67519}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20035967230796814, '_timestamp': 1721930440.6757097}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7227234244346619, '_timestamp': 1721930440.6761298}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'ratio': 0.9993795156478882, '_timestamp': 1721930440.6762378}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930440.6763806}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930440.676567}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.66474556922913, '_timestamp': 1721930440.6766326}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3104336625161013, '_timestamp': 1721930440.6776304}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'train_goal': 0.3447831687419493, '_timestamp': 1721930440.6780686}).
wandb: WARNING (User provided step: 5128 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3104336625161013, '_timestamp': 1721930440.6785038}).
Env Football Algo jrpo Exp base_JRPO updates 5128/100000000000.0 steps in 76.66
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8442/100000000000.0 steps in 75.60
total episode rewards is -30.0
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'value_loss': 0.19157130950130521, '_timestamp': 1721930516.2754035}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004713307875208557, '_timestamp': 1721930516.2755544}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8471798865000406, '_timestamp': 1721930516.2756178}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18051040172576904, '_timestamp': 1721930516.2757032}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2512907385826111, '_timestamp': 1721930516.2759311}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'ratio': 0.9987875819206238, '_timestamp': 1721930516.276053}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721930516.2761805}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930516.27641}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'Episode_Time': 75.59576535224915, '_timestamp': 1721930516.2764683}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930516.2769647}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930516.277366}).
wandb: WARNING (User provided step: 8442 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930516.2777817}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'value_loss': 0.2582986109486471, '_timestamp': 1721930603.1587849}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007993349015790348, '_timestamp': 1721930603.1589324}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.843838036855062, '_timestamp': 1721930603.1590028}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1593903750181198, '_timestamp': 1721930603.1590967}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.17250162363052368, '_timestamp': 1721930603.1594534}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'ratio': 0.9986042380332947, '_timestamp': 1721930603.159692}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930603.159896}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930603.1600008}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.88041830062866, '_timestamp': 1721930603.16006}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930603.160689}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930603.1612015}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930603.1617415}).
Env Football Algo jrpo Exp base_JRPO updates 6094/100000000000.0 steps in 86.88
total episode rewards is -40.0
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'value_loss': 0.6376875939468543, '_timestamp': 1721930643.6646717}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007796704901071887, '_timestamp': 1721930643.6648653}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8397723388671876, '_timestamp': 1721930643.6649365}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22126729786396027, '_timestamp': 1721930643.6650486}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9373698234558105, '_timestamp': 1721930643.6653337}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'ratio': 1.0018590688705444, '_timestamp': 1721930643.6654367}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721930643.6655772}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930643.6662986}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'Episode_Time': 40.50197148323059, '_timestamp': 1721930643.6663585}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930643.6667488}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930643.6669939}).
wandb: WARNING (User provided step: 3089 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930643.6672404}).
Env Football Algo jrpo Exp base_JRPO updates 3089/100000000000.0 steps in 40.50
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5048/100000000000.0 steps in 56.57
total episode rewards is -70.0
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'value_loss': 0.6179823270315925, '_timestamp': 1721930700.2405565}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0024810462136520073, '_timestamp': 1721930700.2407262}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.84304470539093, '_timestamp': 1721930700.2407928}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21995551884174347, '_timestamp': 1721930700.240887}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.235384225845337, '_timestamp': 1721930700.2411468}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'ratio': 1.00123929977417, '_timestamp': 1721930700.2412503}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721930700.2413812}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930700.2419174}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'Episode_Time': 56.57089042663574, '_timestamp': 1721930700.2419782}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.058538275025978526, '_timestamp': 1721930700.242356}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'train_goal': 0.5292691375129892, '_timestamp': 1721930700.242584}).
wandb: WARNING (User provided step: 5048 is less than current step: 12016. Dropping entry: {'train_WDL': 0.058538275025978526, '_timestamp': 1721930700.242817}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'value_loss': 0.9534996498624484, '_timestamp': 1721930729.6711109}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006261293326557885, '_timestamp': 1721930729.6713476}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8466912094751993, '_timestamp': 1721930729.6714163}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2136787474155426, '_timestamp': 1721930729.6715102}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.593234896659851, '_timestamp': 1721930729.671769}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'ratio': 1.0002799034118652, '_timestamp': 1721930729.6718721}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721930729.6724749}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930729.6725726}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'Episode_Time': 29.427412748336792, '_timestamp': 1721930729.6726303}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.25380710659898476, '_timestamp': 1721930729.6730514}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'train_goal': 0.3730964467005076, '_timestamp': 1721930729.6732357}).
wandb: WARNING (User provided step: 1755 is less than current step: 12016. Dropping entry: {'train_WDL': -0.25380710659898476, '_timestamp': 1721930729.673418}).
Env Football Algo jrpo Exp base_JRPO updates 1755/100000000000.0 steps in 29.43
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 6492/100000000000.0 steps in 78.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'value_loss': 0.26648586882278325, '_timestamp': 1721930808.3268309}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'policy_loss': 0.02652779289482472, '_timestamp': 1721930808.3269866}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.847014191945394, '_timestamp': 1721930808.32705}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17531752586364746, '_timestamp': 1721930808.32714}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.15648923814296722, '_timestamp': 1721930808.3273537}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'ratio': 0.9975875020027161, '_timestamp': 1721930808.3274496}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930808.3275735}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930808.327777}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.65244221687317, '_timestamp': 1721930808.3278344}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930808.3284802}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930808.3289778}).
wandb: WARNING (User provided step: 6492 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930808.3295007}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'value_loss': 0.27759217435959727, '_timestamp': 1721930893.4141488}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0008598309704878678, '_timestamp': 1721930893.4144373}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.844464840888977, '_timestamp': 1721930893.4145098}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19391992688179016, '_timestamp': 1721930893.4146755}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.18756620585918427, '_timestamp': 1721930893.4149854}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'ratio': 1.0002529621124268, '_timestamp': 1721930893.4151273}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930893.4159448}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930893.4161224}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.08263897895813, '_timestamp': 1721930893.4161804}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930893.4169204}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930893.417445}).
wandb: WARNING (User provided step: 6658 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930893.4179642}).
Env Football Algo jrpo Exp base_JRPO updates 6658/100000000000.0 steps in 85.08
total episode rewards is -40.0
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'value_loss': 0.9019780956208706, '_timestamp': 1721930938.0725899}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004249584081505115, '_timestamp': 1721930938.0727534}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.843838866551717, '_timestamp': 1721930938.0728207}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21203050017356873, '_timestamp': 1721930938.0729136}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1035747528076172, '_timestamp': 1721930938.0731633}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'ratio': 0.9989063739776611, '_timestamp': 1721930938.0732672}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721930938.0734031}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930938.0736673}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.65363574028015, '_timestamp': 1721930938.0737278}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.1902654867256637, '_timestamp': 1721930938.0740557}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'train_goal': 0.40486725663716816, '_timestamp': 1721930938.0742588}).
wandb: WARNING (User provided step: 2395 is less than current step: 12016. Dropping entry: {'train_WDL': -0.1902654867256637, '_timestamp': 1721930938.0744555}).
Env Football Algo jrpo Exp base_JRPO updates 2395/100000000000.0 steps in 44.65
total episode rewards is -120.0
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'value_loss': 0.8177145317693552, '_timestamp': 1721930975.8217402}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004251187962678766, '_timestamp': 1721930975.8218875}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.838429333368937, '_timestamp': 1721930975.8219533}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2161950170993805, '_timestamp': 1721930975.8220403}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.428175687789917, '_timestamp': 1721930975.8222628}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'ratio': 1.0003701448440552, '_timestamp': 1721930975.8223617}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721930975.8225868}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930975.8226755}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'Episode_Time': 37.74663281440735, '_timestamp': 1721930975.8227324}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930975.8230615}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930975.8232598}).
wandb: WARNING (User provided step: 4129 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930975.8234591}).
Env Football Algo jrpo Exp base_JRPO updates 4129/100000000000.0 steps in 37.75
total episode rewards is -90.0
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'value_loss': 0.2649703874345869, '_timestamp': 1721931064.2053506}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'policy_loss': 0.005138679392208966, '_timestamp': 1721931064.2055125}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839696798324585, '_timestamp': 1721931064.2055776}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1567443162202835, '_timestamp': 1721931064.2056682}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.26817578077316284, '_timestamp': 1721931064.205907}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'ratio': 0.9999299645423889, '_timestamp': 1721931064.206006}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931064.2061336}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931064.2064557}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.38100481033325, '_timestamp': 1721931064.2065144}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931064.2071233}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931064.2076323}).
wandb: WARNING (User provided step: 6694 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931064.2081792}).
Env Football Algo jrpo Exp base_JRPO updates 6694/100000000000.0 steps in 88.38
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5242/100000000000.0 steps in 58.74
total episode rewards is -80.0
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'value_loss': 0.48014939283331237, '_timestamp': 1721931122.949547}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0023228489392689276, '_timestamp': 1721931122.9497342}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8401572863260904, '_timestamp': 1721931122.9498012}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18690520524978638, '_timestamp': 1721931122.949901}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7079614996910095, '_timestamp': 1721931122.9501483}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'ratio': 1.000407338142395, '_timestamp': 1721931122.9505548}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721931122.9506943}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931122.95079}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'Episode_Time': 58.74045252799988, '_timestamp': 1721931122.9508486}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931122.9513264}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931122.95168}).
wandb: WARNING (User provided step: 5242 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931122.9520643}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'value_loss': 0.2733178156885939, '_timestamp': 1721931209.7446494}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006807266951461013, '_timestamp': 1721931209.7448006}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839567731221517, '_timestamp': 1721931209.7448664}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15723754465579987, '_timestamp': 1721931209.744953}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.23269228637218475, '_timestamp': 1721931209.7451804}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'ratio': 0.998846173286438, '_timestamp': 1721931209.7452796}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931209.7454095}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931209.7456057}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.79187178611755, '_timestamp': 1721931209.7456622}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.15805885792243227, '_timestamp': 1721931209.7463381}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'train_goal': 0.5790294289612161, '_timestamp': 1721931209.7469113}).
wandb: WARNING (User provided step: 4738 is less than current step: 12016. Dropping entry: {'train_WDL': 0.15805885792243227, '_timestamp': 1721931209.7474918}).
Env Football Algo jrpo Exp base_JRPO updates 4738/100000000000.0 steps in 86.79
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 7258/100000000000.0 steps in 79.19
total episode rewards is -40.0
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'value_loss': 0.2515483020777659, '_timestamp': 1721931288.9370735}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00705964813590981, '_timestamp': 1721931288.9372382}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.84191153049469, '_timestamp': 1721931288.9373035}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1501079797744751, '_timestamp': 1721931288.9373984}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2213505357503891, '_timestamp': 1721931288.9376702}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'ratio': 0.9995836615562439, '_timestamp': 1721931288.9380176}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931288.9381576}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931288.9382515}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.18818473815918, '_timestamp': 1721931288.938308}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931288.938893}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931288.9393656}).
wandb: WARNING (User provided step: 7258 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931288.9398465}).
Env Football Algo jrpo Exp base_JRPO updates 7833/100000000000.0 steps in 83.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'value_loss': 0.25193456807076775, '_timestamp': 1721931372.9157348}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'policy_loss': -0.009705190202318288, '_timestamp': 1721931372.9158955}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.844085931777954, '_timestamp': 1721931372.915977}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15247753262519836, '_timestamp': 1721931372.9160736}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.33274853229522705, '_timestamp': 1721931372.9163175}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'ratio': 1.0019477605819702, '_timestamp': 1721931372.9164197}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931372.9165597}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931372.9166536}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.97510433197021, '_timestamp': 1721931372.9172194}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931372.917807}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931372.9182372}).
wandb: WARNING (User provided step: 7833 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931372.9186916}).
Env Football Algo jrpo Exp base_JRPO updates 3729/100000000000.0 steps in 44.64
total episode rewards is -50.0
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'value_loss': 0.507028915869693, '_timestamp': 1721931417.564379}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007280174564075423, '_timestamp': 1721931417.5645323}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8420533736546836, '_timestamp': 1721931417.5645978}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18521137535572052, '_timestamp': 1721931417.5646882}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6565125584602356, '_timestamp': 1721931417.5649338}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'ratio': 1.0013748407363892, '_timestamp': 1721931417.5652544}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721931417.56539}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931417.5654807}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.644739866256714, '_timestamp': 1721931417.5655391}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.0971588916169765, '_timestamp': 1721931417.5659184}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'train_goal': 0.4514205541915117, '_timestamp': 1721931417.5661623}).
wandb: WARNING (User provided step: 3729 is less than current step: 12016. Dropping entry: {'train_WDL': -0.0971588916169765, '_timestamp': 1721931417.5663888}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'value_loss': 0.8322943035513163, '_timestamp': 1721931452.1792176}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0022982089497296937, '_timestamp': 1721931452.1793818}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8430269797643026, '_timestamp': 1721931452.1794453}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2326386272907257, '_timestamp': 1721931452.1795385}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3584939241409302, '_timestamp': 1721931452.179766}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'ratio': 1.0012282133102417, '_timestamp': 1721931452.1798642}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721931452.1800156}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931452.1802166}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.61162352561951, '_timestamp': 1721931452.1802762}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.008859357696566999, '_timestamp': 1721931452.1805687}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'train_goal': 0.5044296788482835, '_timestamp': 1721931452.180746}).
wandb: WARNING (User provided step: 2829 is less than current step: 12016. Dropping entry: {'train_WDL': 0.008859357696566999, '_timestamp': 1721931452.1809194}).
Env Football Algo jrpo Exp base_JRPO updates 2829/100000000000.0 steps in 34.61
total episode rewards is -100.0
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'value_loss': 0.8404428289706508, '_timestamp': 1721931505.802153}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005419700124766677, '_timestamp': 1721931505.8023279}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.841770567893982, '_timestamp': 1721931505.8023925}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2127208560705185, '_timestamp': 1721931505.8024895}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1917461156845093, '_timestamp': 1721931505.8027415}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'ratio': 0.9992868304252625, '_timestamp': 1721931505.802959}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721931505.8030944}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931505.8031852}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'Episode_Time': 53.62043523788452, '_timestamp': 1721931505.803241}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3395083719273245, '_timestamp': 1721931505.803789}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'train_goal': 0.33024581403633774, '_timestamp': 1721931505.8041937}).
wandb: WARNING (User provided step: 3736 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3395083719273245, '_timestamp': 1721931505.804592}).
Env Football Algo jrpo Exp base_JRPO updates 3736/100000000000.0 steps in 53.62
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 5204/100000000000.0 steps in 87.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'value_loss': 0.25415472395097216, '_timestamp': 1721931593.351485}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004680856182306646, '_timestamp': 1721931593.3528292}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839248522122701, '_timestamp': 1721931593.3529046}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15294916927814484, '_timestamp': 1721931593.3534982}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3245105445384979, '_timestamp': 1721931593.3538783}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'ratio': 0.9997961521148682, '_timestamp': 1721931593.3548117}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721931593.3549645}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931593.3551695}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.54094171524048, '_timestamp': 1721931593.3552296}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3924050632911392, '_timestamp': 1721931593.356556}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'train_goal': 0.3037974683544304, '_timestamp': 1721931593.357193}).
wandb: WARNING (User provided step: 5204 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3924050632911392, '_timestamp': 1721931593.3578176}).
Env Football Algo jrpo Exp base_JRPO updates 6903/100000000000.0 steps in 87.58
total episode rewards is -40.0
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'value_loss': 0.26451172477177654, '_timestamp': 1721931680.9400175}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0005079324124380946, '_timestamp': 1721931680.940196}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8362036418914793, '_timestamp': 1721931680.940267}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13156753778457642, '_timestamp': 1721931680.940365}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2901352345943451, '_timestamp': 1721931680.9406319}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'ratio': 0.9987367987632751, '_timestamp': 1721931680.9407353}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931680.9414644}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931680.9415662}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.58127021789551, '_timestamp': 1721931680.9416254}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931680.9424286}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931680.9429548}).
wandb: WARNING (User provided step: 6903 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931680.9434652}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'value_loss': 0.2888237966240073, '_timestamp': 1721931750.9857352}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006196948676370084, '_timestamp': 1721931750.9858966}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.837760648727417, '_timestamp': 1721931750.9859653}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1440172642469406, '_timestamp': 1721931750.9860613}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6761555075645447, '_timestamp': 1721931750.9862883}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'ratio': 1.0015047788619995, '_timestamp': 1721931750.986384}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721931750.9865136}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931750.986715}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'Episode_Time': 70.04140663146973, '_timestamp': 1721931750.986775}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931750.987132}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931750.9874053}).
wandb: WARNING (User provided step: 9221 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931750.9876847}).
Env Football Algo jrpo Exp base_JRPO updates 9221/100000000000.0 steps in 70.04
total episode rewards is -50.0
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'value_loss': 0.3190912604132124, '_timestamp': 1721931838.479382}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0008951506034160654, '_timestamp': 1721931838.48064}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.830081221262614, '_timestamp': 1721931838.4807107}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13944131135940552, '_timestamp': 1721931838.4812918}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.33374467492103577, '_timestamp': 1721931838.4816532}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'ratio': 0.9977620840072632, '_timestamp': 1721931838.4817579}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931838.486043}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931838.4866738}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.4861147403717, '_timestamp': 1721931838.4867375}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.07307343608340888, '_timestamp': 1721931838.488101}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'train_goal': 0.5365367180417044, '_timestamp': 1721931838.4887223}).
wandb: WARNING (User provided step: 3970 is less than current step: 12016. Dropping entry: {'train_WDL': 0.07307343608340888, '_timestamp': 1721931838.4893503}).
Env Football Algo jrpo Exp base_JRPO updates 3970/100000000000.0 steps in 87.49
total episode rewards is 0.0
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'value_loss': 0.2770043319106723, '_timestamp': 1721931921.2900362}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0006336112492620789, '_timestamp': 1721931921.2901936}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.837201991081238, '_timestamp': 1721931921.2902603}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1317623257637024, '_timestamp': 1721931921.2903502}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2643304169178009, '_timestamp': 1721931921.290577}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'ratio': 1.0000745058059692, '_timestamp': 1721931921.2906766}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931921.2908075}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931921.290896}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.79989981651306, '_timestamp': 1721931921.2910855}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931921.2917454}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931921.2976696}).
wandb: WARNING (User provided step: 6482 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931921.2982128}).
Env Football Algo jrpo Exp base_JRPO updates 6482/100000000000.0 steps in 82.80
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 9408/100000000000.0 steps in 78.45
total episode rewards is -40.0
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'value_loss': 0.25928228993938923, '_timestamp': 1721931999.7521644}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0016966843163633409, '_timestamp': 1721931999.7523334}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8307624101638793, '_timestamp': 1721931999.7524025}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.146848663687706, '_timestamp': 1721931999.7524977}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2244032621383667, '_timestamp': 1721931999.752734}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'ratio': 0.9998379945755005, '_timestamp': 1721931999.752834}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931999.752965}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931999.753169}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.45274043083191, '_timestamp': 1721931999.7532284}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931999.753703}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931999.754064}).
wandb: WARNING (User provided step: 9408 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931999.7544339}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'value_loss': 0.7091151190673312, '_timestamp': 1721932048.406101}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003178913046528275, '_timestamp': 1721932048.4062567}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.832606291770935, '_timestamp': 1721932048.406323}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22929374873638153, '_timestamp': 1721932048.4064124}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0531383752822876, '_timestamp': 1721932048.4066377}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'ratio': 0.9970787763595581, '_timestamp': 1721932048.4067388}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721932048.4068682}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932048.407064}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'Episode_Time': 48.650829792022705, '_timestamp': 1721932048.4071229}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.38432572369969403, '_timestamp': 1721932048.4075344}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'train_goal': 0.30783713815015296, '_timestamp': 1721932048.4078279}).
wandb: WARNING (User provided step: 2581 is less than current step: 12016. Dropping entry: {'train_WDL': -0.38432572369969403, '_timestamp': 1721932048.4081378}).
Env Football Algo jrpo Exp base_JRPO updates 2581/100000000000.0 steps in 48.65
total episode rewards is -60.0
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'value_loss': 0.8817954215159018, '_timestamp': 1721932083.1307523}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003690835872160581, '_timestamp': 1721932083.1309166}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.835074268976847, '_timestamp': 1721932083.1309872}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22023272514343262, '_timestamp': 1721932083.131077}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.416142463684082, '_timestamp': 1721932083.1313138}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'ratio': 0.9984796643257141, '_timestamp': 1721932083.1314201}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721932083.1318014}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932083.131893}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.72174525260925, '_timestamp': 1721932083.1319818}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.213768115942029, '_timestamp': 1721932083.1322706}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'train_goal': 0.39311594202898553, '_timestamp': 1721932083.1324623}).
wandb: WARNING (User provided step: 2287 is less than current step: 12016. Dropping entry: {'train_WDL': -0.213768115942029, '_timestamp': 1721932083.1326506}).
Env Football Algo jrpo Exp base_JRPO updates 2287/100000000000.0 steps in 34.72
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 6176/100000000000.0 steps in 81.06
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'value_loss': 0.2751671402459033, '_timestamp': 1721932164.190412}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005967366419596753, '_timestamp': 1721932164.1905835}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8391628551483152, '_timestamp': 1721932164.1906507}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1808142066001892, '_timestamp': 1721932164.1907456}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.24385465681552887, '_timestamp': 1721932164.1909857}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'ratio': 1.0007641315460205, '_timestamp': 1721932164.1910834}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932164.1914523}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932164.191544}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.05704474449158, '_timestamp': 1721932164.1916}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.33522212148685404, '_timestamp': 1721932164.195738}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'train_goal': 0.332388939256573, '_timestamp': 1721932164.1963735}).
wandb: WARNING (User provided step: 6176 is less than current step: 12016. Dropping entry: {'train_WDL': -0.33522212148685404, '_timestamp': 1721932164.1969543}).
total episode rewards is -20.0
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'value_loss': 0.48602322561045486, '_timestamp': 1721932232.5225222}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006520116432414701, '_timestamp': 1721932232.5227227}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8391638882954915, '_timestamp': 1721932232.5227928}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1945430040359497, '_timestamp': 1721932232.522897}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8369490504264832, '_timestamp': 1721932232.523176}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'ratio': 0.9985449314117432, '_timestamp': 1721932232.5232832}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721932232.524081}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932232.5241868}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'Episode_Time': 68.32447624206543, '_timestamp': 1721932232.5242467}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932232.5248048}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932232.5252059}).
wandb: WARNING (User provided step: 5567 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932232.525626}).
Env Football Algo jrpo Exp base_JRPO updates 5567/100000000000.0 steps in 68.32
total episode rewards is -80.0
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'value_loss': 0.2901638533485432, '_timestamp': 1721932322.5035934}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0053630725825132685, '_timestamp': 1721932322.5048823}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8404558149973553, '_timestamp': 1721932322.5049536}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13621224462985992, '_timestamp': 1721932322.5055208}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1711726188659668, '_timestamp': 1721932322.505885}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'ratio': 0.9983528852462769, '_timestamp': 1721932322.5059888}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932322.5067225}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932322.5069184}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'Episode_Time': 89.97200441360474, '_timestamp': 1721932322.5069768}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2994018998475431, '_timestamp': 1721932322.5083294}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'train_goal': 0.35029905007622847, '_timestamp': 1721932322.508851}).
wandb: WARNING (User provided step: 6473 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2994018998475431, '_timestamp': 1721932322.5093699}).
Env Football Algo jrpo Exp base_JRPO updates 6473/100000000000.0 steps in 89.97
total episode rewards is -20.0
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'value_loss': 0.5887876038998365, '_timestamp': 1721932387.6434557}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0020316883455961943, '_timestamp': 1721932387.6437244}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8469841384887697, '_timestamp': 1721932387.6437922}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22121216356754303, '_timestamp': 1721932387.643899}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6233755350112915, '_timestamp': 1721932387.6441875}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'ratio': 1.0004223585128784, '_timestamp': 1721932387.6442878}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721932387.6449022}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932387.6450038}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'Episode_Time': 65.13280439376831, '_timestamp': 1721932387.6450636}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.08400965123930687, '_timestamp': 1721932387.64593}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'train_goal': 0.4579951743803466, '_timestamp': 1721932387.6462505}).
wandb: WARNING (User provided step: 6211 is less than current step: 12016. Dropping entry: {'train_WDL': -0.08400965123930687, '_timestamp': 1721932387.6465695}).
Env Football Algo jrpo Exp base_JRPO updates 6211/100000000000.0 steps in 65.13
total episode rewards is -80.0
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'value_loss': 0.2642106100831491, '_timestamp': 1721932473.367305}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'policy_loss': -0.001885934128658846, '_timestamp': 1721932473.3676014}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.837578746477763, '_timestamp': 1721932473.3676713}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.157246395945549, '_timestamp': 1721932473.367771}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.28446951508522034, '_timestamp': 1721932473.3680582}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'ratio': 0.9987162351608276, '_timestamp': 1721932473.3685274}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932473.3687449}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932473.3688438}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.71963953971863, '_timestamp': 1721932473.3689053}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.12895235319830978, '_timestamp': 1721932473.3696322}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'train_goal': 0.4355238234008451, '_timestamp': 1721932473.370067}).
wandb: WARNING (User provided step: 8137 is less than current step: 12016. Dropping entry: {'train_WDL': -0.12895235319830978, '_timestamp': 1721932473.3704987}).
Env Football Algo jrpo Exp base_JRPO updates 8137/100000000000.0 steps in 85.72
total episode rewards is -20.0
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'value_loss': 0.7656416733997563, '_timestamp': 1721932521.2589028}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00505702911876142, '_timestamp': 1721932521.2591376}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8381620613733927, '_timestamp': 1721932521.2592046}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2043432593345642, '_timestamp': 1721932521.2593005}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0873184204101562, '_timestamp': 1721932521.2595391}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'ratio': 0.999230146408081, '_timestamp': 1721932521.2596383}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721932521.2601662}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932521.2602627}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'Episode_Time': 47.887423515319824, '_timestamp': 1721932521.2603202}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.0719386866399582, '_timestamp': 1721932521.2608895}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'train_goal': 0.5359693433199791, '_timestamp': 1721932521.261274}).
wandb: WARNING (User provided step: 2099 is less than current step: 12016. Dropping entry: {'train_WDL': 0.0719386866399582, '_timestamp': 1721932521.2617128}).
Env Football Algo jrpo Exp base_JRPO updates 2099/100000000000.0 steps in 47.89
total episode rewards is -70.0
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'value_loss': 0.3804738231484468, '_timestamp': 1721932593.5751734}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006582405114701638, '_timestamp': 1721932593.576494}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.835317532221476, '_timestamp': 1721932593.5765686}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1976415365934372, '_timestamp': 1721932593.5771835}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.46414297819137573, '_timestamp': 1721932593.577543}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'ratio': 1.0019099712371826, '_timestamp': 1721932593.577648}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721932593.5777805}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932593.5779755}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.30734586715698, '_timestamp': 1721932593.5780344}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2666467602269334, '_timestamp': 1721932593.5791721}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'train_goal': 0.3666766198865333, '_timestamp': 1721932593.5795956}).
wandb: WARNING (User provided step: 5642 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2666467602269334, '_timestamp': 1721932593.580038}).
Env Football Algo jrpo Exp base_JRPO updates 5642/100000000000.0 steps in 72.31
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6328/100000000000.0 steps in 57.26
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'value_loss': 0.6123759842664004, '_timestamp': 1721932650.8378057}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004314457462193483, '_timestamp': 1721932650.8379595}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8342810185750325, '_timestamp': 1721932650.8380237}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22774803638458252, '_timestamp': 1721932650.8381166}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0098241567611694, '_timestamp': 1721932650.8383431}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'ratio': 1.0018781423568726, '_timestamp': 1721932650.8384473}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721932650.838583}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932650.8386714}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'Episode_Time': 57.25652742385864, '_timestamp': 1721932650.8388205}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932650.8391993}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932650.83946}).
wandb: WARNING (User provided step: 6328 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932650.839731}).
total episode rewards is -90.0
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'value_loss': 0.6923666294291615, '_timestamp': 1721932699.5322351}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005580710017008338, '_timestamp': 1721932699.5323873}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8297601540883384, '_timestamp': 1721932699.5324528}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22130098938941956, '_timestamp': 1721932699.5325398}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1955816745758057, '_timestamp': 1721932699.5327606}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'ratio': 0.999879777431488, '_timestamp': 1721932699.5328584}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721932699.5330887}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932699.5331771}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'Episode_Time': 48.69169855117798, '_timestamp': 1721932699.5332344}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932699.5335782}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932699.5338306}).
wandb: WARNING (User provided step: 3818 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932699.5340917}).
Env Football Algo jrpo Exp base_JRPO updates 3818/100000000000.0 steps in 48.69
total episode rewards is -120.0
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'value_loss': 0.654123119233797, '_timestamp': 1721932749.8623042}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004180468301832055, '_timestamp': 1721932749.8624623}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.831720339457194, '_timestamp': 1721932749.8625267}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21304886043071747, '_timestamp': 1721932749.862619}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0438286066055298, '_timestamp': 1721932749.8628411}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'ratio': 0.9999999403953552, '_timestamp': 1721932749.8629394}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721932749.8630612}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932749.8631501}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'Episode_Time': 50.327359199523926, '_timestamp': 1721932749.8633275}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.24781849912739964, '_timestamp': 1721932749.8637693}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'train_goal': 0.3760907504363002, '_timestamp': 1721932749.864113}).
wandb: WARNING (User provided step: 4081 is less than current step: 12016. Dropping entry: {'train_WDL': -0.24781849912739964, '_timestamp': 1721932749.864426}).
Env Football Algo jrpo Exp base_JRPO updates 4081/100000000000.0 steps in 50.33
total episode rewards is -90.0
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'value_loss': 0.6759478191037973, '_timestamp': 1721932799.3054185}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006966206522968908, '_timestamp': 1721932799.305592}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.835231006940206, '_timestamp': 1721932799.3056574}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2169988602399826, '_timestamp': 1721932799.3057516}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8437463641166687, '_timestamp': 1721932799.3059897}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'ratio': 1.000221848487854, '_timestamp': 1721932799.3060884}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721932799.3065114}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932799.3066049}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'Episode_Time': 49.440200328826904, '_timestamp': 1721932799.3066628}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.408133472367049, '_timestamp': 1721932799.3071368}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'train_goal': 0.2959332638164755, '_timestamp': 1721932799.3074574}).
wandb: WARNING (User provided step: 2520 is less than current step: 12016. Dropping entry: {'train_WDL': -0.408133472367049, '_timestamp': 1721932799.3077853}).
Env Football Algo jrpo Exp base_JRPO updates 2520/100000000000.0 steps in 49.44
total episode rewards is -90.0
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'value_loss': 0.47944534990936516, '_timestamp': 1721932871.8628266}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005110515252842257, '_timestamp': 1721932871.8630877}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8305438152949014, '_timestamp': 1721932871.863154}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1951921582221985, '_timestamp': 1721932871.863243}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6379221677780151, '_timestamp': 1721932871.8634686}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'ratio': 1.0011026859283447, '_timestamp': 1721932871.8635662}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721932871.86369}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932871.8638968}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.55418729782104, '_timestamp': 1721932871.8639688}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.313149227261211, '_timestamp': 1721932871.8645322}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'train_goal': 0.34342538636939446, '_timestamp': 1721932871.865005}).
wandb: WARNING (User provided step: 5771 is less than current step: 12016. Dropping entry: {'train_WDL': -0.313149227261211, '_timestamp': 1721932871.8654802}).
Env Football Algo jrpo Exp base_JRPO updates 5771/100000000000.0 steps in 72.55
total episode rewards is -40.0
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'value_loss': 0.6175941363473734, '_timestamp': 1721932921.7625313}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004302410356079539, '_timestamp': 1721932921.7627158}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.827822283109029, '_timestamp': 1721932921.762785}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21688467264175415, '_timestamp': 1721932921.762886}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8524802327156067, '_timestamp': 1721932921.7631586}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'ratio': 0.9996333122253418, '_timestamp': 1721932921.7632608}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721932921.7637286}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932921.7638328}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'Episode_Time': 49.89614295959473, '_timestamp': 1721932921.76389}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.32169448010269575, '_timestamp': 1721932921.7643404}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'train_goal': 0.3391527599486521, '_timestamp': 1721932921.7646365}).
wandb: WARNING (User provided step: 2870 is less than current step: 12016. Dropping entry: {'train_WDL': -0.32169448010269575, '_timestamp': 1721932921.7649205}).
Env Football Algo jrpo Exp base_JRPO updates 2870/100000000000.0 steps in 49.90
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 8361/100000000000.0 steps in 82.57
total episode rewards is -30.0
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'value_loss': 0.1996541243046522, '_timestamp': 1721933004.341723}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00481636679690079, '_timestamp': 1721933004.3430603}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8281326913833618, '_timestamp': 1721933004.3431358}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1803540140390396, '_timestamp': 1721933004.343763}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.22457601130008698, '_timestamp': 1721933004.344147}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'ratio': 0.9996219873428345, '_timestamp': 1721933004.344255}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721933004.3450785}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933004.345297}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.5707437992096, '_timestamp': 1721933004.3453567}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933004.3465068}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933004.3469932}).
wandb: WARNING (User provided step: 8361 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933004.347486}).
Env Football Algo jrpo Exp base_JRPO updates 4679/100000000000.0 steps in 51.71
total episode rewards is -80.0
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'value_loss': 0.44755308341234923, '_timestamp': 1721933056.058672}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002204158826304289, '_timestamp': 1721933056.0588322}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.819455790519714, '_timestamp': 1721933056.0588963}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2123427391052246, '_timestamp': 1721933056.0589905}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6480274796485901, '_timestamp': 1721933056.059222}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'ratio': 1.000152587890625, '_timestamp': 1721933056.059427}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721933056.0595522}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933056.059648}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.710238456726074, '_timestamp': 1721933056.0597029}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933056.0600417}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933056.0602748}).
wandb: WARNING (User provided step: 4679 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933056.0605047}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'value_loss': 0.643817594324549, '_timestamp': 1721933102.5405698}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005568440833206599, '_timestamp': 1721933102.540736}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.823081398010254, '_timestamp': 1721933102.540805}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20359688997268677, '_timestamp': 1721933102.5408957}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9623277187347412, '_timestamp': 1721933102.541143}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'ratio': 0.9996315836906433, '_timestamp': 1721933102.5412424}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721933102.5413775}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933102.5416439}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.479246616363525, '_timestamp': 1721933102.5417032}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933102.5420053}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933102.5422025}).
wandb: WARNING (User provided step: 4643 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933102.5423982}).
Env Football Algo jrpo Exp base_JRPO updates 4643/100000000000.0 steps in 46.48
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 4038/100000000000.0 steps in 65.41
total episode rewards is -70.0
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'value_loss': 0.7458410183837016, '_timestamp': 1721933167.956772}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0048964944204150625, '_timestamp': 1721933167.9569395}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8261157353719075, '_timestamp': 1721933167.9570074}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20928393304347992, '_timestamp': 1721933167.9571023}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9231680631637573, '_timestamp': 1721933167.957356}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'ratio': 0.9989344477653503, '_timestamp': 1721933167.957454}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721933167.9577672}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933167.9578598}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'Episode_Time': 65.41345286369324, '_timestamp': 1721933167.9579182}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.35752239259146806, '_timestamp': 1721933167.9651566}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_goal': 0.321238803704266, '_timestamp': 1721933167.9657898}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_WDL': -0.35752239259146806, '_timestamp': 1721933167.96633}).
Env Football Algo jrpo Exp base_JRPO updates 3678/100000000000.0 steps in 45.82
total episode rewards is -90.0
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'value_loss': 0.6658354306345184, '_timestamp': 1721933213.794406}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0015447770788159687, '_timestamp': 1721933213.7952983}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8229477262496947, '_timestamp': 1721933213.7953718}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21349793672561646, '_timestamp': 1721933213.7958136}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8204191327095032, '_timestamp': 1721933213.80018}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'ratio': 0.9999815821647644, '_timestamp': 1721933213.8003016}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721933213.8004441}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933213.8009586}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'Episode_Time': 45.81593704223633, '_timestamp': 1721933213.8010206}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.08837550421708837, '_timestamp': 1721933213.801748}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'train_goal': 0.4558122478914558, '_timestamp': 1721933213.801984}).
wandb: WARNING (User provided step: 3678 is less than current step: 12016. Dropping entry: {'train_WDL': -0.08837550421708837, '_timestamp': 1721933213.802216}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'value_loss': 0.26575459966125586, '_timestamp': 1721933296.0586245}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'policy_loss': 0.025391722947436694, '_timestamp': 1721933296.058778}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.816983397801717, '_timestamp': 1721933296.0588443}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20160020887851715, '_timestamp': 1721933296.0589342}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4121292233467102, '_timestamp': 1721933296.0591729}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'ratio': 0.9994230270385742, '_timestamp': 1721933296.0594544}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721933296.059588}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933296.059677}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.25555443763733, '_timestamp': 1721933296.059732}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2222222222222222, '_timestamp': 1721933296.060329}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'train_goal': 0.3888888888888889, '_timestamp': 1721933296.0611184}).
wandb: WARNING (User provided step: 7440 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2222222222222222, '_timestamp': 1721933296.061579}).
Env Football Algo jrpo Exp base_JRPO updates 7440/100000000000.0 steps in 82.26
total episode rewards is -20.0
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'value_loss': 0.4165522554206351, '_timestamp': 1721933368.4552252}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0010871632926864549, '_timestamp': 1721933368.4554193}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8229676230748493, '_timestamp': 1721933368.4555023}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19638945162296295, '_timestamp': 1721933368.455608}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.44155192375183105, '_timestamp': 1721933368.4558854}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'ratio': 0.9989778995513916, '_timestamp': 1721933368.456043}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721933368.456188}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933368.4567783}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.39272665977478, '_timestamp': 1721933368.456844}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.44368762870267703, '_timestamp': 1721933368.457639}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'train_goal': 0.7218438143513385, '_timestamp': 1721933368.458096}).
wandb: WARNING (User provided step: 5287 is less than current step: 12016. Dropping entry: {'train_WDL': 0.44368762870267703, '_timestamp': 1721933368.4587207}).
Env Football Algo jrpo Exp base_JRPO updates 5287/100000000000.0 steps in 72.39
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 4580/100000000000.0 steps in 58.49
total episode rewards is -80.0
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'value_loss': 0.48392995237683256, '_timestamp': 1721933426.9559875}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002067288961649562, '_timestamp': 1721933426.9574282}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.817172563870748, '_timestamp': 1721933426.9575367}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1859527975320816, '_timestamp': 1721933426.9581518}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8038467764854431, '_timestamp': 1721933426.9585848}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'ratio': 1.0000954866409302, '_timestamp': 1721933426.9608765}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721933426.9611745}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933426.9613822}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'Episode_Time': 58.491037368774414, '_timestamp': 1721933426.961444}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933426.9627237}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933426.9631722}).
wandb: WARNING (User provided step: 4580 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933426.9636147}).
Env Football Algo jrpo Exp base_JRPO updates 8318/100000000000.0 steps in 87.59
total episode rewards is -10.0
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'value_loss': 0.19086887452285736, '_timestamp': 1721933514.5584815}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005296645495885362, '_timestamp': 1721933514.558646}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8164165592193604, '_timestamp': 1721933514.5587113}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17741355299949646, '_timestamp': 1721933514.5588048}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.37069159746170044, '_timestamp': 1721933514.559044}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'ratio': 0.9992450475692749, '_timestamp': 1721933514.5591433}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721933514.5592742}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933514.5596032}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.59370493888855, '_timestamp': 1721933514.5596611}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.10805148159233763, '_timestamp': 1721933514.5604925}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'train_goal': 0.4459742592038312, '_timestamp': 1721933514.560922}).
wandb: WARNING (User provided step: 8318 is less than current step: 12016. Dropping entry: {'train_WDL': -0.10805148159233763, '_timestamp': 1721933514.5613413}).
Env Football Algo jrpo Exp base_JRPO updates 8481/100000000000.0 steps in 77.61
total episode rewards is -50.0
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'value_loss': 0.2948006869945675, '_timestamp': 1721933592.173112}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0085780228797618, '_timestamp': 1721933592.1742828}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.81112531820933, '_timestamp': 1721933592.1743512}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17840120196342468, '_timestamp': 1721933592.1749198}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3987240493297577, '_timestamp': 1721933592.1752713}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'ratio': 0.9983846545219421, '_timestamp': 1721933592.1758282}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721933592.17598}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933592.1761725}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'Episode_Time': 77.6062707901001, '_timestamp': 1721933592.176232}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933592.177171}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933592.1775336}).
wandb: WARNING (User provided step: 8481 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933592.1779006}).
Env Football Algo jrpo Exp base_JRPO updates 1655/100000000000.0 steps in 29.42
total episode rewards is -60.0
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'value_loss': 0.7086723151057959, '_timestamp': 1721933621.6005843}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'policy_loss': 0.009845705683207294, '_timestamp': 1721933621.6007733}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.7974060487747194, '_timestamp': 1721933621.6008432}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.35793301463127136, '_timestamp': 1721933621.6009462}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9739053845405579, '_timestamp': 1721933621.601218}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'ratio': 0.997816801071167, '_timestamp': 1721933621.6013224}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721933621.6014674}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933621.6019492}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'Episode_Time': 29.421729803085327, '_timestamp': 1721933621.6020112}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.41411192214111925, '_timestamp': 1721933621.6023548}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'train_goal': 0.7070559610705596, '_timestamp': 1721933621.6025546}).
wandb: WARNING (User provided step: 1655 is less than current step: 12016. Dropping entry: {'train_WDL': 0.41411192214111925, '_timestamp': 1721933621.602749}).
Env Football Algo jrpo Exp base_JRPO updates 5213/100000000000.0 steps in 57.30
total episode rewards is -90.0
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'value_loss': 0.8864640481273334, '_timestamp': 1721933678.9086423}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00978221764273864, '_timestamp': 1721933678.9099913}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.803916573524475, '_timestamp': 1721933678.9100645}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2491210699081421, '_timestamp': 1721933678.9106777}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.5329968929290771, '_timestamp': 1721933678.9110708}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'ratio': 1.0094096660614014, '_timestamp': 1721933678.9111743}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721933678.9122348}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933678.9124498}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'Episode_Time': 57.29981827735901, '_timestamp': 1721933678.9125085}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933678.9135277}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933678.9138534}).
wandb: WARNING (User provided step: 5213 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933678.9141808}).
Env Football Algo jrpo Exp base_JRPO updates 6000/100000000000.0 steps in 56.74
total episode rewards is -100.0
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'value_loss': 0.6569967767844598, '_timestamp': 1721933735.6501656}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'policy_loss': 0.01896735284787913, '_timestamp': 1721933735.6503344}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.809308648109436, '_timestamp': 1721933735.6504023}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2446267008781433, '_timestamp': 1721933735.6505017}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9943801164627075, '_timestamp': 1721933735.6507695}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'ratio': 1.006854772567749, '_timestamp': 1721933735.6508706}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721933735.651005}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933735.6513412}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'Episode_Time': 56.73516368865967, '_timestamp': 1721933735.6513999}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933735.6517828}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933735.6521354}).
wandb: WARNING (User provided step: 6000 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933735.6524048}).
Env Football Algo jrpo Exp base_JRPO updates 7292/100000000000.0 steps in 84.96
total episode rewards is -40.0
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'value_loss': 0.257394959233546, '_timestamp': 1721933820.6149197}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007195922695488359, '_timestamp': 1721933820.6151419}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8023873710632325, '_timestamp': 1721933820.6152105}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15755623579025269, '_timestamp': 1721933820.6153052}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3954087495803833, '_timestamp': 1721933820.615531}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'ratio': 0.9988318085670471, '_timestamp': 1721933820.6156313}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721933820.6159291}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933820.6160364}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.96165370941162, '_timestamp': 1721933820.616094}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933820.6167636}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933820.6172197}).
wandb: WARNING (User provided step: 7292 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933820.6176941}).
Env Football Algo jrpo Exp base_JRPO updates 10160/100000000000.0 steps in 88.09
total episode rewards is -30.0
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'value_loss': 0.18690462213892411, '_timestamp': 1721933908.7189949}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003998771305584038, '_timestamp': 1721933908.7201967}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.7946928246816, '_timestamp': 1721933908.7202709}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.165458545088768, '_timestamp': 1721933908.7208095}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.16787470877170563, '_timestamp': 1721933908.7211463}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'ratio': 0.9994215965270996, '_timestamp': 1721933908.7213533}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721933908.7215734}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933908.7217476}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.0949068069458, '_timestamp': 1721933908.7218065}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933908.7229514}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933908.7232783}).
wandb: WARNING (User provided step: 10160 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933908.72758}).
Env Football Algo jrpo Exp base_JRPO updates 5365/100000000000.0 steps in 80.13
total episode rewards is -40.0
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'value_loss': 0.2633768456720281, '_timestamp': 1721933988.856903}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00015614086344915753, '_timestamp': 1721933988.8570533}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.7959586572647095, '_timestamp': 1721933988.8571172}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1832767128944397, '_timestamp': 1721933988.8572035}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.34186822175979614, '_timestamp': 1721933988.85743}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'ratio': 0.9991239905357361, '_timestamp': 1721933988.8575306}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721933988.8577688}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933988.857859}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.12816953659058, '_timestamp': 1721933988.8579154}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933988.858562}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933988.8591108}).
wandb: WARNING (User provided step: 5365 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933988.8596876}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'value_loss': 0.2615923512164348, '_timestamp': 1721934074.2528517}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004068658251781016, '_timestamp': 1721934074.253043}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8038303311665853, '_timestamp': 1721934074.2531102}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16663479804992676, '_timestamp': 1721934074.253216}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3712318241596222, '_timestamp': 1721934074.2535007}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'ratio': 0.999612033367157, '_timestamp': 1721934074.254352}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721934074.2545173}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934074.2546194}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.39224576950073, '_timestamp': 1721934074.2546773}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.40062393076381203, '_timestamp': 1721934074.2555768}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'train_goal': 0.299688034618094, '_timestamp': 1721934074.2613585}).
wandb: WARNING (User provided step: 5063 is less than current step: 12016. Dropping entry: {'train_WDL': -0.40062393076381203, '_timestamp': 1721934074.2620015}).
Env Football Algo jrpo Exp base_JRPO updates 5063/100000000000.0 steps in 85.39
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6046/100000000000.0 steps in 87.16
total episode rewards is -40.0
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'value_loss': 0.24986992263662008, '_timestamp': 1721934161.4328434}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004489922927847753, '_timestamp': 1721934161.4341085}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.804768516222636, '_timestamp': 1721934161.4341822}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20992183685302734, '_timestamp': 1721934161.434775}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.29146334528923035, '_timestamp': 1721934161.4351244}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'ratio': 0.9976977705955505, '_timestamp': 1721934161.4352307}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934161.4359908}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934161.436189}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.1646728515625, '_timestamp': 1721934161.4362483}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934161.4379785}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934161.4387603}).
wandb: WARNING (User provided step: 6046 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934161.4397132}).
Env Football Algo jrpo Exp base_JRPO updates 5715/100000000000.0 steps in 67.67
total episode rewards is -60.0
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'value_loss': 0.3839130244986154, '_timestamp': 1721934229.1139154}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00309194921690505, '_timestamp': 1721934229.11409}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8013035678863525, '_timestamp': 1721934229.1141558}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22013908624649048, '_timestamp': 1721934229.1142516}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.43605494499206543, '_timestamp': 1721934229.1144836}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'ratio': 0.9993736743927002, '_timestamp': 1721934229.114586}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721934229.1147766}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934229.115089}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.67309212684631, '_timestamp': 1721934229.1151493}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934229.1157131}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934229.1161416}).
wandb: WARNING (User provided step: 5715 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934229.116564}).
Env Football Algo jrpo Exp base_JRPO updates 1886/100000000000.0 steps in 25.31
total episode rewards is -110.0
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'value_loss': 0.9695202236870925, '_timestamp': 1721934254.4262364}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002750236737386634, '_timestamp': 1721934254.4264102}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.804067138036092, '_timestamp': 1721934254.426479}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2302079051733017, '_timestamp': 1721934254.426576}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.129599690437317, '_timestamp': 1721934254.4268436}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'ratio': 0.9995541572570801, '_timestamp': 1721934254.4269547}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721934254.4270935}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934254.4271898}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'Episode_Time': 25.308128118515015, '_timestamp': 1721934254.427246}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.08442503639010189, '_timestamp': 1721934254.4275372}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'train_goal': 0.45778748180494905, '_timestamp': 1721934254.4277022}).
wandb: WARNING (User provided step: 1886 is less than current step: 12016. Dropping entry: {'train_WDL': -0.08442503639010189, '_timestamp': 1721934254.4278605}).
Env Football Algo jrpo Exp base_JRPO updates 3113/100000000000.0 steps in 39.95
total episode rewards is -130.0
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'value_loss': 1.0788607919216155, '_timestamp': 1721934294.3782725}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004299845626422515, '_timestamp': 1721934294.3784354}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.805012119611104, '_timestamp': 1721934294.3785017}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23145996034145355, '_timestamp': 1721934294.378598}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.432867169380188, '_timestamp': 1721934294.378835}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'ratio': 1.0005396604537964, '_timestamp': 1721934294.3789322}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721934294.3790514}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934294.3793292}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'Episode_Time': 39.949676513671875, '_timestamp': 1721934294.3793871}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934294.379645}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934294.379822}).
wandb: WARNING (User provided step: 3113 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934294.3800275}).
Env Football Algo jrpo Exp base_JRPO updates 10220/100000000000.0 steps in 81.38
total episode rewards is -30.0
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'value_loss': 0.19639910169450256, '_timestamp': 1721934375.7596385}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003362983984601063, '_timestamp': 1721934375.7598736}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8059190638860065, '_timestamp': 1721934375.7599983}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20004814863204956, '_timestamp': 1721934375.760119}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.15852268040180206, '_timestamp': 1721934375.760458}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'ratio': 1.0006020069122314, '_timestamp': 1721934375.7606049}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721934375.7613854}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934375.7615116}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.37866830825806, '_timestamp': 1721934375.7615728}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934375.7620869}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934375.7624667}).
wandb: WARNING (User provided step: 10220 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934375.762811}).
Env Football Algo jrpo Exp base_JRPO updates 5698/100000000000.0 steps in 86.73
total episode rewards is -20.0
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'value_loss': 0.24241279522616727, '_timestamp': 1721934462.4910529}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0005702265427680686, '_timestamp': 1721934462.4912763}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8102955611546836, '_timestamp': 1721934462.4913445}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19454216957092285, '_timestamp': 1721934462.4914384}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.22091487050056458, '_timestamp': 1721934462.4916985}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'ratio': 1.0014086961746216, '_timestamp': 1721934462.4918005}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721934462.4919662}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934462.4924471}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.72742795944214, '_timestamp': 1721934462.4925072}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.37260804128144487, '_timestamp': 1721934462.493617}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'train_goal': 0.31369597935927757, '_timestamp': 1721934462.4941883}).
wandb: WARNING (User provided step: 5698 is less than current step: 12016. Dropping entry: {'train_WDL': -0.37260804128144487, '_timestamp': 1721934462.4950492}).
Env Football Algo jrpo Exp base_JRPO updates 7877/100000000000.0 steps in 67.75
total episode rewards is -60.0
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'value_loss': 0.33417955295648427, '_timestamp': 1721934530.248786}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005106605279919071, '_timestamp': 1721934530.2489617}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8121286884943646, '_timestamp': 1721934530.2490287}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1893429011106491, '_timestamp': 1721934530.249127}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5266910195350647, '_timestamp': 1721934530.2493734}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'ratio': 1.0001060962677002, '_timestamp': 1721934530.2494729}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721934530.249723}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934530.249813}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.75280618667603, '_timestamp': 1721934530.2498693}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934530.2502196}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934530.2504635}).
wandb: WARNING (User provided step: 7877 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934530.2507071}).
Env Football Algo jrpo Exp base_JRPO updates 9614/100000000000.0 steps in 83.22
total episode rewards is -30.0
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'value_loss': 0.1919598083772386, '_timestamp': 1721934613.4761307}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0037819745789359634, '_timestamp': 1721934613.4762952}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8142563676834107, '_timestamp': 1721934613.4763613}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14170467853546143, '_timestamp': 1721934613.476455}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.18901710212230682, '_timestamp': 1721934613.476702}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'ratio': 1.0016189813613892, '_timestamp': 1721934613.476801}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721934613.4771793}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934613.4772723}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.22431683540344, '_timestamp': 1721934613.4773297}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934613.478081}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934613.4784367}).
wandb: WARNING (User provided step: 9614 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934613.4789634}).
Env Football Algo jrpo Exp base_JRPO updates 5529/100000000000.0 steps in 91.34
total episode rewards is -40.0
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'value_loss': 0.2538452510623028, '_timestamp': 1721934704.8174753}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0041169289355942355, '_timestamp': 1721934704.8176491}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8136454884211224, '_timestamp': 1721934704.8177145}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1658107191324234, '_timestamp': 1721934704.817809}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.18947605788707733, '_timestamp': 1721934704.8180664}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'ratio': 0.9990236759185791, '_timestamp': 1721934704.8181658}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934704.8185787}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934704.8186738}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'Episode_Time': 91.33763909339905, '_timestamp': 1721934704.8187308}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934704.8194094}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934704.8200436}).
wandb: WARNING (User provided step: 5529 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934704.8205907}).
Env Football Algo jrpo Exp base_JRPO updates 5039/100000000000.0 steps in 87.94
total episode rewards is -40.0
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'value_loss': 0.27146729262933755, '_timestamp': 1721934792.766422}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'policy_loss': 0.002787706930442558, '_timestamp': 1721934792.7665973}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.816723182996114, '_timestamp': 1721934792.766665}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17515596747398376, '_timestamp': 1721934792.7667656}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.24730134010314941, '_timestamp': 1721934792.7670233}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'ratio': 1.000159740447998, '_timestamp': 1721934792.7671268}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934792.767689}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934792.767786}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.94481563568115, '_timestamp': 1721934792.7678447}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934792.768586}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934792.7691963}).
wandb: WARNING (User provided step: 5039 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934792.769797}).
Env Football Algo jrpo Exp base_JRPO updates 5015/100000000000.0 steps in 81.83
total episode rewards is -20.0
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'value_loss': 0.2877183540025726, '_timestamp': 1721934874.6001396}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0006868825471610762, '_timestamp': 1721934874.600332}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.811117970148722, '_timestamp': 1721934874.6004019}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16124765574932098, '_timestamp': 1721934874.6005077}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.22047866880893707, '_timestamp': 1721934874.6007912}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'ratio': 0.9989465475082397, '_timestamp': 1721934874.6008954}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721934874.6016083}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934874.601711}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.82933950424194, '_timestamp': 1721934874.6017728}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.40230345518277416, '_timestamp': 1721934874.6025927}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'train_goal': 0.2988482724086129, '_timestamp': 1721934874.6032422}).
wandb: WARNING (User provided step: 5015 is less than current step: 12016. Dropping entry: {'train_WDL': -0.40230345518277416, '_timestamp': 1721934874.6040835}).
Env Football Algo jrpo Exp base_JRPO updates 8285/100000000000.0 steps in 86.76
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'value_loss': 0.26067774757839896, '_timestamp': 1721934961.3735616}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0010646251379512251, '_timestamp': 1721934961.3737414}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8054827658335366, '_timestamp': 1721934961.3738081}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16213589906692505, '_timestamp': 1721934961.3739102}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2876493036746979, '_timestamp': 1721934961.374116}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'ratio': 1.0006846189498901, '_timestamp': 1721934961.374213}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934961.3743384}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934961.3744395}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.7633364200592, '_timestamp': 1721934961.3744977}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934961.3750556}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934961.375478}).
wandb: WARNING (User provided step: 8285 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934961.3777583}).
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6336/100000000000.0 steps in 86.61
total episode rewards is -40.0
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'value_loss': 0.2620698165396849, '_timestamp': 1721935047.9934337}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00763165035842879, '_timestamp': 1721935047.9944582}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8062305132548016, '_timestamp': 1721935047.9945266}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17471113801002502, '_timestamp': 1721935047.995008}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4114665985107422, '_timestamp': 1721935047.9953332}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'ratio': 0.9979133605957031, '_timestamp': 1721935047.9954317}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935047.9956634}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935047.9958382}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.61070728302002, '_timestamp': 1721935047.995896}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935047.9968975}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935047.9974165}).
wandb: WARNING (User provided step: 6336 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935047.997916}).
Env Football Algo jrpo Exp base_JRPO updates 8300/100000000000.0 steps in 81.86
total episode rewards is -20.0
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'value_loss': 0.24444793986331206, '_timestamp': 1721935129.8561063}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0009918009326793254, '_timestamp': 1721935129.8562582}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.81329949537913, '_timestamp': 1721935129.8563242}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16217269003391266, '_timestamp': 1721935129.8564134}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.16792789101600647, '_timestamp': 1721935129.8566465}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'ratio': 0.9985126256942749, '_timestamp': 1721935129.8567486}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721935129.8568716}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935129.8570611}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.85728144645691, '_timestamp': 1721935129.8571193}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.10925373134328359, '_timestamp': 1721935129.857605}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'train_goal': 0.44537313432835823, '_timestamp': 1721935129.8580105}).
wandb: WARNING (User provided step: 8300 is less than current step: 12016. Dropping entry: {'train_WDL': -0.10925373134328359, '_timestamp': 1721935129.8584077}).
Env Football Algo jrpo Exp base_JRPO updates 7363/100000000000.0 steps in 76.45
total episode rewards is -80.0
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'value_loss': 0.5097081741814812, '_timestamp': 1721935206.3139677}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002138037494344947, '_timestamp': 1721935206.314131}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8189789215723673, '_timestamp': 1721935206.314196}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20371654629707336, '_timestamp': 1721935206.314289}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9939567446708679, '_timestamp': 1721935206.3145201}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'ratio': 1.0000348091125488, '_timestamp': 1721935206.3146183}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721935206.3148992}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935206.3149917}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.45433115959167, '_timestamp': 1721935206.315049}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935206.3154998}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935206.315845}).
wandb: WARNING (User provided step: 7363 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935206.3162034}).
Env Football Algo jrpo Exp base_JRPO updates 6094/100000000000.0 steps in 82.47
total episode rewards is -40.0
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'value_loss': 0.3028240338542188, '_timestamp': 1721935288.7866383}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006244310993545999, '_timestamp': 1721935288.7867937}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8157915608088175, '_timestamp': 1721935288.7868578}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19627265632152557, '_timestamp': 1721935288.7869468}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.31629136204719543, '_timestamp': 1721935288.7871795}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'ratio': 0.9984434247016907, '_timestamp': 1721935288.78728}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935288.787396}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935288.7875786}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.46956658363342, '_timestamp': 1721935288.7876365}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935288.7882526}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935288.78878}).
wandb: WARNING (User provided step: 6094 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935288.7893245}).
Env Football Algo jrpo Exp base_JRPO updates 8869/100000000000.0 steps in 84.60
total episode rewards is -10.0
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'value_loss': 0.19166485897731037, '_timestamp': 1721935373.3865616}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0029296802694443614, '_timestamp': 1721935373.3867464}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8171126476923622, '_timestamp': 1721935373.3868153}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14430978894233704, '_timestamp': 1721935373.3869169}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.13011160492897034, '_timestamp': 1721935373.387194}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'ratio': 0.999176561832428, '_timestamp': 1721935373.3873014}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721935373.3881342}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935373.3882372}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.59619879722595, '_timestamp': 1721935373.3919353}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.0272386233893329, '_timestamp': 1721935373.3926103}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'train_goal': 0.48638068830533354, '_timestamp': 1721935373.393075}).
wandb: WARNING (User provided step: 8869 is less than current step: 12016. Dropping entry: {'train_WDL': -0.0272386233893329, '_timestamp': 1721935373.3935294}).
Env Football Algo jrpo Exp base_JRPO updates 4061/100000000000.0 steps in 66.74
total episode rewards is -70.0
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'value_loss': 0.42319607278953, '_timestamp': 1721935440.1353347}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0004221417871303856, '_timestamp': 1721935440.1366744}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.814893356959025, '_timestamp': 1721935440.1367528}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18603573739528656, '_timestamp': 1721935440.1373465}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.579806923866272, '_timestamp': 1721935440.137747}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'ratio': 1.0003403425216675, '_timestamp': 1721935440.1378565}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721935440.1380026}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935440.1382096}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'Episode_Time': 66.73522734642029, '_timestamp': 1721935440.1382756}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935440.1393685}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935440.1398327}).
wandb: WARNING (User provided step: 4061 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935440.1403224}).
Env Football Algo jrpo Exp base_JRPO updates 3627/100000000000.0 steps in 44.65
total episode rewards is -120.0
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'value_loss': 0.692244144876798, '_timestamp': 1721935484.7877965}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'policy_loss': -0.001256021367929255, '_timestamp': 1721935484.787997}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.819251038233439, '_timestamp': 1721935484.7880661}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21774126589298248, '_timestamp': 1721935484.7881668}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8162475824356079, '_timestamp': 1721935484.788427}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'ratio': 1.0008084774017334, '_timestamp': 1721935484.7885287}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721935484.7894146}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935484.7895236}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.646416425704956, '_timestamp': 1721935484.7895834}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935484.7901292}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935484.7903717}).
wandb: WARNING (User provided step: 3627 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935484.7906656}).
Env Football Algo jrpo Exp base_JRPO updates 2801/100000000000.0 steps in 36.25
total episode rewards is -120.0
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'value_loss': 0.8289186285932859, '_timestamp': 1721935521.0464523}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004483764215692645, '_timestamp': 1721935521.0466425}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8194505469004314, '_timestamp': 1721935521.0467088}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21278449892997742, '_timestamp': 1721935521.0468132}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.172437310218811, '_timestamp': 1721935521.0471807}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'ratio': 1.0012885332107544, '_timestamp': 1721935521.0472937}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721935521.04753}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935521.0482373}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'Episode_Time': 36.25439524650574, '_timestamp': 1721935521.0482996}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.26076636147846727, '_timestamp': 1721935521.0488567}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'train_goal': 0.36961681926076634, '_timestamp': 1721935521.049144}).
wandb: WARNING (User provided step: 2801 is less than current step: 12016. Dropping entry: {'train_WDL': -0.26076636147846727, '_timestamp': 1721935521.0493908}).
Env Football Algo jrpo Exp base_JRPO updates 3469/100000000000.0 steps in 67.11
total episode rewards is -80.0
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'value_loss': 0.6784476495285829, '_timestamp': 1721935588.1736674}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0023005367912507305, '_timestamp': 1721935588.1748383}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.824311154683431, '_timestamp': 1721935588.1749346}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.23563812673091888, '_timestamp': 1721935588.1754615}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8220110535621643, '_timestamp': 1721935588.1758633}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'ratio': 1.000531792640686, '_timestamp': 1721935588.1760037}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721935588.1761518}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935588.1768365}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.11273622512817, '_timestamp': 1721935588.1769004}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.16936590721932474, '_timestamp': 1721935588.1782274}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'train_goal': 0.5846829536096624, '_timestamp': 1721935588.178983}).
wandb: WARNING (User provided step: 3469 is less than current step: 12016. Dropping entry: {'train_WDL': 0.16936590721932474, '_timestamp': 1721935588.179706}).
Env Football Algo jrpo Exp base_JRPO updates 3850/100000000000.0 steps in 65.66
total episode rewards is -60.0
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'value_loss': 0.431217983327806, '_timestamp': 1721935653.8449461}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0024837361780616143, '_timestamp': 1721935653.8451374}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.820751503308614, '_timestamp': 1721935653.8452053}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.22499336302280426, '_timestamp': 1721935653.845308}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5421387553215027, '_timestamp': 1721935653.8455367}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'ratio': 1.0003710985183716, '_timestamp': 1721935653.8456368}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721935653.8462012}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935653.8462982}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'Episode_Time': 65.66426801681519, '_timestamp': 1721935653.8463545}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4126237623762376, '_timestamp': 1721935653.846994}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_goal': 0.29368811881188117, '_timestamp': 1721935653.847508}).
wandb: WARNING (User provided step: 3850 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4126237623762376, '_timestamp': 1721935653.8480523}).
Env Football Algo jrpo Exp base_JRPO updates 6235/100000000000.0 steps in 67.11
total episode rewards is -90.0
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'value_loss': 0.5068784382070104, '_timestamp': 1721935720.959155}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00035125364006186526, '_timestamp': 1721935720.9593077}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.817236959139506, '_timestamp': 1721935720.9593744}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20883557200431824, '_timestamp': 1721935720.9594653}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.68156498670578, '_timestamp': 1721935720.9597533}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'ratio': 0.9993546605110168, '_timestamp': 1721935720.9598577}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721935720.9600272}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935720.9602325}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.11038279533386, '_timestamp': 1721935720.9602919}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935720.9607122}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935720.9610322}).
wandb: WARNING (User provided step: 6235 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935720.9613676}).
Env Football Algo jrpo Exp base_JRPO updates 6389/100000000000.0 steps in 83.92
total episode rewards is -20.0
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'value_loss': 0.29608873654389756, '_timestamp': 1721935804.878355}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007619628326259165, '_timestamp': 1721935804.878548}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.824797519048055, '_timestamp': 1721935804.878615}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1810198575258255, '_timestamp': 1721935804.8787174}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.571921706199646, '_timestamp': 1721935804.8789775}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'ratio': 1.0008167028427124, '_timestamp': 1721935804.8790815}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721935804.8792174}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935804.8794367}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.91598582267761, '_timestamp': 1721935804.8794956}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.5480199744512833, '_timestamp': 1721935804.8802834}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'train_goal': 0.22599001277435837, '_timestamp': 1721935804.8808134}).
wandb: WARNING (User provided step: 6389 is less than current step: 12016. Dropping entry: {'train_WDL': -0.5480199744512833, '_timestamp': 1721935804.881345}).
Env Football Algo jrpo Exp base_JRPO updates 6994/100000000000.0 steps in 71.34
total episode rewards is -60.0
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'value_loss': 0.5509273018315435, '_timestamp': 1721935876.220735}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0036849287804216146, '_timestamp': 1721935876.2208812}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8246252234776814, '_timestamp': 1721935876.2209446}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2110653668642044, '_timestamp': 1721935876.2210317}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8092645406723022, '_timestamp': 1721935876.2212486}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'ratio': 1.0005316734313965, '_timestamp': 1721935876.2213452}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721935876.2215579}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935876.221646}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'Episode_Time': 71.33840990066528, '_timestamp': 1721935876.2217023}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.0982532751091703, '_timestamp': 1721935876.2222302}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'train_goal': 0.45087336244541487, '_timestamp': 1721935876.222582}).
wandb: WARNING (User provided step: 6994 is less than current step: 12016. Dropping entry: {'train_WDL': -0.0982532751091703, '_timestamp': 1721935876.222934}).
Env Football Algo jrpo Exp base_JRPO updates 3435/100000000000.0 steps in 73.84
total episode rewards is -60.0
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'value_loss': 0.49409297430266935, '_timestamp': 1721935950.0683491}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006588076960955125, '_timestamp': 1721935950.0686111}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.827179282506307, '_timestamp': 1721935950.068677}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20148779451847076, '_timestamp': 1721935950.0687754}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7557840943336487, '_timestamp': 1721935950.0690658}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'ratio': 1.000135064125061, '_timestamp': 1721935950.0691705}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721935950.0694826}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935950.0696754}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'Episode_Time': 73.84445476531982, '_timestamp': 1721935950.0697367}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4523756906077348, '_timestamp': 1721935950.0709913}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'train_goal': 0.27381215469613257, '_timestamp': 1721935950.07155}).
wandb: WARNING (User provided step: 3435 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4523756906077348, '_timestamp': 1721935950.0722728}).
Env Football Algo jrpo Exp base_JRPO updates 2445/100000000000.0 steps in 51.59
total episode rewards is -20.0
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'value_loss': 0.5076620197917024, '_timestamp': 1721936001.6659405}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003968853744833419, '_timestamp': 1721936001.667037}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8304013935724894, '_timestamp': 1721936001.6671169}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20901933312416077, '_timestamp': 1721936001.667601}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.690237283706665, '_timestamp': 1721936001.6679904}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'ratio': 1.0010709762573242, '_timestamp': 1721936001.6681027}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721936001.6682382}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936001.668867}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.58872103691101, '_timestamp': 1721936001.6689272}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.6648117839607202, '_timestamp': 1721936001.670227}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'train_goal': 0.8324058919803601, '_timestamp': 1721936001.6706362}).
wandb: WARNING (User provided step: 2445 is less than current step: 12016. Dropping entry: {'train_WDL': 0.6648117839607202, '_timestamp': 1721936001.6711555}).
Env Football Algo jrpo Exp base_JRPO updates 7900/100000000000.0 steps in 81.07
total episode rewards is -60.0
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'value_loss': 0.3719566668011248, '_timestamp': 1721936082.7470677}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00018920464674010873, '_timestamp': 1721936082.7472734}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.838781352043152, '_timestamp': 1721936082.7473435}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19046132266521454, '_timestamp': 1721936082.7474434}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4233544170856476, '_timestamp': 1721936082.7476978}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'ratio': 1.0019398927688599, '_timestamp': 1721936082.747798}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721936082.748389}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936082.748488}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.07475447654724, '_timestamp': 1721936082.7485466}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936082.7496982}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936082.7503912}).
wandb: WARNING (User provided step: 7900 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936082.7509892}).
Env Football Algo jrpo Exp base_JRPO updates 7226/100000000000.0 steps in 88.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'value_loss': 0.25194998146345216, '_timestamp': 1721936170.936912}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007434987662903344, '_timestamp': 1721936170.9380422}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8321580330530804, '_timestamp': 1721936170.9381108}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17329804599285126, '_timestamp': 1721936170.9386697}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3232036530971527, '_timestamp': 1721936170.9390125}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'ratio': 0.9985007047653198, '_timestamp': 1721936170.9391124}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936170.9392464}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936170.939906}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.18043923377991, '_timestamp': 1721936170.940047}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936170.9413223}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936170.9418306}).
wandb: WARNING (User provided step: 7226 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936170.9423492}).
Env Football Algo jrpo Exp base_JRPO updates 5505/100000000000.0 steps in 79.14
total episode rewards is -10.0
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'value_loss': 0.343255842026944, '_timestamp': 1721936250.0874155}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0016710649923576662, '_timestamp': 1721936250.0877202}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.830324093500773, '_timestamp': 1721936250.0877905}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1844393014907837, '_timestamp': 1721936250.087882}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.45191508531570435, '_timestamp': 1721936250.0881367}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'ratio': 0.9990756511688232, '_timestamp': 1721936250.088237}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721936250.0883684}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936250.088632}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.14408659934998, '_timestamp': 1721936250.0886889}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.28850967007963596, '_timestamp': 1721936250.0894413}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'train_goal': 0.644254835039818, '_timestamp': 1721936250.0899215}).
wandb: WARNING (User provided step: 5505 is less than current step: 12016. Dropping entry: {'train_WDL': 0.28850967007963596, '_timestamp': 1721936250.090434}).
Env Football Algo jrpo Exp base_JRPO updates 6576/100000000000.0 steps in 81.59
total episode rewards is -20.0
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'value_loss': 0.24330582540715112, '_timestamp': 1721936331.6793497}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00625390143521751, '_timestamp': 1721936331.6794996}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8244099108378093, '_timestamp': 1721936331.6795623}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.12630623579025269, '_timestamp': 1721936331.6796508}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.47270065546035767, '_timestamp': 1721936331.6798782}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'ratio': 0.99918133020401, '_timestamp': 1721936331.680003}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721936331.6801376}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936331.6803248}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.58804154396057, '_timestamp': 1721936331.6803842}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2939221272554606, '_timestamp': 1721936331.6809797}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'train_goal': 0.3530389363722697, '_timestamp': 1721936331.6818907}).
wandb: WARNING (User provided step: 6576 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2939221272554606, '_timestamp': 1721936331.6823936}).
Env Football Algo jrpo Exp base_JRPO updates 3312/100000000000.0 steps in 53.84
total episode rewards is -40.0
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'value_loss': 0.3793783309031278, '_timestamp': 1721936385.526507}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0001438352089220037, '_timestamp': 1721936385.5266638}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.82369482199351, '_timestamp': 1721936385.5267284}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16179798543453217, '_timestamp': 1721936385.5268178}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5229408144950867, '_timestamp': 1721936385.52706}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'ratio': 0.9993773698806763, '_timestamp': 1721936385.5271544}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936385.5274544}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936385.527547}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'Episode_Time': 53.84320783615112, '_timestamp': 1721936385.527602}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.36466715435259694, '_timestamp': 1721936385.5280774}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'train_goal': 0.31766642282370156, '_timestamp': 1721936385.5284278}).
wandb: WARNING (User provided step: 3312 is less than current step: 12016. Dropping entry: {'train_WDL': -0.36466715435259694, '_timestamp': 1721936385.5287828}).
Env Football Algo jrpo Exp base_JRPO updates 6306/100000000000.0 steps in 80.24
total episode rewards is -60.0
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'value_loss': 0.3785887766908854, '_timestamp': 1721936465.7697783}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'policy_loss': 0.001574978343754386, '_timestamp': 1721936465.7700324}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8290877310434976, '_timestamp': 1721936465.7701032}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19626079499721527, '_timestamp': 1721936465.7702048}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.45301851630210876, '_timestamp': 1721936465.7704816}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'ratio': 0.9987938404083252, '_timestamp': 1721936465.7705848}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721936465.7708473}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936465.771514}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.24000287055969, '_timestamp': 1721936465.7715747}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936465.7725925}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936465.7731469}).
wandb: WARNING (User provided step: 6306 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936465.7736444}).
Env Football Algo jrpo Exp base_JRPO updates 8364/100000000000.0 steps in 70.43
total episode rewards is -70.0
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'value_loss': 0.39971831764482585, '_timestamp': 1721936536.203398}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004433975698969637, '_timestamp': 1721936536.2036135}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8274615589777627, '_timestamp': 1721936536.2036803}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19809654355049133, '_timestamp': 1721936536.2037706}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5141520500183105, '_timestamp': 1721936536.2041192}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'ratio': 1.0041474103927612, '_timestamp': 1721936536.2042208}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721936536.2047904}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936536.2048848}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'Episode_Time': 70.42867875099182, '_timestamp': 1721936536.2049427}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936536.205433}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936536.2057476}).
wandb: WARNING (User provided step: 8364 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936536.2062407}).
Env Football Algo jrpo Exp base_JRPO updates 5925/100000000000.0 steps in 85.41
total episode rewards is -40.0
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'value_loss': 0.28545152546760316, '_timestamp': 1721936621.6169257}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'policy_loss': -0.010818604403466452, '_timestamp': 1721936621.6170714}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.835522174835205, '_timestamp': 1721936621.6171348}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.11815334856510162, '_timestamp': 1721936621.61722}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.28288570046424866, '_timestamp': 1721936621.61744}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'ratio': 0.9970725774765015, '_timestamp': 1721936621.6175368}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936621.6176655}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936621.617874}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.4098014831543, '_timestamp': 1721936621.6179318}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936621.618548}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936621.6190665}).
wandb: WARNING (User provided step: 5925 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936621.6196125}).
Env Football Algo jrpo Exp base_JRPO updates 3114/100000000000.0 steps in 48.12
total episode rewards is -60.0
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'value_loss': 0.5893209791307648, '_timestamp': 1721936669.7378643}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0023843644004470357, '_timestamp': 1721936669.7380154}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8319664986928306, '_timestamp': 1721936669.7380805}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.21995316445827484, '_timestamp': 1721936669.7381694}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.941585123538971, '_timestamp': 1721936669.7383964}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'ratio': 0.9993610978126526, '_timestamp': 1721936669.7384932}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721936669.7387147}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936669.7388046}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'Episode_Time': 48.117390632629395, '_timestamp': 1721936669.7388618}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3792603335750544, '_timestamp': 1721936669.7393088}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'train_goal': 0.3103698332124728, '_timestamp': 1721936669.7396545}).
wandb: WARNING (User provided step: 3114 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3792603335750544, '_timestamp': 1721936669.7400362}).
Env Football Algo jrpo Exp base_JRPO updates 5452/100000000000.0 steps in 86.07
total episode rewards is -40.0
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'value_loss': 0.28115683218891113, '_timestamp': 1721936755.8129432}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0003572967027624448, '_timestamp': 1721936755.813145}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.82305627822876, '_timestamp': 1721936755.813215}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14765116572380066, '_timestamp': 1721936755.8133187}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.17222829163074493, '_timestamp': 1721936755.8136287}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'ratio': 1.0001757144927979, '_timestamp': 1721936755.81447}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936755.814998}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936755.8151097}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.07195210456848, '_timestamp': 1721936755.815171}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936755.815978}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936755.8165543}).
wandb: WARNING (User provided step: 5452 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936755.8176076}).
Env Football Algo jrpo Exp base_JRPO updates 3263/100000000000.0 steps in 58.74
total episode rewards is -30.0
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'value_loss': 0.4502102837416654, '_timestamp': 1721936814.560029}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0036691512347897513, '_timestamp': 1721936814.5601869}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8204366970062256, '_timestamp': 1721936814.5602527}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19159862399101257, '_timestamp': 1721936814.560344}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6239265203475952, '_timestamp': 1721936814.5605817}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'ratio': 0.9989530444145203, '_timestamp': 1721936814.5606816}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721936814.561}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936814.5610943}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'Episode_Time': 58.74125123023987, '_timestamp': 1721936814.5611517}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.1441784548422198, '_timestamp': 1721936814.5617015}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'train_goal': 0.5720892274211099, '_timestamp': 1721936814.5621476}).
wandb: WARNING (User provided step: 3263 is less than current step: 12016. Dropping entry: {'train_WDL': 0.1441784548422198, '_timestamp': 1721936814.562593}).
Env Football Algo jrpo Exp base_JRPO updates 5783/100000000000.0 steps in 85.77
total episode rewards is -40.0
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'value_loss': 0.25902279605235284, '_timestamp': 1721936900.334708}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007079579621010149, '_timestamp': 1721936900.3348584}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.820647800763448, '_timestamp': 1721936900.3349226}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19441285729408264, '_timestamp': 1721936900.3350127}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.12957394123077393, '_timestamp': 1721936900.3352475}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'ratio': 0.9992901086807251, '_timestamp': 1721936900.335347}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936900.3356042}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936900.3356988}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.77124500274658, '_timestamp': 1721936900.3357587}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936900.3365679}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936900.3371153}).
wandb: WARNING (User provided step: 5783 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936900.3376696}).
Env Football Algo jrpo Exp base_JRPO updates 3748/100000000000.0 steps in 76.58
total episode rewards is -20.0
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'value_loss': 0.3704442274135848, '_timestamp': 1721936976.9202533}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002158315236059328, '_timestamp': 1721936976.9204113}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8273976627985635, '_timestamp': 1721936976.9204803}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17974334955215454, '_timestamp': 1721936976.9205697}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7443710565567017, '_timestamp': 1721936976.9208097}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'ratio': 0.9979899525642395, '_timestamp': 1721936976.9209216}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721936976.9211698}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936976.9212615}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.5818464756012, '_timestamp': 1721936976.9213197}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.0922970159611381, '_timestamp': 1721936976.9220319}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'train_goal': 0.546148507980569, '_timestamp': 1721936976.9226027}).
wandb: WARNING (User provided step: 3748 is less than current step: 12016. Dropping entry: {'train_WDL': 0.0922970159611381, '_timestamp': 1721936976.9231756}).
Env Football Algo jrpo Exp base_JRPO updates 6444/100000000000.0 steps in 82.67
total episode rewards is -20.0
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'value_loss': 0.2762925881909905, '_timestamp': 1721937059.593369}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00038334676685432593, '_timestamp': 1721937059.5935261}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.821992015838623, '_timestamp': 1721937059.5935922}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18943877518177032, '_timestamp': 1721937059.5936813}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.17083139717578888, '_timestamp': 1721937059.5939069}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'ratio': 1.0004178285598755, '_timestamp': 1721937059.594037}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937059.594222}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937059.5943677}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'Episode_Time': 82.66944360733032, '_timestamp': 1721937059.5944278}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.30434782608695654, '_timestamp': 1721937059.5950649}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'train_goal': 0.34782608695652173, '_timestamp': 1721937059.595572}).
wandb: WARNING (User provided step: 6444 is less than current step: 12016. Dropping entry: {'train_WDL': -0.30434782608695654, '_timestamp': 1721937059.5961015}).
Env Football Algo jrpo Exp base_JRPO updates 7288/100000000000.0 steps in 78.14
total episode rewards is -60.0
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'value_loss': 0.39638382198366645, '_timestamp': 1721937137.7354348}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004720992194488644, '_timestamp': 1721937137.73559}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.820085868835449, '_timestamp': 1721937137.7356558}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18249905109405518, '_timestamp': 1721937137.735748}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.602587103843689, '_timestamp': 1721937137.735998}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'ratio': 1.000127911567688, '_timestamp': 1721937137.736099}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721937137.7363534}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937137.7364464}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.13844919204712, '_timestamp': 1721937137.7365034}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937137.7370439}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937137.737466}).
wandb: WARNING (User provided step: 7288 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937137.7379048}).
Env Football Algo jrpo Exp base_JRPO updates 7744/100000000000.0 steps in 83.21
total episode rewards is -40.0
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'value_loss': 0.2627826197026297, '_timestamp': 1721937220.9469743}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00021538562296579281, '_timestamp': 1721937220.9471288}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829009051322937, '_timestamp': 1721937220.9471948}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1493886113166809, '_timestamp': 1721937220.9472857}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.20814213156700134, '_timestamp': 1721937220.9475234}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'ratio': 0.9966973066329956, '_timestamp': 1721937220.9476244}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721937220.947982}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937220.948078}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.20836567878723, '_timestamp': 1721937220.9481368}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937220.9486616}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937220.9490943}).
wandb: WARNING (User provided step: 7744 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937220.9495473}).
Env Football Algo jrpo Exp base_JRPO updates 4374/100000000000.0 steps in 81.14
total episode rewards is 0.0
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'value_loss': 0.28278588977952795, '_timestamp': 1721937302.0867474}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0040944961314865694, '_timestamp': 1721937302.086899}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.819025541941325, '_timestamp': 1721937302.086965}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15243114531040192, '_timestamp': 1721937302.0870528}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.31386440992355347, '_timestamp': 1721937302.087285}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'ratio': 0.9978370666503906, '_timestamp': 1721937302.0875237}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721937302.087671}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937302.0877604}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.13635206222534, '_timestamp': 1721937302.0878177}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.12083568605307736, '_timestamp': 1721937302.0885901}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'train_goal': 0.5604178430265386, '_timestamp': 1721937302.0891857}).
wandb: WARNING (User provided step: 4374 is less than current step: 12016. Dropping entry: {'train_WDL': 0.12083568605307736, '_timestamp': 1721937302.0897906}).
Env Football Algo jrpo Exp base_JRPO updates 9883/100000000000.0 steps in 78.92
total episode rewards is -20.0
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'value_loss': 0.13803376043525836, '_timestamp': 1721937381.0067317}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0038456324257034186, '_timestamp': 1721937381.0069}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8141553290685017, '_timestamp': 1721937381.006967}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1596941351890564, '_timestamp': 1721937381.0070612}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.10962814837694168, '_timestamp': 1721937381.0073092}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'ratio': 1.000177264213562, '_timestamp': 1721937381.0074093}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937381.007545}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937381.0076368}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.91574883460999, '_timestamp': 1721937381.007702}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937381.008199}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937381.0085423}).
wandb: WARNING (User provided step: 9883 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937381.0088878}).
Env Football Algo jrpo Exp base_JRPO updates 5060/100000000000.0 steps in 87.41
total episode rewards is -20.0
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'value_loss': 0.28488797365066904, '_timestamp': 1721937468.4241884}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005657385369413532, '_timestamp': 1721937468.4243789}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8107960748672487, '_timestamp': 1721937468.4244459}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18419326841831207, '_timestamp': 1721937468.4245565}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.46254390478134155, '_timestamp': 1721937468.4248714}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'ratio': 0.9978106021881104, '_timestamp': 1721937468.4249763}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937468.4251196}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937468.4256923}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.41439151763916, '_timestamp': 1721937468.4257555}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.40925553319919517, '_timestamp': 1721937468.4265301}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'train_goal': 0.2953722334004024, '_timestamp': 1721937468.4271243}).
wandb: WARNING (User provided step: 5060 is less than current step: 12016. Dropping entry: {'train_WDL': -0.40925553319919517, '_timestamp': 1721937468.4277284}).
Env Football Algo jrpo Exp base_JRPO updates 7407/100000000000.0 steps in 80.49
total episode rewards is -10.0
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'value_loss': 0.20506329915331056, '_timestamp': 1721937548.922748}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003182382145896554, '_timestamp': 1721937548.9229066}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.81289381980896, '_timestamp': 1721937548.9229705}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17330795526504517, '_timestamp': 1721937548.923062}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.23992018401622772, '_timestamp': 1721937548.9232943}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'ratio': 0.9990059733390808, '_timestamp': 1721937548.9233952}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721937548.9236298}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937548.923722}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.49408483505249, '_timestamp': 1721937548.9237807}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.21374950612406163, '_timestamp': 1721937548.9243586}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'train_goal': 0.3931252469379692, '_timestamp': 1721937548.9248137}).
wandb: WARNING (User provided step: 7407 is less than current step: 12016. Dropping entry: {'train_WDL': -0.21374950612406163, '_timestamp': 1721937548.9252775}).
Env Football Algo jrpo Exp base_JRPO updates 2689/100000000000.0 steps in 35.10
total episode rewards is -50.0
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'value_loss': 0.6428499267250299, '_timestamp': 1721937584.0307894}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004156019439881978, '_timestamp': 1721937584.030939}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.810598481496175, '_timestamp': 1721937584.0310025}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19579219818115234, '_timestamp': 1721937584.0310893}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.064803123474121, '_timestamp': 1721937584.0313191}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'ratio': 1.0001955032348633, '_timestamp': 1721937584.0314145}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721937584.031533}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937584.0317307}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'Episode_Time': 35.10464334487915, '_timestamp': 1721937584.0317867}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.034229828850855744, '_timestamp': 1721937584.0320706}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'train_goal': 0.5171149144254279, '_timestamp': 1721937584.0322347}).
wandb: WARNING (User provided step: 2689 is less than current step: 12016. Dropping entry: {'train_WDL': 0.034229828850855744, '_timestamp': 1721937584.0323908}).
Env Football Algo jrpo Exp base_JRPO updates 3101/100000000000.0 steps in 34.63
total episode rewards is -70.0
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'value_loss': 0.7801270860930284, '_timestamp': 1721937618.6617777}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002672760444887293, '_timestamp': 1721937618.6619616}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8131210215886435, '_timestamp': 1721937618.6620293}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.2093881219625473, '_timestamp': 1721937618.6621299}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9771909713745117, '_timestamp': 1721937618.6628127}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'ratio': 0.9996355175971985, '_timestamp': 1721937618.6630323}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721937618.6631756}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937618.6632705}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.62858033180237, '_timestamp': 1721937618.6633282}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.05141269106067624, '_timestamp': 1721937618.6636596}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'train_goal': 0.4742936544696619, '_timestamp': 1721937618.6638763}).
wandb: WARNING (User provided step: 3101 is less than current step: 12016. Dropping entry: {'train_WDL': -0.05141269106067624, '_timestamp': 1721937618.664108}).
Env Football Algo jrpo Exp base_JRPO updates 4587/100000000000.0 steps in 79.04
total episode rewards is -60.0
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'value_loss': 0.5002227081389476, '_timestamp': 1721937697.7138565}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006918626083837201, '_timestamp': 1721937697.7152214}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.809858109156291, '_timestamp': 1721937697.7153025}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1612921804189682, '_timestamp': 1721937697.7158577}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6167111992835999, '_timestamp': 1721937697.7162895}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'ratio': 0.9961522817611694, '_timestamp': 1721937697.7163954}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721937697.7166414}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937697.7175086}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.04421472549438, '_timestamp': 1721937697.7175748}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.39433049089651995, '_timestamp': 1721937697.7193332}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'train_goal': 0.30283475455174, '_timestamp': 1721937697.7202284}).
wandb: WARNING (User provided step: 4587 is less than current step: 12016. Dropping entry: {'train_WDL': -0.39433049089651995, '_timestamp': 1721937697.7209227}).
Env Football Algo jrpo Exp base_JRPO updates 6113/100000000000.0 steps in 79.58
total episode rewards is -20.0
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'value_loss': 0.29060248531633986, '_timestamp': 1721937777.3005037}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0019219441298628226, '_timestamp': 1721937777.3007095}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.81299868106842, '_timestamp': 1721937777.300778}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.12069294601678848, '_timestamp': 1721937777.3008769}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.33304205536842346, '_timestamp': 1721937777.3011217}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'ratio': 1.0006400346755981, '_timestamp': 1721937777.3012216}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937777.3017712}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937777.3018677}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'Episode_Time': 79.57828426361084, '_timestamp': 1721937777.3019257}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.33025767975694836, '_timestamp': 1721937777.3032544}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'train_goal': 0.33487116012152585, '_timestamp': 1721937777.3038652}).
wandb: WARNING (User provided step: 6113 is less than current step: 12016. Dropping entry: {'train_WDL': -0.33025767975694836, '_timestamp': 1721937777.3044152}).
Env Football Algo jrpo Exp base_JRPO updates 4576/100000000000.0 steps in 68.66
total episode rewards is -80.0
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'value_loss': 0.47693163962413865, '_timestamp': 1721937845.9664319}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00584544703985254, '_timestamp': 1721937845.9676406}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8188363790512083, '_timestamp': 1721937845.9677093}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16197876632213593, '_timestamp': 1721937845.9683049}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7511945962905884, '_timestamp': 1721937845.9686108}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'ratio': 0.9995512366294861, '_timestamp': 1721937845.9687123}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721937845.9689603}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937845.9692397}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'Episode_Time': 68.65627717971802, '_timestamp': 1721937845.9693005}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937845.9703279}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937845.9708064}).
wandb: WARNING (User provided step: 4576 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937845.9712684}).
Env Football Algo jrpo Exp base_JRPO updates 4746/100000000000.0 steps in 42.77
total episode rewards is -90.0
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'value_loss': 0.6664959747344256, '_timestamp': 1721937888.7413049}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00115558906327351, '_timestamp': 1721937888.7414577}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8139582602183024, '_timestamp': 1721937888.7415211}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20688411593437195, '_timestamp': 1721937888.7416062}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.005757451057434, '_timestamp': 1721937888.74184}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'ratio': 0.9998930096626282, '_timestamp': 1721937888.741938}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721937888.7420666}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937888.7422588}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'Episode_Time': 42.76902937889099, '_timestamp': 1721937888.7423158}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.12413261372397841, '_timestamp': 1721937888.7426536}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'train_goal': 0.5620663068619892, '_timestamp': 1721937888.742869}).
wandb: WARNING (User provided step: 4746 is less than current step: 12016. Dropping entry: {'train_WDL': 0.12413261372397841, '_timestamp': 1721937888.7430832}).
Env Football Algo jrpo Exp base_JRPO updates 6605/100000000000.0 steps in 61.84
total episode rewards is -90.0
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'value_loss': 0.6108799492567778, '_timestamp': 1721937950.5887723}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0007837284127769332, '_timestamp': 1721937950.5889375}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.815093183517456, '_timestamp': 1721937950.5890026}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19800780713558197, '_timestamp': 1721937950.5890963}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9901449680328369, '_timestamp': 1721937950.5893323}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'ratio': 0.9988685250282288, '_timestamp': 1721937950.5894337}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721937950.5895674}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937950.5898597}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'Episode_Time': 61.84131455421448, '_timestamp': 1721937950.5899177}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937950.5903296}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937950.59063}).
wandb: WARNING (User provided step: 6605 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937950.5909324}).
Env Football Algo jrpo Exp base_JRPO updates 7800/100000000000.0 steps in 81.30
total episode rewards is -30.0
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'value_loss': 0.20549834512562182, '_timestamp': 1721938031.8935316}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0076106886526880165, '_timestamp': 1721938031.893681}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8110969734191893, '_timestamp': 1721938031.8937461}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15169218182563782, '_timestamp': 1721938031.8938348}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.42615437507629395, '_timestamp': 1721938031.894064}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'ratio': 1.002530813217163, '_timestamp': 1721938031.8941631}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721938031.8942933}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938031.894382}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.30169439315796, '_timestamp': 1721938031.894441}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938031.894968}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938031.8953965}).
wandb: WARNING (User provided step: 7800 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938031.895847}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'value_loss': 0.3628246015977735, '_timestamp': 1721938110.8776755}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006019894301813717, '_timestamp': 1721938110.8778286}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.815930355389913, '_timestamp': 1721938110.8778946}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.160926952958107, '_timestamp': 1721938110.8779857}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4142507314682007, '_timestamp': 1721938110.8782315}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'ratio': 1.0001263618469238, '_timestamp': 1721938110.8783314}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721938110.8787694}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938110.8788614}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.98094201087952, '_timestamp': 1721938110.8789175}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938110.8793936}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938110.8797717}).
wandb: WARNING (User provided step: 7198 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938110.8801844}).
Env Football Algo jrpo Exp base_JRPO updates 7198/100000000000.0 steps in 78.98
total episode rewards is -60.0
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'value_loss': 0.644129192220668, '_timestamp': 1721938165.1060612}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005100134485401213, '_timestamp': 1721938165.1062493}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.822468360265096, '_timestamp': 1721938165.1063204}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17551033198833466, '_timestamp': 1721938165.106425}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9159771203994751, '_timestamp': 1721938165.1067107}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'ratio': 1.0024538040161133, '_timestamp': 1721938165.1068137}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721938165.1076636}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938165.1077638}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'Episode_Time': 54.22489094734192, '_timestamp': 1721938165.1078303}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.4354081478116008, '_timestamp': 1721938165.1085715}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'train_goal': 0.2822959260941996, '_timestamp': 1721938165.1090329}).
wandb: WARNING (User provided step: 3107 is less than current step: 12016. Dropping entry: {'train_WDL': -0.4354081478116008, '_timestamp': 1721938165.109462}).
Env Football Algo jrpo Exp base_JRPO updates 3107/100000000000.0 steps in 54.22
total episode rewards is -80.0
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'value_loss': 0.2693890498954958, '_timestamp': 1721938251.2878633}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'policy_loss': 0.002382843389932532, '_timestamp': 1721938251.2880216}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.822283016840617, '_timestamp': 1721938251.2880874}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15130241215229034, '_timestamp': 1721938251.288176}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.40606993436813354, '_timestamp': 1721938251.2884}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'ratio': 0.9938737154006958, '_timestamp': 1721938251.2885134}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721938251.288798}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938251.2888901}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.17741751670837, '_timestamp': 1721938251.2889485}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3066949552098067, '_timestamp': 1721938251.2896078}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'train_goal': 0.34665252239509664, '_timestamp': 1721938251.2904673}).
wandb: WARNING (User provided step: 6516 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3066949552098067, '_timestamp': 1721938251.2909775}).
Env Football Algo jrpo Exp base_JRPO updates 6516/100000000000.0 steps in 86.18
total episode rewards is -20.0
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'value_loss': 0.2952923061264058, '_timestamp': 1721938331.3513725}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006875924434668074, '_timestamp': 1721938331.3515282}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8244603045781456, '_timestamp': 1721938331.351597}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13475438952445984, '_timestamp': 1721938331.3516884}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5267298817634583, '_timestamp': 1721938331.351923}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'ratio': 0.9960727095603943, '_timestamp': 1721938331.352035}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721938331.3524904}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938331.3525832}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.05391526222229, '_timestamp': 1721938331.352643}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938331.3530612}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938331.353339}).
wandb: WARNING (User provided step: 10211 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938331.3536174}).
Env Football Algo jrpo Exp base_JRPO updates 10211/100000000000.0 steps in 80.05
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 4301/100000000000.0 steps in 41.14
total episode rewards is -120.0
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'value_loss': 0.7374011957769593, '_timestamp': 1721938372.4932625}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007836870176640028, '_timestamp': 1721938372.493409}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8252854204177855, '_timestamp': 1721938372.4934742}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17912136018276215, '_timestamp': 1721938372.493566}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0255285501480103, '_timestamp': 1721938372.493824}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'ratio': 0.9996013641357422, '_timestamp': 1721938372.4940495}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721938372.4941845}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938372.4942746}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'Episode_Time': 41.13881301879883, '_timestamp': 1721938372.4943323}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938372.494628}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938372.4948425}).
wandb: WARNING (User provided step: 4301 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938372.4950566}).
Env Football Algo jrpo Exp base_JRPO updates 1220/100000000000.0 steps in 27.76
total episode rewards is -120.0
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'value_loss': 1.1670471823215485, '_timestamp': 1721938400.2580643}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0035358758239696425, '_timestamp': 1721938400.2582538}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.823296685218811, '_timestamp': 1721938400.2583406}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20729655027389526, '_timestamp': 1721938400.2584503}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.3359044790267944, '_timestamp': 1721938400.2587326}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'ratio': 0.9998328685760498, '_timestamp': 1721938400.258837}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721938400.2589836}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938400.2626917}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'Episode_Time': 27.761504411697388, '_timestamp': 1721938400.2627914}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.6583162217659138, '_timestamp': 1721938400.2632325}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'train_goal': 0.8291581108829569, '_timestamp': 1721938400.2634542}).
wandb: WARNING (User provided step: 1220 is less than current step: 12016. Dropping entry: {'train_WDL': 0.6583162217659138, '_timestamp': 1721938400.263672}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'value_loss': 0.2650753040549656, '_timestamp': 1721938483.584723}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'policy_loss': 0.010872360435557008, '_timestamp': 1721938483.5848894}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.832751302719116, '_timestamp': 1721938483.584956}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1618543118238449, '_timestamp': 1721938483.5850463}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1827843338251114, '_timestamp': 1721938483.5852792}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'ratio': 1.0014315843582153, '_timestamp': 1721938483.5853808}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721938483.5855105}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938483.585727}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.32027339935303, '_timestamp': 1721938483.5857844}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3572354211663067, '_timestamp': 1721938483.5864522}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'train_goal': 0.32138228941684666, '_timestamp': 1721938483.5869875}).
wandb: WARNING (User provided step: 5740 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3572354211663067, '_timestamp': 1721938483.587536}).
Env Football Algo jrpo Exp base_JRPO updates 5740/100000000000.0 steps in 83.32
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 7224/100000000000.0 steps in 85.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'value_loss': 0.27520076908636837, '_timestamp': 1721938568.8297048}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0005781418830156326, '_timestamp': 1721938568.8298628}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8323233111699424, '_timestamp': 1721938568.8299353}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14154347777366638, '_timestamp': 1721938568.83003}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.30112382769584656, '_timestamp': 1721938568.8302813}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'ratio': 0.9993882775306702, '_timestamp': 1721938568.8303838}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721938568.8310106}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938568.831107}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.24125170707703, '_timestamp': 1721938568.8311646}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938568.8317537}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938568.8322496}).
wandb: WARNING (User provided step: 7224 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938568.8327377}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'value_loss': 0.5763624510355294, '_timestamp': 1721938623.6103816}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00048799894323262077, '_timestamp': 1721938623.6105459}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.830040618578593, '_timestamp': 1721938623.6106138}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18105357885360718, '_timestamp': 1721938623.6107085}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6897176504135132, '_timestamp': 1721938623.6109586}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'ratio': 1.0020556449890137, '_timestamp': 1721938623.6113293}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721938623.6114743}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938623.6115646}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'Episode_Time': 54.77639293670654, '_timestamp': 1721938623.6116211}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938623.6120214}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938623.6123047}).
wandb: WARNING (User provided step: 5410 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938623.6125937}).
Env Football Algo jrpo Exp base_JRPO updates 5410/100000000000.0 steps in 54.78
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 6685/100000000000.0 steps in 84.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'value_loss': 0.2717398504365701, '_timestamp': 1721938708.263764}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005523427737740955, '_timestamp': 1721938708.2639687}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.831482931772868, '_timestamp': 1721938708.2640421}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15984195470809937, '_timestamp': 1721938708.2641456}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.31267064809799194, '_timestamp': 1721938708.264373}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'ratio': 0.9984049797058105, '_timestamp': 1721938708.2644775}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721938708.2653012}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938708.2654083}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.65013337135315, '_timestamp': 1721938708.2654753}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938708.2661278}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938708.2666502}).
wandb: WARNING (User provided step: 6685 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938708.2671754}).
Env Football Algo jrpo Exp base_JRPO updates 8862/100000000000.0 steps in 87.82
total episode rewards is -30.0
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'value_loss': 0.19411761626824348, '_timestamp': 1721938796.0836968}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006778784201014787, '_timestamp': 1721938796.0838456}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.829905484517415, '_timestamp': 1721938796.0839102}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13748426735401154, '_timestamp': 1721938796.0840147}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1198599636554718, '_timestamp': 1721938796.0842547}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'ratio': 1.000783085823059, '_timestamp': 1721938796.084353}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721938796.084589}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938796.0846798}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.81566381454468, '_timestamp': 1721938796.0847354}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938796.0852144}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938796.0855916}).
wandb: WARNING (User provided step: 8862 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938796.0859852}).
Env Football Algo jrpo Exp base_JRPO updates 8348/100000000000.0 steps in 66.47
total episode rewards is -50.0
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'value_loss': 0.2910679587628692, '_timestamp': 1721938862.5606654}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002855018279127156, '_timestamp': 1721938862.5608225}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8321173715591432, '_timestamp': 1721938862.5608888}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17659850418567657, '_timestamp': 1721938862.5609803}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5136505365371704, '_timestamp': 1721938862.5612097}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'ratio': 0.998227059841156, '_timestamp': 1721938862.5613077}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721938862.5615408}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938862.561633}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'Episode_Time': 66.47378659248352, '_timestamp': 1721938862.5616913}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938862.5621154}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938862.5624254}).
wandb: WARNING (User provided step: 8348 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938862.5627367}).
Env Football Algo jrpo Exp base_JRPO updates 5095/100000000000.0 steps in 87.57
total episode rewards is -20.0
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'value_loss': 0.26967617403754657, '_timestamp': 1721938950.1322956}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0035881247848737986, '_timestamp': 1721938950.1325476}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8378360811869303, '_timestamp': 1721938950.1326175}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1412087380886078, '_timestamp': 1721938950.1327186}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3434229791164398, '_timestamp': 1721938950.1343508}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'ratio': 1.0008395910263062, '_timestamp': 1721938950.1345053}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721938950.134728}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938950.1348336}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.56836581230164, '_timestamp': 1721938950.1348913}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.39727410398788493, '_timestamp': 1721938950.1361363}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'train_goal': 0.30136294800605756, '_timestamp': 1721938950.1367564}).
wandb: WARNING (User provided step: 5095 is less than current step: 12016. Dropping entry: {'train_WDL': -0.39727410398788493, '_timestamp': 1721938950.1373572}).
Env Football Algo jrpo Exp base_JRPO updates 4023/100000000000.0 steps in 52.34
total episode rewards is -60.0
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'value_loss': 0.6063338764229168, '_timestamp': 1721939002.4827225}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0020808683793681363, '_timestamp': 1721939002.4835556}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8354758739471437, '_timestamp': 1721939002.4836266}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19101284444332123, '_timestamp': 1721939002.4840448}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8924082517623901, '_timestamp': 1721939002.484387}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'ratio': 1.001250982284546, '_timestamp': 1721939002.4849987}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721939002.4851477}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939002.485323}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'Episode_Time': 52.341118812561035, '_timestamp': 1721939002.4853814}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939002.4861732}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939002.4865053}).
wandb: WARNING (User provided step: 4023 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939002.4868371}).
Env Football Algo jrpo Exp base_JRPO updates 5135/100000000000.0 steps in 51.39
total episode rewards is -100.0
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'value_loss': 0.7302360893661777, '_timestamp': 1721939053.8733132}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0018606389050061505, '_timestamp': 1721939053.8734822}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8376098346710203, '_timestamp': 1721939053.8735495}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1918913722038269, '_timestamp': 1721939053.873643}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0720549821853638, '_timestamp': 1721939053.8738985}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'ratio': 1.0018460750579834, '_timestamp': 1721939053.8743079}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721939053.8744478}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939053.8745365}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'Episode_Time': 51.38567638397217, '_timestamp': 1721939053.8745925}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939053.8750014}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939053.8752322}).
wandb: WARNING (User provided step: 5135 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939053.8754642}).
Env Football Algo jrpo Exp base_JRPO updates 7536/100000000000.0 steps in 84.17
total episode rewards is -80.0
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'value_loss': 0.4696784806686143, '_timestamp': 1721939138.048156}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0010583160064804057, '_timestamp': 1721939138.048364}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8389800882339475, '_timestamp': 1721939138.0484316}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.187453955411911, '_timestamp': 1721939138.0485637}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.669459879398346, '_timestamp': 1721939138.0488095}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'ratio': 1.0014135837554932, '_timestamp': 1721939138.0490317}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721939138.0492363}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939138.0493414}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'Episode_Time': 84.1714174747467, '_timestamp': 1721939138.049401}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939138.0500693}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939138.0506568}).
wandb: WARNING (User provided step: 7536 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939138.0511043}).
Env Football Algo jrpo Exp base_JRPO updates 9104/100000000000.0 steps in 78.99
total episode rewards is -40.0
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'value_loss': 0.23054583318997174, '_timestamp': 1721939217.0442066}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002791381681066317, '_timestamp': 1721939217.0453823}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8406398344039916, '_timestamp': 1721939217.0454507}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14370766282081604, '_timestamp': 1721939217.045979}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.265811562538147, '_timestamp': 1721939217.046323}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'ratio': 0.9986007809638977, '_timestamp': 1721939217.0468183}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721939217.0469549}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939217.0471478}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.98772168159485, '_timestamp': 1721939217.0472069}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939217.0482109}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939217.048651}).
wandb: WARNING (User provided step: 9104 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939217.0490804}).
Env Football Algo jrpo Exp base_JRPO updates 4437/100000000000.0 steps in 52.47
total episode rewards is -50.0
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'value_loss': 0.44053094847748675, '_timestamp': 1721939269.519627}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'policy_loss': -0.007774007965053897, '_timestamp': 1721939269.5197773}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8374691851933798, '_timestamp': 1721939269.519842}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17393961548805237, '_timestamp': 1721939269.5199301}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5479608774185181, '_timestamp': 1721939269.5201747}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'ratio': 0.9978732466697693, '_timestamp': 1721939269.520276}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721939269.5204082}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939269.5205998}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'Episode_Time': 52.46936821937561, '_timestamp': 1721939269.5206583}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.11685994647636039, '_timestamp': 1721939269.5210404}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'train_goal': 0.4415700267618198, '_timestamp': 1721939269.5212939}).
wandb: WARNING (User provided step: 4437 is less than current step: 12016. Dropping entry: {'train_WDL': -0.11685994647636039, '_timestamp': 1721939269.5215476}).
Env Football Algo jrpo Exp base_JRPO updates 5977/100000000000.0 steps in 69.26
total episode rewards is -60.0
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'value_loss': 0.501273472905159, '_timestamp': 1721939338.784526}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00662251568690408, '_timestamp': 1721939338.7846746}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8345003016789754, '_timestamp': 1721939338.7847385}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17352674901485443, '_timestamp': 1721939338.784825}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6579747796058655, '_timestamp': 1721939338.7850509}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'ratio': 0.9964306950569153, '_timestamp': 1721939338.785251}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721939338.7853882}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939338.7854786}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'Episode_Time': 69.26218342781067, '_timestamp': 1721939338.7855365}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.28546409807355516, '_timestamp': 1721939338.78608}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'train_goal': 0.3572679509632224, '_timestamp': 1721939338.7865226}).
wandb: WARNING (User provided step: 5977 is less than current step: 12016. Dropping entry: {'train_WDL': -0.28546409807355516, '_timestamp': 1721939338.7869735}).
Env Football Algo jrpo Exp base_JRPO updates 6686/100000000000.0 steps in 68.19
total episode rewards is -70.0
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'value_loss': 0.41577970994636415, '_timestamp': 1721939406.9776511}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004451575489996079, '_timestamp': 1721939406.9777994}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.838332856496175, '_timestamp': 1721939406.9778647}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18592944741249084, '_timestamp': 1721939406.9779532}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.45030245184898376, '_timestamp': 1721939406.978185}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'ratio': 0.9979724287986755, '_timestamp': 1721939406.9782844}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721939406.978548}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939406.9786415}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'Episode_Time': 68.18985199928284, '_timestamp': 1721939406.9786992}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939406.9791021}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939406.9794104}).
wandb: WARNING (User provided step: 6686 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939406.9797263}).
Env Football Algo jrpo Exp base_JRPO updates 8424/100000000000.0 steps in 80.14
total episode rewards is -20.0
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'value_loss': 0.26542805002226183, '_timestamp': 1721939487.1228528}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005198161205141029, '_timestamp': 1721939487.1230354}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8392133617401125, '_timestamp': 1721939487.1231046}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16119611263275146, '_timestamp': 1721939487.1232057}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4933994710445404, '_timestamp': 1721939487.1234727}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'ratio': 0.9994526505470276, '_timestamp': 1721939487.1235735}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721939487.123708}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939487.1238017}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'Episode_Time': 80.14185380935669, '_timestamp': 1721939487.1238563}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.09245742092457421, '_timestamp': 1721939487.1244605}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'train_goal': 0.4537712895377129, '_timestamp': 1721939487.1248903}).
wandb: WARNING (User provided step: 8424 is less than current step: 12016. Dropping entry: {'train_WDL': -0.09245742092457421, '_timestamp': 1721939487.1253138}).
Env Football Algo jrpo Exp base_JRPO updates 1885/100000000000.0 steps in 39.98
total episode rewards is -90.0
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'value_loss': 0.7249571333701412, '_timestamp': 1721939527.110454}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003759215522053031, '_timestamp': 1721939527.1114998}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.836660877863566, '_timestamp': 1721939527.111572}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19324439764022827, '_timestamp': 1721939527.1120505}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9310141205787659, '_timestamp': 1721939527.11241}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'ratio': 0.9995942711830139, '_timestamp': 1721939527.1128476}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721939527.1131504}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939527.113344}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'Episode_Time': 39.98008847236633, '_timestamp': 1721939527.1134002}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.38743633276740236, '_timestamp': 1721939527.1141703}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'train_goal': 0.3062818336162988, '_timestamp': 1721939527.1144338}).
wandb: WARNING (User provided step: 1885 is less than current step: 12016. Dropping entry: {'train_WDL': -0.38743633276740236, '_timestamp': 1721939527.1146872}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'value_loss': 0.2550880474597216, '_timestamp': 1721939610.5111659}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0033120432109960043, '_timestamp': 1721939610.5113297}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8357160822550456, '_timestamp': 1721939610.5113966}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14010046422481537, '_timestamp': 1721939610.511492}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.19000355899333954, '_timestamp': 1721939610.511681}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'ratio': 0.9945833683013916, '_timestamp': 1721939610.5175602}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721939610.5177426}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939610.5178425}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.39568448066711, '_timestamp': 1721939610.5179026}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939610.5185492}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939610.519004}).
wandb: WARNING (User provided step: 8178 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939610.5194385}).
Env Football Algo jrpo Exp base_JRPO updates 8178/100000000000.0 steps in 83.40
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5538/100000000000.0 steps in 81.97
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'value_loss': 0.2863819505367428, '_timestamp': 1721939692.496632}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'policy_loss': 0.005830627084748509, '_timestamp': 1721939692.4977033}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.836193683942159, '_timestamp': 1721939692.497778}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1713697463274002, '_timestamp': 1721939692.4982662}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1578771322965622, '_timestamp': 1721939692.4985952}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'ratio': 0.9993428587913513, '_timestamp': 1721939692.4986959}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721939692.4991422}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939692.4993153}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.97221899032593, '_timestamp': 1721939692.499374}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.37349397590361444, '_timestamp': 1721939692.5005279}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'train_goal': 0.3132530120481928, '_timestamp': 1721939692.501181}).
wandb: WARNING (User provided step: 5538 is less than current step: 12016. Dropping entry: {'train_WDL': -0.37349397590361444, '_timestamp': 1721939692.5017486}).
total episode rewards is -20.0
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'value_loss': 0.28763055623120937, '_timestamp': 1721939780.731088}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0032354142216111845, '_timestamp': 1721939780.7312334}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8353403282165526, '_timestamp': 1721939780.7312973}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17081432044506073, '_timestamp': 1721939780.7313821}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1345236450433731, '_timestamp': 1721939780.7316055}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'ratio': 1.0001943111419678, '_timestamp': 1721939780.7317996}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721939780.7319314}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939780.7320447}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.22860860824585, '_timestamp': 1721939780.7321022}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.37587168758716877, '_timestamp': 1721939780.7327662}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'train_goal': 0.6879358437935844, '_timestamp': 1721939780.7332633}).
wandb: WARNING (User provided step: 6396 is less than current step: 12016. Dropping entry: {'train_WDL': 0.37587168758716877, '_timestamp': 1721939780.7337587}).
Env Football Algo jrpo Exp base_JRPO updates 6396/100000000000.0 steps in 88.23
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 7200/100000000000.0 steps in 58.74
total episode rewards is -80.0
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'value_loss': 0.4781085558701307, '_timestamp': 1721939839.4740326}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0003619296185206622, '_timestamp': 1721939839.4742107}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8355302095413206, '_timestamp': 1721939839.474279}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17782098054885864, '_timestamp': 1721939839.4746401}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.7174820899963379, '_timestamp': 1721939839.4751763}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'ratio': 0.9984567761421204, '_timestamp': 1721939839.4753346}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721939839.4754632}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939839.4755633}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'Episode_Time': 58.7393217086792, '_timestamp': 1721939839.4756236}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939839.4762368}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939839.4765127}).
wandb: WARNING (User provided step: 7200 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939839.4767897}).
Env Football Algo jrpo Exp base_JRPO updates 6998/100000000000.0 steps in 87.79
total episode rewards is -10.0
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'value_loss': 0.2390207636228297, '_timestamp': 1721939927.2739496}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0032759371902405594, '_timestamp': 1721939927.2752843}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.831650053660075, '_timestamp': 1721939927.2753594}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17564988136291504, '_timestamp': 1721939927.2759972}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2331683188676834, '_timestamp': 1721939927.2763991}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'ratio': 1.0017516613006592, '_timestamp': 1721939927.2765064}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721939927.2766542}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939927.2775307}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.79115033149719, '_timestamp': 1721939927.277594}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.25343664083979006, '_timestamp': 1721939927.2788367}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'train_goal': 0.373281679580105, '_timestamp': 1721939927.2794049}).
wandb: WARNING (User provided step: 6998 is less than current step: 12016. Dropping entry: {'train_WDL': -0.25343664083979006, '_timestamp': 1721939927.279905}).
Env Football Algo jrpo Exp base_JRPO updates 4561/100000000000.0 steps in 52.58
total episode rewards is -120.0
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'value_loss': 0.7438054472208023, '_timestamp': 1721939979.8628144}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'policy_loss': -0.003042702313978225, '_timestamp': 1721939979.8629785}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8331812683741253, '_timestamp': 1721939979.863043}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18722502887248993, '_timestamp': 1721939979.8631394}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.1818000078201294, '_timestamp': 1721939979.8633804}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'ratio': 1.001489281654358, '_timestamp': 1721939979.863593}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721939979.8637314}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939979.8638237}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'Episode_Time': 52.581621170043945, '_timestamp': 1721939979.863881}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939979.8643498}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939979.86462}).
wandb: WARNING (User provided step: 4561 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939979.8648958}).
Env Football Algo jrpo Exp base_JRPO updates 6344/100000000000.0 steps in 76.30
total episode rewards is -80.0
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'value_loss': 0.566215515434742, '_timestamp': 1721940056.164188}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'policy_loss': 0.003521563394460827, '_timestamp': 1721940056.1644404}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.836789469718933, '_timestamp': 1721940056.164517}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20520570874214172, '_timestamp': 1721940056.1646194}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.72510826587677, '_timestamp': 1721940056.1648936}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'ratio': 1.000300645828247, '_timestamp': 1721940056.1649945}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721940056.1657639}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940056.1658714}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'Episode_Time': 76.2982861995697, '_timestamp': 1721940056.1659298}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940056.1666367}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940056.1670737}).
wandb: WARNING (User provided step: 6344 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940056.167511}).
Env Football Algo jrpo Exp base_JRPO updates 1966/100000000000.0 steps in 33.47
total episode rewards is -100.0
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'value_loss': 1.1538624223073324, '_timestamp': 1721940089.6366165}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0011247775449980207, '_timestamp': 1721940089.6367977}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8381397914886475, '_timestamp': 1721940089.6368687}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20828573405742645, '_timestamp': 1721940089.6369703}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.184577226638794, '_timestamp': 1721940089.6372554}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'ratio': 0.9994652271270752, '_timestamp': 1721940089.6379335}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721940089.6380873}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940089.6381865}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'Episode_Time': 33.468114614486694, '_timestamp': 1721940089.6382453}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.22750073768073178, '_timestamp': 1721940089.6386948}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_goal': 0.6137503688403659, '_timestamp': 1721940089.6389675}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_WDL': 0.22750073768073178, '_timestamp': 1721940089.6392345}).
Env Football Algo jrpo Exp base_JRPO updates 2115/100000000000.0 steps in 44.15
total episode rewards is -50.0
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'value_loss': 1.1394795615474382, '_timestamp': 1721940133.7955067}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0011486227026519676, '_timestamp': 1721940133.7957637}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8393393834431966, '_timestamp': 1721940133.7958357}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20515163242816925, '_timestamp': 1721940133.7959356}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.074515461921692, '_timestamp': 1721940133.7963262}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'ratio': 0.9989612102508545, '_timestamp': 1721940133.796461}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721940133.7971678}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940133.797285}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'Episode_Time': 44.154605865478516, '_timestamp': 1721940133.7973504}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.37223796033994333, '_timestamp': 1721940133.7981648}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'train_goal': 0.3138810198300283, '_timestamp': 1721940133.7984626}).
wandb: WARNING (User provided step: 2115 is less than current step: 12016. Dropping entry: {'train_WDL': -0.37223796033994333, '_timestamp': 1721940133.7987447}).
Env Football Algo jrpo Exp base_JRPO updates 6162/100000000000.0 steps in 87.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'value_loss': 0.2706117433286272, '_timestamp': 1721940221.2606366}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0032722941945151737, '_timestamp': 1721940221.2608304}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.844506950378418, '_timestamp': 1721940221.2608988}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18422433733940125, '_timestamp': 1721940221.2610009}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.219740092754364, '_timestamp': 1721940221.261258}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'ratio': 0.9980751872062683, '_timestamp': 1721940221.2616866}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721940221.2618442}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940221.2619398}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.46077752113342, '_timestamp': 1721940221.2619996}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940221.262697}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940221.2636218}).
wandb: WARNING (User provided step: 6162 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940221.2645757}).
Env Football Algo jrpo Exp base_JRPO updates 2539/100000000000.0 steps in 38.72
total episode rewards is -60.0
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'value_loss': 0.6855775789668163, '_timestamp': 1721940259.9917903}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'policy_loss': 0.007107152370590484, '_timestamp': 1721940259.992999}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.838580598831177, '_timestamp': 1721940259.9930732}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18683455884456635, '_timestamp': 1721940259.9936492}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8826205730438232, '_timestamp': 1721940259.99402}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'ratio': 0.9987238049507141, '_timestamp': 1721940259.994134}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721940259.9948823}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940259.995076}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'Episode_Time': 38.721540212631226, '_timestamp': 1721940259.9951441}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.4291351529102269, '_timestamp': 1721940259.9960256}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'train_goal': 0.7145675764551135, '_timestamp': 1721940259.9962928}).
wandb: WARNING (User provided step: 2539 is less than current step: 12016. Dropping entry: {'train_WDL': 0.4291351529102269, '_timestamp': 1721940259.996548}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'value_loss': 1.0168847285707792, '_timestamp': 1721940309.8507009}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'policy_loss': 0.00014916762554397186, '_timestamp': 1721940309.8508754}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8395535628000896, '_timestamp': 1721940309.8509414}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18725132942199707, '_timestamp': 1721940309.851039}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.134257197380066, '_timestamp': 1721940309.851304}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'ratio': 0.9985812902450562, '_timestamp': 1721940309.8514032}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721940309.8518145}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940309.8519068}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'Episode_Time': 49.853191614151, '_timestamp': 1721940309.851999}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.37780656303972365, '_timestamp': 1721940309.8525195}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'train_goal': 0.31109671848013815, '_timestamp': 1721940309.852843}).
wandb: WARNING (User provided step: 2673 is less than current step: 12016. Dropping entry: {'train_WDL': -0.37780656303972365, '_timestamp': 1721940309.8531668}).
Env Football Algo jrpo Exp base_JRPO updates 2673/100000000000.0 steps in 49.85
total episode rewards is -50.0
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'value_loss': 0.27350862157579586, '_timestamp': 1721940395.8702872}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0039007989084348083, '_timestamp': 1721940395.8704507}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8384446414311726, '_timestamp': 1721940395.8705177}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16061289608478546, '_timestamp': 1721940395.8706102}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.1873442679643631, '_timestamp': 1721940395.8708603}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'ratio': 0.9984097480773926, '_timestamp': 1721940395.8709638}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721940395.8712575}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940395.8713505}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.01620030403137, '_timestamp': 1721940395.8714082}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.15475377864456363, '_timestamp': 1721940395.872199}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'train_goal': 0.5773768893222818, '_timestamp': 1721940395.8728297}).
wandb: WARNING (User provided step: 4745 is less than current step: 12016. Dropping entry: {'train_WDL': 0.15475377864456363, '_timestamp': 1721940395.873457}).
Env Football Algo jrpo Exp base_JRPO updates 4745/100000000000.0 steps in 86.02
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 9897/100000000000.0 steps in 87.55
total episode rewards is -30.0
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'value_loss': 0.18718897456574873, '_timestamp': 1721940483.4235365}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0041259563799637055, '_timestamp': 1721940483.4236915}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.837344217300415, '_timestamp': 1721940483.4237607}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14740312099456787, '_timestamp': 1721940483.4238513}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.23170265555381775, '_timestamp': 1721940483.424113}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'ratio': 0.9994518160820007, '_timestamp': 1721940483.4242198}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721940483.4243495}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940483.4244392}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.54897975921631, '_timestamp': 1721940483.424499}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940483.4249306}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940483.4252641}).
wandb: WARNING (User provided step: 9897 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940483.4256976}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'value_loss': 0.44226749759633094, '_timestamp': 1721940540.0282097}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'policy_loss': -0.006842951150805069, '_timestamp': 1721940540.0283961}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.84243980884552, '_timestamp': 1721940540.0284672}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16779984533786774, '_timestamp': 1721940540.028571}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5743394494056702, '_timestamp': 1721940540.0288363}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'ratio': 1.0014564990997314, '_timestamp': 1721940540.0289404}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721940540.0290856}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940540.0295925}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'Episode_Time': 56.601630449295044, '_timestamp': 1721940540.029652}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3159430238544706, '_timestamp': 1721940540.03021}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'train_goal': 0.3420284880727647, '_timestamp': 1721940540.0306237}).
wandb: WARNING (User provided step: 4243 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3159430238544706, '_timestamp': 1721940540.0311637}).
Env Football Algo jrpo Exp base_JRPO updates 4243/100000000000.0 steps in 56.60
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 6117/100000000000.0 steps in 78.97
total episode rewards is -80.0
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'value_loss': 0.49242231393853825, '_timestamp': 1721940619.0058625}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0023625438617697605, '_timestamp': 1721940619.007111}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.843562773068746, '_timestamp': 1721940619.007185}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17165064811706543, '_timestamp': 1721940619.0077493}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6768425107002258, '_timestamp': 1721940619.0081334}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'ratio': 1.0003912448883057, '_timestamp': 1721940619.0088923}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721940619.0090287}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940619.0092282}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.96905636787415, '_timestamp': 1721940619.009286}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940619.0104048}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940619.0111673}).
wandb: WARNING (User provided step: 6117 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940619.011637}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'value_loss': 0.716146933734417, '_timestamp': 1721940653.866254}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002316973541164771, '_timestamp': 1721940653.8664083}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8445287227630613, '_timestamp': 1721940653.866473}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19123385846614838, '_timestamp': 1721940653.866563}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8596268892288208, '_timestamp': 1721940653.8667984}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'ratio': 1.001772403717041, '_timestamp': 1721940653.8668966}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721940653.8670251}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940653.8672144}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'Episode_Time': 34.8537175655365, '_timestamp': 1721940653.8672726}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.6951551442569407, '_timestamp': 1721940653.8675184}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_goal': 0.15242242787152968, '_timestamp': 1721940653.8676946}).
wandb: WARNING (User provided step: 4038 is less than current step: 12016. Dropping entry: {'train_WDL': -0.6951551442569407, '_timestamp': 1721940653.8678675}).
Env Football Algo jrpo Exp base_JRPO updates 4038/100000000000.0 steps in 34.85
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 6296/100000000000.0 steps in 59.12
total episode rewards is -100.0
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'value_loss': 0.7029956127206485, '_timestamp': 1721940712.9916975}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0015153146166509638, '_timestamp': 1721940712.9927368}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8427593437830607, '_timestamp': 1721940712.9928071}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.20171105861663818, '_timestamp': 1721940712.993264}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8616054654121399, '_timestamp': 1721940712.9935927}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'ratio': 1.0008269548416138, '_timestamp': 1721940712.9936948}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721940712.9941294}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940712.9943082}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'Episode_Time': 59.118841886520386, '_timestamp': 1721940712.9943683}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940712.99509}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940712.9953058}).
wandb: WARNING (User provided step: 6296 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940712.9955206}).
Env Football Algo jrpo Exp base_JRPO updates 1715/100000000000.0 steps in 41.81
total episode rewards is -60.0
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'value_loss': 0.8427176725740234, '_timestamp': 1721940754.8112876}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00337600987618013, '_timestamp': 1721940754.8114731}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.839181950887044, '_timestamp': 1721940754.8115394}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19744305312633514, '_timestamp': 1721940754.8116374}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.048982858657837, '_timestamp': 1721940754.8118978}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'ratio': 0.9994398951530457, '_timestamp': 1721940754.812022}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721940754.8121667}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940754.8124037}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'Episode_Time': 41.814866065979004, '_timestamp': 1721940754.8124635}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.54, '_timestamp': 1721940754.8129737}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'train_goal': 0.77, '_timestamp': 1721940754.813338}).
wandb: WARNING (User provided step: 1715 is less than current step: 12016. Dropping entry: {'train_WDL': 0.54, '_timestamp': 1721940754.8136942}).
Env Football Algo jrpo Exp base_JRPO updates 5942/100000000000.0 steps in 56.29
total episode rewards is -80.0
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'value_loss': 0.4979487975935141, '_timestamp': 1721940811.1100492}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'policy_loss': -0.00520581505416582, '_timestamp': 1721940811.1113513}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8438474305470787, '_timestamp': 1721940811.1114256}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1755247861146927, '_timestamp': 1721940811.1120322}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5679190754890442, '_timestamp': 1721940811.1123724}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'ratio': 1.0012080669403076, '_timestamp': 1721940811.1124747}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721940811.1132157}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940811.1134272}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'Episode_Time': 56.29024887084961, '_timestamp': 1721940811.113489}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940811.1146555}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940811.1150846}).
wandb: WARNING (User provided step: 5942 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940811.1155198}).
Env Football Algo jrpo Exp base_JRPO updates 3896/100000000000.0 steps in 50.14
total episode rewards is -150.0
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'value_loss': 0.9378771393746138, '_timestamp': 1721940861.260245}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0022600773855810984, '_timestamp': 1721940861.260417}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.842782605489095, '_timestamp': 1721940861.2604861}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1971324384212494, '_timestamp': 1721940861.2605822}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.2048320770263672, '_timestamp': 1721940861.2608263}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'ratio': 1.0014604330062866, '_timestamp': 1721940861.260926}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721940861.2612178}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940861.2613096}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'Episode_Time': 50.14375448226929, '_timestamp': 1721940861.2613676}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940861.2617424}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940861.262082}).
wandb: WARNING (User provided step: 3896 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940861.262316}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'value_loss': 0.7533682497342428, '_timestamp': 1721940908.0452893}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0006312041108806928, '_timestamp': 1721940908.0465398}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.840140217145284, '_timestamp': 1721940908.0466328}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18251904845237732, '_timestamp': 1721940908.0472155}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8621353507041931, '_timestamp': 1721940908.0476065}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'ratio': 1.0004887580871582, '_timestamp': 1721940908.048317}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721940908.0486207}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940908.048821}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'Episode_Time': 46.777286767959595, '_timestamp': 1721940908.0488803}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940908.0497682}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940908.0500057}).
wandb: WARNING (User provided step: 5398 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940908.050236}).
Env Football Algo jrpo Exp base_JRPO updates 5398/100000000000.0 steps in 46.78
total episode rewards is -130.0
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'value_loss': 0.7265899181365967, '_timestamp': 1721940950.1160173}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002280517504841555, '_timestamp': 1721940950.1162}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8434982315699258, '_timestamp': 1721940950.1162677}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1954890936613083, '_timestamp': 1721940950.1163685}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9338815808296204, '_timestamp': 1721940950.116622}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'ratio': 0.9987337589263916, '_timestamp': 1721940950.116724}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721940950.117359}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940950.1174552}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'Episode_Time': 42.06486463546753, '_timestamp': 1721940950.117512}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940950.1178274}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940950.1180327}).
wandb: WARNING (User provided step: 4659 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940950.118241}).
Env Football Algo jrpo Exp base_JRPO updates 4659/100000000000.0 steps in 42.06
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5011/100000000000.0 steps in 66.56
total episode rewards is -80.0
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'value_loss': 0.7101162938152751, '_timestamp': 1721941016.682945}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'policy_loss': 0.006491036764540089, '_timestamp': 1721941016.6831443}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8466224972407024, '_timestamp': 1721941016.6832135}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1907343715429306, '_timestamp': 1721941016.6833084}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9163353443145752, '_timestamp': 1721941016.6835585}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'ratio': 0.9999628663063049, '_timestamp': 1721941016.6841922}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721941016.684431}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941016.6845343}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'Episode_Time': 66.56350016593933, '_timestamp': 1721941016.6845942}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.23858238947753013, '_timestamp': 1721941016.6854784}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'train_goal': 0.3807088052612349, '_timestamp': 1721941016.685862}).
wandb: WARNING (User provided step: 5011 is less than current step: 12016. Dropping entry: {'train_WDL': -0.23858238947753013, '_timestamp': 1721941016.6863139}).
Env Football Algo jrpo Exp base_JRPO updates 6413/100000000000.0 steps in 86.28
total episode rewards is -20.0
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'value_loss': 0.33486470157901443, '_timestamp': 1721941102.9697073}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0026203902585742373, '_timestamp': 1721941102.96986}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8470381275812784, '_timestamp': 1721941102.9699295}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.24289771914482117, '_timestamp': 1721941102.9700217}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2545754611492157, '_timestamp': 1721941102.9702508}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'ratio': 0.9989803433418274, '_timestamp': 1721941102.9704614}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721941102.9705987}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941102.9706886}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.28245186805725, '_timestamp': 1721941102.9707453}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3096541283335274, '_timestamp': 1721941102.971346}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'train_goal': 0.34517293583323627, '_timestamp': 1721941102.9718492}).
wandb: WARNING (User provided step: 6413 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3096541283335274, '_timestamp': 1721941102.972388}).
Env Football Algo jrpo Exp base_JRPO updates 6600/100000000000.0 steps in 67.75
total episode rewards is -70.0
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'value_loss': 0.5211315697431564, '_timestamp': 1721941170.7247033}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0031311325404870635, '_timestamp': 1721941170.724855}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8531014347076415, '_timestamp': 1721941170.7249198}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.19232484698295593, '_timestamp': 1721941170.725009}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.349462628364563, '_timestamp': 1721941170.7252452}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'ratio': 0.9991638660430908, '_timestamp': 1721941170.7253456}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721941170.7255933}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941170.7256835}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'Episode_Time': 67.7513632774353, '_timestamp': 1721941170.72574}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941170.726201}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941170.726576}).
wandb: WARNING (User provided step: 6600 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941170.7269516}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'value_loss': 0.4794292654345433, '_timestamp': 1721941228.2562733}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0054471776774153114, '_timestamp': 1721941228.256429}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8545320908228557, '_timestamp': 1721941228.2564936}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17460745573043823, '_timestamp': 1721941228.2565844}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.6179265379905701, '_timestamp': 1721941228.2568092}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'ratio': 1.0002493858337402, '_timestamp': 1721941228.2571356}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721941228.257274}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941228.2573662}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'Episode_Time': 57.52841925621033, '_timestamp': 1721941228.2574244}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941228.2578757}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941228.258231}).
wandb: WARNING (User provided step: 3718 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941228.2585876}).
Env Football Algo jrpo Exp base_JRPO updates 3718/100000000000.0 steps in 57.53
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 8168/100000000000.0 steps in 60.32
total episode rewards is -70.0
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'value_loss': 0.4054411842363576, '_timestamp': 1721941288.58085}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'policy_loss': 0.0024938152051375557, '_timestamp': 1721941288.5811312}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.852386582692464, '_timestamp': 1721941288.5812013}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18305903673171997, '_timestamp': 1721941288.5813076}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.505842924118042, '_timestamp': 1721941288.5815928}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'ratio': 1.0002295970916748, '_timestamp': 1721941288.5824797}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721941288.5827172}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941288.5828168}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'Episode_Time': 60.32116174697876, '_timestamp': 1721941288.582876}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941288.5832808}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941288.5834956}).
wandb: WARNING (User provided step: 8168 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941288.5837097}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'value_loss': 0.281521135084331, '_timestamp': 1721941376.2165124}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0007637342537054792, '_timestamp': 1721941376.2176888}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8572846905390423, '_timestamp': 1721941376.2177632}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18129168450832367, '_timestamp': 1721941376.2182777}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.20189756155014038, '_timestamp': 1721941376.2186346}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'ratio': 0.9996500015258789, '_timestamp': 1721941376.218737}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721941376.2195597}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941376.219771}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'Episode_Time': 87.62797093391418, '_timestamp': 1721941376.2198293}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2537760579203595, '_timestamp': 1721941376.2210243}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'train_goal': 0.37311197103982024, '_timestamp': 1721941376.2215352}).
wandb: WARNING (User provided step: 6989 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2537760579203595, '_timestamp': 1721941376.2220683}).
Env Football Algo jrpo Exp base_JRPO updates 6989/100000000000.0 steps in 87.63
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 2796/100000000000.0 steps in 50.45
total episode rewards is -60.0
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'value_loss': 0.8375266926238935, '_timestamp': 1721941426.6688287}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004770536904215987, '_timestamp': 1721941426.6690302}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8594954665501913, '_timestamp': 1721941426.6690996}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17316079139709473, '_timestamp': 1721941426.669194}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8126267194747925, '_timestamp': 1721941426.669437}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'ratio': 1.0013095140457153, '_timestamp': 1721941426.6695373}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721941426.669843}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941426.6699364}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'Episode_Time': 50.445544481277466, '_timestamp': 1721941426.669995}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3894777413759877, '_timestamp': 1721941426.6704922}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'train_goal': 0.30526112931200616, '_timestamp': 1721941426.670872}).
wandb: WARNING (User provided step: 2796 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3894777413759877, '_timestamp': 1721941426.671225}).
Env Football Algo jrpo Exp base_JRPO updates 8412/100000000000.0 steps in 83.53
total episode rewards is -70.0
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'value_loss': 0.41644910485173264, '_timestamp': 1721941510.2019267}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'policy_loss': 0.007902094298042357, '_timestamp': 1721941510.203208}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8605890226364137, '_timestamp': 1721941510.2032793}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16653628647327423, '_timestamp': 1721941510.2038822}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.4849212169647217, '_timestamp': 1721941510.204531}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'ratio': 1.0008262395858765, '_timestamp': 1721941510.2048683}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721941510.2050965}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941510.2052817}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.52520847320557, '_timestamp': 1721941510.20534}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941510.2064812}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941510.207006}).
wandb: WARNING (User provided step: 8412 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941510.207403}).
Env Football Algo jrpo Exp base_JRPO updates 6688/100000000000.0 steps in 69.19
total episode rewards is -50.0
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'value_loss': 0.44948764736453695, '_timestamp': 1721941579.396378}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004521135312970727, '_timestamp': 1721941579.3966296}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8643790086110434, '_timestamp': 1721941579.3966968}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1766449362039566, '_timestamp': 1721941579.3968015}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5684215426445007, '_timestamp': 1721941579.3970659}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'ratio': 0.9997633099555969, '_timestamp': 1721941579.3971696}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721941579.397576}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941579.3976753}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'Episode_Time': 69.18781065940857, '_timestamp': 1721941579.3977325}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.14285714285714285, '_timestamp': 1721941579.3983362}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'train_goal': 0.42857142857142855, '_timestamp': 1721941579.3987226}).
wandb: WARNING (User provided step: 6688 is less than current step: 12016. Dropping entry: {'train_WDL': -0.14285714285714285, '_timestamp': 1721941579.399102}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'value_loss': 0.2779442657747616, '_timestamp': 1721941665.2436652}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'policy_loss': 0.017191606156072035, '_timestamp': 1721941665.2438889}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8693682797749838, '_timestamp': 1721941665.2439632}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1497192680835724, '_timestamp': 1721941665.2440572}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.26413488388061523, '_timestamp': 1721941665.2443047}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'ratio': 0.9987203478813171, '_timestamp': 1721941665.2444048}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721941665.244917}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941665.245016}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.84340834617615, '_timestamp': 1721941665.245075}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.3697461062513335, '_timestamp': 1721941665.2459745}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'train_goal': 0.31512694687433324, '_timestamp': 1721941665.246523}).
wandb: WARNING (User provided step: 5626 is less than current step: 12016. Dropping entry: {'train_WDL': -0.3697461062513335, '_timestamp': 1721941665.2471182}).
Env Football Algo jrpo Exp base_JRPO updates 5626/100000000000.0 steps in 85.84
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 3377/100000000000.0 steps in 42.38
total episode rewards is -60.0
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'value_loss': 0.7555409427732229, '_timestamp': 1721941707.6298473}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0001776063246264433, '_timestamp': 1721941707.6300085}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8683494408925374, '_timestamp': 1721941707.630075}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17172832787036896, '_timestamp': 1721941707.6301696}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9836305975914001, '_timestamp': 1721941707.6304066}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'ratio': 1.001134991645813, '_timestamp': 1721941707.6305072}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721941707.6308265}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941707.630919}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'Episode_Time': 42.37627053260803, '_timestamp': 1721941707.630976}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.14686295127935506, '_timestamp': 1721941707.6313546}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'train_goal': 0.42656852436032244, '_timestamp': 1721941707.631581}).
wandb: WARNING (User provided step: 3377 is less than current step: 12016. Dropping entry: {'train_WDL': -0.14686295127935506, '_timestamp': 1721941707.631806}).
Env Football Algo jrpo Exp base_JRPO updates 8611/100000000000.0 steps in 86.22
total episode rewards is -30.0
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'value_loss': 0.22324216133216396, '_timestamp': 1721941793.8567545}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0005070878177260359, '_timestamp': 1721941793.857028}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.863227252960205, '_timestamp': 1721941793.8571377}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15546511113643646, '_timestamp': 1721941793.857262}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.16862614452838898, '_timestamp': 1721941793.8575883}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'ratio': 0.9994702339172363, '_timestamp': 1721941793.8585653}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941793.8587842}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941793.8588977}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'Episode_Time': 86.22372150421143, '_timestamp': 1721941793.8589582}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941793.8596246}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941793.860141}).
wandb: WARNING (User provided step: 8611 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941793.860579}).
Env Football Algo jrpo Exp base_JRPO updates 8678/100000000000.0 steps in 83.93
total episode rewards is -30.0
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'value_loss': 0.17329387170582777, '_timestamp': 1721941877.7892382}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0031578429947452, '_timestamp': 1721941877.7893941}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8709733057022095, '_timestamp': 1721941877.78946}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1381099820137024, '_timestamp': 1721941877.7895532}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.15570037066936493, '_timestamp': 1721941877.7897997}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'ratio': 0.9981136322021484, '_timestamp': 1721941877.7901785}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941877.7903073}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941877.7903988}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'Episode_Time': 83.92748141288757, '_timestamp': 1721941877.7904572}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941877.7909548}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941877.7916534}).
wandb: WARNING (User provided step: 8678 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941877.7920842}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'value_loss': 0.40462143188808114, '_timestamp': 1721941921.4585423}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002087000409179988, '_timestamp': 1721941921.4588068}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8680795415242515, '_timestamp': 1721941921.4588764}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.168797567486763, '_timestamp': 1721941921.458979}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5059401988983154, '_timestamp': 1721941921.4592304}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'ratio': 1.000955581665039, '_timestamp': 1721941921.459445}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721941921.4596484}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941921.4597456}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'Episode_Time': 43.66549611091614, '_timestamp': 1721941921.4598033}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941921.4601896}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941921.4603972}).
wandb: WARNING (User provided step: 4732 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941921.4606025}).
Env Football Algo jrpo Exp base_JRPO updates 4732/100000000000.0 steps in 43.67
total episode rewards is -70.0
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'value_loss': 0.18785149743547663, '_timestamp': 1721942007.1090903}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0021027563246510303, '_timestamp': 1721942007.1092892}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866033043861389, '_timestamp': 1721942007.1093583}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.14726288616657257, '_timestamp': 1721942007.1094508}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.40945205092430115, '_timestamp': 1721942007.109699}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'ratio': 0.9988446235656738, '_timestamp': 1721942007.1099267}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721942007.110069}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942007.1101599}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'Episode_Time': 85.64755964279175, '_timestamp': 1721942007.1102173}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942007.1106224}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942007.1109798}).
wandb: WARNING (User provided step: 11937 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942007.1112218}).
Env Football Algo jrpo Exp base_JRPO updates 11937/100000000000.0 steps in 85.65
total episode rewards is -30.0
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'value_loss': 0.557223635877793, '_timestamp': 1721942059.660045}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'policy_loss': -0.0012540728538685169, '_timestamp': 1721942059.6602144}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8662738196055093, '_timestamp': 1721942059.6602821}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18537108600139618, '_timestamp': 1721942059.6603749}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.8559386134147644, '_timestamp': 1721942059.6607292}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'ratio': 0.9994105100631714, '_timestamp': 1721942059.6609025}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721942059.6610448}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942059.6611369}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'Episode_Time': 52.54800248146057, '_timestamp': 1721942059.6611955}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.1934065934065934, '_timestamp': 1721942059.6616228}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'train_goal': 0.4032967032967033, '_timestamp': 1721942059.6618948}).
wandb: WARNING (User provided step: 4075 is less than current step: 12016. Dropping entry: {'train_WDL': -0.1934065934065934, '_timestamp': 1721942059.6621637}).
Env Football Algo jrpo Exp base_JRPO updates 4075/100000000000.0 steps in 52.55
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 5466/100000000000.0 steps in 60.64
total episode rewards is -100.0
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'value_loss': 0.8116194314261278, '_timestamp': 1721942120.3002813}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005669024072315855, '_timestamp': 1721942120.3004456}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.861264435450236, '_timestamp': 1721942120.3005116}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1762406826019287, '_timestamp': 1721942120.3006072}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 1.0951628684997559, '_timestamp': 1721942120.3008487}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'ratio': 0.9991660714149475, '_timestamp': 1721942120.3013153}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721942120.3014467}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942120.30154}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'Episode_Time': 60.63717794418335, '_timestamp': 1721942120.3015969}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942120.30197}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942120.3022327}).
wandb: WARNING (User provided step: 5466 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942120.3024993}).
Env Football Algo jrpo Exp base_JRPO updates 5313/100000000000.0 steps in 72.23
total episode rewards is -30.0
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'value_loss': 0.38067236826444667, '_timestamp': 1721942192.533823}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'policy_loss': 0.002748987082935249, '_timestamp': 1721942192.533983}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8528177754084267, '_timestamp': 1721942192.5340493}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1645267754793167, '_timestamp': 1721942192.5341408}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.3124966323375702, '_timestamp': 1721942192.5343833}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'ratio': 0.9980096817016602, '_timestamp': 1721942192.5344856}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721942192.5346198}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942192.5347114}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'Episode_Time': 72.2301893234253, '_timestamp': 1721942192.5347662}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.3003474302144483, '_timestamp': 1721942192.5354378}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'train_goal': 0.6501737151072241, '_timestamp': 1721942192.536225}).
wandb: WARNING (User provided step: 5313 is less than current step: 12016. Dropping entry: {'train_WDL': 0.3003474302144483, '_timestamp': 1721942192.5367222}).
Env Football Algo jrpo Exp base_JRPO updates 3779/100000000000.0 steps in 71.62
total episode rewards is -60.0
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'value_loss': 0.49956160380194586, '_timestamp': 1721942264.153306}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'policy_loss': 0.005482660255317266, '_timestamp': 1721942264.153457}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.853829503059387, '_timestamp': 1721942264.1535213}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.18041522800922394, '_timestamp': 1721942264.1536117}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.593461811542511, '_timestamp': 1721942264.1538486}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'ratio': 0.9986385107040405, '_timestamp': 1721942264.1541295}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721942264.1542485}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942264.1543384}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'Episode_Time': 71.61584973335266, '_timestamp': 1721942264.1543934}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.40692864529472594, '_timestamp': 1721942264.1549609}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_goal': 0.29653567735263703, '_timestamp': 1721942264.1554177}).
wandb: WARNING (User provided step: 3779 is less than current step: 12016. Dropping entry: {'train_WDL': -0.40692864529472594, '_timestamp': 1721942264.1558878}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'value_loss': 0.2757022125122603, '_timestamp': 1721942339.5933552}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002655111384034778, '_timestamp': 1721942339.5935118}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.857530465126038, '_timestamp': 1721942339.5935788}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1624026596546173, '_timestamp': 1721942339.593668}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.292277991771698, '_timestamp': 1721942339.5939}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'ratio': 0.9987139105796814, '_timestamp': 1721942339.594}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721942339.5942898}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942339.594381}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'Episode_Time': 75.43673920631409, '_timestamp': 1721942339.5944412}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.2847571189279732, '_timestamp': 1721942339.5950334}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'train_goal': 0.3576214405360134, '_timestamp': 1721942339.5955226}).
wandb: WARNING (User provided step: 6642 is less than current step: 12016. Dropping entry: {'train_WDL': -0.2847571189279732, '_timestamp': 1721942339.5960512}).
Env Football Algo jrpo Exp base_JRPO updates 6642/100000000000.0 steps in 75.44
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6409/100000000000.0 steps in 78.23
total episode rewards is -50.0
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'value_loss': 0.3677936534164473, '_timestamp': 1721942417.8307881}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005455830803257413, '_timestamp': 1721942417.8309681}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8522210756937665, '_timestamp': 1721942417.831036}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1638369858264923, '_timestamp': 1721942417.831142}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.41623979806900024, '_timestamp': 1721942417.831408}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'ratio': 1.0011245012283325, '_timestamp': 1721942417.8318775}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721942417.8320236}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942417.8321211}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.23378467559814, '_timestamp': 1721942417.832178}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942417.8327153}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942417.8331513}).
wandb: WARNING (User provided step: 6409 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942417.8335938}).
Env Football Algo jrpo Exp base_JRPO updates 7792/100000000000.0 steps in 69.54
total episode rewards is -80.0
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'value_loss': 0.46265414138945443, '_timestamp': 1721942487.3722858}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004609356183403482, '_timestamp': 1721942487.3724437}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.860476139386495, '_timestamp': 1721942487.3725097}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17909106612205505, '_timestamp': 1721942487.3726017}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5999902486801147, '_timestamp': 1721942487.372836}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'ratio': 1.0013128519058228, '_timestamp': 1721942487.3729365}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721942487.3732429}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942487.3733335}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'Episode_Time': 69.53777384757996, '_timestamp': 1721942487.3733912}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942487.3739526}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942487.3744102}).
wandb: WARNING (User provided step: 7792 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942487.3746965}).
Env Football Algo jrpo Exp base_JRPO updates 4624/100000000000.0 steps in 64.19
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'value_loss': 0.5081578403773407, '_timestamp': 1721942551.5685184}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'policy_loss': -0.005883990774552027, '_timestamp': 1721942551.5687003}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8636701695124307, '_timestamp': 1721942551.56877}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.15789197385311127, '_timestamp': 1721942551.568874}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.629458487033844, '_timestamp': 1721942551.5696197}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'ratio': 0.9984645843505859, '_timestamp': 1721942551.5697289}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721942551.5698686}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942551.569965}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'Episode_Time': 64.19286441802979, '_timestamp': 1721942551.570024}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942551.5706193}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942551.5710986}).
wandb: WARNING (User provided step: 4624 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942551.5715556}).
total episode rewards is -90.0
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'value_loss': 0.7078816755115986, '_timestamp': 1721942578.650874}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004005791348172352, '_timestamp': 1721942578.6522048}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8626434993743897, '_timestamp': 1721942578.6522799}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.17619174718856812, '_timestamp': 1721942578.6528757}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.9919279217720032, '_timestamp': 1721942578.653213}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'ratio': 0.9979634881019592, '_timestamp': 1721942578.6533246}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721942578.653486}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942578.6542828}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'Episode_Time': 27.073503732681274, '_timestamp': 1721942578.6543453}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.7955997161107168, '_timestamp': 1721942578.6551876}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_goal': 0.8977998580553584, '_timestamp': 1721942578.6553638}).
wandb: WARNING (User provided step: 1966 is less than current step: 12016. Dropping entry: {'train_WDL': 0.7955997161107168, '_timestamp': 1721942578.6555355}).
Env Football Algo jrpo Exp base_JRPO updates 1966/100000000000.0 steps in 27.07
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 10413/100000000000.0 steps in 89.09
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'value_loss': 0.13642257411886627, '_timestamp': 1721942667.7425027}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'policy_loss': 0.004427319266130022, '_timestamp': 1721942667.7426674}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8586308558781943, '_timestamp': 1721942667.7427325}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1382678896188736, '_timestamp': 1721942667.742827}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.14798682928085327, '_timestamp': 1721942667.743068}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'ratio': 0.9994727969169617, '_timestamp': 1721942667.7433846}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721942667.7435195}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942667.7436128}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'Episode_Time': 89.0860333442688, '_timestamp': 1721942667.7436693}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942667.7440996}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942667.7444198}).
wandb: WARNING (User provided step: 10413 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942667.7447379}).
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5711/100000000000.0 steps in 55.53
total episode rewards is -50.0
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'value_loss': 0.440500846899425, '_timestamp': 1721942723.279269}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'policy_loss': -0.002568966160955218, '_timestamp': 1721942723.280211}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8568237098058065, '_timestamp': 1721942723.2802796}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16836567223072052, '_timestamp': 1721942723.2807295}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.5796858072280884, '_timestamp': 1721942723.2810512}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'ratio': 0.9990739226341248, '_timestamp': 1721942723.2811527}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721942723.281424}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942723.281657}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'Episode_Time': 55.52971696853638, '_timestamp': 1721942723.2817166}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.07419980601357905, '_timestamp': 1721942723.2824912}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'train_goal': 0.4629000969932105, '_timestamp': 1721942723.2827919}).
wandb: WARNING (User provided step: 5711 is less than current step: 12016. Dropping entry: {'train_WDL': -0.07419980601357905, '_timestamp': 1721942723.283081}).
Env Football Algo jrpo Exp base_JRPO updates 4491/100000000000.0 steps in 78.05
total episode rewards is -30.0
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'value_loss': 0.4465216468181461, '_timestamp': 1721942801.3353066}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'policy_loss': 0.005845829554600641, '_timestamp': 1721942801.3354673}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.862484191258748, '_timestamp': 1721942801.3355324}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1578861027956009, '_timestamp': 1721942801.335624}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.547005295753479, '_timestamp': 1721942801.3358757}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'ratio': 0.9992371797561646, '_timestamp': 1721942801.336203}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721942801.3363445}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942801.336436}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'Episode_Time': 78.05129909515381, '_timestamp': 1721942801.3364947}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'train_goal_diff': 0.19148438413849572, '_timestamp': 1721942801.3371701}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'train_goal': 0.5957421920692478, '_timestamp': 1721942801.3376725}).
wandb: WARNING (User provided step: 4491 is less than current step: 12016. Dropping entry: {'train_WDL': 0.19148438413849572, '_timestamp': 1721942801.3381765}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'value_loss': 0.24808922697169086, '_timestamp': 1721942890.2219336}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'policy_loss': -0.008868920834696231, '_timestamp': 1721942890.222194}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.866770435969035, '_timestamp': 1721942890.2222688}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.13397318124771118, '_timestamp': 1721942890.2223744}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.2277732640504837, '_timestamp': 1721942890.222666}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'ratio': 0.9940290451049805, '_timestamp': 1721942890.2227743}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721942890.2230372}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942890.223141}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'Episode_Time': 88.88230085372925, '_timestamp': 1721942890.2232025}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942890.2240977}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942890.2245762}).
wandb: WARNING (User provided step: 7318 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942890.2250693}).
Env Football Algo jrpo Exp base_JRPO updates 7318/100000000000.0 steps in 88.88
total episode rewards is -40.0
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'value_loss': 0.24520121740177273, '_timestamp': 1721942972.2038977}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004199835026326279, '_timestamp': 1721942972.2048135}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.8670404863357546, '_timestamp': 1721942972.2048838}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.1700289398431778, '_timestamp': 1721942972.2054791}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.35537463426589966, '_timestamp': 1721942972.2059293}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'ratio': 1.0016154050827026, '_timestamp': 1721942972.2060304}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721942972.2061658}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942972.2063239}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'Episode_Time': 81.97466540336609, '_timestamp': 1721942972.206381}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942972.2072942}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942972.207775}).
wandb: WARNING (User provided step: 7301 is less than current step: 12016. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942972.2082696}).
Env Football Algo jrpo Exp base_JRPO updates 7301/100000000000.0 steps in 81.97
total episode rewards is -40.0
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'value_loss': 0.26232446790362396, '_timestamp': 1721943062.475119}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'policy_loss': -0.004216790209805671, '_timestamp': 1721943062.4754345}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'dist_entropy': 2.869366814295451, '_timestamp': 1721943062.4755318}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'actor_grad_norm': 0.16963478922843933, '_timestamp': 1721943062.4756444}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'critic_grad_norm': 0.20185920596122742, '_timestamp': 1721943062.4759781}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'ratio': 0.9999905824661255, '_timestamp': 1721943062.4761372}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721943062.4763737}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943062.4771528}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'Episode_Time': 90.26561427116394, '_timestamp': 1721943062.4772189}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'train_goal_diff': -0.0807799442896936, '_timestamp': 1721943062.4779906}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'train_goal': 0.4596100278551532, '_timestamp': 1721943062.4784632}).
wandb: WARNING (User provided step: 8538 is less than current step: 12016. Dropping entry: {'train_WDL': -0.0807799442896936, '_timestamp': 1721943062.4789076}).
Env Football Algo jrpo Exp base_JRPO updates 8538/100000000000.0 steps in 90.27
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 12030/100000000000.0 steps in 87.63
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5114/100000000000.0 steps in 79.49
total episode rewards is -40.0
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'value_loss': 0.345712331160903, '_timestamp': 1721943229.605654}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'policy_loss': -0.005749237621848806, '_timestamp': 1721943229.6058586}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8641202592849733, '_timestamp': 1721943229.6059291}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14755886793136597, '_timestamp': 1721943229.6060455}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3573056161403656, '_timestamp': 1721943229.606336}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'ratio': 1.000179648399353, '_timestamp': 1721943229.6064446}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721943229.6065888}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943229.6074631}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.48637843132019, '_timestamp': 1721943229.6075225}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943229.6083744}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943229.60901}).
wandb: WARNING (User provided step: 5114 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943229.6096225}).
Env Football Algo jrpo Exp base_JRPO updates 3908/100000000000.0 steps in 54.15
total episode rewards is -80.0
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'value_loss': 0.729217419375976, '_timestamp': 1721943283.7624917}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'policy_loss': -0.006419271919100235, '_timestamp': 1721943283.762652}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8610929012298585, '_timestamp': 1721943283.7627149}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17407584190368652, '_timestamp': 1721943283.7628045}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8956993818283081, '_timestamp': 1721943283.7630394}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'ratio': 0.998637318611145, '_timestamp': 1721943283.7631361}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721943283.763267}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943283.763509}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'Episode_Time': 54.151829957962036, '_timestamp': 1721943283.7635682}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943283.7639408}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943283.7642388}).
wandb: WARNING (User provided step: 3908 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943283.7645168}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'value_loss': 0.2334111325442791, '_timestamp': 1721943368.8008883}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'policy_loss': 0.011337989523308351, '_timestamp': 1721943368.8010447}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8613208723068237, '_timestamp': 1721943368.801109}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16558720171451569, '_timestamp': 1721943368.801198}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.45390161871910095, '_timestamp': 1721943368.8014407}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'ratio': 0.9996798038482666, '_timestamp': 1721943368.8015394}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721943368.8016703}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943368.8017595}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.03557777404785, '_timestamp': 1721943368.8018148}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.5864379522916108, '_timestamp': 1721943368.8025153}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'train_goal': 0.7932189761458054, '_timestamp': 1721943368.802971}).
wandb: WARNING (User provided step: 7538 is less than current step: 12030. Dropping entry: {'train_WDL': 0.5864379522916108, '_timestamp': 1721943368.8034127}).
Env Football Algo jrpo Exp base_JRPO updates 7538/100000000000.0 steps in 85.04
total episode rewards is 10.0
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'value_loss': 0.29634674025078617, '_timestamp': 1721943447.5425422}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002881004421118026, '_timestamp': 1721943447.5426972}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.856254432996114, '_timestamp': 1721943447.5427618}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17568187415599823, '_timestamp': 1721943447.542849}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.30646324157714844, '_timestamp': 1721943447.5430753}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'ratio': 0.9994080066680908, '_timestamp': 1721943447.543175}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721943447.5434077}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943447.5434957}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.7382800579071, '_timestamp': 1721943447.5435517}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.30751228644980105, '_timestamp': 1721943447.5442102}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'train_goal': 0.34624385677509945, '_timestamp': 1721943447.5447106}).
wandb: WARNING (User provided step: 6454 is less than current step: 12030. Dropping entry: {'train_WDL': -0.30751228644980105, '_timestamp': 1721943447.5452251}).
Env Football Algo jrpo Exp base_JRPO updates 6454/100000000000.0 steps in 78.74
total episode rewards is -20.0
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'value_loss': 0.2884122067814072, '_timestamp': 1721943536.3985882}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0020761074874705325, '_timestamp': 1721943536.3987458}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8503790426254274, '_timestamp': 1721943536.3988118}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16626642644405365, '_timestamp': 1721943536.3989036}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2653948664665222, '_timestamp': 1721943536.3991427}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'ratio': 0.9984153509140015, '_timestamp': 1721943536.3992448}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721943536.3995085}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943536.399686}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.85248732566833, '_timestamp': 1721943536.3997445}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943536.4003432}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943536.4008253}).
wandb: WARNING (User provided step: 6844 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943536.401327}).
Env Football Algo jrpo Exp base_JRPO updates 6844/100000000000.0 steps in 88.85
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8897/100000000000.0 steps in 87.83
total episode rewards is -40.0
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'value_loss': 0.25454800441861153, '_timestamp': 1721943624.2332404}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0012283443380147218, '_timestamp': 1721943624.2334304}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8511222807566323, '_timestamp': 1721943624.2334988}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15560568869113922, '_timestamp': 1721943624.2338734}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.46856680512428284, '_timestamp': 1721943624.234233}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'ratio': 0.9976325631141663, '_timestamp': 1721943624.2345479}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721943624.2347474}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943624.234852}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.83091831207275, '_timestamp': 1721943624.2349105}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943624.2355225}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943624.2359812}).
wandb: WARNING (User provided step: 8897 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943624.236399}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'value_loss': 0.48555331755429504, '_timestamp': 1721943677.146371}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015587421572611977, '_timestamp': 1721943677.146535}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8490512386957803, '_timestamp': 1721943677.1466017}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16691717505455017, '_timestamp': 1721943677.1466928}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7988381385803223, '_timestamp': 1721943677.1469364}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'ratio': 0.999152421951294, '_timestamp': 1721943677.1470368}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721943677.1471605}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943677.1472504}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.90922713279724, '_timestamp': 1721943677.1476433}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943677.1480005}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943677.1482322}).
wandb: WARNING (User provided step: 6445 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943677.1485598}).
Env Football Algo jrpo Exp base_JRPO updates 6445/100000000000.0 steps in 52.91
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 8981/100000000000.0 steps in 86.69
total episode rewards is -10.0
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'value_loss': 0.1986603539530188, '_timestamp': 1721943763.8433676}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'policy_loss': 0.015561947295985494, '_timestamp': 1721943763.8435197}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.848201797803243, '_timestamp': 1721943763.8435843}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14483299851417542, '_timestamp': 1721943763.8436728}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.26537102460861206, '_timestamp': 1721943763.8439107}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'ratio': 1.0001815557479858, '_timestamp': 1721943763.8440287}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721943763.8443656}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943763.8444562}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.69413113594055, '_timestamp': 1721943763.844514}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.02641634823060309, '_timestamp': 1721943763.845027}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_goal': 0.48679182588469844, '_timestamp': 1721943763.8454056}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_WDL': -0.02641634823060309, '_timestamp': 1721943763.8457901}).
Env Football Algo jrpo Exp base_JRPO updates 3930/100000000000.0 steps in 37.55
total episode rewards is -90.0
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'value_loss': 0.5193979957948128, '_timestamp': 1721943801.3965576}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0007597715101049593, '_timestamp': 1721943801.3967068}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8459394804636635, '_timestamp': 1721943801.396772}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17397986352443695, '_timestamp': 1721943801.396859}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6104280352592468, '_timestamp': 1721943801.3970919}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'ratio': 0.9975287318229675, '_timestamp': 1721943801.397195}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721943801.3973184}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943801.3975148}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'Episode_Time': 37.54991030693054, '_timestamp': 1721943801.3975735}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943801.3978386}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943801.3980234}).
wandb: WARNING (User provided step: 3930 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943801.3982072}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'value_loss': 0.4952737185296913, '_timestamp': 1721943881.0245261}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003881498049789419, '_timestamp': 1721943881.0246809}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.846083889007568, '_timestamp': 1721943881.0247474}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1686636507511139, '_timestamp': 1721943881.0248353}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6679887771606445, '_timestamp': 1721943881.0250604}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'ratio': 0.9988701343536377, '_timestamp': 1721943881.0251606}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721943881.025297}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943881.025389}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.62525415420532, '_timestamp': 1721943881.0254457}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943881.0260441}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943881.026527}).
wandb: WARNING (User provided step: 5875 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943881.0270128}).
Env Football Algo jrpo Exp base_JRPO updates 5875/100000000000.0 steps in 79.63
total episode rewards is -80.0
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'value_loss': 0.38883481979990997, '_timestamp': 1721943951.44289}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0020773706449350965, '_timestamp': 1721943951.4430463}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8432355244954426, '_timestamp': 1721943951.4431117}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16983112692832947, '_timestamp': 1721943951.4469392}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.45823121070861816, '_timestamp': 1721943951.4472182}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'ratio': 0.9987797141075134, '_timestamp': 1721943951.4473195}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721943951.4476268}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943951.447724}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'Episode_Time': 70.4149661064148, '_timestamp': 1721943951.4477828}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943951.4484203}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943951.448872}).
wandb: WARNING (User provided step: 5586 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943951.4493198}).
Env Football Algo jrpo Exp base_JRPO updates 5586/100000000000.0 steps in 70.41
total episode rewards is -60.0
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'value_loss': 0.7399308427671591, '_timestamp': 1721944013.3298712}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0023208783303077024, '_timestamp': 1721944013.3300526}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8418356704711916, '_timestamp': 1721944013.330121}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1714959442615509, '_timestamp': 1721944013.3302238}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.915963351726532, '_timestamp': 1721944013.330486}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'ratio': 0.999629020690918, '_timestamp': 1721944013.330587}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721944013.3310122}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944013.3311155}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.87970685958862, '_timestamp': 1721944013.3311744}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.022702104097452935, '_timestamp': 1721944013.3316295}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'train_goal': 0.48864894795127356, '_timestamp': 1721944013.3319051}).
wandb: WARNING (User provided step: 5413 is less than current step: 12030. Dropping entry: {'train_WDL': -0.022702104097452935, '_timestamp': 1721944013.3322039}).
Env Football Algo jrpo Exp base_JRPO updates 5413/100000000000.0 steps in 61.88
total episode rewards is -100.0
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'value_loss': 0.21851621174563965, '_timestamp': 1721944101.527361}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003974324443358152, '_timestamp': 1721944101.5275295}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.84008557955424, '_timestamp': 1721944101.5275967}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13877840340137482, '_timestamp': 1721944101.5276911}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1070747897028923, '_timestamp': 1721944101.5281649}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'ratio': 0.9980835318565369, '_timestamp': 1721944101.5283718}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721944101.5285122}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944101.5286078}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.19423365592957, '_timestamp': 1721944101.528668}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944101.529344}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944101.5297074}).
wandb: WARNING (User provided step: 9577 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944101.5301034}).
Env Football Algo jrpo Exp base_JRPO updates 9577/100000000000.0 steps in 88.19
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 4654/100000000000.0 steps in 65.45
total episode rewards is -20.0
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'value_loss': 0.5023309109111627, '_timestamp': 1721944166.9762444}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004986832343662779, '_timestamp': 1721944166.9763975}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8388357400894164, '_timestamp': 1721944166.9764616}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14897982776165009, '_timestamp': 1721944166.9765508}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6027171015739441, '_timestamp': 1721944166.9767847}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'ratio': 0.9935492277145386, '_timestamp': 1721944166.9768836}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721944166.9770105}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944166.977255}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.445232629776, '_timestamp': 1721944166.9773128}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.2700241092954728, '_timestamp': 1721944166.9779391}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'train_goal': 0.6350120546477364, '_timestamp': 1721944166.9783916}).
wandb: WARNING (User provided step: 4654 is less than current step: 12030. Dropping entry: {'train_WDL': 0.2700241092954728, '_timestamp': 1721944166.9790044}).
Env Football Algo jrpo Exp base_JRPO updates 5882/100000000000.0 steps in 87.80
total episode rewards is -20.0
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'value_loss': 0.2791287363693118, '_timestamp': 1721944254.781295}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00017727246313976744, '_timestamp': 1721944254.7814515}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8326081244150796, '_timestamp': 1721944254.7815204}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1677839756011963, '_timestamp': 1721944254.7816129}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2199055552482605, '_timestamp': 1721944254.7818534}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'ratio': 0.9830701947212219, '_timestamp': 1721944254.7819548}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721944254.7823765}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944254.7824724}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.80139064788818, '_timestamp': 1721944254.7825294}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.35051546391752575, '_timestamp': 1721944254.783238}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'train_goal': 0.3247422680412371, '_timestamp': 1721944254.7842162}).
wandb: WARNING (User provided step: 5882 is less than current step: 12030. Dropping entry: {'train_WDL': -0.35051546391752575, '_timestamp': 1721944254.7847676}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'value_loss': 0.353970746511283, '_timestamp': 1721944336.122296}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'policy_loss': -0.006610560265835374, '_timestamp': 1721944336.1224453}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.832164082527161, '_timestamp': 1721944336.1225095}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14248967170715332, '_timestamp': 1721944336.1225986}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3002261817455292, '_timestamp': 1721944336.1228333}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'ratio': 0.987798273563385, '_timestamp': 1721944336.1229327}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721944336.1231532}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944336.1232405}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.33680582046509, '_timestamp': 1721944336.1232963}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944336.1240034}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944336.1245842}).
wandb: WARNING (User provided step: 3791 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944336.1251974}).
Env Football Algo jrpo Exp base_JRPO updates 3791/100000000000.0 steps in 81.34
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 3591/100000000000.0 steps in 49.15
total episode rewards is -70.0
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'value_loss': 0.5589460870437324, '_timestamp': 1721944385.2750049}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'policy_loss': -0.006372648283334759, '_timestamp': 1721944385.2752018}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8295505905151366, '_timestamp': 1721944385.2752721}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17356795072555542, '_timestamp': 1721944385.2753804}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6942023038864136, '_timestamp': 1721944385.275656}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'ratio': 0.9892531633377075, '_timestamp': 1721944385.2757607}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721944385.276513}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944385.2766159}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'Episode_Time': 49.148834228515625, '_timestamp': 1721944385.2766747}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.27524010306863433, '_timestamp': 1721944385.2771568}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'train_goal': 0.36237994846568283, '_timestamp': 1721944385.2774692}).
wandb: WARNING (User provided step: 3591 is less than current step: 12030. Dropping entry: {'train_WDL': -0.27524010306863433, '_timestamp': 1721944385.277781}).
Env Football Algo jrpo Exp base_JRPO updates 3539/100000000000.0 steps in 41.92
total episode rewards is -80.0
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'value_loss': 0.9160364157706499, '_timestamp': 1721944427.2065275}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004094002477359027, '_timestamp': 1721944427.2080264}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8325950495402017, '_timestamp': 1721944427.2081053}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17097964882850647, '_timestamp': 1721944427.2087605}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.0160586833953857, '_timestamp': 1721944427.2092037}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'ratio': 0.995702862739563, '_timestamp': 1721944427.2093177}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721944427.2095964}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944427.2098184}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.92173194885254, '_timestamp': 1721944427.2098806}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1151430565247732, '_timestamp': 1721944427.2110636}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'train_goal': 0.4424284717376134, '_timestamp': 1721944427.211325}).
wandb: WARNING (User provided step: 3539 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1151430565247732, '_timestamp': 1721944427.211569}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'value_loss': 0.5319586459547281, '_timestamp': 1721944482.0181985}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'policy_loss': -0.006261898660935307, '_timestamp': 1721944482.0183682}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8295772012074787, '_timestamp': 1721944482.0184343}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1586795598268509, '_timestamp': 1721944482.0185292}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8061758875846863, '_timestamp': 1721944482.018766}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'ratio': 0.997355580329895, '_timestamp': 1721944482.0189974}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721944482.0191352}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944482.0192292}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'Episode_Time': 54.80493974685669, '_timestamp': 1721944482.0192873}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944482.0198197}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944482.020166}).
wandb: WARNING (User provided step: 5170 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944482.0204413}).
Env Football Algo jrpo Exp base_JRPO updates 5170/100000000000.0 steps in 54.80
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 4424/100000000000.0 steps in 64.85
total episode rewards is -70.0
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'value_loss': 0.5276531161678334, '_timestamp': 1721944546.8666673}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0007043880206765607, '_timestamp': 1721944546.8668523}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8284315856297813, '_timestamp': 1721944546.8669293}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17089137434959412, '_timestamp': 1721944546.8670325}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7626370191574097, '_timestamp': 1721944546.8673105}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'ratio': 0.9999035596847534, '_timestamp': 1721944546.8674216}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721944546.8678768}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944546.8679943}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.84539270401001, '_timestamp': 1721944546.8680599}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.36078886310904873, '_timestamp': 1721944546.8689823}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'train_goal': 0.31960556844547566, '_timestamp': 1721944546.8694162}).
wandb: WARNING (User provided step: 4424 is less than current step: 12030. Dropping entry: {'train_WDL': -0.36078886310904873, '_timestamp': 1721944546.8698616}).
Env Football Algo jrpo Exp base_JRPO updates 4293/100000000000.0 steps in 61.95
total episode rewards is -60.0
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'value_loss': 0.5104911519711216, '_timestamp': 1721944608.81951}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'policy_loss': -0.007833769912977004, '_timestamp': 1721944608.8196769}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.825821525255839, '_timestamp': 1721944608.8197412}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15220127999782562, '_timestamp': 1721944608.819838}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5250116586685181, '_timestamp': 1721944608.820044}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'ratio': 0.9960253238677979, '_timestamp': 1721944608.820623}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721944608.820757}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944608.8208487}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.94869875907898, '_timestamp': 1721944608.820904}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2957492795389049, '_timestamp': 1721944608.8214104}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'train_goal': 0.3521253602305475, '_timestamp': 1721944608.8217654}).
wandb: WARNING (User provided step: 4293 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2957492795389049, '_timestamp': 1721944608.8221257}).
Env Football Algo jrpo Exp base_JRPO updates 3377/100000000000.0 steps in 42.52
total episode rewards is -140.0
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'value_loss': 0.8312525182962418, '_timestamp': 1721944651.3418944}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'policy_loss': -0.005625746895869573, '_timestamp': 1721944651.3420734}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8245846192042032, '_timestamp': 1721944651.3421428}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1777673065662384, '_timestamp': 1721944651.342245}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.163320541381836, '_timestamp': 1721944651.342515}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'ratio': 1.0000358819961548, '_timestamp': 1721944651.3426156}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721944651.3427362}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944651.343376}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'Episode_Time': 42.518909215927124, '_timestamp': 1721944651.3434372}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944651.3439178}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944651.344209}).
wandb: WARNING (User provided step: 3377 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944651.3444824}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'value_loss': 0.9278086085120837, '_timestamp': 1721944694.0315363}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005584437004290522, '_timestamp': 1721944694.0317056}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8297280279795327, '_timestamp': 1721944694.031771}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.19398851692676544, '_timestamp': 1721944694.0318651}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.3728007078170776, '_timestamp': 1721944694.0321393}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'ratio': 0.9989683032035828, '_timestamp': 1721944694.032241}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721944694.0323744}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944694.032749}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'Episode_Time': 42.686296463012695, '_timestamp': 1721944694.0328083}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944694.0330567}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944694.033216}).
wandb: WARNING (User provided step: 4252 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944694.0333729}).
Env Football Algo jrpo Exp base_JRPO updates 4252/100000000000.0 steps in 42.69
total episode rewards is -160.0
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'value_loss': 1.0490093750258287, '_timestamp': 1721944727.4252803}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021524599438998847, '_timestamp': 1721944727.426509}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.828264673550924, '_timestamp': 1721944727.4265819}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.18450310826301575, '_timestamp': 1721944727.4271579}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.2951213121414185, '_timestamp': 1721944727.427507}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'ratio': 0.9979677796363831, '_timestamp': 1721944727.427608}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721944727.427926}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944727.4281323}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'Episode_Time': 33.38589882850647, '_timestamp': 1721944727.4281907}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.05813385442110405, '_timestamp': 1721944727.4289424}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'train_goal': 0.47093307278944796, '_timestamp': 1721944727.4291456}).
wandb: WARNING (User provided step: 2853 is less than current step: 12030. Dropping entry: {'train_WDL': -0.05813385442110405, '_timestamp': 1721944727.4293401}).
Env Football Algo jrpo Exp base_JRPO updates 2853/100000000000.0 steps in 33.39
total episode rewards is -160.0
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'value_loss': 0.8314753318826358, '_timestamp': 1721944780.6396723}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0018640373911087713, '_timestamp': 1721944780.6398509}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8266550588607786, '_timestamp': 1721944780.6399205}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17869731783866882, '_timestamp': 1721944780.6400366}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8120044469833374, '_timestamp': 1721944780.6403046}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'ratio': 0.99973064661026, '_timestamp': 1721944780.640408}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721944780.6405375}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944780.6411467}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'Episode_Time': 53.2093288898468, '_timestamp': 1721944780.6412072}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.19802193076757688, '_timestamp': 1721944780.641649}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'train_goal': 0.40098903461621155, '_timestamp': 1721944780.6419666}).
wandb: WARNING (User provided step: 4869 is less than current step: 12030. Dropping entry: {'train_WDL': -0.19802193076757688, '_timestamp': 1721944780.6422713}).
Env Football Algo jrpo Exp base_JRPO updates 4869/100000000000.0 steps in 53.21
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 3263/100000000000.0 steps in 61.22
total episode rewards is -90.0
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'value_loss': 0.6600653388847907, '_timestamp': 1721944841.8603303}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0008557269248800973, '_timestamp': 1721944841.8604891}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.830307401021322, '_timestamp': 1721944841.8605545}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1744009554386139, '_timestamp': 1721944841.8606448}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7430203557014465, '_timestamp': 1721944841.8609045}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'ratio': 1.0017794370651245, '_timestamp': 1721944841.8610022}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721944841.8612514}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944841.861343}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.21714448928833, '_timestamp': 1721944841.8613975}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.39045628700801116, '_timestamp': 1721944841.861895}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'train_goal': 0.3047718564959944, '_timestamp': 1721944841.8622582}).
wandb: WARNING (User provided step: 3263 is less than current step: 12030. Dropping entry: {'train_WDL': -0.39045628700801116, '_timestamp': 1721944841.8626266}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'value_loss': 0.41934318852145225, '_timestamp': 1721944920.7037992}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'policy_loss': 0.016212942661513807, '_timestamp': 1721944920.7039902}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838433731396993, '_timestamp': 1721944920.7040606}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1671188324689865, '_timestamp': 1721944920.708593}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.30355384945869446, '_timestamp': 1721944920.7089322}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'ratio': 1.0020110607147217, '_timestamp': 1721944920.7090392}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721944920.7091868}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944920.7092884}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.84013056755066, '_timestamp': 1721944920.7093494}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944920.710062}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944920.7105598}).
wandb: WARNING (User provided step: 5736 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944920.7110834}).
Env Football Algo jrpo Exp base_JRPO updates 5736/100000000000.0 steps in 78.84
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 11956/100000000000.0 steps in 85.33
total episode rewards is -20.0
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'value_loss': 0.13850800861604512, '_timestamp': 1721945006.041404}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003064658627845347, '_timestamp': 1721945006.0415797}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8412425978978475, '_timestamp': 1721945006.0416558}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12448891252279282, '_timestamp': 1721945006.041752}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16246052086353302, '_timestamp': 1721945006.0420156}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'ratio': 0.9995669722557068, '_timestamp': 1721945006.0421324}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721945006.0426176}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945006.0427132}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.3295648097992, '_timestamp': 1721945006.0427709}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945006.0431054}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945006.0433533}).
wandb: WARNING (User provided step: 11956 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945006.0435922}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'value_loss': 0.25760942853366336, '_timestamp': 1721945083.4726098}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004876290480606258, '_timestamp': 1721945083.4727771}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8397296142578123, '_timestamp': 1721945083.4728556}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1665407419204712, '_timestamp': 1721945083.472957}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.15552662312984467, '_timestamp': 1721945083.4732141}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'ratio': 0.9981433153152466, '_timestamp': 1721945083.473332}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945083.4736226}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945083.473728}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.4282956123352, '_timestamp': 1721945083.4737957}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945083.4743392}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945083.474778}).
wandb: WARNING (User provided step: 9260 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945083.4752395}).
Env Football Algo jrpo Exp base_JRPO updates 9260/100000000000.0 steps in 77.43
total episode rewards is -40.0
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'value_loss': 0.7830851918458939, '_timestamp': 1721945118.9518785}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003902864846168086, '_timestamp': 1721945118.9558213}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8453958241144814, '_timestamp': 1721945118.9558988}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.18501593172550201, '_timestamp': 1721945118.956005}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9821754097938538, '_timestamp': 1721945118.9562626}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'ratio': 0.9998775720596313, '_timestamp': 1721945118.956363}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721945118.9569745}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945118.9570754}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'Episode_Time': 35.4758563041687, '_timestamp': 1721945118.957133}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945118.9573762}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945118.9575074}).
wandb: WARNING (User provided step: 2804 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945118.9576354}).
Env Football Algo jrpo Exp base_JRPO updates 2804/100000000000.0 steps in 35.48
total episode rewards is -120.0
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'value_loss': 0.6803095370158553, '_timestamp': 1721945176.7980547}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002896745325900459, '_timestamp': 1721945176.7983549}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8450502427419027, '_timestamp': 1721945176.7984262}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16993194818496704, '_timestamp': 1721945176.798533}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8245956301689148, '_timestamp': 1721945176.7988205}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'ratio': 0.998306393623352, '_timestamp': 1721945176.7989273}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721945176.7999053}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945176.8000457}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.839401960372925, '_timestamp': 1721945176.800106}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945176.800709}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945176.8010159}).
wandb: WARNING (User provided step: 5998 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945176.8013008}).
Env Football Algo jrpo Exp base_JRPO updates 5998/100000000000.0 steps in 57.84
total episode rewards is -120.0
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'value_loss': 0.8020916845897833, '_timestamp': 1721945206.845838}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0028200885477902677, '_timestamp': 1721945206.846076}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8465666913986207, '_timestamp': 1721945206.8461432}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1633244901895523, '_timestamp': 1721945206.846235}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.835290789604187, '_timestamp': 1721945206.8464792}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'ratio': 1.0003215074539185, '_timestamp': 1721945206.8465805}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721945206.846767}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945206.84687}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'Episode_Time': 30.042771577835083, '_timestamp': 1721945206.8469303}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945206.847254}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945206.8474045}).
wandb: WARNING (User provided step: 3216 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945206.8475475}).
Env Football Algo jrpo Exp base_JRPO updates 3216/100000000000.0 steps in 30.04
total episode rewards is -140.0
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'value_loss': 0.6230348434547583, '_timestamp': 1721945279.2097964}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007603252516904225, '_timestamp': 1721945279.209962}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8458239126205442, '_timestamp': 1721945279.2100272}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17230907082557678, '_timestamp': 1721945279.2101197}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7661128044128418, '_timestamp': 1721945279.2103438}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'ratio': 0.9985589981079102, '_timestamp': 1721945279.2105916}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721945279.2107244}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945279.2108176}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.36126565933228, '_timestamp': 1721945279.2108755}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2898236931642437, '_timestamp': 1721945279.2114499}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'train_goal': 0.35508815341787814, '_timestamp': 1721945279.2118485}).
wandb: WARNING (User provided step: 5094 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2898236931642437, '_timestamp': 1721945279.2122695}).
Env Football Algo jrpo Exp base_JRPO updates 5094/100000000000.0 steps in 72.36
total episode rewards is -80.0
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'value_loss': 0.36178449749946595, '_timestamp': 1721945355.5372193}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002069596920046024, '_timestamp': 1721945355.537374}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8511422650019327, '_timestamp': 1721945355.5374382}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16612038016319275, '_timestamp': 1721945355.5375292}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.22541923820972443, '_timestamp': 1721945355.5377765}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'ratio': 0.9997974634170532, '_timestamp': 1721945355.538235}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945355.538363}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945355.538457}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.32374262809753, '_timestamp': 1721945355.5385146}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945355.5391448}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945355.5396304}).
wandb: WARNING (User provided step: 6086 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945355.540183}).
Env Football Algo jrpo Exp base_JRPO updates 6086/100000000000.0 steps in 76.32
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 3072/100000000000.0 steps in 34.36
total episode rewards is -70.0
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'value_loss': 0.6026427295431495, '_timestamp': 1721945389.9018543}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00478051390304851, '_timestamp': 1721945389.9020169}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8523884693781536, '_timestamp': 1721945389.9020813}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16490131616592407, '_timestamp': 1721945389.9021745}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7613181471824646, '_timestamp': 1721945389.9024127}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'ratio': 0.9990647435188293, '_timestamp': 1721945389.9025111}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721945389.9027543}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945389.9028456}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'Episode_Time': 34.3608922958374, '_timestamp': 1721945389.9029026}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.33844842284739984, '_timestamp': 1721945389.9031591}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'train_goal': 0.6692242114236999, '_timestamp': 1721945389.9033017}).
wandb: WARNING (User provided step: 3072 is less than current step: 12030. Dropping entry: {'train_WDL': 0.33844842284739984, '_timestamp': 1721945389.9034393}).
Env Football Algo jrpo Exp base_JRPO updates 2548/100000000000.0 steps in 48.10
total episode rewards is -50.0
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'value_loss': 0.8772562532126904, '_timestamp': 1721945438.0078664}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002714323604789873, '_timestamp': 1721945438.008034}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8542484537760417, '_timestamp': 1721945438.0080986}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1628500074148178, '_timestamp': 1721945438.0081868}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9082643985748291, '_timestamp': 1721945438.0084002}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'ratio': 0.9980156421661377, '_timestamp': 1721945438.0085998}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721945438.0087316}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945438.0088205}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'Episode_Time': 48.10363292694092, '_timestamp': 1721945438.0088768}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.1867816091954023, '_timestamp': 1721945438.0093002}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'train_goal': 0.5933908045977011, '_timestamp': 1721945438.0096195}).
wandb: WARNING (User provided step: 2548 is less than current step: 12030. Dropping entry: {'train_WDL': 0.1867816091954023, '_timestamp': 1721945438.0099394}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'value_loss': 0.5417228790620963, '_timestamp': 1721945521.1930792}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001019553887890652, '_timestamp': 1721945521.1932683}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8527520227432253, '_timestamp': 1721945521.1933372}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15979783236980438, '_timestamp': 1721945521.1934395}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3495398461818695, '_timestamp': 1721945521.1937215}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'ratio': 0.9993822574615479, '_timestamp': 1721945521.1938229}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721945521.194553}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945521.1946526}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.18228149414062, '_timestamp': 1721945521.1947114}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3564390078151546, '_timestamp': 1721945521.1954434}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'train_goal': 0.3217804960924227, '_timestamp': 1721945521.1960227}).
wandb: WARNING (User provided step: 5511 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3564390078151546, '_timestamp': 1721945521.1965697}).
Env Football Algo jrpo Exp base_JRPO updates 5511/100000000000.0 steps in 83.18
total episode rewards is -60.0
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'value_loss': 0.591642890671889, '_timestamp': 1721945591.1751034}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0019758685235865413, '_timestamp': 1721945591.1763108}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8497079610824585, '_timestamp': 1721945591.1763802}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1594213992357254, '_timestamp': 1721945591.1769178}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.49648794531822205, '_timestamp': 1721945591.1772804}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'ratio': 1.000957727432251, '_timestamp': 1721945591.177383}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721945591.1775193}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945591.1779773}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'Episode_Time': 69.9723870754242, '_timestamp': 1721945591.1780388}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.39975, '_timestamp': 1721945591.1791897}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'train_goal': 0.300125, '_timestamp': 1721945591.1800673}).
wandb: WARNING (User provided step: 4075 is less than current step: 12030. Dropping entry: {'train_WDL': -0.39975, '_timestamp': 1721945591.1805873}).
Env Football Algo jrpo Exp base_JRPO updates 4075/100000000000.0 steps in 69.97
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 2574/100000000000.0 steps in 40.97
total episode rewards is -120.0
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'value_loss': 0.6926821770270666, '_timestamp': 1721945632.1516032}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0037187332892790435, '_timestamp': 1721945632.1517665}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.85465985139211, '_timestamp': 1721945632.1518335}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16487587988376617, '_timestamp': 1721945632.1519308}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7380017638206482, '_timestamp': 1721945632.1521714}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'ratio': 1.0011036396026611, '_timestamp': 1721945632.152271}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721945632.1526232}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945632.1527174}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'Episode_Time': 40.969987869262695, '_timestamp': 1721945632.1527746}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945632.1531796}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945632.1534722}).
wandb: WARNING (User provided step: 2574 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945632.1536896}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'value_loss': 0.9183239407340685, '_timestamp': 1721945685.067438}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004252209306384126, '_timestamp': 1721945685.067715}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8556265592575074, '_timestamp': 1721945685.0677845}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16439151763916016, '_timestamp': 1721945685.0678818}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9513497948646545, '_timestamp': 1721945685.0681963}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'ratio': 1.0005134344100952, '_timestamp': 1721945685.0682998}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721945685.06915}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945685.069258}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.91274309158325, '_timestamp': 1721945685.069318}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2779653387350889, '_timestamp': 1721945685.0699084}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'train_goal': 0.36101733063245556, '_timestamp': 1721945685.0702395}).
wandb: WARNING (User provided step: 3702 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2779653387350889, '_timestamp': 1721945685.0707035}).
Env Football Algo jrpo Exp base_JRPO updates 3702/100000000000.0 steps in 52.91
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 4464/100000000000.0 steps in 64.69
total episode rewards is -40.0
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'value_loss': 0.34885220090548197, '_timestamp': 1721945749.7620118}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009609001740075958, '_timestamp': 1721945749.7621903}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.856445008913676, '_timestamp': 1721945749.7622573}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1708124279975891, '_timestamp': 1721945749.762352}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2171451896429062, '_timestamp': 1721945749.7626169}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'ratio': 1.0006275177001953, '_timestamp': 1721945749.7627177}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945749.7633018}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945749.7634032}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.69036507606506, '_timestamp': 1721945749.7634597}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.34680912503609584, '_timestamp': 1721945749.7640698}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'train_goal': 0.3265954374819521, '_timestamp': 1721945749.7645173}).
wandb: WARNING (User provided step: 4464 is less than current step: 12030. Dropping entry: {'train_WDL': -0.34680912503609584, '_timestamp': 1721945749.7649503}).
Env Football Algo jrpo Exp base_JRPO updates 5002/100000000000.0 steps in 58.29
total episode rewards is -80.0
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'value_loss': 0.5843924894556403, '_timestamp': 1721945808.0517564}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005052744536127042, '_timestamp': 1721945808.0519247}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8527958726882936, '_timestamp': 1721945808.052009}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.168892502784729, '_timestamp': 1721945808.052106}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6445842385292053, '_timestamp': 1721945808.0523694}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'ratio': 1.0003772974014282, '_timestamp': 1721945808.0524693}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721945808.0529244}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945808.0530193}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'Episode_Time': 58.28602075576782, '_timestamp': 1721945808.0530765}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.10849056603773585, '_timestamp': 1721945808.05343}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'train_goal': 0.44575471698113206, '_timestamp': 1721945808.0536714}).
wandb: WARNING (User provided step: 5002 is less than current step: 12030. Dropping entry: {'train_WDL': -0.10849056603773585, '_timestamp': 1721945808.053903}).
Env Football Algo jrpo Exp base_JRPO updates 7330/100000000000.0 steps in 88.55
total episode rewards is -40.0
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'value_loss': 0.2776393975193302, '_timestamp': 1721945896.6113005}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0007506993838857549, '_timestamp': 1721945896.6114638}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8491469383239747, '_timestamp': 1721945896.6115298}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1378040313720703, '_timestamp': 1721945896.6116228}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1818597912788391, '_timestamp': 1721945896.6118689}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'ratio': 1.000293254852295, '_timestamp': 1721945896.6119893}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945896.6122773}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945896.6123698}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.55361700057983, '_timestamp': 1721945896.6124263}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945896.6130445}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945896.613515}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945896.6139965}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'value_loss': 0.36460907022158306, '_timestamp': 1721945972.0634696}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00377604561431023, '_timestamp': 1721945972.0636423}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8489039770762123, '_timestamp': 1721945972.0637102}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1543755829334259, '_timestamp': 1721945972.063808}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3476066589355469, '_timestamp': 1721945972.0641115}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'ratio': 1.0005635023117065, '_timestamp': 1721945972.064215}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721945972.0646038}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945972.064831}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'Episode_Time': 75.44863820075989, '_timestamp': 1721945972.0648885}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945972.0653448}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945972.0656853}).
wandb: WARNING (User provided step: 7186 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945972.0660226}).
Env Football Algo jrpo Exp base_JRPO updates 7186/100000000000.0 steps in 75.45
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 6122/100000000000.0 steps in 76.87
total episode rewards is -60.0
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'value_loss': 0.45043069574361044, '_timestamp': 1721946048.9402862}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004258879664703273, '_timestamp': 1721946048.9404826}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8480845435460407, '_timestamp': 1721946048.9405491}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16663230955600739, '_timestamp': 1721946048.9406457}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.47044190764427185, '_timestamp': 1721946048.9409013}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'ratio': 0.9990541934967041, '_timestamp': 1721946048.9413867}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721946048.9416347}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946048.9417334}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.87332153320312, '_timestamp': 1721946048.941791}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946048.942443}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946048.9428773}).
wandb: WARNING (User provided step: 6122 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946048.9432917}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'value_loss': 0.4114962539076805, '_timestamp': 1721946128.8573873}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009645461572799831, '_timestamp': 1721946128.8575604}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.850943257013957, '_timestamp': 1721946128.8576272}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16347497701644897, '_timestamp': 1721946128.857722}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4344506561756134, '_timestamp': 1721946128.85798}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'ratio': 0.9989152550697327, '_timestamp': 1721946128.8580801}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721946128.8582118}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946128.8583107}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.91329264640808, '_timestamp': 1721946128.8586066}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946128.8592408}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946128.8596873}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946128.8602035}).
Env Football Algo jrpo Exp base_JRPO updates 6322/100000000000.0 steps in 79.91
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 4432/100000000000.0 steps in 44.18
total episode rewards is -100.0
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'value_loss': 0.5882415065169334, '_timestamp': 1721946173.042055}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013921737601049243, '_timestamp': 1721946173.0422127}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8501778427759805, '_timestamp': 1721946173.0422776}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1601964384317398, '_timestamp': 1721946173.0423706}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8116401433944702, '_timestamp': 1721946173.0426795}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'ratio': 0.9991892576217651, '_timestamp': 1721946173.0428967}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721946173.043023}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946173.0431128}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.18096590042114, '_timestamp': 1721946173.043172}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946173.0434675}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946173.043682}).
wandb: WARNING (User provided step: 4432 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946173.0439029}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'value_loss': 0.525173271043847, '_timestamp': 1721946239.9365492}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0027614996555106095, '_timestamp': 1721946239.9367242}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8489812660217284, '_timestamp': 1721946239.936795}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16378995776176453, '_timestamp': 1721946239.9368927}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9137378334999084, '_timestamp': 1721946239.937164}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'ratio': 1.0003633499145508, '_timestamp': 1721946239.937271}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721946239.9374137}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946239.9379292}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'Episode_Time': 66.89174485206604, '_timestamp': 1721946239.9379914}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946239.9383695}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946239.9386163}).
wandb: WARNING (User provided step: 8184 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946239.9388592}).
Env Football Algo jrpo Exp base_JRPO updates 8184/100000000000.0 steps in 66.89
total episode rewards is -90.0
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'value_loss': 0.5769154606387019, '_timestamp': 1721946300.234573}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001753382096067071, '_timestamp': 1721946300.2347343}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8443874009450276, '_timestamp': 1721946300.234802}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16154536604881287, '_timestamp': 1721946300.234896}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7012853026390076, '_timestamp': 1721946300.2351375}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'ratio': 0.9997425675392151, '_timestamp': 1721946300.235247}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721946300.2354891}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946300.2356355}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.294995069503784, '_timestamp': 1721946300.235694}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2789473684210526, '_timestamp': 1721946300.2363758}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'train_goal': 0.3605263157894737, '_timestamp': 1721946300.2367208}).
wandb: WARNING (User provided step: 4560 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2789473684210526, '_timestamp': 1721946300.2370725}).
Env Football Algo jrpo Exp base_JRPO updates 4560/100000000000.0 steps in 60.29
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 9437/100000000000.0 steps in 86.86
total episode rewards is -40.0
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'value_loss': 0.23573072210419924, '_timestamp': 1721946387.0942316}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'policy_loss': 0.010261418204754591, '_timestamp': 1721946387.0944219}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.851544140179952, '_timestamp': 1721946387.0944886}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14393337070941925, '_timestamp': 1721946387.094582}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2605217695236206, '_timestamp': 1721946387.094844}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'ratio': 0.9993627071380615, '_timestamp': 1721946387.0949576}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721946387.0951066}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946387.0957913}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.85630655288696, '_timestamp': 1721946387.095851}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946387.1001503}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946387.1006305}).
wandb: WARNING (User provided step: 9437 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946387.101063}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'value_loss': 0.2893233799732601, '_timestamp': 1721946467.806516}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0048679750833737975, '_timestamp': 1721946467.8066735}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8436628437042235, '_timestamp': 1721946467.8067389}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1541658192873001, '_timestamp': 1721946467.806843}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.37985238432884216, '_timestamp': 1721946467.807252}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'ratio': 0.9999698400497437, '_timestamp': 1721946467.8074484}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721946467.8075826}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946467.807673}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.70454955101013, '_timestamp': 1721946467.8077316}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946467.8083322}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946467.8087502}).
wandb: WARNING (User provided step: 7745 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946467.8091826}).
Env Football Algo jrpo Exp base_JRPO updates 7745/100000000000.0 steps in 80.70
total episode rewards is -50.0
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'value_loss': 0.5246991486909489, '_timestamp': 1721946532.9371274}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0045470039616338906, '_timestamp': 1721946532.937296}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8429944388071697, '_timestamp': 1721946532.9373631}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.162007138133049, '_timestamp': 1721946532.9374576}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6443699598312378, '_timestamp': 1721946532.9377134}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'ratio': 0.9984443187713623, '_timestamp': 1721946532.937815}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721946532.9379487}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946532.9380422}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.1271002292633, '_timestamp': 1721946532.9382555}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946532.9388509}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946532.939209}).
wandb: WARNING (User provided step: 4419 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946532.9395568}).
Env Football Algo jrpo Exp base_JRPO updates 4419/100000000000.0 steps in 65.13
total episode rewards is -90.0
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'value_loss': 0.5552163415588438, '_timestamp': 1721946590.9873395}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021325721909912923, '_timestamp': 1721946590.987509}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.843068930308024, '_timestamp': 1721946590.9875743}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17235857248306274, '_timestamp': 1721946590.9876764}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8163957595825195, '_timestamp': 1721946590.987973}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'ratio': 1.0007027387619019, '_timestamp': 1721946590.988081}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721946590.9883327}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946590.9884305}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'Episode_Time': 58.04689311981201, '_timestamp': 1721946590.9884887}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946590.9888725}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946590.9891603}).
wandb: WARNING (User provided step: 5501 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946590.989456}).
Env Football Algo jrpo Exp base_JRPO updates 5501/100000000000.0 steps in 58.05
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 4667/100000000000.0 steps in 90.63
total episode rewards is -20.0
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'value_loss': 0.2871858985015812, '_timestamp': 1721946681.6194484}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008968082891854768, '_timestamp': 1721946681.619606}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.841785699526469, '_timestamp': 1721946681.6196704}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15735451877117157, '_timestamp': 1721946681.6197603}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17764931917190552, '_timestamp': 1721946681.620031}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'ratio': 1.0014580488204956, '_timestamp': 1721946681.620135}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721946681.620576}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946681.6208422}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.62926745414734, '_timestamp': 1721946681.620942}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4237878641246492, '_timestamp': 1721946681.6216717}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'train_goal': 0.2881060679376754, '_timestamp': 1721946681.6222901}).
wandb: WARNING (User provided step: 4667 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4237878641246492, '_timestamp': 1721946681.622888}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'value_loss': 0.24300369374454023, '_timestamp': 1721946766.6189744}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009803964637976606, '_timestamp': 1721946766.6191454}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83937642733256, '_timestamp': 1721946766.6192095}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15275336802005768, '_timestamp': 1721946766.6193042}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17452110350131989, '_timestamp': 1721946766.6195498}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'ratio': 1.0008975267410278, '_timestamp': 1721946766.6197321}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721946766.619906}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946766.6200228}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.9952552318573, '_timestamp': 1721946766.6200805}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.21610169491525424, '_timestamp': 1721946766.6207201}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'train_goal': 0.3919491525423729, '_timestamp': 1721946766.6211917}).
wandb: WARNING (User provided step: 7448 is less than current step: 12030. Dropping entry: {'train_WDL': -0.21610169491525424, '_timestamp': 1721946766.62165}).
Env Football Algo jrpo Exp base_JRPO updates 7448/100000000000.0 steps in 85.00
total episode rewards is -20.0
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'value_loss': 0.23790430795866996, '_timestamp': 1721946853.3594146}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0050565146196944015, '_timestamp': 1721946853.3596172}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8346287886301678, '_timestamp': 1721946853.359684}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1552811861038208, '_timestamp': 1721946853.3597732}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3284262716770172, '_timestamp': 1721946853.3600433}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'ratio': 1.0010749101638794, '_timestamp': 1721946853.3601508}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721946853.360289}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946853.3605058}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.73681020736694, '_timestamp': 1721946853.360566}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946853.361367}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946853.3622768}).
wandb: WARNING (User provided step: 6210 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946853.3631964}).
Env Football Algo jrpo Exp base_JRPO updates 6210/100000000000.0 steps in 86.74
total episode rewards is -40.0
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'value_loss': 0.2854785657223935, '_timestamp': 1721946944.5276291}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005790062874633198, '_timestamp': 1721946944.527842}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839581464131673, '_timestamp': 1721946944.5279262}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15521320700645447, '_timestamp': 1721946944.528048}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21087390184402466, '_timestamp': 1721946944.5287514}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'ratio': 0.9994378685951233, '_timestamp': 1721946944.5290992}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721946944.5293992}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946944.5295215}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.16315913200378, '_timestamp': 1721946944.5295825}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3752799402794071, '_timestamp': 1721946944.530771}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'train_goal': 0.3123600298602965, '_timestamp': 1721946944.5313857}).
wandb: WARNING (User provided step: 5623 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3752799402794071, '_timestamp': 1721946944.5319903}).
Env Football Algo jrpo Exp base_JRPO updates 5623/100000000000.0 steps in 91.16
total episode rewards is -20.0
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'value_loss': 0.28892112223276245, '_timestamp': 1721947031.5536983}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006704505833331495, '_timestamp': 1721947031.553871}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8314316670099893, '_timestamp': 1721947031.553941}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14964495599269867, '_timestamp': 1721947031.5540378}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2731919288635254, '_timestamp': 1721947031.554301}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'ratio': 1.0012341737747192, '_timestamp': 1721947031.5544033}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721947031.5546412}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947031.5547616}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.02057647705078, '_timestamp': 1721947031.5548341}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.11456274122187705, '_timestamp': 1721947031.5556228}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'train_goal': 0.5572813706109385, '_timestamp': 1721947031.5562449}).
wandb: WARNING (User provided step: 4377 is less than current step: 12030. Dropping entry: {'train_WDL': 0.11456274122187705, '_timestamp': 1721947031.5568595}).
Env Football Algo jrpo Exp base_JRPO updates 4377/100000000000.0 steps in 87.02
total episode rewards is 0.0
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'value_loss': 0.5123105282212297, '_timestamp': 1721947103.5337007}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003954294029390439, '_timestamp': 1721947103.5338602}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.833281571070353, '_timestamp': 1721947103.5339255}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17066974937915802, '_timestamp': 1721947103.5340168}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5318332314491272, '_timestamp': 1721947103.5342665}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'ratio': 1.0008246898651123, '_timestamp': 1721947103.5343661}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721947103.5347204}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947103.5348165}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'Episode_Time': 71.97605061531067, '_timestamp': 1721947103.5348723}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947103.535454}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947103.535886}).
wandb: WARNING (User provided step: 4677 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947103.5363817}).
Env Football Algo jrpo Exp base_JRPO updates 4677/100000000000.0 steps in 71.98
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 2237/100000000000.0 steps in 34.75
total episode rewards is -100.0
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'value_loss': 1.006247474004825, '_timestamp': 1721947138.2907338}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0025531230789298813, '_timestamp': 1721947138.2909029}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.826415284474691, '_timestamp': 1721947138.2909703}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16870206594467163, '_timestamp': 1721947138.2910795}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9841400384902954, '_timestamp': 1721947138.2913413}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'ratio': 0.9991506934165955, '_timestamp': 1721947138.291445}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721947138.2915788}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947138.291672}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'Episode_Time': 34.753498554229736, '_timestamp': 1721947138.2920187}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.27809307604994327, '_timestamp': 1721947138.2923827}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'train_goal': 0.36095346197502837, '_timestamp': 1721947138.2926035}).
wandb: WARNING (User provided step: 2237 is less than current step: 12030. Dropping entry: {'train_WDL': -0.27809307604994327, '_timestamp': 1721947138.2928247}).
Env Football Algo jrpo Exp base_JRPO updates 5568/100000000000.0 steps in 89.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'value_loss': 0.2577124545319627, '_timestamp': 1721947228.2704208}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009023344655288383, '_timestamp': 1721947228.2706587}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8293358945846556, '_timestamp': 1721947228.2707267}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1520717591047287, '_timestamp': 1721947228.2708237}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1518133133649826, '_timestamp': 1721947228.2710977}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'ratio': 0.9997562766075134, '_timestamp': 1721947228.2711995}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947228.2718217}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947228.2719235}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.97603225708008, '_timestamp': 1721947228.2719934}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947228.273175}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947228.273847}).
wandb: WARNING (User provided step: 5568 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947228.2745085}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'value_loss': 0.5143113693222403, '_timestamp': 1721947297.5473342}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0009761346758265669, '_timestamp': 1721947297.5477371}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.834964772860209, '_timestamp': 1721947297.5478063}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1574658453464508, '_timestamp': 1721947297.548002}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6228638291358948, '_timestamp': 1721947297.5482557}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'ratio': 0.9989352822303772, '_timestamp': 1721947297.5483596}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721947297.5485575}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947297.5491388}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'Episode_Time': 69.27024102210999, '_timestamp': 1721947297.5491996}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4103699471504071, '_timestamp': 1721947297.5498993}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'train_goal': 0.29481502642479646, '_timestamp': 1721947297.5503669}).
wandb: WARNING (User provided step: 3394 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4103699471504071, '_timestamp': 1721947297.55083}).
Env Football Algo jrpo Exp base_JRPO updates 3394/100000000000.0 steps in 69.27
total episode rewards is -70.0
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'value_loss': 0.5336931677162647, '_timestamp': 1721947354.91038}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0032007553389606378, '_timestamp': 1721947354.9105742}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8297406228383384, '_timestamp': 1721947354.9106398}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17589503526687622, '_timestamp': 1721947354.910732}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6835470199584961, '_timestamp': 1721947354.910982}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'ratio': 0.9988688230514526, '_timestamp': 1721947354.9110818}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721947354.9116006}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947354.9116983}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.358391523361206, '_timestamp': 1721947354.911755}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32216155149689324, '_timestamp': 1721947354.912732}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'train_goal': 0.33891922425155335, '_timestamp': 1721947354.9130886}).
wandb: WARNING (User provided step: 3774 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32216155149689324, '_timestamp': 1721947354.9134393}).
Env Football Algo jrpo Exp base_JRPO updates 3774/100000000000.0 steps in 57.36
total episode rewards is -70.0
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'value_loss': 0.15404237917624414, '_timestamp': 1721947443.8104973}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0012188758848545452, '_timestamp': 1721947443.8107}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8317228587468466, '_timestamp': 1721947443.8107688}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1320641189813614, '_timestamp': 1721947443.8108797}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14784614741802216, '_timestamp': 1721947443.8111665}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'ratio': 1.00067138671875, '_timestamp': 1721947443.8112738}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721947443.8120525}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947443.812159}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.89572358131409, '_timestamp': 1721947443.812217}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947443.8127272}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947443.813091}).
wandb: WARNING (User provided step: 10017 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947443.8134558}).
Env Football Algo jrpo Exp base_JRPO updates 10017/100000000000.0 steps in 88.90
total episode rewards is -20.0
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'value_loss': 0.41621939798817037, '_timestamp': 1721947501.359534}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013267943748117735, '_timestamp': 1721947501.35969}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8302609395980833, '_timestamp': 1721947501.359756}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16304725408554077, '_timestamp': 1721947501.3598464}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5976818799972534, '_timestamp': 1721947501.3600929}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'ratio': 1.00046968460083, '_timestamp': 1721947501.3601923}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721947501.3603768}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947501.3605072}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.545029640197754, '_timestamp': 1721947501.3605666}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947501.3609736}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947501.3612728}).
wandb: WARNING (User provided step: 5031 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947501.3617322}).
Env Football Algo jrpo Exp base_JRPO updates 5031/100000000000.0 steps in 57.55
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 6032/100000000000.0 steps in 79.32
total episode rewards is -70.0
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'value_loss': 0.4380643470150729, '_timestamp': 1721947580.6810415}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004039832527390293, '_timestamp': 1721947580.6812084}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8331075604756673, '_timestamp': 1721947580.681276}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1618138551712036, '_timestamp': 1721947580.6813734}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4767424762248993, '_timestamp': 1721947580.6816328}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'ratio': 1.0002259016036987, '_timestamp': 1721947580.6821644}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721947580.6825008}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947580.6826425}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.31597995758057, '_timestamp': 1721947580.6827018}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947580.6832716}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947580.6836898}).
wandb: WARNING (User provided step: 6032 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947580.6841438}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'value_loss': 0.2682187233461688, '_timestamp': 1721947672.2723494}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0068187366581211484, '_timestamp': 1721947672.2725344}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8405054664611815, '_timestamp': 1721947672.272602}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1448899805545807, '_timestamp': 1721947672.2727036}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19673259556293488, '_timestamp': 1721947672.2729816}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'ratio': 1.000805139541626, '_timestamp': 1721947672.2734506}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947672.2738028}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947672.2739055}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.58726692199707, '_timestamp': 1721947672.2739723}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947672.2745643}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947672.275024}).
wandb: WARNING (User provided step: 7421 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947672.2755034}).
Env Football Algo jrpo Exp base_JRPO updates 7421/100000000000.0 steps in 91.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'value_loss': 0.2488891063351184, '_timestamp': 1721947758.1588895}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00751247916254215, '_timestamp': 1721947758.1591458}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8410279099146525, '_timestamp': 1721947758.1592138}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1507585197687149, '_timestamp': 1721947758.1593046}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1846974790096283, '_timestamp': 1721947758.1595445}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'ratio': 1.000341773033142, '_timestamp': 1721947758.1600113}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947758.1602776}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947758.160375}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.88223385810852, '_timestamp': 1721947758.1604347}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947758.1616788}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947758.1622152}).
wandb: WARNING (User provided step: 6583 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947758.1631124}).
Env Football Algo jrpo Exp base_JRPO updates 6583/100000000000.0 steps in 85.88
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4591/100000000000.0 steps in 82.79
total episode rewards is -40.0
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'value_loss': 0.35188370470578473, '_timestamp': 1721947840.9580803}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005433251570066204, '_timestamp': 1721947840.9582338}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845911645889282, '_timestamp': 1721947840.9582999}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16082614660263062, '_timestamp': 1721947840.958391}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.27092233300209045, '_timestamp': 1721947840.9586353}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'ratio': 1.000075340270996, '_timestamp': 1721947840.9588258}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947840.9590244}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947840.9591167}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.79391121864319, '_timestamp': 1721947840.9591756}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4078556496864342, '_timestamp': 1721947840.9598122}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'train_goal': 0.2960721751567829, '_timestamp': 1721947840.9603674}).
wandb: WARNING (User provided step: 4591 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4078556496864342, '_timestamp': 1721947840.960912}).
Env Football Algo jrpo Exp base_JRPO updates 5980/100000000000.0 steps in 71.84
total episode rewards is -40.0
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'value_loss': 0.3598043343021224, '_timestamp': 1721947912.803735}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007196140826999908, '_timestamp': 1721947912.803881}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.843551068305969, '_timestamp': 1721947912.8039453}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1490953415632248, '_timestamp': 1721947912.8040552}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6042377352714539, '_timestamp': 1721947912.8042967}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'ratio': 0.9980552196502686, '_timestamp': 1721947912.8043952}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947912.8046386}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947912.8047287}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'Episode_Time': 71.84199857711792, '_timestamp': 1721947912.804785}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.29398058252427184, '_timestamp': 1721947912.8053434}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'train_goal': 0.3530097087378641, '_timestamp': 1721947912.8060985}).
wandb: WARNING (User provided step: 5980 is less than current step: 12030. Dropping entry: {'train_WDL': -0.29398058252427184, '_timestamp': 1721947912.8065696}).
Env Football Algo jrpo Exp base_JRPO updates 7320/100000000000.0 steps in 74.64
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'value_loss': 0.4696705910532425, '_timestamp': 1721947987.4484527}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003068389117446107, '_timestamp': 1721947987.4486177}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8452771663665772, '_timestamp': 1721947987.4486828}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15868385136127472, '_timestamp': 1721947987.4487755}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4665577709674835, '_timestamp': 1721947987.449013}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'ratio': 0.9985561370849609, '_timestamp': 1721947987.4491131}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721947987.4496357}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947987.4497275}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'Episode_Time': 74.64098930358887, '_timestamp': 1721947987.4497845}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947987.450214}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947987.4505372}).
wandb: WARNING (User provided step: 7320 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947987.4508724}).
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 7026/100000000000.0 steps in 63.46
total episode rewards is -70.0
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'value_loss': 0.5220287383409837, '_timestamp': 1721948050.9084687}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002861848068520582, '_timestamp': 1721948050.9086144}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8407734791437784, '_timestamp': 1721948050.9086792}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16039152443408966, '_timestamp': 1721948050.9087687}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.782917320728302, '_timestamp': 1721948050.9089959}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'ratio': 0.9997496008872986, '_timestamp': 1721948050.9092007}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721948050.909322}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948050.9094129}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.45689797401428, '_timestamp': 1721948050.9094694}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948050.909855}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948050.9101768}).
wandb: WARNING (User provided step: 7026 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948050.9104998}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'value_loss': 0.25186906216976546, '_timestamp': 1721948140.4346135}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00027250008250121025, '_timestamp': 1721948140.4348292}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8381978607177736, '_timestamp': 1721948140.434899}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1602196991443634, '_timestamp': 1721948140.434987}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13870057463645935, '_timestamp': 1721948140.435207}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'ratio': 0.998632550239563, '_timestamp': 1721948140.4353104}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948140.435439}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948140.4356277}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.52332735061646, '_timestamp': 1721948140.435687}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948140.436294}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948140.4367926}).
wandb: WARNING (User provided step: 6387 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948140.437314}).
Env Football Algo jrpo Exp base_JRPO updates 6387/100000000000.0 steps in 89.52
total episode rewards is -40.0
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'value_loss': 0.25222083354058367, '_timestamp': 1721948230.899761}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0018812668602913617, '_timestamp': 1721948230.8999212}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8359405835469564, '_timestamp': 1721948230.9000037}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15296587347984314, '_timestamp': 1721948230.9000947}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2007759064435959, '_timestamp': 1721948230.9004483}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'ratio': 0.9981431365013123, '_timestamp': 1721948230.9006221}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948230.900759}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948230.9008515}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.46156167984009, '_timestamp': 1721948230.9009094}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948230.9013557}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948230.9017088}).
wandb: WARNING (User provided step: 9552 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948230.9020712}).
Env Football Algo jrpo Exp base_JRPO updates 9552/100000000000.0 steps in 90.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'value_loss': 0.24076101435891664, '_timestamp': 1721948314.1513145}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001496391308028251, '_timestamp': 1721948314.1514714}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839853572845459, '_timestamp': 1721948314.151535}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14480094611644745, '_timestamp': 1721948314.1516242}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.22396385669708252, '_timestamp': 1721948314.1518567}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'ratio': 1.0010956525802612, '_timestamp': 1721948314.152103}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948314.1522396}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948314.152328}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.2483651638031, '_timestamp': 1721948314.1523838}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948314.1530814}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948314.1536767}).
wandb: WARNING (User provided step: 8497 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948314.154293}).
Env Football Algo jrpo Exp base_JRPO updates 8497/100000000000.0 steps in 83.25
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6980/100000000000.0 steps in 75.32
total episode rewards is -50.0
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'value_loss': 0.4302171790739521, '_timestamp': 1721948389.472446}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002870211829431355, '_timestamp': 1721948389.4726334}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8453121471405027, '_timestamp': 1721948389.4727004}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15650123357772827, '_timestamp': 1721948389.472803}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6392709016799927, '_timestamp': 1721948389.473077}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'ratio': 1.000720500946045, '_timestamp': 1721948389.4735355}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721948389.4738648}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948389.4739738}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'Episode_Time': 75.31689834594727, '_timestamp': 1721948389.4740345}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.10982867448151488, '_timestamp': 1721948389.4746451}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'train_goal': 0.44508566275924255, '_timestamp': 1721948389.475045}).
wandb: WARNING (User provided step: 6980 is less than current step: 12030. Dropping entry: {'train_WDL': -0.10982867448151488, '_timestamp': 1721948389.4754703}).
Env Football Algo jrpo Exp base_JRPO updates 5673/100000000000.0 steps in 65.74
total episode rewards is -110.0
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'value_loss': 0.6213632515321176, '_timestamp': 1721948455.220526}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00237940793299155, '_timestamp': 1721948455.221549}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8433777491251626, '_timestamp': 1721948455.2216206}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1599024534225464, '_timestamp': 1721948455.2220633}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9336159229278564, '_timestamp': 1721948455.2228646}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'ratio': 1.0004804134368896, '_timestamp': 1721948455.2229722}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721948455.223094}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948455.2232974}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.74019742012024, '_timestamp': 1721948455.2233562}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948455.224352}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948455.2246547}).
wandb: WARNING (User provided step: 5673 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948455.22496}).
Env Football Algo jrpo Exp base_JRPO updates 5887/100000000000.0 steps in 86.80
total episode rewards is -40.0
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'value_loss': 0.2568570854188874, '_timestamp': 1721948542.023304}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'policy_loss': 0.013160972565722961, '_timestamp': 1721948542.0235016}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.842386382420858, '_timestamp': 1721948542.0235684}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1533099114894867, '_timestamp': 1721948542.0236664}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18524831533432007, '_timestamp': 1721948542.0239267}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'ratio': 1.0006558895111084, '_timestamp': 1721948542.0246286}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948542.0247884}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948542.0248861}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.79749965667725, '_timestamp': 1721948542.024943}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948542.0256863}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948542.0265381}).
wandb: WARNING (User provided step: 5887 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948542.0273905}).
Env Football Algo jrpo Exp base_JRPO updates 6042/100000000000.0 steps in 89.58
total episode rewards is -40.0
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'value_loss': 0.24369532951774697, '_timestamp': 1721948631.6035807}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006794005460881938, '_timestamp': 1721948631.6037598}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8363366667429606, '_timestamp': 1721948631.6038404}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14640749990940094, '_timestamp': 1721948631.603986}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.11854184418916702, '_timestamp': 1721948631.604751}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'ratio': 1.000934362411499, '_timestamp': 1721948631.604877}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948631.6050162}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948631.6051137}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.57527732849121, '_timestamp': 1721948631.6051707}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948631.6059365}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948631.6064725}).
wandb: WARNING (User provided step: 6042 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948631.6070192}).
Env Football Algo jrpo Exp base_JRPO updates 3650/100000000000.0 steps in 61.38
total episode rewards is -60.0
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'value_loss': 0.3658785045892, '_timestamp': 1721948692.9890578}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007061052227557715, '_timestamp': 1721948692.9892476}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8340614732106526, '_timestamp': 1721948692.9893177}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14808635413646698, '_timestamp': 1721948692.9894252}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4218705892562866, '_timestamp': 1721948692.9897017}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'ratio': 1.0010310411453247, '_timestamp': 1721948692.9898028}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721948692.9906092}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948692.9907103}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.38094234466553, '_timestamp': 1721948692.9907694}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948692.9913628}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948692.9918666}).
wandb: WARNING (User provided step: 3650 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948692.9922736}).
Env Football Algo jrpo Exp base_JRPO updates 6322/100000000000.0 steps in 71.41
total episode rewards is -80.0
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'value_loss': 0.5412110370987405, '_timestamp': 1721948764.4118528}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001196441786014475, '_timestamp': 1721948764.413203}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.827736775080363, '_timestamp': 1721948764.4132996}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16749267280101776, '_timestamp': 1721948764.4138978}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7242282032966614, '_timestamp': 1721948764.4143105}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'ratio': 1.0013102293014526, '_timestamp': 1721948764.4150066}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721948764.4152524}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948764.4154506}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'Episode_Time': 71.41365551948547, '_timestamp': 1721948764.4155116}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948764.4165895}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948764.417042}).
wandb: WARNING (User provided step: 6322 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948764.4174805}).
Env Football Algo jrpo Exp base_JRPO updates 7094/100000000000.0 steps in 89.38
total episode rewards is -40.0
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'value_loss': 0.2468123157892842, '_timestamp': 1721948853.7962737}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003189761337659244, '_timestamp': 1721948853.796458}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.831773114204407, '_timestamp': 1721948853.7965252}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15597248077392578, '_timestamp': 1721948853.7966273}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.277218222618103, '_timestamp': 1721948853.7973633}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'ratio': 1.0007596015930176, '_timestamp': 1721948853.7977006}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948853.7979014}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948853.798005}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.37786531448364, '_timestamp': 1721948853.7980626}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948853.79873}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948853.7992659}).
wandb: WARNING (User provided step: 7094 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948853.79977}).
Env Football Algo jrpo Exp base_JRPO updates 5112/100000000000.0 steps in 55.90
total episode rewards is -50.0
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'value_loss': 0.52499360922724, '_timestamp': 1721948909.6976573}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0029059876284979204, '_timestamp': 1721948909.6978235}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.837504296302795, '_timestamp': 1721948909.6978886}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15364661812782288, '_timestamp': 1721948909.6979833}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7697552442550659, '_timestamp': 1721948909.6982126}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'ratio': 1.001421570777893, '_timestamp': 1721948909.698321}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721948909.698457}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948909.698547}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'Episode_Time': 55.897011518478394, '_timestamp': 1721948909.698603}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.0849919311457773, '_timestamp': 1721948909.6990063}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'train_goal': 0.45750403442711135, '_timestamp': 1721948909.6992745}).
wandb: WARNING (User provided step: 5112 is less than current step: 12030. Dropping entry: {'train_WDL': -0.0849919311457773, '_timestamp': 1721948909.6995397}).
Env Football Algo jrpo Exp base_JRPO updates 7348/100000000000.0 steps in 84.47
total episode rewards is -40.0
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'value_loss': 0.25644634031147384, '_timestamp': 1721948994.1745553}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004700341026764363, '_timestamp': 1721948994.174704}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8446926323572796, '_timestamp': 1721948994.1747682}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1481582224369049, '_timestamp': 1721948994.174855}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.31039685010910034, '_timestamp': 1721948994.1751592}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'ratio': 1.000223159790039, '_timestamp': 1721948994.175305}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721948994.1754344}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948994.1755211}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.4741849899292, '_timestamp': 1721948994.175576}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948994.1761029}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948994.1790013}).
wandb: WARNING (User provided step: 7348 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948994.1794794}).
Env Football Algo jrpo Exp base_JRPO updates 5100/100000000000.0 steps in 61.74
total episode rewards is -70.0
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'value_loss': 0.6319685181975365, '_timestamp': 1721949055.91992}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004041535337843622, '_timestamp': 1721949055.9201999}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8425280030568443, '_timestamp': 1721949055.920271}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17139624059200287, '_timestamp': 1721949055.920379}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7056229114532471, '_timestamp': 1721949055.9206052}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'ratio': 1.001027226448059, '_timestamp': 1721949055.9212441}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721949055.9213762}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949055.9214854}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.73956108093262, '_timestamp': 1721949055.9215431}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1511758118701008, '_timestamp': 1721949055.9221954}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'train_goal': 0.4244120940649496, '_timestamp': 1721949055.9226375}).
wandb: WARNING (User provided step: 5100 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1511758118701008, '_timestamp': 1721949055.9230084}).
Env Football Algo jrpo Exp base_JRPO updates 6956/100000000000.0 steps in 85.35
total episode rewards is -20.0
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'value_loss': 0.26970472335796025, '_timestamp': 1721949141.2755048}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00023441199058045944, '_timestamp': 1721949141.2767234}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8440863545735677, '_timestamp': 1721949141.276792}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14982090890407562, '_timestamp': 1721949141.277367}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20626729726791382, '_timestamp': 1721949141.2777214}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'ratio': 0.9984169602394104, '_timestamp': 1721949141.278123}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721949141.2782633}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949141.2784553}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.34684944152832, '_timestamp': 1721949141.2785122}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.26355047240179014, '_timestamp': 1721949141.2796981}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'train_goal': 0.3682247637991049, '_timestamp': 1721949141.2802382}).
wandb: WARNING (User provided step: 6956 is less than current step: 12030. Dropping entry: {'train_WDL': -0.26355047240179014, '_timestamp': 1721949141.2807326}).
Env Football Algo jrpo Exp base_JRPO updates 6119/100000000000.0 steps in 90.94
total episode rewards is -20.0
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'value_loss': 0.2521148555595816, '_timestamp': 1721949232.2222593}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0008685498088016175, '_timestamp': 1721949232.2224333}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845330139795939, '_timestamp': 1721949232.2225006}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14741407334804535, '_timestamp': 1721949232.2226028}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.24179206788539886, '_timestamp': 1721949232.2228599}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'ratio': 1.0013235807418823, '_timestamp': 1721949232.2229629}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721949232.2232552}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949232.2233493}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.94047832489014, '_timestamp': 1721949232.2234058}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32845400292759824, '_timestamp': 1721949232.2241123}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'train_goal': 0.33577299853620085, '_timestamp': 1721949232.2246306}).
wandb: WARNING (User provided step: 6119 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32845400292759824, '_timestamp': 1721949232.2251675}).
Env Football Algo jrpo Exp base_JRPO updates 3927/100000000000.0 steps in 65.11
total episode rewards is -80.0
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'value_loss': 0.5105128701031209, '_timestamp': 1721949297.338162}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003244723996249377, '_timestamp': 1721949297.3383255}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845440231959025, '_timestamp': 1721949297.3383908}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1516639143228531, '_timestamp': 1721949297.3384812}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6844426989555359, '_timestamp': 1721949297.3387275}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'ratio': 0.9989554286003113, '_timestamp': 1721949297.3388257}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721949297.339217}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949297.3394165}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.11147689819336, '_timestamp': 1721949297.3394754}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949297.340216}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949297.3406374}).
wandb: WARNING (User provided step: 3927 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949297.341074}).
Env Football Algo jrpo Exp base_JRPO updates 8135/100000000000.0 steps in 94.12
total episode rewards is -40.0
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'value_loss': 0.26555795890822387, '_timestamp': 1721949391.4585907}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00822356839121009, '_timestamp': 1721949391.4587529}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8439087454477945, '_timestamp': 1721949391.458818}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1637886017560959, '_timestamp': 1721949391.458912}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2562057673931122, '_timestamp': 1721949391.4591608}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'ratio': 1.0007675886154175, '_timestamp': 1721949391.459263}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949391.4595404}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949391.459636}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'Episode_Time': 94.11671924591064, '_timestamp': 1721949391.4596927}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949391.4602675}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949391.4606884}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949391.461122}).
Env Football Algo jrpo Exp base_JRPO updates 7102/100000000000.0 steps in 87.72
total episode rewards is -40.0
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'value_loss': 0.2283612394387213, '_timestamp': 1721949479.1777387}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003517876661305005, '_timestamp': 1721949479.1779375}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8434630409876505, '_timestamp': 1721949479.178005}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1508161574602127, '_timestamp': 1721949479.1781027}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.22172077000141144, '_timestamp': 1721949479.1783476}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'ratio': 0.9996746778488159, '_timestamp': 1721949479.1784487}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949479.178652}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949479.1791081}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.71564674377441, '_timestamp': 1721949479.1791673}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949479.179943}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949479.1804729}).
wandb: WARNING (User provided step: 7102 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949479.180968}).
Env Football Algo jrpo Exp base_JRPO updates 4984/100000000000.0 steps in 48.78
total episode rewards is -60.0
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'value_loss': 0.3710387525707483, '_timestamp': 1721949527.970996}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0017284671434511741, '_timestamp': 1721949527.9720325}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.836237942377726, '_timestamp': 1721949527.9721088}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14491486549377441, '_timestamp': 1721949527.9725897}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4148551821708679, '_timestamp': 1721949527.9729588}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'ratio': 1.0005115270614624, '_timestamp': 1721949527.9730606}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721949527.9732032}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949527.9733758}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'Episode_Time': 48.78457450866699, '_timestamp': 1721949527.9734344}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949527.974174}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949527.9744365}).
wandb: WARNING (User provided step: 4984 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949527.974682}).
Env Football Algo jrpo Exp base_JRPO updates 7236/100000000000.0 steps in 89.13
total episode rewards is -40.0
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'value_loss': 0.26830423761624844, '_timestamp': 1721949617.1057796}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'policy_loss': 0.014695709511288442, '_timestamp': 1721949617.1059587}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8330753215154014, '_timestamp': 1721949617.1060264}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13980445265769958, '_timestamp': 1721949617.1061275}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18909747898578644, '_timestamp': 1721949617.106387}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'ratio': 0.9989058375358582, '_timestamp': 1721949617.1064925}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949617.107142}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949617.107239}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.13025116920471, '_timestamp': 1721949617.1072965}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949617.1079345}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949617.108469}).
wandb: WARNING (User provided step: 7236 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949617.1089606}).
Env Football Algo jrpo Exp base_JRPO updates 5972/100000000000.0 steps in 58.16
total episode rewards is -90.0
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'value_loss': 0.5552666426201661, '_timestamp': 1721949675.2728167}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00563832996871497, '_timestamp': 1721949675.2729902}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.832895097732544, '_timestamp': 1721949675.273056}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1679505556821823, '_timestamp': 1721949675.2731602}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7391311526298523, '_timestamp': 1721949675.2734118}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'ratio': 0.9977257251739502, '_timestamp': 1721949675.2735138}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721949675.273649}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949675.274069}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'Episode_Time': 58.162789821624756, '_timestamp': 1721949675.2741294}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949675.2746024}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949675.274921}).
wandb: WARNING (User provided step: 5972 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949675.275259}).
Env Football Algo jrpo Exp base_JRPO updates 3642/100000000000.0 steps in 75.71
total episode rewards is -70.0
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'value_loss': 0.6716678873697917, '_timestamp': 1721949750.989595}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002042057912137049, '_timestamp': 1721949750.9897523}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.829874178568522, '_timestamp': 1721949750.9898174}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1721772700548172, '_timestamp': 1721949750.9899065}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.828895092010498, '_timestamp': 1721949750.990137}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'ratio': 0.9992877244949341, '_timestamp': 1721949750.9902444}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721949750.9905372}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949750.9906275}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'Episode_Time': 75.71342515945435, '_timestamp': 1721949750.990683}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4418216499761564, '_timestamp': 1721949750.991269}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'train_goal': 0.2790891750119218, '_timestamp': 1721949750.9917548}).
wandb: WARNING (User provided step: 3642 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4418216499761564, '_timestamp': 1721949750.9922762}).
Env Football Algo jrpo Exp base_JRPO updates 4813/100000000000.0 steps in 63.32
total episode rewards is -80.0
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'value_loss': 0.5108591335453093, '_timestamp': 1721949814.3177497}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016662781961107006, '_timestamp': 1721949814.3179393}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.832958124478658, '_timestamp': 1721949814.3180072}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15499718487262726, '_timestamp': 1721949814.3181102}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6243486404418945, '_timestamp': 1721949814.3183944}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'ratio': 0.9995158314704895, '_timestamp': 1721949814.3184927}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721949814.3190434}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949814.3193202}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.32439875602722, '_timestamp': 1721949814.3194447}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949814.3200445}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949814.3204849}).
wandb: WARNING (User provided step: 4813 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949814.3209028}).
Env Football Algo jrpo Exp base_JRPO updates 5495/100000000000.0 steps in 72.25
total episode rewards is -80.0
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'value_loss': 0.6751591414927195, '_timestamp': 1721949886.5673366}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002714806292206049, '_timestamp': 1721949886.5675495}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.833094293276469, '_timestamp': 1721949886.5676184}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1557139903306961, '_timestamp': 1721949886.5677125}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6943031549453735, '_timestamp': 1721949886.5679603}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'ratio': 1.0003690719604492, '_timestamp': 1721949886.5681164}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721949886.5684202}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949886.5685155}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.24564027786255, '_timestamp': 1721949886.5685763}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2280888888888889, '_timestamp': 1721949886.5693069}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'train_goal': 0.38595555555555555, '_timestamp': 1721949886.5697858}).
wandb: WARNING (User provided step: 5495 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2280888888888889, '_timestamp': 1721949886.5702713}).
Env Football Algo jrpo Exp base_JRPO updates 5414/100000000000.0 steps in 48.05
total episode rewards is -110.0
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'value_loss': 0.7588282677531243, '_timestamp': 1721949934.6210494}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0010951092024333775, '_timestamp': 1721949934.6212106}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.831333975791931, '_timestamp': 1721949934.621277}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17080563306808472, '_timestamp': 1721949934.62137}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9556342959403992, '_timestamp': 1721949934.6216166}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'ratio': 0.999500572681427, '_timestamp': 1721949934.6217167}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721949934.6218467}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949934.6219354}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'Episode_Time': 48.049954891204834, '_timestamp': 1721949934.6223779}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.9930898321816387, '_timestamp': 1721949934.6226726}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'train_goal': 0.0034550839091806516, '_timestamp': 1721949934.6228604}).
wandb: WARNING (User provided step: 5414 is less than current step: 12030. Dropping entry: {'train_WDL': -0.9930898321816387, '_timestamp': 1721949934.62305}).
Env Football Algo jrpo Exp base_JRPO updates 6295/100000000000.0 steps in 70.96
total episode rewards is -80.0
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'value_loss': 0.5980024069175124, '_timestamp': 1721950005.5873156}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0010975218646975312, '_timestamp': 1721950005.5874805}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838056042989095, '_timestamp': 1721950005.5875456}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16417288780212402, '_timestamp': 1721950005.5876393}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7813209891319275, '_timestamp': 1721950005.587874}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'ratio': 0.9997294545173645, '_timestamp': 1721950005.5881944}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721950005.5883307}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950005.5884242}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'Episode_Time': 70.96322512626648, '_timestamp': 1721950005.588484}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950005.588935}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950005.5892973}).
wandb: WARNING (User provided step: 6295 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950005.589666}).
Env Football Algo jrpo Exp base_JRPO updates 5351/100000000000.0 steps in 71.34
total episode rewards is -70.0
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'value_loss': 0.3903847367564837, '_timestamp': 1721950076.9337869}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003431189044301088, '_timestamp': 1721950076.9339406}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.835057722727458, '_timestamp': 1721950076.9340048}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15631042420864105, '_timestamp': 1721950076.934096}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4566587805747986, '_timestamp': 1721950076.9343393}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'ratio': 0.99921053647995, '_timestamp': 1721950076.9344401}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950076.9345703}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950076.9348528}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'Episode_Time': 71.34295177459717, '_timestamp': 1721950076.934909}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950076.9354904}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950076.9359727}).
wandb: WARNING (User provided step: 5351 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950076.936457}).
Env Football Algo jrpo Exp base_JRPO updates 3550/100000000000.0 steps in 47.80
total episode rewards is -90.0
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'value_loss': 0.519411445762962, '_timestamp': 1721950124.7541459}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002358724250661908, '_timestamp': 1721950124.7544045}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8379433584213256, '_timestamp': 1721950124.7544773}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17136764526367188, '_timestamp': 1721950124.7545717}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.46575823426246643, '_timestamp': 1721950124.754817}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'ratio': 0.9993892908096313, '_timestamp': 1721950124.7549179}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721950124.7550552}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950124.7551455}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'Episode_Time': 47.80490565299988, '_timestamp': 1721950124.7552018}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950124.755547}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950124.7558022}).
wandb: WARNING (User provided step: 3550 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950124.7560768}).
Env Football Algo jrpo Exp base_JRPO updates 2620/100000000000.0 steps in 41.92
total episode rewards is -110.0
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'value_loss': 0.7837993518263101, '_timestamp': 1721950166.680353}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0030047021511321265, '_timestamp': 1721950166.6805089}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8366569471359253, '_timestamp': 1721950166.6805768}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16897620260715485, '_timestamp': 1721950166.680666}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9651345014572144, '_timestamp': 1721950166.6808937}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'ratio': 0.9974169135093689, '_timestamp': 1721950166.680994}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721950166.681266}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950166.681363}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.9235737323761, '_timestamp': 1721950166.6814213}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32187028657616895, '_timestamp': 1721950166.6817644}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'train_goal': 0.33906485671191555, '_timestamp': 1721950166.6820166}).
wandb: WARNING (User provided step: 2620 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32187028657616895, '_timestamp': 1721950166.6822686}).
Env Football Algo jrpo Exp base_JRPO updates 8086/100000000000.0 steps in 80.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'value_loss': 0.2680134543497115, '_timestamp': 1721950246.9004722}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006196187247211734, '_timestamp': 1721950246.9006293}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.840617496172587, '_timestamp': 1721950246.9006941}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15033912658691406, '_timestamp': 1721950246.9007847}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.28367701172828674, '_timestamp': 1721950246.9009984}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'ratio': 0.9987921118736267, '_timestamp': 1721950246.901219}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721950246.9013498}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950246.9014401}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.21731352806091, '_timestamp': 1721950246.9014978}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950246.9020438}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950246.9024682}).
wandb: WARNING (User provided step: 8086 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950246.902906}).
Env Football Algo jrpo Exp base_JRPO updates 5646/100000000000.0 steps in 61.73
total episode rewards is -60.0
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'value_loss': 0.45692663529732575, '_timestamp': 1721950308.636669}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0015362698774940024, '_timestamp': 1721950308.6368556}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8395723327000937, '_timestamp': 1721950308.6369243}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16731594502925873, '_timestamp': 1721950308.6370268}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6274509429931641, '_timestamp': 1721950308.6372833}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'ratio': 0.9984984397888184, '_timestamp': 1721950308.6373858}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721950308.6376886}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950308.637787}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.7327241897583, '_timestamp': 1721950308.6378446}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950308.6382563}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950308.6385581}).
wandb: WARNING (User provided step: 5646 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950308.6388476}).
Env Football Algo jrpo Exp base_JRPO updates 6659/100000000000.0 steps in 84.49
total episode rewards is -20.0
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'value_loss': 0.278763862697718, '_timestamp': 1721950393.1285}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0027323529326046506, '_timestamp': 1721950393.1286733}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8382604471842448, '_timestamp': 1721950393.1287436}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14897330105304718, '_timestamp': 1721950393.1288376}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35821714997291565, '_timestamp': 1721950393.1291018}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'ratio': 1.0000954866409302, '_timestamp': 1721950393.129605}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721950393.1297462}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950393.1298416}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.48858046531677, '_timestamp': 1721950393.1298985}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.28425848219637934, '_timestamp': 1721950393.1305516}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'train_goal': 0.35787075890181036, '_timestamp': 1721950393.1310472}).
wandb: WARNING (User provided step: 6659 is less than current step: 12030. Dropping entry: {'train_WDL': -0.28425848219637934, '_timestamp': 1721950393.1315472}).
Env Football Algo jrpo Exp base_JRPO updates 5145/100000000000.0 steps in 57.69
total episode rewards is -70.0
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'value_loss': 0.5481270621716976, '_timestamp': 1721950450.8231368}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0017679752161105474, '_timestamp': 1721950450.823288}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.831320293744405, '_timestamp': 1721950450.8233538}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16158796846866608, '_timestamp': 1721950450.823442}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7194005250930786, '_timestamp': 1721950450.8236763}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'ratio': 1.0001882314682007, '_timestamp': 1721950450.8237765}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950450.8239067}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950450.8241212}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.690876960754395, '_timestamp': 1721950450.8241787}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.16125786163522013, '_timestamp': 1721950450.824537}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'train_goal': 0.4193710691823899, '_timestamp': 1721950450.8248086}).
wandb: WARNING (User provided step: 5145 is less than current step: 12030. Dropping entry: {'train_WDL': -0.16125786163522013, '_timestamp': 1721950450.8250856}).
Env Football Algo jrpo Exp base_JRPO updates 4297/100000000000.0 steps in 84.76
total episode rewards is -20.0
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'value_loss': 0.2748172523512039, '_timestamp': 1721950535.5822368}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008297528494537498, '_timestamp': 1721950535.5823894}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8262997182210285, '_timestamp': 1721950535.582453}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13883769512176514, '_timestamp': 1721950535.5825412}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20521020889282227, '_timestamp': 1721950535.5827723}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'ratio': 0.9993190765380859, '_timestamp': 1721950535.582874}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721950535.5829923}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950535.5830824}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.75628876686096, '_timestamp': 1721950535.5831375}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.45174250210221434, '_timestamp': 1721950535.5838292}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_goal': 0.27412874894889283, '_timestamp': 1721950535.5848098}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_WDL': -0.45174250210221434, '_timestamp': 1721950535.5854359}).
Env Football Algo jrpo Exp base_JRPO updates 4314/100000000000.0 steps in 80.95
total episode rewards is -20.0
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'value_loss': 0.3984020458022133, '_timestamp': 1721950616.5383883}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006450545685559822, '_timestamp': 1721950616.5385377}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.823839956919352, '_timestamp': 1721950616.5386014}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15107642114162445, '_timestamp': 1721950616.5386891}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35998550057411194, '_timestamp': 1721950616.5389242}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'ratio': 0.9999197721481323, '_timestamp': 1721950616.5390224}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721950616.5392957}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950616.5393908}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.95207118988037, '_timestamp': 1721950616.539449}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.1476819158735032, '_timestamp': 1721950616.5401273}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'train_goal': 0.5738409579367516, '_timestamp': 1721950616.540684}).
wandb: WARNING (User provided step: 4314 is less than current step: 12030. Dropping entry: {'train_WDL': 0.1476819158735032, '_timestamp': 1721950616.5412471}).
Env Football Algo jrpo Exp base_JRPO updates 6889/100000000000.0 steps in 72.88
total episode rewards is -40.0
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'value_loss': 0.3676687124588837, '_timestamp': 1721950689.4253373}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002294673688496308, '_timestamp': 1721950689.4255016}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8167853673299152, '_timestamp': 1721950689.4255736}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15274615585803986, '_timestamp': 1721950689.4256663}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.36181238293647766, '_timestamp': 1721950689.425898}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'ratio': 0.9981775879859924, '_timestamp': 1721950689.426138}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721950689.4263775}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950689.4264753}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.88287854194641, '_timestamp': 1721950689.4265347}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.14256688113782595, '_timestamp': 1721950689.4270306}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'train_goal': 0.42871655943108705, '_timestamp': 1721950689.427407}).
wandb: WARNING (User provided step: 6889 is less than current step: 12030. Dropping entry: {'train_WDL': -0.14256688113782595, '_timestamp': 1721950689.4277873}).
Env Football Algo jrpo Exp base_JRPO updates 6949/100000000000.0 steps in 86.26
total episode rewards is -40.0
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'value_loss': 0.3115091424357767, '_timestamp': 1721950775.6910417}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008145485915786897, '_timestamp': 1721950775.6911993}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.815677638053894, '_timestamp': 1721950775.6912663}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15861192345619202, '_timestamp': 1721950775.691359}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20541387796401978, '_timestamp': 1721950775.6916}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'ratio': 1.000038981437683, '_timestamp': 1721950775.6918857}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721950775.6920304}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950775.6921294}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.26237678527832, '_timestamp': 1721950775.6921875}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950775.6927516}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950775.693226}).
wandb: WARNING (User provided step: 6949 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950775.6937242}).
Env Football Algo jrpo Exp base_JRPO updates 4761/100000000000.0 steps in 54.69
total episode rewards is -70.0
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'value_loss': 0.7112785962844889, '_timestamp': 1721950830.387216}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013417870964622125, '_timestamp': 1721950830.387413}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8141514984766642, '_timestamp': 1721950830.3874831}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17245811223983765, '_timestamp': 1721950830.3875926}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.089601993560791, '_timestamp': 1721950830.3878717}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'ratio': 1.0013096332550049, '_timestamp': 1721950830.3885853}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950830.3888}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950830.3889024}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'Episode_Time': 54.69224762916565, '_timestamp': 1721950830.388961}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.09250136836343732, '_timestamp': 1721950830.3894267}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'train_goal': 0.4537493158182813, '_timestamp': 1721950830.3897178}).
wandb: WARNING (User provided step: 4761 is less than current step: 12030. Dropping entry: {'train_WDL': -0.09250136836343732, '_timestamp': 1721950830.3900168}).
Env Football Algo jrpo Exp base_JRPO updates 7040/100000000000.0 steps in 85.50
total episode rewards is -30.0
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'value_loss': 0.24210795374936425, '_timestamp': 1721950915.8908582}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0007615219863752524, '_timestamp': 1721950915.891014}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.822768677075704, '_timestamp': 1721950915.8910792}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16027992963790894, '_timestamp': 1721950915.8911693}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20918749272823334, '_timestamp': 1721950915.8914108}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'ratio': 0.9980939030647278, '_timestamp': 1721950915.8915102}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721950915.8918757}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950915.8919868}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.49988079071045, '_timestamp': 1721950915.8920453}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950915.8926308}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950915.8930993}).
wandb: WARNING (User provided step: 7040 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950915.8935888}).
Env Football Algo jrpo Exp base_JRPO updates 6113/100000000000.0 steps in 51.40
total episode rewards is -60.0
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'value_loss': 0.42685554110445084, '_timestamp': 1721950967.2987883}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0023059873515740036, '_timestamp': 1721950967.2992074}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8176811869939167, '_timestamp': 1721950967.299278}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1496879905462265, '_timestamp': 1721950967.29938}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5539775490760803, '_timestamp': 1721950967.299644}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'ratio': 1.0003052949905396, '_timestamp': 1721950967.3001213}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721950967.3002708}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950967.3003676}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.40432596206665, '_timestamp': 1721950967.3004255}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950967.300739}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950967.3009322}).
wandb: WARNING (User provided step: 6113 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950967.301128}).
Env Football Algo jrpo Exp base_JRPO updates 6095/100000000000.0 steps in 91.02
total episode rewards is -40.0
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'value_loss': 0.2541077961307019, '_timestamp': 1721951058.3246486}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007859177708160131, '_timestamp': 1721951058.3248105}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8147961489359536, '_timestamp': 1721951058.3248758}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15985023975372314, '_timestamp': 1721951058.324967}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.28788742423057556, '_timestamp': 1721951058.325206}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'ratio': 1.0004521608352661, '_timestamp': 1721951058.3253067}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951058.3254397}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951058.32571}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.02265048027039, '_timestamp': 1721951058.3257675}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951058.3264272}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951058.326943}).
wandb: WARNING (User provided step: 6095 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951058.3274896}).
Env Football Algo jrpo Exp base_JRPO updates 5074/100000000000.0 steps in 55.59
total episode rewards is -50.0
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'value_loss': 0.4527593907279273, '_timestamp': 1721951113.9171727}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0009416546222443382, '_timestamp': 1721951113.9173758}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.816442632675171, '_timestamp': 1721951113.9174523}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1753804236650467, '_timestamp': 1721951113.9175477}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6162360906600952, '_timestamp': 1721951113.9177911}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'ratio': 1.000182867050171, '_timestamp': 1721951113.9178927}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721951113.9183235}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951113.9184217}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'Episode_Time': 55.58844518661499, '_timestamp': 1721951113.918483}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.08903757076685538, '_timestamp': 1721951113.9191053}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'train_goal': 0.4554812146165723, '_timestamp': 1721951113.9193947}).
wandb: WARNING (User provided step: 5074 is less than current step: 12030. Dropping entry: {'train_WDL': -0.08903757076685538, '_timestamp': 1721951113.9196734}).
Env Football Algo jrpo Exp base_JRPO updates 2299/100000000000.0 steps in 43.51
total episode rewards is -100.0
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'value_loss': 1.1346972130735715, '_timestamp': 1721951157.4305694}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0026814562352349943, '_timestamp': 1721951157.4308715}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.816914119720459, '_timestamp': 1721951157.4309404}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1780226081609726, '_timestamp': 1721951157.431041}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.2682554721832275, '_timestamp': 1721951157.4313033}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'ratio': 1.0004022121429443, '_timestamp': 1721951157.4314058}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721951157.431743}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951157.4324229}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'Episode_Time': 43.50966548919678, '_timestamp': 1721951157.4324853}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.308818279186005, '_timestamp': 1721951157.4333813}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'train_goal': 0.3455908604069975, '_timestamp': 1721951157.433647}).
wandb: WARNING (User provided step: 2299 is less than current step: 12030. Dropping entry: {'train_WDL': -0.308818279186005, '_timestamp': 1721951157.4339051}).
Env Football Algo jrpo Exp base_JRPO updates 4775/100000000000.0 steps in 86.92
total episode rewards is -20.0
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'value_loss': 0.2631823582815317, '_timestamp': 1721951244.3565328}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008212639471682147, '_timestamp': 1721951244.3567696}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8190113496780396, '_timestamp': 1721951244.3568397}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13255620002746582, '_timestamp': 1721951244.3569353}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13281133770942688, '_timestamp': 1721951244.3571932}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'ratio': 0.9994179606437683, '_timestamp': 1721951244.3572948}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721951244.3578098}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951244.3579078}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.92137050628662, '_timestamp': 1721951244.3579664}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4208312958435208, '_timestamp': 1721951244.3589427}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'train_goal': 0.2895843520782396, '_timestamp': 1721951244.3595424}).
wandb: WARNING (User provided step: 4775 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4208312958435208, '_timestamp': 1721951244.3601756}).
Env Football Algo jrpo Exp base_JRPO updates 6400/100000000000.0 steps in 89.50
total episode rewards is -40.0
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'value_loss': 0.2856732280063443, '_timestamp': 1721951333.861304}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00617610895356241, '_timestamp': 1721951333.8614979}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.815661768913269, '_timestamp': 1721951333.8615696}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1507304608821869, '_timestamp': 1721951333.8616774}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16011182963848114, '_timestamp': 1721951333.861958}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'ratio': 0.9996106028556824, '_timestamp': 1721951333.8620925}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951333.8622391}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951333.863039}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.50010323524475, '_timestamp': 1721951333.8631015}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951333.8638132}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951333.8643851}).
wandb: WARNING (User provided step: 6400 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951333.8649294}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'value_loss': 0.27873491325376865, '_timestamp': 1721951423.559621}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'policy_loss': 0.01123029382006886, '_timestamp': 1721951423.5597827}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8165130265553793, '_timestamp': 1721951423.5598474}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14117641746997833, '_timestamp': 1721951423.559936}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.15775340795516968, '_timestamp': 1721951423.560187}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'ratio': 1.0004212856292725, '_timestamp': 1721951423.5602875}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951423.560416}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951423.5606542}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.69393348693848, '_timestamp': 1721951423.5607111}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951423.5613472}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951423.5618699}).
wandb: WARNING (User provided step: 5781 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951423.5624201}).
Env Football Algo jrpo Exp base_JRPO updates 5781/100000000000.0 steps in 89.69
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4281/100000000000.0 steps in 56.81
total episode rewards is -50.0
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'value_loss': 0.6226045169557134, '_timestamp': 1721951480.3688836}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001779438896725575, '_timestamp': 1721951480.3690722}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8197908496856687, '_timestamp': 1721951480.3691406}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15771211683750153, '_timestamp': 1721951480.369244}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.822079062461853, '_timestamp': 1721951480.369471}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'ratio': 1.0006133317947388, '_timestamp': 1721951480.3695722}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721951480.3697104}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951480.369811}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.8055419921875, '_timestamp': 1721951480.369871}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.4075561233801789, '_timestamp': 1721951480.37075}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'train_goal': 0.7037780616900894, '_timestamp': 1721951480.3711114}).
wandb: WARNING (User provided step: 4281 is less than current step: 12030. Dropping entry: {'train_WDL': 0.4075561233801789, '_timestamp': 1721951480.3714716}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'value_loss': 0.7270783653793236, '_timestamp': 1721951517.241115}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0008230456960033432, '_timestamp': 1721951517.2412677}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8182978343963625, '_timestamp': 1721951517.2413328}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1691802740097046, '_timestamp': 1721951517.2414212}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.0018551349639893, '_timestamp': 1721951517.2416673}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'ratio': 1.0008444786071777, '_timestamp': 1721951517.2417645}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721951517.2420297}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951517.24212}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'Episode_Time': 36.86881065368652, '_timestamp': 1721951517.2421782}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951517.2424374}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951517.2426167}).
wandb: WARNING (User provided step: 3829 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951517.242795}).
Env Football Algo jrpo Exp base_JRPO updates 3829/100000000000.0 steps in 36.87
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5620/100000000000.0 steps in 60.05
total episode rewards is -100.0
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'value_loss': 0.6874551767110825, '_timestamp': 1721951577.2890732}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013572699180804193, '_timestamp': 1721951577.2892249}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8212041441599527, '_timestamp': 1721951577.289292}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16236090660095215, '_timestamp': 1721951577.2893827}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.868282675743103, '_timestamp': 1721951577.2896209}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'ratio': 1.000520944595337, '_timestamp': 1721951577.2897224}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721951577.289844}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951577.2900875}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.04545831680298, '_timestamp': 1721951577.2901464}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951577.2905076}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951577.2907922}).
wandb: WARNING (User provided step: 5620 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951577.291078}).
Env Football Algo jrpo Exp base_JRPO updates 7756/100000000000.0 steps in 83.03
total episode rewards is -40.0
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'value_loss': 0.25816613496281204, '_timestamp': 1721951660.3209662}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002454226165233801, '_timestamp': 1721951660.3211281}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.823211801846822, '_timestamp': 1721951660.3211944}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15080532431602478, '_timestamp': 1721951660.3212883}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20319893956184387, '_timestamp': 1721951660.321523}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'ratio': 1.0002256631851196, '_timestamp': 1721951660.321625}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951660.3218968}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951660.3219895}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.02866649627686, '_timestamp': 1721951660.3220482}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951660.3225996}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951660.3230505}).
wandb: WARNING (User provided step: 7756 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951660.3235097}).
Env Football Algo jrpo Exp base_JRPO updates 8251/100000000000.0 steps in 85.48
total episode rewards is -30.0
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'value_loss': 0.17331145831228545, '_timestamp': 1721951745.8088913}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011725152637033413, '_timestamp': 1721951745.8090773}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.821902085940043, '_timestamp': 1721951745.8091447}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15724171698093414, '_timestamp': 1721951745.809247}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13345392048358917, '_timestamp': 1721951745.809522}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'ratio': 1.0002976655960083, '_timestamp': 1721951745.8096259}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721951745.809766}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951745.8098614}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.4844982624054, '_timestamp': 1721951745.8103456}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951745.8109348}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951745.8113668}).
wandb: WARNING (User provided step: 8251 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951745.8118064}).
Env Football Algo jrpo Exp base_JRPO updates 5120/100000000000.0 steps in 77.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'value_loss': 0.33606130052513133, '_timestamp': 1721951823.331865}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021990730275865643, '_timestamp': 1721951823.3320398}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.822161506017049, '_timestamp': 1721951823.3321059}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15674909949302673, '_timestamp': 1721951823.3321977}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3109535276889801, '_timestamp': 1721951823.3324466}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'ratio': 1.0016487836837769, '_timestamp': 1721951823.3325455}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721951823.3329556}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951823.3330512}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.51913332939148, '_timestamp': 1721951823.333111}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.34430379746835443, '_timestamp': 1721951823.3337119}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'train_goal': 0.3278481012658228, '_timestamp': 1721951823.3341782}).
wandb: WARNING (User provided step: 5120 is less than current step: 12030. Dropping entry: {'train_WDL': -0.34430379746835443, '_timestamp': 1721951823.3346586}).
Env Football Algo jrpo Exp base_JRPO updates 4433/100000000000.0 steps in 50.55
total episode rewards is -90.0
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'value_loss': 0.5131391879046957, '_timestamp': 1721951873.8865867}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0024216066684069424, '_timestamp': 1721951873.8867345}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.823427251180013, '_timestamp': 1721951873.8868}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16636922955513, '_timestamp': 1721951873.8868873}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7000746130943298, '_timestamp': 1721951873.8871155}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'ratio': 1.0016491413116455, '_timestamp': 1721951873.8872135}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721951873.887341}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951873.8874264}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.55123972892761, '_timestamp': 1721951873.887581}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951873.8879743}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951873.8882835}).
wandb: WARNING (User provided step: 4433 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951873.8885946}).
Env Football Algo jrpo Exp base_JRPO updates 1532/100000000000.0 steps in 29.92
total episode rewards is -70.0
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'value_loss': 0.7203752841800452, '_timestamp': 1721951903.8055205}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0029557421154459006, '_timestamp': 1721951903.8056865}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8229658158620197, '_timestamp': 1721951903.805751}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17009104788303375, '_timestamp': 1721951903.8058467}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8140272498130798, '_timestamp': 1721951903.8060863}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'ratio': 1.0009047985076904, '_timestamp': 1721951903.8061886}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951903.8063214}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951903.806605}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'Episode_Time': 29.9159517288208, '_timestamp': 1721951903.8066645}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.9281646955759965, '_timestamp': 1721951903.8070884}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'train_goal': 0.9640823477879983, '_timestamp': 1721951903.8072882}).
wandb: WARNING (User provided step: 1532 is less than current step: 12030. Dropping entry: {'train_WDL': 0.9281646955759965, '_timestamp': 1721951903.8074844}).
Env Football Algo jrpo Exp base_JRPO updates 3601/100000000000.0 steps in 53.62
total episode rewards is -70.0
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'value_loss': 0.8131472727842629, '_timestamp': 1721951957.4328952}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002546491752533863, '_timestamp': 1721951957.433044}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8235808356602985, '_timestamp': 1721951957.4331083}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16399255394935608, '_timestamp': 1721951957.4331963}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8049479722976685, '_timestamp': 1721951957.433445}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'ratio': 1.0000104904174805, '_timestamp': 1721951957.433548}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951957.4336655}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951957.4338498}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'Episode_Time': 53.62458920478821, '_timestamp': 1721951957.4339097}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951957.4342797}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951957.434574}).
wandb: WARNING (User provided step: 3601 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951957.434874}).
Env Football Algo jrpo Exp base_JRPO updates 6582/100000000000.0 steps in 84.36
total episode rewards is -40.0
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'value_loss': 0.2588982761348598, '_timestamp': 1721952041.8003}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'policy_loss': 0.010680739335172499, '_timestamp': 1721952041.8006043}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8258052094777426, '_timestamp': 1721952041.8006732}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13800406455993652, '_timestamp': 1721952041.8007782}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.23523323237895966, '_timestamp': 1721952041.8010545}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'ratio': 1.0006004571914673, '_timestamp': 1721952041.8011584}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952041.8017378}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952041.8020728}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.36447620391846, '_timestamp': 1721952041.8021348}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952041.8032875}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952041.8038254}).
wandb: WARNING (User provided step: 6582 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952041.8047469}).
Env Football Algo jrpo Exp base_JRPO updates 7822/100000000000.0 steps in 88.81
total episode rewards is -20.0
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'value_loss': 0.24959064402617515, '_timestamp': 1721952130.621941}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0005677072812492648, '_timestamp': 1721952130.6225722}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8305450359980266, '_timestamp': 1721952130.622644}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14657817780971527, '_timestamp': 1721952130.622926}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1512628048658371, '_timestamp': 1721952130.6232312}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'ratio': 0.9989637732505798, '_timestamp': 1721952130.6233358}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721952130.6241467}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952130.6242955}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.81396770477295, '_timestamp': 1721952130.624356}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.17163555307885206, '_timestamp': 1721952130.6251004}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'train_goal': 0.414182223460574, '_timestamp': 1721952130.625559}).
wandb: WARNING (User provided step: 7822 is less than current step: 12030. Dropping entry: {'train_WDL': -0.17163555307885206, '_timestamp': 1721952130.6260002}).
Env Football Algo jrpo Exp base_JRPO updates 6560/100000000000.0 steps in 93.82
total episode rewards is -40.0
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'value_loss': 0.29310946267990706, '_timestamp': 1721952224.4467456}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007860325898509473, '_timestamp': 1721952224.4469385}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8302739461263022, '_timestamp': 1721952224.4470074}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15120437741279602, '_timestamp': 1721952224.4471245}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.34679216146469116, '_timestamp': 1721952224.4474247}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'ratio': 1.0006909370422363, '_timestamp': 1721952224.4475358}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952224.4476824}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952224.448379}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'Episode_Time': 93.8197660446167, '_timestamp': 1721952224.4484437}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952224.4491124}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952224.4496133}).
wandb: WARNING (User provided step: 6560 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952224.4501505}).
Env Football Algo jrpo Exp base_JRPO updates 3745/100000000000.0 steps in 44.88
total episode rewards is -90.0
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'value_loss': 0.7590846727105478, '_timestamp': 1721952269.334281}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0015335760754533112, '_timestamp': 1721952269.33445}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.829344835281372, '_timestamp': 1721952269.3345168}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14880576729774475, '_timestamp': 1721952269.3346138}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.0267714262008667, '_timestamp': 1721952269.3348544}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'ratio': 1.0008313655853271, '_timestamp': 1721952269.3349543}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721952269.3351986}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952269.3353007}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.883193492889404, '_timestamp': 1721952269.3353581}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.6192700729927008, '_timestamp': 1721952269.3358922}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_goal': 0.8096350364963504, '_timestamp': 1721952269.336214}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_WDL': 0.6192700729927008, '_timestamp': 1721952269.3364697}).
Env Football Algo jrpo Exp base_JRPO updates 2487/100000000000.0 steps in 43.09
total episode rewards is -60.0
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'value_loss': 0.8579224382340908, '_timestamp': 1721952312.4271066}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002161422769422643, '_timestamp': 1721952312.4273136}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8303879165649413, '_timestamp': 1721952312.427383}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15220531821250916, '_timestamp': 1721952312.427478}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9235833883285522, '_timestamp': 1721952312.4277272}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'ratio': 0.9998815059661865, '_timestamp': 1721952312.427829}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721952312.4281046}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952312.4284863}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'Episode_Time': 43.08983111381531, '_timestamp': 1721952312.428546}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3114754098360656, '_timestamp': 1721952312.4296517}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'train_goal': 0.3442622950819672, '_timestamp': 1721952312.4300587}).
wandb: WARNING (User provided step: 2487 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3114754098360656, '_timestamp': 1721952312.4304585}).
Env Football Algo jrpo Exp base_JRPO updates 6916/100000000000.0 steps in 59.58
total episode rewards is -110.0
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'value_loss': 0.9823368551333745, '_timestamp': 1721952372.0156121}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004132480175467208, '_timestamp': 1721952372.0158}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.831132542292277, '_timestamp': 1721952372.0158715}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16224244236946106, '_timestamp': 1721952372.015987}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.11082923412323, '_timestamp': 1721952372.0162396}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'ratio': 1.0003036260604858, '_timestamp': 1721952372.0164592}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721952372.0165977}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952372.016691}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.58406949043274, '_timestamp': 1721952372.0167484}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952372.0171058}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952372.01728}).
wandb: WARNING (User provided step: 6916 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952372.0174809}).
Env Football Algo jrpo Exp base_JRPO updates 3388/100000000000.0 steps in 44.61
total episode rewards is -90.0
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'value_loss': 0.6343302086740732, '_timestamp': 1721952416.6273968}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0033268606026346484, '_timestamp': 1721952416.6276324}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.827888412475586, '_timestamp': 1721952416.6277022}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17072857916355133, '_timestamp': 1721952416.627806}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7608473896980286, '_timestamp': 1721952416.6281207}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'ratio': 1.0022376775741577, '_timestamp': 1721952416.628356}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721952416.6286318}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952416.6289246}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.60867881774902, '_timestamp': 1721952416.6292124}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1886143259305599, '_timestamp': 1721952416.629844}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'train_goal': 0.40569283703472003, '_timestamp': 1721952416.6301355}).
wandb: WARNING (User provided step: 3388 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1886143259305599, '_timestamp': 1721952416.6304023}).
Env Football Algo jrpo Exp base_JRPO updates 8687/100000000000.0 steps in 92.24
total episode rewards is -10.0
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'value_loss': 0.2056428662315011, '_timestamp': 1721952508.8717449}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021532563461611667, '_timestamp': 1721952508.8719604}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8306873655319214, '_timestamp': 1721952508.8720317}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14942513406276703, '_timestamp': 1721952508.8721359}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13970282673835754, '_timestamp': 1721952508.8728309}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'ratio': 1.0016624927520752, '_timestamp': 1721952508.872946}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721952508.8731732}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952508.873271}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'Episode_Time': 92.23998785018921, '_timestamp': 1721952508.8733268}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.05876762236654522, '_timestamp': 1721952508.874004}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'train_goal': 0.4706161888167274, '_timestamp': 1721952508.8746536}).
wandb: WARNING (User provided step: 8687 is less than current step: 12030. Dropping entry: {'train_WDL': -0.05876762236654522, '_timestamp': 1721952508.875088}).
Env Football Algo jrpo Exp base_JRPO updates 3497/100000000000.0 steps in 44.05
total episode rewards is -60.0
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'value_loss': 0.5754593044395248, '_timestamp': 1721952552.9259624}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002051720010737578, '_timestamp': 1721952552.9261508}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8294234466552735, '_timestamp': 1721952552.9262207}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15980024635791779, '_timestamp': 1721952552.926323}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7040296196937561, '_timestamp': 1721952552.9265845}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'ratio': 0.9996463060379028, '_timestamp': 1721952552.926688}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721952552.9268281}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952552.9271972}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.04972052574158, '_timestamp': 1721952552.9272575}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.25448430493273544, '_timestamp': 1721952552.9276743}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'train_goal': 0.3727578475336323, '_timestamp': 1721952552.9279768}).
wandb: WARNING (User provided step: 3497 is less than current step: 12030. Dropping entry: {'train_WDL': -0.25448430493273544, '_timestamp': 1721952552.9282556}).
Env Football Algo jrpo Exp base_JRPO updates 7113/100000000000.0 steps in 93.93
total episode rewards is -30.0
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'value_loss': 0.2351405959475475, '_timestamp': 1721952646.8592324}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006214224110978345, '_timestamp': 1721952646.8594584}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8272287384668986, '_timestamp': 1721952646.8595247}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15147532522678375, '_timestamp': 1721952646.859618}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19621488451957703, '_timestamp': 1721952646.859801}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'ratio': 0.9985870718955994, '_timestamp': 1721952646.8600354}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721952646.8602417}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952646.860339}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'Episode_Time': 93.92991781234741, '_timestamp': 1721952646.8603997}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952646.861082}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952646.861546}).
wandb: WARNING (User provided step: 7113 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952646.8620334}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'value_loss': 0.6267191953832905, '_timestamp': 1721952706.7285533}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0014880759891336007, '_timestamp': 1721952706.7295506}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8241828870773316, '_timestamp': 1721952706.729624}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16067065298557281, '_timestamp': 1721952706.7300987}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5239852070808411, '_timestamp': 1721952706.7304559}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'ratio': 0.9987703561782837, '_timestamp': 1721952706.7305582}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721952706.7309082}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952706.731123}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.86164927482605, '_timestamp': 1721952706.731182}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3352263237013529, '_timestamp': 1721952706.732172}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'train_goal': 0.3323868381493235, '_timestamp': 1721952706.7325583}).
wandb: WARNING (User provided step: 4018 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3352263237013529, '_timestamp': 1721952706.7329469}).
Env Football Algo jrpo Exp base_JRPO updates 4018/100000000000.0 steps in 59.86
total episode rewards is -80.0
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'value_loss': 0.18506847753577554, '_timestamp': 1721952790.802722}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007531679960278173, '_timestamp': 1721952790.802876}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.823559004465739, '_timestamp': 1721952790.8029408}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14908728003501892, '_timestamp': 1721952790.8030322}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2046344131231308, '_timestamp': 1721952790.8032668}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'ratio': 0.9975156784057617, '_timestamp': 1721952790.8033667}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721952790.8036144}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952790.803706}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.06884360313416, '_timestamp': 1721952790.8037634}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952790.8042698}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952790.8046517}).
wandb: WARNING (User provided step: 8894 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952790.805042}).
Env Football Algo jrpo Exp base_JRPO updates 8894/100000000000.0 steps in 84.07
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 6236/100000000000.0 steps in 60.49
total episode rewards is -50.0
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'value_loss': 0.3065900790349891, '_timestamp': 1721952851.2982109}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0038916054417495616, '_timestamp': 1721952851.2983906}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.819806447029114, '_timestamp': 1721952851.2984576}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1708293855190277, '_timestamp': 1721952851.2985606}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.33849266171455383, '_timestamp': 1721952851.298826}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'ratio': 0.9995429515838623, '_timestamp': 1721952851.2989297}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721952851.2990525}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952851.2995129}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.49227285385132, '_timestamp': 1721952851.2995732}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952851.300009}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952851.3003407}).
wandb: WARNING (User provided step: 6236 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952851.3006723}).
Env Football Algo jrpo Exp base_JRPO updates 6160/100000000000.0 steps in 84.84
total episode rewards is -20.0
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'value_loss': 0.31065009569011937, '_timestamp': 1721952936.1399734}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001088621529440085, '_timestamp': 1721952936.1401238}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8186580689748126, '_timestamp': 1721952936.140188}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15411826968193054, '_timestamp': 1721952936.1402767}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5022637844085693, '_timestamp': 1721952936.1405122}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'ratio': 0.9967458248138428, '_timestamp': 1721952936.1406116}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721952936.1409662}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952936.1410594}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.83846306800842, '_timestamp': 1721952936.1411178}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4142533936651584, '_timestamp': 1721952936.1417372}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'train_goal': 0.29287330316742083, '_timestamp': 1721952936.142247}).
wandb: WARNING (User provided step: 6160 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4142533936651584, '_timestamp': 1721952936.1427739}).
Env Football Algo jrpo Exp base_JRPO updates 6380/100000000000.0 steps in 92.70
total episode rewards is -20.0
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'value_loss': 0.26474784446841415, '_timestamp': 1721953028.8481894}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016619733298042169, '_timestamp': 1721953028.848371}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.826251204808553, '_timestamp': 1721953028.8484404}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1425677090883255, '_timestamp': 1721953028.8485398}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12821689248085022, '_timestamp': 1721953028.8488083}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'ratio': 0.999840497970581, '_timestamp': 1721953028.8489115}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721953028.8490467}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953028.8495557}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'Episode_Time': 92.70447611808777, '_timestamp': 1721953028.849614}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3122969837587007, '_timestamp': 1721953028.850657}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'train_goal': 0.34385150812064963, '_timestamp': 1721953028.851181}).
wandb: WARNING (User provided step: 6380 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3122969837587007, '_timestamp': 1721953028.8517356}).
Env Football Algo jrpo Exp base_JRPO updates 6834/100000000000.0 steps in 90.94
total episode rewards is -40.0
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'value_loss': 0.24980388170457446, '_timestamp': 1721953119.7974412}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0027262242953293024, '_timestamp': 1721953119.7976103}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8269446738560995, '_timestamp': 1721953119.797676}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15939095616340637, '_timestamp': 1721953119.797769}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.23188093304634094, '_timestamp': 1721953119.7980726}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'ratio': 1.001749873161316, '_timestamp': 1721953119.7981734}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953119.798319}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953119.7984085}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.94449281692505, '_timestamp': 1721953119.7984672}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953119.7990565}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953119.7995539}).
wandb: WARNING (User provided step: 6834 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953119.800102}).
Env Football Algo jrpo Exp base_JRPO updates 4296/100000000000.0 steps in 52.17
total episode rewards is -50.0
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'value_loss': 0.4686329423993205, '_timestamp': 1721953171.9696918}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003197078189308134, '_timestamp': 1721953171.969847}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.826013118426005, '_timestamp': 1721953171.9699118}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15592682361602783, '_timestamp': 1721953171.970004}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7445385456085205, '_timestamp': 1721953171.970232}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'ratio': 1.0018223524093628, '_timestamp': 1721953171.970332}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721953171.9704528}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953171.970635}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.16846680641174, '_timestamp': 1721953171.9706929}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953171.9710736}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953171.971379}).
wandb: WARNING (User provided step: 4296 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953171.9716957}).
Env Football Algo jrpo Exp base_JRPO updates 7758/100000000000.0 steps in 74.35
total episode rewards is -80.0
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'value_loss': 0.47709931870301564, '_timestamp': 1721953246.3201818}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'policy_loss': 3.0503724701702595e-06, '_timestamp': 1721953246.320333}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.819577178955078, '_timestamp': 1721953246.3204129}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16170306503772736, '_timestamp': 1721953246.3205}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5232694149017334, '_timestamp': 1721953246.3207345}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'ratio': 0.9999486804008484, '_timestamp': 1721953246.3208346}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721953246.3209653}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953246.3211436}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'Episode_Time': 74.34764003753662, '_timestamp': 1721953246.3212016}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953246.3216016}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953246.3218985}).
wandb: WARNING (User provided step: 7758 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953246.3222048}).
Env Football Algo jrpo Exp base_JRPO updates 3831/100000000000.0 steps in 49.58
total episode rewards is -70.0
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'value_loss': 0.6708698228125771, '_timestamp': 1721953295.9018297}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013491473715597142, '_timestamp': 1721953295.9019897}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8238029702504477, '_timestamp': 1721953295.902055}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17313487827777863, '_timestamp': 1721953295.902146}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6781778931617737, '_timestamp': 1721953295.9024014}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'ratio': 1.000794768333435, '_timestamp': 1721953295.9025042}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721953295.9028952}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953295.902988}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'Episode_Time': 49.57876920700073, '_timestamp': 1721953295.9030454}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.337312204157234, '_timestamp': 1721953295.9034715}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'train_goal': 0.331343897921383, '_timestamp': 1721953295.903798}).
wandb: WARNING (User provided step: 3831 is less than current step: 12030. Dropping entry: {'train_WDL': -0.337312204157234, '_timestamp': 1721953295.9041462}).
Env Football Algo jrpo Exp base_JRPO updates 7858/100000000000.0 steps in 88.62
total episode rewards is -40.0
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'value_loss': 0.2590289046227311, '_timestamp': 1721953384.5249095}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0007590082679719975, '_timestamp': 1721953384.5250576}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8234509150187175, '_timestamp': 1721953384.5251286}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15609045326709747, '_timestamp': 1721953384.525217}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18293717503547668, '_timestamp': 1721953384.5254455}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'ratio': 1.000374436378479, '_timestamp': 1721953384.5255451}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953384.5256772}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953384.5257962}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.61996388435364, '_timestamp': 1721953384.52593}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953384.5264595}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953384.5268888}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953384.5273414}).
Env Football Algo jrpo Exp base_JRPO updates 4088/100000000000.0 steps in 56.45
total episode rewards is -80.0
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'value_loss': 0.555463107029597, '_timestamp': 1721953440.9736705}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016456799084941546, '_timestamp': 1721953440.9738257}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8192183923721315, '_timestamp': 1721953440.9738908}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.168880894780159, '_timestamp': 1721953440.9739783}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6465611457824707, '_timestamp': 1721953440.9742086}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'ratio': 0.9998123645782471, '_timestamp': 1721953440.974387}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721953440.974581}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953440.9746695}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.44534087181091, '_timestamp': 1721953440.9747264}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953440.9752018}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953440.975588}).
wandb: WARNING (User provided step: 4088 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953440.975995}).
Env Football Algo jrpo Exp base_JRPO updates 4050/100000000000.0 steps in 44.75
total episode rewards is -90.0
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'value_loss': 0.6495398807153105, '_timestamp': 1721953485.7236493}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0023200732252250116, '_timestamp': 1721953485.7238073}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8161262973149617, '_timestamp': 1721953485.7238717}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16768397390842438, '_timestamp': 1721953485.7239769}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7695096731185913, '_timestamp': 1721953485.7242122}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'ratio': 1.0006601810455322, '_timestamp': 1721953485.7243223}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721953485.7244542}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953485.7245457}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.746280670166016, '_timestamp': 1721953485.7246017}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.04722792607802875, '_timestamp': 1721953485.724929}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'train_goal': 0.5236139630390144, '_timestamp': 1721953485.7251377}).
wandb: WARNING (User provided step: 4050 is less than current step: 12030. Dropping entry: {'train_WDL': 0.04722792607802875, '_timestamp': 1721953485.7253408}).
Env Football Algo jrpo Exp base_JRPO updates 3436/100000000000.0 steps in 72.74
total episode rewards is 10.0
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'value_loss': 0.556465131683896, '_timestamp': 1721953558.4625607}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0035067798463084424, '_timestamp': 1721953558.4627051}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.81509104569753, '_timestamp': 1721953558.4627705}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.153701514005661, '_timestamp': 1721953558.462858}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5824148654937744, '_timestamp': 1721953558.46308}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'ratio': 1.000223994255066, '_timestamp': 1721953558.463177}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721953558.463296}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953558.4633856}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.73656606674194, '_timestamp': 1721953558.4635549}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.623151399085009, '_timestamp': 1721953558.4643083}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'train_goal': 0.8115756995425045, '_timestamp': 1721953558.464841}).
wandb: WARNING (User provided step: 3436 is less than current step: 12030. Dropping entry: {'train_WDL': 0.623151399085009, '_timestamp': 1721953558.4653716}).
Env Football Algo jrpo Exp base_JRPO updates 5403/100000000000.0 steps in 72.60
total episode rewards is -50.0
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'value_loss': 0.4364638981471459, '_timestamp': 1721953631.061811}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021943966541827344, '_timestamp': 1721953631.0619905}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8172231499354043, '_timestamp': 1721953631.062058}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.159193754196167, '_timestamp': 1721953631.0621572}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5048418045043945, '_timestamp': 1721953631.0624235}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'ratio': 1.0007110834121704, '_timestamp': 1721953631.062529}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721953631.062668}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953631.0631828}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.59557056427002, '_timestamp': 1721953631.0632436}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2711517252245155, '_timestamp': 1721953631.063842}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'train_goal': 0.36442413738774226, '_timestamp': 1721953631.064288}).
wandb: WARNING (User provided step: 5403 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2711517252245155, '_timestamp': 1721953631.0647035}).
Env Football Algo jrpo Exp base_JRPO updates 7330/100000000000.0 steps in 74.91
total episode rewards is -70.0
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'value_loss': 0.39862991832196715, '_timestamp': 1721953705.9760673}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001330086118541658, '_timestamp': 1721953705.9763167}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8172920020421346, '_timestamp': 1721953705.976648}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15615218877792358, '_timestamp': 1721953705.977463}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5528175830841064, '_timestamp': 1721953705.9778929}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'ratio': 1.001217007637024, '_timestamp': 1721953705.9785395}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721953705.9789886}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953705.9792264}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'Episode_Time': 74.91043663024902, '_timestamp': 1721953705.9792929}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953705.9803946}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953705.9808226}).
wandb: WARNING (User provided step: 7330 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953705.9812374}).
Env Football Algo jrpo Exp base_JRPO updates 4663/100000000000.0 steps in 62.81
total episode rewards is -50.0
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'value_loss': 0.4444613894075155, '_timestamp': 1721953768.7947166}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'policy_loss': 0.000863755236302192, '_timestamp': 1721953768.7948694}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.821018911997477, '_timestamp': 1721953768.794935}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15900681912899017, '_timestamp': 1721953768.79503}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4749152362346649, '_timestamp': 1721953768.7952738}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'ratio': 1.001434087753296, '_timestamp': 1721953768.7953742}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721953768.7955737}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953768.7958584}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'Episode_Time': 62.81255841255188, '_timestamp': 1721953768.7959166}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.9995936611133686, '_timestamp': 1721953768.796441}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'train_goal': 0.0002031694433157253, '_timestamp': 1721953768.7967634}).
wandb: WARNING (User provided step: 4663 is less than current step: 12030. Dropping entry: {'train_WDL': -0.9995936611133686, '_timestamp': 1721953768.7970967}).
Env Football Algo jrpo Exp base_JRPO updates 4201/100000000000.0 steps in 47.64
total episode rewards is -100.0
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'value_loss': 0.7671182684103648, '_timestamp': 1721953816.440371}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001937877182693531, '_timestamp': 1721953816.4405196}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.823710741996765, '_timestamp': 1721953816.440584}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17123930156230927, '_timestamp': 1721953816.4412444}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.0450721979141235, '_timestamp': 1721953816.4415963}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'ratio': 1.000251054763794, '_timestamp': 1721953816.4416947}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721953816.4418213}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953816.4421015}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'Episode_Time': 47.64248275756836, '_timestamp': 1721953816.4421601}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953816.4430285}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953816.4433157}).
wandb: WARNING (User provided step: 4201 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953816.4435964}).
Env Football Algo jrpo Exp base_JRPO updates 4880/100000000000.0 steps in 51.52
total episode rewards is -80.0
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'value_loss': 0.4944388964523872, '_timestamp': 1721953867.9671516}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022691188200648564, '_timestamp': 1721953867.9673123}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8212114556630454, '_timestamp': 1721953867.9673781}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1708189696073532, '_timestamp': 1721953867.9674702}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5740435123443604, '_timestamp': 1721953867.967704}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'ratio': 0.9995445013046265, '_timestamp': 1721953867.967808}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721953867.9681027}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953867.9681933}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.52262592315674, '_timestamp': 1721953867.9682498}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953867.96868}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953867.9689815}).
wandb: WARNING (User provided step: 4880 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953867.9693005}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'value_loss': 0.23643304107089838, '_timestamp': 1721953956.0394375}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0018352218946771851, '_timestamp': 1721953956.0396311}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.825672885576884, '_timestamp': 1721953956.0397065}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14208078384399414, '_timestamp': 1721953956.039816}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13255494832992554, '_timestamp': 1721953956.0401282}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'ratio': 1.0005995035171509, '_timestamp': 1721953956.040259}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721953956.0406392}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953956.0408971}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.06906509399414, '_timestamp': 1721953956.0409675}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3586688137412775, '_timestamp': 1721953956.041667}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'train_goal': 0.32066559312936127, '_timestamp': 1721953956.0422308}).
wandb: WARNING (User provided step: 5685 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3586688137412775, '_timestamp': 1721953956.0427868}).
Env Football Algo jrpo Exp base_JRPO updates 5685/100000000000.0 steps in 88.07
total episode rewards is -20.0
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'value_loss': 0.3593281617760658, '_timestamp': 1721954020.389424}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009937873755310042, '_timestamp': 1721954020.3896372}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8329956483840943, '_timestamp': 1721954020.389706}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15142402052879333, '_timestamp': 1721954020.3898113}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35493239760398865, '_timestamp': 1721954020.3900914}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'ratio': 0.9990575313568115, '_timestamp': 1721954020.390194}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721954020.3904266}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954020.3911376}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.34556603431702, '_timestamp': 1721954020.3911986}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954020.3921726}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954020.392592}).
wandb: WARNING (User provided step: 4917 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954020.3930054}).
Env Football Algo jrpo Exp base_JRPO updates 4917/100000000000.0 steps in 64.35
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 7940/100000000000.0 steps in 83.21
total episode rewards is -60.0
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'value_loss': 0.3664760763182615, '_timestamp': 1721954103.6133473}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004712643853272311, '_timestamp': 1721954103.6146584}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8384681526819864, '_timestamp': 1721954103.6147363}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15219177305698395, '_timestamp': 1721954103.6153483}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3649049401283264, '_timestamp': 1721954103.6157472}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'ratio': 0.9991056323051453, '_timestamp': 1721954103.615857}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721954103.6160412}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954103.616251}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.21432566642761, '_timestamp': 1721954103.6170363}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954103.6180923}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954103.61861}).
wandb: WARNING (User provided step: 7940 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954103.6190903}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'value_loss': 0.6361429723600547, '_timestamp': 1721954154.0967088}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0034456888392257194, '_timestamp': 1721954154.096881}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8415738360087075, '_timestamp': 1721954154.09695}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16113950312137604, '_timestamp': 1721954154.097051}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6620763540267944, '_timestamp': 1721954154.0973368}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'ratio': 1.0012704133987427, '_timestamp': 1721954154.0974457}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721954154.097593}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954154.0982087}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.47675037384033, '_timestamp': 1721954154.0982761}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954154.0986426}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954154.098871}).
wandb: WARNING (User provided step: 4766 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954154.0991058}).
Env Football Algo jrpo Exp base_JRPO updates 4766/100000000000.0 steps in 50.48
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5732/100000000000.0 steps in 84.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'value_loss': 0.2614569209485004, '_timestamp': 1721954238.6918712}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0044802639307454225, '_timestamp': 1721954238.6920936}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8396098105112713, '_timestamp': 1721954238.6921632}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1533469557762146, '_timestamp': 1721954238.692264}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12898294627666473, '_timestamp': 1721954238.6925337}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'ratio': 1.000197410583496, '_timestamp': 1721954238.6926413}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954238.6928148}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954238.6933773}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.5917158126831, '_timestamp': 1721954238.693437}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954238.6943712}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954238.6949372}).
wandb: WARNING (User provided step: 5732 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954238.6955132}).
Env Football Algo jrpo Exp base_JRPO updates 1899/100000000000.0 steps in 41.91
total episode rewards is -40.0
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'value_loss': 0.6145894207805395, '_timestamp': 1721954280.6098716}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0007220999826677144, '_timestamp': 1721954280.6112385}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.833968900044759, '_timestamp': 1721954280.6113372}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1637345552444458, '_timestamp': 1721954280.611967}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6803646087646484, '_timestamp': 1721954280.6124148}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'ratio': 0.9997085928916931, '_timestamp': 1721954280.6125562}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954280.612715}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954280.613517}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.90815043449402, '_timestamp': 1721954280.6135824}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.7447877417734238, '_timestamp': 1721954280.6146686}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'train_goal': 0.8723938708867118, '_timestamp': 1721954280.6149838}).
wandb: WARNING (User provided step: 1899 is less than current step: 12030. Dropping entry: {'train_WDL': 0.7447877417734238, '_timestamp': 1721954280.6152759}).
Env Football Algo jrpo Exp base_JRPO updates 7309/100000000000.0 steps in 76.07
total episode rewards is -40.0
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'value_loss': 0.35461645332320285, '_timestamp': 1721954356.6897151}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0031726707744140488, '_timestamp': 1721954356.6899014}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.828384003639221, '_timestamp': 1721954356.6899767}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1592579483985901, '_timestamp': 1721954356.6900811}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.30828312039375305, '_timestamp': 1721954356.690355}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'ratio': 1.0024904012680054, '_timestamp': 1721954356.690462}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954356.6906047}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954356.6914654}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.0735251903534, '_timestamp': 1721954356.6915288}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1014957264957265, '_timestamp': 1721954356.692152}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'train_goal': 0.44925213675213677, '_timestamp': 1721954356.6925497}).
wandb: WARNING (User provided step: 7309 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1014957264957265, '_timestamp': 1721954356.692926}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'value_loss': 0.695595614934961, '_timestamp': 1721954392.3634598}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002696617872376616, '_timestamp': 1721954392.3647604}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8298402293523153, '_timestamp': 1721954392.3648336}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.166477769613266, '_timestamp': 1721954392.3654122}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9449098110198975, '_timestamp': 1721954392.3658013}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'ratio': 1.0019652843475342, '_timestamp': 1721954392.3659036}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721954392.3668742}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954392.3670847}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'Episode_Time': 35.66467642784119, '_timestamp': 1721954392.3671424}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.14737378888322283, '_timestamp': 1721954392.3680518}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'train_goal': 0.5736868944416115, '_timestamp': 1721954392.3682752}).
wandb: WARNING (User provided step: 3824 is less than current step: 12030. Dropping entry: {'train_WDL': 0.14737378888322283, '_timestamp': 1721954392.3684733}).
Env Football Algo jrpo Exp base_JRPO updates 3824/100000000000.0 steps in 35.66
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 6286/100000000000.0 steps in 91.82
total episode rewards is -20.0
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'value_loss': 0.28856138133754333, '_timestamp': 1721954484.1863587}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00588692551284718, '_timestamp': 1721954484.1865373}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8342263142267865, '_timestamp': 1721954484.1866157}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1500583440065384, '_timestamp': 1721954484.1867166}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1873409003019333, '_timestamp': 1721954484.1870108}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'ratio': 1.000264286994934, '_timestamp': 1721954484.1871178}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721954484.1872637}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954484.1881351}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.81695604324341, '_timestamp': 1721954484.1881986}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32522377782878126, '_timestamp': 1721954484.1889093}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'train_goal': 0.33738811108560934, '_timestamp': 1721954484.189458}).
wandb: WARNING (User provided step: 6286 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32522377782878126, '_timestamp': 1721954484.1899996}).
Env Football Algo jrpo Exp base_JRPO updates 5522/100000000000.0 steps in 82.93
total episode rewards is -10.0
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'value_loss': 0.4190364365683248, '_timestamp': 1721954567.124206}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0047750230905391315, '_timestamp': 1721954567.1243796}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8358643579483034, '_timestamp': 1721954567.1244469}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1542903482913971, '_timestamp': 1721954567.124541}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5647401809692383, '_timestamp': 1721954567.1250198}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'ratio': 0.9976581335067749, '_timestamp': 1721954567.1253643}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721954567.1255088}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954567.1256049}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.93308639526367, '_timestamp': 1721954567.1256633}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.3841815874806147, '_timestamp': 1721954567.1264791}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'train_goal': 0.6920907937403074, '_timestamp': 1721954567.12711}).
wandb: WARNING (User provided step: 5522 is less than current step: 12030. Dropping entry: {'train_WDL': 0.3841815874806147, '_timestamp': 1721954567.127547}).
Env Football Algo jrpo Exp base_JRPO updates 5559/100000000000.0 steps in 91.87
total episode rewards is -20.0
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'value_loss': 0.2470592965418473, '_timestamp': 1721954658.9937155}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0031736793466067563, '_timestamp': 1721954658.9939532}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8376645771662394, '_timestamp': 1721954658.9940214}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14937080442905426, '_timestamp': 1721954658.9941185}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17810949683189392, '_timestamp': 1721954658.9943862}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'ratio': 0.9997889399528503, '_timestamp': 1721954658.9944944}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721954658.9953084}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954658.9954135}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.86529731750488, '_timestamp': 1721954658.995472}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.36743988984217774, '_timestamp': 1721954658.996365}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'train_goal': 0.31628005507891116, '_timestamp': 1721954658.9969697}).
wandb: WARNING (User provided step: 5559 is less than current step: 12030. Dropping entry: {'train_WDL': -0.36743988984217774, '_timestamp': 1721954658.9975698}).
Env Football Algo jrpo Exp base_JRPO updates 6514/100000000000.0 steps in 73.26
total episode rewards is -30.0
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'value_loss': 0.3087283541529905, '_timestamp': 1721954732.2612765}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0030388107268178523, '_timestamp': 1721954732.2615304}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8404169940948485, '_timestamp': 1721954732.2616005}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13478638231754303, '_timestamp': 1721954732.2617416}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14108377695083618, '_timestamp': 1721954732.2638602}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'ratio': 0.99942547082901, '_timestamp': 1721954732.2640018}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721954732.264491}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954732.264627}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'Episode_Time': 73.26161861419678, '_timestamp': 1721954732.264687}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.19143955860224043, '_timestamp': 1721954732.2653227}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'train_goal': 0.4042802206988798, '_timestamp': 1721954732.2658217}).
wandb: WARNING (User provided step: 6514 is less than current step: 12030. Dropping entry: {'train_WDL': -0.19143955860224043, '_timestamp': 1721954732.2662213}).
Env Football Algo jrpo Exp base_JRPO updates 2751/100000000000.0 steps in 43.27
total episode rewards is -50.0
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'value_loss': 0.6357039287189643, '_timestamp': 1721954775.542647}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002868403140067433, '_timestamp': 1721954775.5428278}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839199401537577, '_timestamp': 1721954775.5428963}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1642342358827591, '_timestamp': 1721954775.5429957}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6767855882644653, '_timestamp': 1721954775.5432682}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'ratio': 0.9987362027168274, '_timestamp': 1721954775.5457544}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721954775.5459943}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954775.546105}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'Episode_Time': 43.27365303039551, '_timestamp': 1721954775.546167}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.4635823694904658, '_timestamp': 1721954775.5467393}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'train_goal': 0.7317911847452329, '_timestamp': 1721954775.5470183}).
wandb: WARNING (User provided step: 2751 is less than current step: 12030. Dropping entry: {'train_WDL': 0.4635823694904658, '_timestamp': 1721954775.5472918}).
Env Football Algo jrpo Exp base_JRPO updates 5900/100000000000.0 steps in 94.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'value_loss': 0.23386619633451725, '_timestamp': 1721954870.5307999}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0043420888759040585, '_timestamp': 1721954870.531021}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8380208857854208, '_timestamp': 1721954870.5311255}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13487833738327026, '_timestamp': 1721954870.5312462}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2565719187259674, '_timestamp': 1721954870.5315452}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'ratio': 1.0011919736862183, '_timestamp': 1721954870.5316634}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954870.531808}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954870.5323122}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'Episode_Time': 94.98254084587097, '_timestamp': 1721954870.5326083}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954870.533345}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954870.5338955}).
wandb: WARNING (User provided step: 5900 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954870.5344632}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'value_loss': 0.2770941424773385, '_timestamp': 1721954959.6183374}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004136944520287216, '_timestamp': 1721954959.6185126}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.829839013417562, '_timestamp': 1721954959.6185806}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15568271279335022, '_timestamp': 1721954959.6186793}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16958311200141907, '_timestamp': 1721954959.6189356}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'ratio': 0.9989403486251831, '_timestamp': 1721954959.6191883}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721954959.619522}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954959.6196165}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.08300590515137, '_timestamp': 1721954959.6196747}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3850658857979502, '_timestamp': 1721954959.6204822}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'train_goal': 0.3074670571010249, '_timestamp': 1721954959.6210604}).
wandb: WARNING (User provided step: 5438 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3850658857979502, '_timestamp': 1721954959.6216276}).
Env Football Algo jrpo Exp base_JRPO updates 5438/100000000000.0 steps in 89.08
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 2498/100000000000.0 steps in 44.44
total episode rewards is -30.0
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'value_loss': 0.7278633740420143, '_timestamp': 1721955004.0589216}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015163596032653005, '_timestamp': 1721955004.0591452}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8374210691452024, '_timestamp': 1721955004.0592458}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1557496041059494, '_timestamp': 1721955004.0593505}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7675549387931824, '_timestamp': 1721955004.059611}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'ratio': 0.998073160648346, '_timestamp': 1721955004.0597136}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721955004.0598524}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955004.0603817}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.43603563308716, '_timestamp': 1721955004.060454}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.46043656207366984, '_timestamp': 1721955004.060854}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'train_goal': 0.730218281036835, '_timestamp': 1721955004.0611126}).
wandb: WARNING (User provided step: 2498 is less than current step: 12030. Dropping entry: {'train_WDL': 0.46043656207366984, '_timestamp': 1721955004.0613554}).
Env Football Algo jrpo Exp base_JRPO updates 6977/100000000000.0 steps in 64.83
total episode rewards is -90.0
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'value_loss': 0.5351474540929, '_timestamp': 1721955068.8913968}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00035454965060732014, '_timestamp': 1721955068.8924165}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839770264625549, '_timestamp': 1721955068.8924882}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15644612908363342, '_timestamp': 1721955068.892931}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7858835458755493, '_timestamp': 1721955068.8932672}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'ratio': 0.9988716840744019, '_timestamp': 1721955068.8933713}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721955068.894051}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955068.8942366}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.82521414756775, '_timestamp': 1721955068.8942962}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955068.8951025}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955068.8953843}).
wandb: WARNING (User provided step: 6977 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955068.8956685}).
Env Football Algo jrpo Exp base_JRPO updates 4638/100000000000.0 steps in 87.76
total episode rewards is -20.0
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'value_loss': 0.29456468685762954, '_timestamp': 1721955156.6580982}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009057905514879772, '_timestamp': 1721955156.6582496}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838444646199544, '_timestamp': 1721955156.6583152}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14857982099056244, '_timestamp': 1721955156.6584055}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3171229064464569, '_timestamp': 1721955156.658584}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'ratio': 0.9986154437065125, '_timestamp': 1721955156.6586835}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721955156.6587942}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955156.658884}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.76118230819702, '_timestamp': 1721955156.6589413}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.42636556649295504, '_timestamp': 1721955156.6596596}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'train_goal': 0.2868172167535225, '_timestamp': 1721955156.6602511}).
wandb: WARNING (User provided step: 4638 is less than current step: 12030. Dropping entry: {'train_WDL': -0.42636556649295504, '_timestamp': 1721955156.660858}).
Env Football Algo jrpo Exp base_JRPO updates 3136/100000000000.0 steps in 51.41
total episode rewards is -70.0
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'value_loss': 0.6531539322560033, '_timestamp': 1721955208.0684218}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'policy_loss': 0.000988828480282488, '_timestamp': 1721955208.068579}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.834279704093933, '_timestamp': 1721955208.0686424}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17234818637371063, '_timestamp': 1721955208.0687332}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8116213083267212, '_timestamp': 1721955208.0689528}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'ratio': 1.0008177757263184, '_timestamp': 1721955208.0690494}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721955208.069273}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955208.0693634}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.40644550323486, '_timestamp': 1721955208.0694199}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3688094775684599, '_timestamp': 1721955208.0698607}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'train_goal': 0.31559526121577003, '_timestamp': 1721955208.0702069}).
wandb: WARNING (User provided step: 3136 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3688094775684599, '_timestamp': 1721955208.0705478}).
Env Football Algo jrpo Exp base_JRPO updates 6806/100000000000.0 steps in 66.96
total episode rewards is -90.0
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'value_loss': 0.5373687063902617, '_timestamp': 1721955275.0281441}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015245740623989453, '_timestamp': 1721955275.0282996}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83657305876414, '_timestamp': 1721955275.028364}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.17106974124908447, '_timestamp': 1721955275.0284526}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5368136167526245, '_timestamp': 1721955275.0286844}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'ratio': 1.000424861907959, '_timestamp': 1721955275.028785}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721955275.0289197}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955275.0292065}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'Episode_Time': 66.95691084861755, '_timestamp': 1721955275.029273}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955275.0296743}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955275.0299847}).
wandb: WARNING (User provided step: 6806 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955275.0303063}).
Env Football Algo jrpo Exp base_JRPO updates 6813/100000000000.0 steps in 65.43
total episode rewards is -70.0
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'value_loss': 0.47645786953469116, '_timestamp': 1721955340.4587574}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0007825186625511075, '_timestamp': 1721955340.4589152}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838491048812866, '_timestamp': 1721955340.4589822}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16137033700942993, '_timestamp': 1721955340.4590764}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.636887788772583, '_timestamp': 1721955340.459309}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'ratio': 1.0012853145599365, '_timestamp': 1721955340.459408}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721955340.4596558}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955340.4597487}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.42728114128113, '_timestamp': 1721955340.4598074}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.002677376171352075, '_timestamp': 1721955340.4602876}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'train_goal': 0.501338688085676, '_timestamp': 1721955340.4605913}).
wandb: WARNING (User provided step: 6813 is less than current step: 12030. Dropping entry: {'train_WDL': 0.002677376171352075, '_timestamp': 1721955340.4608972}).
Env Football Algo jrpo Exp base_JRPO updates 6784/100000000000.0 steps in 85.49
total episode rewards is -20.0
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'value_loss': 0.30224402553479496, '_timestamp': 1721955425.946992}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0020015306381780344, '_timestamp': 1721955425.9471443}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8429340934753418, '_timestamp': 1721955425.947208}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1605769693851471, '_timestamp': 1721955425.9472952}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.24608463048934937, '_timestamp': 1721955425.9475317}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'ratio': 0.9986414909362793, '_timestamp': 1721955425.947632}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721955425.9478636}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955425.9479601}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.48526453971863, '_timestamp': 1721955425.948018}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2811587147030185, '_timestamp': 1721955425.9486027}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'train_goal': 0.3594206426484908, '_timestamp': 1721955425.949076}).
wandb: WARNING (User provided step: 6784 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2811587147030185, '_timestamp': 1721955425.9495661}).
Env Football Algo jrpo Exp base_JRPO updates 6730/100000000000.0 steps in 78.62
total episode rewards is -20.0
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'value_loss': 0.2585832207308461, '_timestamp': 1721955504.566795}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004173915518331342, '_timestamp': 1721955504.566947}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8445644903182985, '_timestamp': 1721955504.5670145}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1443597823381424, '_timestamp': 1721955504.5671055}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12794092297554016, '_timestamp': 1721955504.5673397}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'ratio': 0.9997948408126831, '_timestamp': 1721955504.567441}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721955504.5677075}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955504.5678027}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.6160306930542, '_timestamp': 1721955504.567861}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.27835550181378477, '_timestamp': 1721955504.5684917}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'train_goal': 0.3608222490931076, '_timestamp': 1721955504.5689723}).
wandb: WARNING (User provided step: 6730 is less than current step: 12030. Dropping entry: {'train_WDL': -0.27835550181378477, '_timestamp': 1721955504.569468}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'value_loss': 0.3842431894317269, '_timestamp': 1721955581.3693697}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002083840354947218, '_timestamp': 1721955581.369552}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8414792982737223, '_timestamp': 1721955581.3696194}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1478777676820755, '_timestamp': 1721955581.3697212}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4509180784225464, '_timestamp': 1721955581.369994}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'ratio': 0.9988328218460083, '_timestamp': 1721955581.370097}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955581.3702369}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955581.37033}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.79848432540894, '_timestamp': 1721955581.3703883}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1432634198364735, '_timestamp': 1721955581.3710213}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'train_goal': 0.42836829008176325, '_timestamp': 1721955581.3713868}).
wandb: WARNING (User provided step: 6669 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1432634198364735, '_timestamp': 1721955581.371759}).
Env Football Algo jrpo Exp base_JRPO updates 6669/100000000000.0 steps in 76.80
total episode rewards is -40.0
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'value_loss': 0.25566556516181055, '_timestamp': 1721955661.5023699}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003592331877734978, '_timestamp': 1721955661.5025294}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.84497420946757, '_timestamp': 1721955661.5025935}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14258676767349243, '_timestamp': 1721955661.5026848}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.24577327072620392, '_timestamp': 1721955661.5029182}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'ratio': 0.998952329158783, '_timestamp': 1721955661.5030203}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721955661.5031524}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955661.503387}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.12941098213196, '_timestamp': 1721955661.5034485}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.3720420177767517, '_timestamp': 1721955661.5042005}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'train_goal': 0.6860210088883758, '_timestamp': 1721955661.504709}).
wandb: WARNING (User provided step: 6337 is less than current step: 12030. Dropping entry: {'train_WDL': 0.3720420177767517, '_timestamp': 1721955661.5052178}).
Env Football Algo jrpo Exp base_JRPO updates 6337/100000000000.0 steps in 80.13
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 1792/100000000000.0 steps in 28.77
total episode rewards is -100.0
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'value_loss': 0.583006878302743, '_timestamp': 1721955690.2779353}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013635985654157896, '_timestamp': 1721955690.2780945}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8398460563023886, '_timestamp': 1721955690.278161}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15682227909564972, '_timestamp': 1721955690.278254}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.740832507610321, '_timestamp': 1721955690.2784872}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'ratio': 0.9991273283958435, '_timestamp': 1721955690.2785943}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721955690.278751}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955690.2788439}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'Episode_Time': 28.771703720092773, '_timestamp': 1721955690.2791963}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955690.2794044}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955690.279525}).
wandb: WARNING (User provided step: 1792 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955690.2796435}).
Env Football Algo jrpo Exp base_JRPO updates 6689/100000000000.0 steps in 80.40
total episode rewards is -40.0
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'value_loss': 0.24258686555355477, '_timestamp': 1721955770.6825993}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0065045348062024765, '_timestamp': 1721955770.6827579}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8411543560028076, '_timestamp': 1721955770.6828222}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12661491334438324, '_timestamp': 1721955770.682912}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18022774159908295, '_timestamp': 1721955770.6831431}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'ratio': 1.0000369548797607, '_timestamp': 1721955770.683242}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955770.6833754}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955770.6834652}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.4021315574646, '_timestamp': 1721955770.6836953}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955770.6842992}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955770.6847918}).
wandb: WARNING (User provided step: 6689 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955770.6853018}).
Env Football Algo jrpo Exp base_JRPO updates 6994/100000000000.0 steps in 90.27
total episode rewards is -10.0
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'value_loss': 0.20226085518797238, '_timestamp': 1721955860.954512}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00252007810845195, '_timestamp': 1721955860.9546578}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838506366411845, '_timestamp': 1721955860.9547236}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1265866607427597, '_timestamp': 1721955860.954814}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2373465597629547, '_timestamp': 1721955860.9550383}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'ratio': 0.9984087347984314, '_timestamp': 1721955860.955137}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721955860.9552603}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955860.9553497}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.26835799217224, '_timestamp': 1721955860.955511}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.25805645765675744, '_timestamp': 1721955860.956092}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'train_goal': 0.3709717711716213, '_timestamp': 1721955860.9565656}).
wandb: WARNING (User provided step: 6994 is less than current step: 12030. Dropping entry: {'train_WDL': -0.25805645765675744, '_timestamp': 1721955860.9570484}).
Env Football Algo jrpo Exp base_JRPO updates 4883/100000000000.0 steps in 88.58
total episode rewards is -20.0
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'value_loss': 0.27091572097793687, '_timestamp': 1721955949.5406952}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0018023954364859188, '_timestamp': 1721955949.5408754}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8389508374532064, '_timestamp': 1721955949.5409443}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15034082531929016, '_timestamp': 1721955949.5410433}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17038841545581818, '_timestamp': 1721955949.5413153}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'ratio': 0.999293863773346, '_timestamp': 1721955949.5416567}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721955949.5418382}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955949.5420856}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.58278203010559, '_timestamp': 1721955949.5421448}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.41583473361668477, '_timestamp': 1721955949.5428898}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'train_goal': 0.2920826331916576, '_timestamp': 1721955949.5434763}).
wandb: WARNING (User provided step: 4883 is less than current step: 12030. Dropping entry: {'train_WDL': -0.41583473361668477, '_timestamp': 1721955949.5441144}).
Env Football Algo jrpo Exp base_JRPO updates 4887/100000000000.0 steps in 83.20
total episode rewards is -10.0
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'value_loss': 0.3490961865743156, '_timestamp': 1721956032.7408242}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004392022750107571, '_timestamp': 1721956032.7409904}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8406956640879315, '_timestamp': 1721956032.741056}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14610539376735687, '_timestamp': 1721956032.741156}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1818908452987671, '_timestamp': 1721956032.7414162}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'ratio': 0.9988611340522766, '_timestamp': 1721956032.7415318}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721956032.7419496}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956032.74217}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.19575262069702, '_timestamp': 1721956032.7422333}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.19396416221314053, '_timestamp': 1721956032.7430804}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'train_goal': 0.5969820811065703, '_timestamp': 1721956032.7436547}).
wandb: WARNING (User provided step: 4887 is less than current step: 12030. Dropping entry: {'train_WDL': 0.19396416221314053, '_timestamp': 1721956032.7442214}).
Env Football Algo jrpo Exp base_JRPO updates 3581/100000000000.0 steps in 42.92
total episode rewards is -120.0
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'value_loss': 0.8968352163831393, '_timestamp': 1721956075.6656113}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022893275923949355, '_timestamp': 1721956075.6657922}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8404234584172565, '_timestamp': 1721956075.66586}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16270798444747925, '_timestamp': 1721956075.6659594}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.2617789506912231, '_timestamp': 1721956075.6662266}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'ratio': 0.9999476075172424, '_timestamp': 1721956075.6663253}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721956075.6669862}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956075.671267}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'Episode_Time': 42.92042255401611, '_timestamp': 1721956075.671392}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.2181500872600349, '_timestamp': 1721956075.6719308}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'train_goal': 0.6090750436300174, '_timestamp': 1721956075.6721861}).
wandb: WARNING (User provided step: 3581 is less than current step: 12030. Dropping entry: {'train_WDL': 0.2181500872600349, '_timestamp': 1721956075.6724412}).
Env Football Algo jrpo Exp base_JRPO updates 8510/100000000000.0 steps in 68.19
total episode rewards is -90.0
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'value_loss': 0.536684698642542, '_timestamp': 1721956143.8659658}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002330078900655887, '_timestamp': 1721956143.8671296}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8440829610824583, '_timestamp': 1721956143.8672025}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16231440007686615, '_timestamp': 1721956143.8677666}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6518188714981079, '_timestamp': 1721956143.8681471}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'ratio': 1.0001753568649292, '_timestamp': 1721956143.868256}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721956143.868404}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956143.8693478}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'Episode_Time': 68.18826651573181, '_timestamp': 1721956143.869408}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956143.8702676}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956143.8705354}).
wandb: WARNING (User provided step: 8510 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956143.8708131}).
Env Football Algo jrpo Exp base_JRPO updates 4525/100000000000.0 steps in 93.29
total episode rewards is -20.0
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'value_loss': 0.23145080336524795, '_timestamp': 1721956237.161824}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006660210946720326, '_timestamp': 1721956237.1619945}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.849031235376994, '_timestamp': 1721956237.1620605}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14562438428401947, '_timestamp': 1721956237.1621547}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.10869897156953812, '_timestamp': 1721956237.162394}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'ratio': 0.9993354678153992, '_timestamp': 1721956237.1624906}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721956237.162774}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956237.162869}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'Episode_Time': 93.29007005691528, '_timestamp': 1721956237.1629262}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4293078758949881, '_timestamp': 1721956237.1638374}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'train_goal': 0.28534606205250596, '_timestamp': 1721956237.1645079}).
wandb: WARNING (User provided step: 4525 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4293078758949881, '_timestamp': 1721956237.16516}).
Env Football Algo jrpo Exp base_JRPO updates 4558/100000000000.0 steps in 80.07
total episode rewards is -30.0
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'value_loss': 0.35319612896535546, '_timestamp': 1721956317.2313821}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004243173890281469, '_timestamp': 1721956317.231574}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.852983694076538, '_timestamp': 1721956317.2316449}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1443641632795334, '_timestamp': 1721956317.2317488}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3001144230365753, '_timestamp': 1721956317.2320633}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'ratio': 1.000064492225647, '_timestamp': 1721956317.2321715}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721956317.232325}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956317.2332187}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.06526279449463, '_timestamp': 1721956317.233285}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.41782138161221805, '_timestamp': 1721956317.2342558}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'train_goal': 0.291089309193891, '_timestamp': 1721956317.2348385}).
wandb: WARNING (User provided step: 4558 is less than current step: 12030. Dropping entry: {'train_WDL': -0.41782138161221805, '_timestamp': 1721956317.235865}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'value_loss': 0.7010834744138023, '_timestamp': 1721956372.8922367}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0019666298381829012, '_timestamp': 1721956372.892414}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8524091116587322, '_timestamp': 1721956372.8924809}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15465915203094482, '_timestamp': 1721956372.892584}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7524239420890808, '_timestamp': 1721956372.892849}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'ratio': 1.0014455318450928, '_timestamp': 1721956372.892952}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721956372.8930867}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956372.8935828}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'Episode_Time': 55.655293464660645, '_timestamp': 1721956372.893643}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956372.8939862}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956372.8942077}).
wandb: WARNING (User provided step: 5225 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956372.89444}).
Env Football Algo jrpo Exp base_JRPO updates 5225/100000000000.0 steps in 55.66
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 3142/100000000000.0 steps in 50.96
total episode rewards is -70.0
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'value_loss': 0.6551308194796245, '_timestamp': 1721956423.8647919}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003406668448393854, '_timestamp': 1721956423.8660908}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.85706849416097, '_timestamp': 1721956423.8661625}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1542973518371582, '_timestamp': 1721956423.866792}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7525257468223572, '_timestamp': 1721956423.8672493}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'ratio': 0.9988576769828796, '_timestamp': 1721956423.8673549}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721956423.867877}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956423.86811}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.964290380477905, '_timestamp': 1721956423.868168}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.2972529725297253, '_timestamp': 1721956423.869201}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'train_goal': 0.6486264862648626, '_timestamp': 1721956423.8695457}).
wandb: WARNING (User provided step: 3142 is less than current step: 12030. Dropping entry: {'train_WDL': 0.2972529725297253, '_timestamp': 1721956423.869931}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'value_loss': 0.5639444395030538, '_timestamp': 1721956495.226616}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0011235777969704941, '_timestamp': 1721956495.2267916}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8571323696772257, '_timestamp': 1721956495.2268734}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15215332806110382, '_timestamp': 1721956495.2269735}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6719974279403687, '_timestamp': 1721956495.227181}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'ratio': 0.9995372891426086, '_timestamp': 1721956495.2273011}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721956495.2279363}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956495.228068}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'Episode_Time': 71.35335063934326, '_timestamp': 1721956495.2281287}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3879544221378188, '_timestamp': 1721956495.2286959}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'train_goal': 0.30602278893109064, '_timestamp': 1721956495.229147}).
wandb: WARNING (User provided step: 3973 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3879544221378188, '_timestamp': 1721956495.229606}).
Env Football Algo jrpo Exp base_JRPO updates 3973/100000000000.0 steps in 71.35
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 3311/100000000000.0 steps in 42.18
total episode rewards is -90.0
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'value_loss': 0.5402682951961955, '_timestamp': 1721956537.4069653}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0001717892954669272, '_timestamp': 1721956537.4071531}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8528341468175253, '_timestamp': 1721956537.4072247}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15092341601848602, '_timestamp': 1721956537.4073293}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.578470766544342, '_timestamp': 1721956537.4076116}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'ratio': 0.9993216395378113, '_timestamp': 1721956537.4077125}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721956537.4078555}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956537.4087486}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'Episode_Time': 42.17644739151001, '_timestamp': 1721956537.4088116}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956537.4092243}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956537.409499}).
wandb: WARNING (User provided step: 3311 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956537.4097795}).
Env Football Algo jrpo Exp base_JRPO updates 4337/100000000000.0 steps in 87.01
total episode rewards is -40.0
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'value_loss': 0.3613215453674396, '_timestamp': 1721956624.4234314}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003055889509075011, '_timestamp': 1721956624.4235878}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8606835889816282, '_timestamp': 1721956624.4236526}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1477777063846588, '_timestamp': 1721956624.4237432}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.39671075344085693, '_timestamp': 1721956624.4239845}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'ratio': 0.9996403455734253, '_timestamp': 1721956624.4242108}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956624.4243453}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956624.4244363}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.01276111602783, '_timestamp': 1721956624.424493}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.44241015208757145, '_timestamp': 1721956624.4252193}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'train_goal': 0.2787949239562143, '_timestamp': 1721956624.4258106}).
wandb: WARNING (User provided step: 4337 is less than current step: 12030. Dropping entry: {'train_WDL': -0.44241015208757145, '_timestamp': 1721956624.4264123}).
Env Football Algo jrpo Exp base_JRPO updates 8098/100000000000.0 steps in 83.41
total episode rewards is -30.0
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'value_loss': 0.1941914216677348, '_timestamp': 1721956707.8345551}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0014877601784731571, '_timestamp': 1721956707.8347988}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.860521295865377, '_timestamp': 1721956707.8348675}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15120145678520203, '_timestamp': 1721956707.8349724}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.28204458951950073, '_timestamp': 1721956707.8352535}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'ratio': 0.9997115135192871, '_timestamp': 1721956707.835364}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721956707.8355737}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956707.8363085}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.40704345703125, '_timestamp': 1721956707.8363717}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956707.837208}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956707.8376582}).
wandb: WARNING (User provided step: 8098 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956707.8381193}).
Env Football Algo jrpo Exp base_JRPO updates 4398/100000000000.0 steps in 56.91
total episode rewards is -80.0
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'value_loss': 0.4879802209759752, '_timestamp': 1721956764.7559826}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0036483624373795463, '_timestamp': 1721956764.7573872}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8512350781758626, '_timestamp': 1721956764.757466}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15159004926681519, '_timestamp': 1721956764.7580876}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.45617207884788513, '_timestamp': 1721956764.7593613}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'ratio': 1.0001879930496216, '_timestamp': 1721956764.7595565}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721956764.7597246}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956764.7599642}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.91157364845276, '_timestamp': 1721956764.760024}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956764.7610862}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956764.7616045}).
wandb: WARNING (User provided step: 4398 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956764.7620904}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'value_loss': 0.18155690545216202, '_timestamp': 1721956853.0110636}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'policy_loss': 0.012534493941542072, '_timestamp': 1721956853.0113125}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8433961200714113, '_timestamp': 1721956853.0113783}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1325613409280777, '_timestamp': 1721956853.0114727}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17681202292442322, '_timestamp': 1721956853.0117152}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'ratio': 1.000942349433899, '_timestamp': 1721956853.0118127}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721956853.0120206}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956853.0122743}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.2479133605957, '_timestamp': 1721956853.0123336}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956853.0128324}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956853.0131762}).
wandb: WARNING (User provided step: 10195 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956853.0135064}).
Env Football Algo jrpo Exp base_JRPO updates 10195/100000000000.0 steps in 88.25
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 4910/100000000000.0 steps in 62.88
total episode rewards is -60.0
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'value_loss': 0.362966332839181, '_timestamp': 1721956915.901376}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0009666633803863078, '_timestamp': 1721956915.9025533}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8393569231033324, '_timestamp': 1721956915.9026244}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14272233843803406, '_timestamp': 1721956915.9031775}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4334210455417633, '_timestamp': 1721956915.9035344}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'ratio': 0.9989814758300781, '_timestamp': 1721956915.9041042}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721956915.9042406}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956915.9044306}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'Episode_Time': 62.882222414016724, '_timestamp': 1721956915.9044902}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956915.9054582}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956915.9058375}).
wandb: WARNING (User provided step: 4910 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956915.9062104}).
Env Football Algo jrpo Exp base_JRPO updates 7049/100000000000.0 steps in 91.92
total episode rewards is -40.0
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'value_loss': 0.25453616061558326, '_timestamp': 1721957007.8263998}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001374945907543103, '_timestamp': 1721957007.8265555}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8419075043996176, '_timestamp': 1721957007.8266242}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15447209775447845, '_timestamp': 1721957007.8267152}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18612532317638397, '_timestamp': 1721957007.8270004}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'ratio': 0.9988503456115723, '_timestamp': 1721957007.8271027}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957007.8274446}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957007.8275366}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.91926956176758, '_timestamp': 1721957007.827594}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957007.8281872}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957007.8286583}).
wandb: WARNING (User provided step: 7049 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957007.829152}).
Env Football Algo jrpo Exp base_JRPO updates 3688/100000000000.0 steps in 38.93
total episode rewards is -110.0
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'value_loss': 0.6907996482153733, '_timestamp': 1721957046.7576725}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003611860329595705, '_timestamp': 1721957046.7578175}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845484962463379, '_timestamp': 1721957046.757881}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15670347213745117, '_timestamp': 1721957046.7579658}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8271546959877014, '_timestamp': 1721957046.758195}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'ratio': 1.0010292530059814, '_timestamp': 1721957046.7582927}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721957046.758518}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957046.7586098}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'Episode_Time': 38.92765164375305, '_timestamp': 1721957046.7586653}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957046.758903}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957046.759062}).
wandb: WARNING (User provided step: 3688 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957046.7592213}).
Env Football Algo jrpo Exp base_JRPO updates 5019/100000000000.0 steps in 50.11
total episode rewards is -80.0
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'value_loss': 0.5873830413694183, '_timestamp': 1721957096.868433}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0020901484174343445, '_timestamp': 1721957096.8686488}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8452304045359296, '_timestamp': 1721957096.8687177}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1514206826686859, '_timestamp': 1721957096.8688178}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5816338658332825, '_timestamp': 1721957096.869073}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'ratio': 1.0016781091690063, '_timestamp': 1721957096.869171}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721957096.8696105}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957096.869708}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.108431339263916, '_timestamp': 1721957096.8697653}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.031955438287892116, '_timestamp': 1721957096.8702316}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'train_goal': 0.4840222808560539, '_timestamp': 1721957096.870498}).
wandb: WARNING (User provided step: 5019 is less than current step: 12030. Dropping entry: {'train_WDL': -0.031955438287892116, '_timestamp': 1721957096.8707564}).
Env Football Algo jrpo Exp base_JRPO updates 4186/100000000000.0 steps in 67.28
total episode rewards is -100.0
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'value_loss': 0.7307149319599072, '_timestamp': 1721957164.1553178}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0024718140061789503, '_timestamp': 1721957164.155479}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8495120159784952, '_timestamp': 1721957164.1555471}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1529572308063507, '_timestamp': 1721957164.1556454}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7210929989814758, '_timestamp': 1721957164.1558917}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'ratio': 0.999660849571228, '_timestamp': 1721957164.1573436}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721957164.1574743}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957164.1579156}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'Episode_Time': 67.283695936203, '_timestamp': 1721957164.1579742}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.30509118541033436, '_timestamp': 1721957164.1588066}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'train_goal': 0.34745440729483285, '_timestamp': 1721957164.1591716}).
wandb: WARNING (User provided step: 4186 is less than current step: 12030. Dropping entry: {'train_WDL': -0.30509118541033436, '_timestamp': 1721957164.159674}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'value_loss': 0.24144297915510834, '_timestamp': 1721957246.175019}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0069629821971951365, '_timestamp': 1721957246.1751766}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.850033082962036, '_timestamp': 1721957246.1752427}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14239497482776642, '_timestamp': 1721957246.175334}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19294410943984985, '_timestamp': 1721957246.175583}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'ratio': 1.000588297843933, '_timestamp': 1721957246.1756828}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957246.1761844}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957246.1762807}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.01439642906189, '_timestamp': 1721957246.1763391}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957246.1768548}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957246.1774943}).
wandb: WARNING (User provided step: 8808 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957246.1779003}).
Env Football Algo jrpo Exp base_JRPO updates 8808/100000000000.0 steps in 82.01
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6789/100000000000.0 steps in 59.39
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'value_loss': 0.45308965651939315, '_timestamp': 1721957305.570099}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011754844842168193, '_timestamp': 1721957305.5702708}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.855341636339823, '_timestamp': 1721957305.5703394}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1488976925611496, '_timestamp': 1721957305.570436}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5132331252098083, '_timestamp': 1721957305.5706947}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'ratio': 1.0010185241699219, '_timestamp': 1721957305.5707994}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721957305.5710442}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957305.5711439}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.39136505126953, '_timestamp': 1721957305.571202}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957305.5714307}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957305.5715837}).
wandb: WARNING (User provided step: 6789 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957305.571731}).
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 6517/100000000000.0 steps in 77.19
total episode rewards is -60.0
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'value_loss': 0.5083754694461823, '_timestamp': 1721957382.7684562}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004226817267481238, '_timestamp': 1721957382.7696438}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8543929147720335, '_timestamp': 1721957382.7697165}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15548351407051086, '_timestamp': 1721957382.7702131}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.39888203144073486, '_timestamp': 1721957382.770575}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'ratio': 1.00092613697052, '_timestamp': 1721957382.7713623}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721957382.7715876}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957382.7717664}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.19281315803528, '_timestamp': 1721957382.771825}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2698234799663771, '_timestamp': 1721957382.7731678}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'train_goal': 0.36508826001681144, '_timestamp': 1721957382.77363}).
wandb: WARNING (User provided step: 6517 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2698234799663771, '_timestamp': 1721957382.7740908}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'value_loss': 0.667819758305947, '_timestamp': 1721957462.1629665}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0027964951392884054, '_timestamp': 1721957462.1631682}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.851277340253194, '_timestamp': 1721957462.1632347}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15536069869995117, '_timestamp': 1721957462.1633344}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7126829624176025, '_timestamp': 1721957462.1635935}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'ratio': 0.9991794228553772, '_timestamp': 1721957462.163696}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721957462.1638157}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957462.1639102}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.38778495788574, '_timestamp': 1721957462.1639926}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957462.164918}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957462.1653337}).
wandb: WARNING (User provided step: 5737 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957462.165757}).
Env Football Algo jrpo Exp base_JRPO updates 5737/100000000000.0 steps in 79.39
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 8326/100000000000.0 steps in 88.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'value_loss': 0.20301472835242748, '_timestamp': 1721957550.682565}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0003610752635480215, '_timestamp': 1721957550.682748}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8482319355010985, '_timestamp': 1721957550.682813}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14284050464630127, '_timestamp': 1721957550.6829104}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.06771034002304077, '_timestamp': 1721957550.6831586}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'ratio': 0.9999955296516418, '_timestamp': 1721957550.6833622}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721957550.6835673}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957550.6836631}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.5158383846283, '_timestamp': 1721957550.683721}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957550.6843429}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957550.6847916}).
wandb: WARNING (User provided step: 8326 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957550.6852243}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'value_loss': 0.303575942479074, '_timestamp': 1721957636.4383078}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009527058592296575, '_timestamp': 1721957636.4384887}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.847882614135742, '_timestamp': 1721957636.4385567}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1497011035680771, '_timestamp': 1721957636.438662}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1505623608827591, '_timestamp': 1721957636.438986}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'ratio': 1.0001918077468872, '_timestamp': 1721957636.4390922}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721957636.4395401}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957636.439638}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.75209474563599, '_timestamp': 1721957636.4396958}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3897318644772397, '_timestamp': 1721957636.4404461}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'train_goal': 0.3051340677613802, '_timestamp': 1721957636.4410288}).
wandb: WARNING (User provided step: 5378 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3897318644772397, '_timestamp': 1721957636.441613}).
Env Football Algo jrpo Exp base_JRPO updates 5378/100000000000.0 steps in 85.75
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5317/100000000000.0 steps in 79.47
total episode rewards is -70.0
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'value_loss': 0.46103703014552594, '_timestamp': 1721957715.9200902}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015878736274316906, '_timestamp': 1721957715.9213302}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8494369713465373, '_timestamp': 1721957715.9214056}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16043877601623535, '_timestamp': 1721957715.9219623}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35478243231773376, '_timestamp': 1721957715.922339}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'ratio': 0.9996708631515503, '_timestamp': 1721957715.9231207}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721957715.92325}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957715.9234512}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.47280979156494, '_timestamp': 1721957715.9235098}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957715.9246325}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957715.9252768}).
wandb: WARNING (User provided step: 5317 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957715.9257224}).
Env Football Algo jrpo Exp base_JRPO updates 5291/100000000000.0 steps in 79.53
total episode rewards is -40.0
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'value_loss': 0.3702696403985222, '_timestamp': 1721957795.4568532}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013800749842387933, '_timestamp': 1721957795.4570253}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8459156195322675, '_timestamp': 1721957795.4570904}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15080252289772034, '_timestamp': 1721957795.4571898}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2743343412876129, '_timestamp': 1721957795.4574409}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'ratio': 1.000041127204895, '_timestamp': 1721957795.4575396}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957795.458001}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957795.458096}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.5302722454071, '_timestamp': 1721957795.4581537}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3614315987756063, '_timestamp': 1721957795.4588094}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'train_goal': 0.31928420061219687, '_timestamp': 1721957795.459316}).
wandb: WARNING (User provided step: 5291 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3614315987756063, '_timestamp': 1721957795.4598336}).
Env Football Algo jrpo Exp base_JRPO updates 5235/100000000000.0 steps in 77.65
total episode rewards is -60.0
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'value_loss': 0.4861655501524607, '_timestamp': 1721957873.1178389}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001940263990254607, '_timestamp': 1721957873.119215}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8486896546681724, '_timestamp': 1721957873.1192982}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15373601019382477, '_timestamp': 1721957873.1199281}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4749518930912018, '_timestamp': 1721957873.1203604}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'ratio': 0.9986335635185242, '_timestamp': 1721957873.1204622}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721957873.1206727}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957873.1208906}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.65113401412964, '_timestamp': 1721957873.1209497}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.309038737446198, '_timestamp': 1721957873.122125}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'train_goal': 0.345480631276901, '_timestamp': 1721957873.1225824}).
wandb: WARNING (User provided step: 5235 is less than current step: 12030. Dropping entry: {'train_WDL': -0.309038737446198, '_timestamp': 1721957873.1230216}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'value_loss': 0.24590781525708735, '_timestamp': 1721957960.562147}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0001649241366859163, '_timestamp': 1721957960.5623229}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8368997939427696, '_timestamp': 1721957960.5623887}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1462220847606659, '_timestamp': 1721957960.5624912}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16080304980278015, '_timestamp': 1721957960.5627666}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'ratio': 1.0007352828979492, '_timestamp': 1721957960.5628712}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721957960.5636284}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957960.5637336}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.43822526931763, '_timestamp': 1721957960.563792}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3711383834109183, '_timestamp': 1721957960.5645647}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'train_goal': 0.31443080829454084, '_timestamp': 1721957960.565144}).
wandb: WARNING (User provided step: 5548 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3711383834109183, '_timestamp': 1721957960.5657086}).
Env Football Algo jrpo Exp base_JRPO updates 5548/100000000000.0 steps in 87.44
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5931/100000000000.0 steps in 84.78
total episode rewards is -40.0
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'value_loss': 0.26565697157755497, '_timestamp': 1721958045.3441834}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009809794895118103, '_timestamp': 1721958045.344356}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.836804035504659, '_timestamp': 1721958045.3444238}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14923712611198425, '_timestamp': 1721958045.3445199}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1541743129491806, '_timestamp': 1721958045.3447695}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'ratio': 0.9996590614318848, '_timestamp': 1721958045.3450398}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958045.345181}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958045.345273}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.77762651443481, '_timestamp': 1721958045.345331}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958045.34598}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958045.3465054}).
wandb: WARNING (User provided step: 5931 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958045.347061}).
Env Football Algo jrpo Exp base_JRPO updates 6484/100000000000.0 steps in 90.57
total episode rewards is -50.0
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'value_loss': 0.3346708588860929, '_timestamp': 1721958135.9206626}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006912744724589478, '_timestamp': 1721958135.9208417}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.832348098754883, '_timestamp': 1721958135.920908}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13700024783611298, '_timestamp': 1721958135.9271522}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2417551726102829, '_timestamp': 1721958135.9275625}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'ratio': 0.9998987913131714, '_timestamp': 1721958135.9277534}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721958135.927962}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958135.9288342}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.57250452041626, '_timestamp': 1721958135.9289064}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958135.9296803}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958135.9302132}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958135.930746}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'value_loss': 0.25171558396386295, '_timestamp': 1721958220.609294}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'policy_loss': 0.014775345029775053, '_timestamp': 1721958220.6102974}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.824931812286377, '_timestamp': 1721958220.6103687}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12995977699756622, '_timestamp': 1721958220.6108546}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21969711780548096, '_timestamp': 1721958220.6111948}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'ratio': 1.0004905462265015, '_timestamp': 1721958220.611299}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958220.611839}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958220.61206}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.66915512084961, '_timestamp': 1721958220.6121213}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958220.6131544}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958220.613733}).
wandb: WARNING (User provided step: 7572 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958220.6142116}).
Env Football Algo jrpo Exp base_JRPO updates 7572/100000000000.0 steps in 84.67
total episode rewards is -40.0
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'value_loss': 0.319058374260397, '_timestamp': 1721958302.5737698}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005353029267474388, '_timestamp': 1721958302.5739248}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8209002367655436, '_timestamp': 1721958302.5739918}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14267723262310028, '_timestamp': 1721958302.5740821}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18963512778282166, '_timestamp': 1721958302.5743232}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'ratio': 1.002466082572937, '_timestamp': 1721958302.5744226}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958302.5745528}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958302.5746434}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.95855641365051, '_timestamp': 1721958302.5747008}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.26854498434735263, '_timestamp': 1721958302.575541}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'train_goal': 0.3657275078263237, '_timestamp': 1721958302.5759912}).
wandb: WARNING (User provided step: 6478 is less than current step: 12030. Dropping entry: {'train_WDL': -0.26854498434735263, '_timestamp': 1721958302.576442}).
Env Football Algo jrpo Exp base_JRPO updates 6478/100000000000.0 steps in 81.96
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 9040/100000000000.0 steps in 88.61
total episode rewards is -30.0
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'value_loss': 0.19382965522624243, '_timestamp': 1721958391.1905398}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0046369341322376086, '_timestamp': 1721958391.190721}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.827954797744751, '_timestamp': 1721958391.1907892}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14341974258422852, '_timestamp': 1721958391.1908906}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4333512485027313, '_timestamp': 1721958391.19116}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'ratio': 1.0005322694778442, '_timestamp': 1721958391.1912615}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958391.191632}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958391.1917336}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.6131055355072, '_timestamp': 1721958391.191791}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958391.1923327}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958391.1927338}).
wandb: WARNING (User provided step: 9040 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958391.1931317}).
Env Football Algo jrpo Exp base_JRPO updates 2676/100000000000.0 steps in 38.60
total episode rewards is -60.0
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'value_loss': 0.372930283791696, '_timestamp': 1721958429.7943094}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00010772703758751353, '_timestamp': 1721958429.795573}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8245553970336914, '_timestamp': 1721958429.7956522}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14593622088432312, '_timestamp': 1721958429.7962487}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.38358476758003235, '_timestamp': 1721958429.7966235}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'ratio': 1.0010826587677002, '_timestamp': 1721958429.7967315}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721958429.7968726}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958429.7976952}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'Episode_Time': 38.5953471660614, '_timestamp': 1721958429.7977552}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958429.7986033}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958429.79884}).
wandb: WARNING (User provided step: 2676 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958429.799075}).
Env Football Algo jrpo Exp base_JRPO updates 4964/100000000000.0 steps in 72.40
total episode rewards is -110.0
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'value_loss': 0.7778135847051938, '_timestamp': 1721958502.2016523}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013139356776082423, '_timestamp': 1721958502.2018318}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.833721095720927, '_timestamp': 1721958502.2018993}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16100068390369415, '_timestamp': 1721958502.2020004}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8921234607696533, '_timestamp': 1721958502.2022598}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'ratio': 0.9997100234031677, '_timestamp': 1721958502.2025094}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721958502.2029755}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958502.2030718}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.40136122703552, '_timestamp': 1721958502.2031312}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2964240903387704, '_timestamp': 1721958502.2037165}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'train_goal': 0.3517879548306148, '_timestamp': 1721958502.20414}).
wandb: WARNING (User provided step: 4964 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2964240903387704, '_timestamp': 1721958502.2045515}).
Env Football Algo jrpo Exp base_JRPO updates 7291/100000000000.0 steps in 86.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'value_loss': 0.2724107449168029, '_timestamp': 1721958588.4517038}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003917278414980198, '_timestamp': 1721958588.452977}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8382480812072752, '_timestamp': 1721958588.4530532}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13222211599349976, '_timestamp': 1721958588.4536405}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2687601149082184, '_timestamp': 1721958588.4540234}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'ratio': 1.001577615737915, '_timestamp': 1721958588.4541557}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958588.455139}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958588.4553285}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.24132108688354, '_timestamp': 1721958588.4553905}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958588.4568794}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958588.4574265}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958588.4579518}).
Env Football Algo jrpo Exp base_JRPO updates 7751/100000000000.0 steps in 92.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'value_loss': 0.25059372536527613, '_timestamp': 1721958680.6757333}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0040531830648736404, '_timestamp': 1721958680.6759655}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8384791819254556, '_timestamp': 1721958680.6760387}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.132341668009758, '_timestamp': 1721958680.676139}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2837446331977844, '_timestamp': 1721958680.6764092}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'ratio': 0.9997273087501526, '_timestamp': 1721958680.6765542}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958680.6774504}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958680.6775575}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'Episode_Time': 92.2164957523346, '_timestamp': 1721958680.677617}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958680.6785364}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958680.6789865}).
wandb: WARNING (User provided step: 7751 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958680.679447}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'value_loss': 0.5629897276125848, '_timestamp': 1721958745.2603347}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0010751086124219, '_timestamp': 1721958745.2605243}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8373422861099242, '_timestamp': 1721958745.2605934}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1451302021741867, '_timestamp': 1721958745.2606916}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6416589021682739, '_timestamp': 1721958745.2609625}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'ratio': 0.9976342916488647, '_timestamp': 1721958745.26107}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958745.2612565}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958745.2613595}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.57919669151306, '_timestamp': 1721958745.2614172}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.5712916038898781, '_timestamp': 1721958745.2623696}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'train_goal': 0.785645801944939, '_timestamp': 1721958745.2630296}).
wandb: WARNING (User provided step: 2459 is less than current step: 12030. Dropping entry: {'train_WDL': 0.5712916038898781, '_timestamp': 1721958745.2634778}).
Env Football Algo jrpo Exp base_JRPO updates 2459/100000000000.0 steps in 64.58
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7397/100000000000.0 steps in 86.88
total episode rewards is -20.0
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'value_loss': 0.2634247208169351, '_timestamp': 1721958832.148974}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0037012818145255246, '_timestamp': 1721958832.1502845}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.840591427485148, '_timestamp': 1721958832.1503563}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13959388434886932, '_timestamp': 1721958832.1509552}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1520102322101593, '_timestamp': 1721958832.1513417}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'ratio': 1.0005046129226685, '_timestamp': 1721958832.1514425}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721958832.1521614}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958832.1523657}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.87941980361938, '_timestamp': 1721958832.1524239}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2145205839800079, '_timestamp': 1721958832.153598}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'train_goal': 0.3927397080099961, '_timestamp': 1721958832.1541}).
wandb: WARNING (User provided step: 7397 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2145205839800079, '_timestamp': 1721958832.154575}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'value_loss': 0.6049137482481698, '_timestamp': 1721958891.8288283}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004166255975651439, '_timestamp': 1721958891.8291528}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8414683961868286, '_timestamp': 1721958891.8292623}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15763714909553528, '_timestamp': 1721958891.8293688}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8837685585021973, '_timestamp': 1721958891.8296473}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'ratio': 0.9991063475608826, '_timestamp': 1721958891.8297856}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721958891.8306744}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958891.830778}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.67330360412598, '_timestamp': 1721958891.8308372}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958891.8314507}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958891.8317893}).
wandb: WARNING (User provided step: 5590 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958891.8321457}).
Env Football Algo jrpo Exp base_JRPO updates 5590/100000000000.0 steps in 59.67
total episode rewards is -100.0
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'value_loss': 0.6489284803966681, '_timestamp': 1721958955.5188446}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002243011244184648, '_timestamp': 1721958955.5200427}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838036594390869, '_timestamp': 1721958955.5201206}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1538253128528595, '_timestamp': 1721958955.5206501}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9166342616081238, '_timestamp': 1721958955.5209641}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'ratio': 0.9995943307876587, '_timestamp': 1721958955.5210698}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721958955.5216415}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958955.521829}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.68135714530945, '_timestamp': 1721958955.521888}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958955.5228646}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958955.5232408}).
wandb: WARNING (User provided step: 4569 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958955.5236597}).
Env Football Algo jrpo Exp base_JRPO updates 4569/100000000000.0 steps in 63.68
total episode rewards is -110.0
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'value_loss': 0.11152583776973188, '_timestamp': 1721959039.593123}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0032082953699864446, '_timestamp': 1721959039.593277}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8358424218495686, '_timestamp': 1721959039.5933423}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.11365355551242828, '_timestamp': 1721959039.5934327}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1399184614419937, '_timestamp': 1721959039.5936704}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'ratio': 1.0002926588058472, '_timestamp': 1721959039.5937715}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721959039.5940943}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959039.5941863}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.06859350204468, '_timestamp': 1721959039.5942454}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959039.5946312}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959039.5949273}).
wandb: WARNING (User provided step: 10615 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959039.595238}).
Env Football Algo jrpo Exp base_JRPO updates 10615/100000000000.0 steps in 84.07
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5738/100000000000.0 steps in 62.83
total episode rewards is -50.0
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'value_loss': 0.3195996453581999, '_timestamp': 1721959102.424587}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011474514026970912, '_timestamp': 1721959102.4247408}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83985865910848, '_timestamp': 1721959102.4248068}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15689939260482788, '_timestamp': 1721959102.4248967}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.27133089303970337, '_timestamp': 1721959102.4251266}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'ratio': 1.0004560947418213, '_timestamp': 1721959102.4252272}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721959102.4255688}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959102.4256594}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'Episode_Time': 62.82842445373535, '_timestamp': 1721959102.425715}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959102.4261248}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959102.4264374}).
wandb: WARNING (User provided step: 5738 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959102.426761}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'value_loss': 0.9081969472020864, '_timestamp': 1721959132.0985796}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015995268383994698, '_timestamp': 1721959132.098734}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8398172950744627, '_timestamp': 1721959132.098801}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16282249987125397, '_timestamp': 1721959132.0988915}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7462918162345886, '_timestamp': 1721959132.0991375}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'ratio': 0.9999592304229736, '_timestamp': 1721959132.0992374}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721959132.0993705}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959132.0996876}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'Episode_Time': 29.670995950698853, '_timestamp': 1721959132.0997477}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.17123795404002964, '_timestamp': 1721959132.1000545}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'train_goal': 0.4143810229799852, '_timestamp': 1721959132.1002095}).
wandb: WARNING (User provided step: 1696 is less than current step: 12030. Dropping entry: {'train_WDL': -0.17123795404002964, '_timestamp': 1721959132.1003609}).
Env Football Algo jrpo Exp base_JRPO updates 1696/100000000000.0 steps in 29.67
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 5164/100000000000.0 steps in 81.36
total episode rewards is -20.0
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'value_loss': 0.25724608065676874, '_timestamp': 1721959213.460374}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'policy_loss': 0.011755676100826047, '_timestamp': 1721959213.4605327}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8383853435516357, '_timestamp': 1721959213.4605978}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13479351997375488, '_timestamp': 1721959213.4606912}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12372288107872009, '_timestamp': 1721959213.4609287}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'ratio': 1.0011504888534546, '_timestamp': 1721959213.4610271}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721959213.4615147}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959213.4616072}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.35915493965149, '_timestamp': 1721959213.4616644}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3926392842618951, '_timestamp': 1721959213.462365}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'train_goal': 0.30368035786905245, '_timestamp': 1721959213.462931}).
wandb: WARNING (User provided step: 5164 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3926392842618951, '_timestamp': 1721959213.463509}).
Env Football Algo jrpo Exp base_JRPO updates 5281/100000000000.0 steps in 49.62
total episode rewards is -70.0
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'value_loss': 0.40076505661942063, '_timestamp': 1721959263.0819201}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00046647488517919555, '_timestamp': 1721959263.0821168}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8380029646555585, '_timestamp': 1721959263.082191}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1407475620508194, '_timestamp': 1721959263.0822997}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4067760705947876, '_timestamp': 1721959263.0825915}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'ratio': 0.998802900314331, '_timestamp': 1721959263.0826962}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721959263.0834956}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959263.0836053}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'Episode_Time': 49.617353200912476, '_timestamp': 1721959263.0836635}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959263.090676}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959263.091042}).
wandb: WARNING (User provided step: 5281 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959263.0912888}).
Env Football Algo jrpo Exp base_JRPO updates 9384/100000000000.0 steps in 85.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'value_loss': 0.2535593829521288, '_timestamp': 1721959348.3119242}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005072410673407527, '_timestamp': 1721959348.3120992}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8413015826543173, '_timestamp': 1721959348.3121712}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13955911993980408, '_timestamp': 1721959348.3122647}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1959109604358673, '_timestamp': 1721959348.3124857}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'ratio': 0.9996199011802673, '_timestamp': 1721959348.3125818}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959348.3128376}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959348.3129294}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.21938157081604, '_timestamp': 1721959348.312986}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959348.31358}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959348.3139496}).
wandb: WARNING (User provided step: 9384 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959348.314452}).
Env Football Algo jrpo Exp base_JRPO updates 3117/100000000000.0 steps in 66.93
total episode rewards is -40.0
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'value_loss': 0.4843588516674936, '_timestamp': 1721959415.2469678}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0001272316765001354, '_timestamp': 1721959415.2471204}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.840086654027303, '_timestamp': 1721959415.2471862}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15000410377979279, '_timestamp': 1721959415.2472837}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.544802725315094, '_timestamp': 1721959415.2475147}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'ratio': 0.9984618425369263, '_timestamp': 1721959415.2477815}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959415.2479198}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959415.248024}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'Episode_Time': 66.93179297447205, '_timestamp': 1721959415.2480822}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.09697520446579255, '_timestamp': 1721959415.2486336}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'train_goal': 0.5484876022328963, '_timestamp': 1721959415.2490761}).
wandb: WARNING (User provided step: 3117 is less than current step: 12030. Dropping entry: {'train_WDL': 0.09697520446579255, '_timestamp': 1721959415.249515}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'value_loss': 0.18851172393265492, '_timestamp': 1721959494.5314245}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006969707839889452, '_timestamp': 1721959494.5315785}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.837228789329529, '_timestamp': 1721959494.5316412}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14599451422691345, '_timestamp': 1721959494.5317307}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20833070576190948, '_timestamp': 1721959494.5319839}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'ratio': 1.0010905265808105, '_timestamp': 1721959494.532251}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721959494.5323784}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959494.532474}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.2810411453247, '_timestamp': 1721959494.5325313}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959494.5330067}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959494.5333953}).
wandb: WARNING (User provided step: 8703 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959494.5338035}).
Env Football Algo jrpo Exp base_JRPO updates 8703/100000000000.0 steps in 79.28
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 5933/100000000000.0 steps in 83.39
total episode rewards is -40.0
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'value_loss': 0.2885096188642395, '_timestamp': 1721959577.9198792}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004412269202681879, '_timestamp': 1721959577.9200509}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8442916186650593, '_timestamp': 1721959577.9201162}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13200882077217102, '_timestamp': 1721959577.9202056}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2224361151456833, '_timestamp': 1721959577.9204435}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'ratio': 0.9977214932441711, '_timestamp': 1721959577.920542}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959577.9209492}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959577.9210396}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.38539505004883, '_timestamp': 1721959577.921096}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959577.9217205}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959577.922237}).
wandb: WARNING (User provided step: 5933 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959577.9227788}).
Env Football Algo jrpo Exp base_JRPO updates 2032/100000000000.0 steps in 41.35
total episode rewards is -110.0
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'value_loss': 0.8977966198325157, '_timestamp': 1721959619.275933}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0014051234050809094, '_timestamp': 1721959619.2773287}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8451112508773804, '_timestamp': 1721959619.2773967}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15981613099575043, '_timestamp': 1721959619.2774901}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8735073804855347, '_timestamp': 1721959619.2777236}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'ratio': 0.9971395134925842, '_timestamp': 1721959619.2778234}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721959619.277955}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959619.278302}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.35237789154053, '_timestamp': 1721959619.278359}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3241758241758242, '_timestamp': 1721959619.2786663}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'train_goal': 0.33791208791208793, '_timestamp': 1721959619.2788825}).
wandb: WARNING (User provided step: 2032 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3241758241758242, '_timestamp': 1721959619.2790961}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'value_loss': 0.1862001663392099, '_timestamp': 1721959697.2349954}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0041967390209902075, '_timestamp': 1721959697.2354515}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8512234338124594, '_timestamp': 1721959697.2355604}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13835392892360687, '_timestamp': 1721959697.2357273}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21149861812591553, '_timestamp': 1721959697.2395241}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'ratio': 0.9985166788101196, '_timestamp': 1721959697.2397156}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721959697.2401335}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959697.2412446}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.95397353172302, '_timestamp': 1721959697.241316}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.25681818181818183, '_timestamp': 1721959697.2422109}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'train_goal': 0.3715909090909091, '_timestamp': 1721959697.242812}).
wandb: WARNING (User provided step: 7080 is less than current step: 12030. Dropping entry: {'train_WDL': -0.25681818181818183, '_timestamp': 1721959697.2433307}).
Env Football Algo jrpo Exp base_JRPO updates 7080/100000000000.0 steps in 77.95
total episode rewards is -10.0
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'value_loss': 0.2479102750440749, '_timestamp': 1721959788.7822754}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0054205890527615945, '_timestamp': 1721959788.782439}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.856258193651835, '_timestamp': 1721959788.7825048}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14203083515167236, '_timestamp': 1721959788.7826}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14584894478321075, '_timestamp': 1721959788.7828581}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'ratio': 1.0006781816482544, '_timestamp': 1721959788.7829611}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721959788.78356}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959788.7836556}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.5378954410553, '_timestamp': 1721959788.7837121}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.17670120414449733, '_timestamp': 1721959788.7843955}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_goal': 0.41164939792775135, '_timestamp': 1721959788.7848842}).
wandb: WARNING (User provided step: 7858 is less than current step: 12030. Dropping entry: {'train_WDL': -0.17670120414449733, '_timestamp': 1721959788.7853446}).
Env Football Algo jrpo Exp base_JRPO updates 7858/100000000000.0 steps in 91.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'value_loss': 0.20855480051909883, '_timestamp': 1721959874.6715455}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002558086227266661, '_timestamp': 1721959874.671843}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8494113365809124, '_timestamp': 1721959874.6719627}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1293165534734726, '_timestamp': 1721959874.6721036}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19017985463142395, '_timestamp': 1721959874.67243}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'ratio': 0.9995443224906921, '_timestamp': 1721959874.6726058}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721959874.6730216}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959874.6738162}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.88461112976074, '_timestamp': 1721959874.674178}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959874.6749845}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959874.6754074}).
wandb: WARNING (User provided step: 9810 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959874.6758285}).
Env Football Algo jrpo Exp base_JRPO updates 9810/100000000000.0 steps in 85.88
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 3739/100000000000.0 steps in 39.70
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'value_loss': 0.6650579726944367, '_timestamp': 1721959914.3801131}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0032793946226593105, '_timestamp': 1721959914.3802698}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8499389441808063, '_timestamp': 1721959914.3803358}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1490236520767212, '_timestamp': 1721959914.3804262}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8669594526290894, '_timestamp': 1721959914.3806674}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'ratio': 0.999613344669342, '_timestamp': 1721959914.3807683}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721959914.3808863}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959914.3811238}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'Episode_Time': 39.70327305793762, '_timestamp': 1721959914.3811815}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959914.3814738}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959914.3816736}).
wandb: WARNING (User provided step: 3739 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959914.3818665}).
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 6323/100000000000.0 steps in 85.28
total episode rewards is -40.0
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'value_loss': 0.2696557952801231, '_timestamp': 1721959999.6599214}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'policy_loss': 0.014389448804916658, '_timestamp': 1721959999.660082}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8465115213394165, '_timestamp': 1721959999.6601484}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13436688482761383, '_timestamp': 1721959999.6602366}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16233426332473755, '_timestamp': 1721959999.6604552}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'ratio': 0.9993401169776917, '_timestamp': 1721959999.6605535}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959999.660684}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959999.6607718}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.27713918685913, '_timestamp': 1721959999.6609426}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959999.6615958}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959999.662097}).
wandb: WARNING (User provided step: 6323 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959999.662629}).
Env Football Algo jrpo Exp base_JRPO updates 1474/100000000000.0 steps in 39.98
total episode rewards is -70.0
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'value_loss': 0.7960065886874994, '_timestamp': 1721960039.6404366}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00332057805887113, '_timestamp': 1721960039.6405873}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.848884627024333, '_timestamp': 1721960039.6406527}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14854790270328522, '_timestamp': 1721960039.6407409}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9078698754310608, '_timestamp': 1721960039.640971}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'ratio': 1.0010048151016235, '_timestamp': 1721960039.6410716}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721960039.641343}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960039.6414413}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'Episode_Time': 39.97669959068298, '_timestamp': 1721960039.6415036}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.5976704683329289, '_timestamp': 1721960039.6419234}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'train_goal': 0.7988352341664644, '_timestamp': 1721960039.642209}).
wandb: WARNING (User provided step: 1474 is less than current step: 12030. Dropping entry: {'train_WDL': 0.5976704683329289, '_timestamp': 1721960039.6425033}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'value_loss': 0.27572949836961924, '_timestamp': 1721960118.7780144}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0023943907053520282, '_timestamp': 1721960118.7782028}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.853036650021871, '_timestamp': 1721960118.7782707}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1320672184228897, '_timestamp': 1721960118.7783716}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.15230555832386017, '_timestamp': 1721960118.7786417}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'ratio': 0.9986199140548706, '_timestamp': 1721960118.7787454}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960118.7788846}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960118.7792895}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.13466238975525, '_timestamp': 1721960118.779351}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960118.7800539}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960118.780594}).
wandb: WARNING (User provided step: 5679 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960118.7811682}).
Env Football Algo jrpo Exp base_JRPO updates 5679/100000000000.0 steps in 79.13
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 7600/100000000000.0 steps in 84.88
total episode rewards is -30.0
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'value_loss': 0.20998115070901502, '_timestamp': 1721960203.6593716}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00262583316808256, '_timestamp': 1721960203.6595302}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.852880360285441, '_timestamp': 1721960203.6595972}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1471993327140808, '_timestamp': 1721960203.659691}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2994643449783325, '_timestamp': 1721960203.6599448}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'ratio': 1.0004428625106812, '_timestamp': 1721960203.660079}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960203.6602073}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960203.6607943}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.87724351882935, '_timestamp': 1721960203.6608562}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960203.6614387}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960203.6619005}).
wandb: WARNING (User provided step: 7600 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960203.6623633}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'value_loss': 0.26380287748528647, '_timestamp': 1721960290.9696896}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00546566943537376, '_timestamp': 1721960290.9698377}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8591557709376016, '_timestamp': 1721960290.9699016}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14780347049236298, '_timestamp': 1721960290.9699867}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.09103849530220032, '_timestamp': 1721960290.9702096}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'ratio': 1.0014369487762451, '_timestamp': 1721960290.970308}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960290.970541}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960290.970631}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.30647349357605, '_timestamp': 1721960290.9706867}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960290.9713516}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960290.971919}).
wandb: WARNING (User provided step: 4821 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960290.9725287}).
Env Football Algo jrpo Exp base_JRPO updates 4821/100000000000.0 steps in 87.31
total episode rewards is -40.0
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'value_loss': 0.3027364749818419, '_timestamp': 1721960368.7749372}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0014168909522413742, '_timestamp': 1721960368.7751145}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.862378832499186, '_timestamp': 1721960368.7751892}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13545581698417664, '_timestamp': 1721960368.775281}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.25910964608192444, '_timestamp': 1721960368.7755346}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'ratio': 1.0012614727020264, '_timestamp': 1721960368.7756531}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960368.7757823}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960368.7760239}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.80143928527832, '_timestamp': 1721960368.776085}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.19847174743615523, '_timestamp': 1721960368.7766316}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'train_goal': 0.5992358737180776, '_timestamp': 1721960368.7769675}).
wandb: WARNING (User provided step: 10007 is less than current step: 12030. Dropping entry: {'train_WDL': 0.19847174743615523, '_timestamp': 1721960368.7772987}).
Env Football Algo jrpo Exp base_JRPO updates 10007/100000000000.0 steps in 77.80
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 8845/100000000000.0 steps in 87.42
total episode rewards is -20.0
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'value_loss': 0.23831646250929528, '_timestamp': 1721960456.1985698}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004152769075978237, '_timestamp': 1721960456.1987238}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871236604054769, '_timestamp': 1721960456.1987884}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14117316901683807, '_timestamp': 1721960456.1988785}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14812970161437988, '_timestamp': 1721960456.1991115}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'ratio': 1.0014551877975464, '_timestamp': 1721960456.1992135}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721960456.199332}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960456.1994257}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.42026114463806, '_timestamp': 1721960456.1994858}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.028107229894394802, '_timestamp': 1721960456.200052}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'train_goal': 0.4859463850528026, '_timestamp': 1721960456.2004337}).
wandb: WARNING (User provided step: 8845 is less than current step: 12030. Dropping entry: {'train_WDL': -0.028107229894394802, '_timestamp': 1721960456.200823}).
Env Football Algo jrpo Exp base_JRPO updates 4647/100000000000.0 steps in 48.22
total episode rewards is -90.0
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'value_loss': 0.524576360049347, '_timestamp': 1721960504.4197028}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011642751435283572, '_timestamp': 1721960504.4198625}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871935567855835, '_timestamp': 1721960504.4199295}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14614377915859222, '_timestamp': 1721960504.42004}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7200295925140381, '_timestamp': 1721960504.4202898}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'ratio': 0.9996803998947144, '_timestamp': 1721960504.4203908}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721960504.4205115}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960504.421107}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'Episode_Time': 48.218149185180664, '_timestamp': 1721960504.4211683}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960504.4215386}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960504.4218004}).
wandb: WARNING (User provided step: 4647 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960504.422068}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'value_loss': 0.5472230492966871, '_timestamp': 1721960567.912533}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0024868265135834615, '_timestamp': 1721960567.91271}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8760098679860433, '_timestamp': 1721960567.9127777}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14660394191741943, '_timestamp': 1721960567.912877}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6400392055511475, '_timestamp': 1721960567.913103}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'ratio': 0.9984809756278992, '_timestamp': 1721960567.9132032}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721960567.9134645}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960567.913562}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.4896342754364, '_timestamp': 1721960567.9136193}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960567.9140959}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960567.9144387}).
wandb: WARNING (User provided step: 4540 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960567.9147859}).
Env Football Algo jrpo Exp base_JRPO updates 4540/100000000000.0 steps in 63.49
total episode rewards is -90.0
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'value_loss': 0.2528572436918815, '_timestamp': 1721960649.2193525}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'policy_loss': 2.6723193004727365e-05, '_timestamp': 1721960649.2207544}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8841119464238485, '_timestamp': 1721960649.220837}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13184405863285065, '_timestamp': 1721960649.2214599}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1205189898610115, '_timestamp': 1721960649.2218566}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'ratio': 1.0011166334152222, '_timestamp': 1721960649.2219632}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721960649.2222252}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960649.222433}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.29847288131714, '_timestamp': 1721960649.2232227}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.08880073237717424, '_timestamp': 1721960649.225019}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'train_goal': 0.4555996338114129, '_timestamp': 1721960649.2254834}).
wandb: WARNING (User provided step: 8446 is less than current step: 12030. Dropping entry: {'train_WDL': -0.08880073237717424, '_timestamp': 1721960649.2262049}).
Env Football Algo jrpo Exp base_JRPO updates 8446/100000000000.0 steps in 81.30
total episode rewards is -20.0
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'value_loss': 0.4898605615521471, '_timestamp': 1721960733.9483583}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0023232528973797647, '_timestamp': 1721960733.948607}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8854816166559853, '_timestamp': 1721960733.948674}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14198900759220123, '_timestamp': 1721960733.948768}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3590439558029175, '_timestamp': 1721960733.9490051}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'ratio': 1.000118374824524, '_timestamp': 1721960733.9491036}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721960733.94968}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960733.9497712}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.72117590904236, '_timestamp': 1721960733.9498286}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960733.9505067}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960733.951012}).
wandb: WARNING (User provided step: 4559 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960733.9515457}).
Env Football Algo jrpo Exp base_JRPO updates 4559/100000000000.0 steps in 84.72
total episode rewards is -70.0
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'value_loss': 0.27087675319751725, '_timestamp': 1721960821.919162}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0036837045409871885, '_timestamp': 1721960821.9193337}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.885856393178304, '_timestamp': 1721960821.9193997}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14721882343292236, '_timestamp': 1721960821.919494}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1082676500082016, '_timestamp': 1721960821.9197664}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'ratio': 1.0006282329559326, '_timestamp': 1721960821.9198694}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721960821.9200258}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960821.920119}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.96676445007324, '_timestamp': 1721960821.9204755}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.5446815894499393, '_timestamp': 1721960821.9213467}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'train_goal': 0.7723407947249696, '_timestamp': 1721960821.9220064}).
wandb: WARNING (User provided step: 3474 is less than current step: 12030. Dropping entry: {'train_WDL': 0.5446815894499393, '_timestamp': 1721960821.9226685}).
Env Football Algo jrpo Exp base_JRPO updates 3474/100000000000.0 steps in 87.97
total episode rewards is 20.0
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'value_loss': 0.25147015957937885, '_timestamp': 1721960903.2701986}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001076956008085593, '_timestamp': 1721960903.2703674}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.889952114423116, '_timestamp': 1721960903.2704341}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12327691912651062, '_timestamp': 1721960903.270529}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.23536039888858795, '_timestamp': 1721960903.2707922}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'ratio': 0.9979888200759888, '_timestamp': 1721960903.2708917}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960903.271064}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960903.27116}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.34627318382263, '_timestamp': 1721960903.2712164}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960903.2719905}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960903.272407}).
wandb: WARNING (User provided step: 8785 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960903.2728267}).
Env Football Algo jrpo Exp base_JRPO updates 8785/100000000000.0 steps in 81.35
total episode rewards is -40.0
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'value_loss': 0.27186470796975, '_timestamp': 1721960992.239352}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0017908146496241292, '_timestamp': 1721960992.2395222}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.892232343355815, '_timestamp': 1721960992.2395895}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1336723417043686, '_timestamp': 1721960992.2396839}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3507581055164337, '_timestamp': 1721960992.2399375}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'ratio': 0.9996500611305237, '_timestamp': 1721960992.2400544}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960992.240194}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960992.2405958}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.96569204330444, '_timestamp': 1721960992.2406616}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960992.2413044}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960992.242179}).
wandb: WARNING (User provided step: 6206 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960992.24272}).
Env Football Algo jrpo Exp base_JRPO updates 6206/100000000000.0 steps in 88.97
total episode rewards is -40.0
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'value_loss': 0.23355367650277914, '_timestamp': 1721961081.8056376}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0004911169953023393, '_timestamp': 1721961081.8058074}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.891579858462016, '_timestamp': 1721961081.805875}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14021152257919312, '_timestamp': 1721961081.805973}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.31242185831069946, '_timestamp': 1721961081.806227}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'ratio': 1.0005251169204712, '_timestamp': 1721961081.8063276}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721961081.8066719}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961081.8067684}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.56208729743958, '_timestamp': 1721961081.8068266}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961081.8073173}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961081.8077047}).
wandb: WARNING (User provided step: 9089 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961081.8081272}).
Env Football Algo jrpo Exp base_JRPO updates 9089/100000000000.0 steps in 89.56
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4208/100000000000.0 steps in 85.02
total episode rewards is -20.0
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'value_loss': 0.26784475638220706, '_timestamp': 1721961166.8308268}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0027388846524991095, '_timestamp': 1721961166.8309896}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.891364822387695, '_timestamp': 1721961166.8310559}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1335781067609787, '_timestamp': 1721961166.831147}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.11607509851455688, '_timestamp': 1721961166.8314137}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'ratio': 0.9997892379760742, '_timestamp': 1721961166.8315146}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961166.8316543}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961166.831746}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.02190709114075, '_timestamp': 1721961166.8322957}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4503335804299481, '_timestamp': 1721961166.83306}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'train_goal': 0.27483320978502596, '_timestamp': 1721961166.8336709}).
wandb: WARNING (User provided step: 4208 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4503335804299481, '_timestamp': 1721961166.8342988}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'value_loss': 0.22615763273711006, '_timestamp': 1721961255.6408014}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003554215791809838, '_timestamp': 1721961255.640999}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8865010150273642, '_timestamp': 1721961255.6410704}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1307365745306015, '_timestamp': 1721961255.641176}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21684293448925018, '_timestamp': 1721961255.6414766}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'ratio': 0.9994732737541199, '_timestamp': 1721961255.6415818}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721961255.6425412}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961255.6426463}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.79196429252625, '_timestamp': 1721961255.6427062}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.24932423735358475, '_timestamp': 1721961255.6433718}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'train_goal': 0.3753378813232076, '_timestamp': 1721961255.644238}).
wandb: WARNING (User provided step: 7231 is less than current step: 12030. Dropping entry: {'train_WDL': -0.24932423735358475, '_timestamp': 1721961255.6447434}).
Env Football Algo jrpo Exp base_JRPO updates 7231/100000000000.0 steps in 88.79
total episode rewards is -10.0
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'value_loss': 0.6591605111335714, '_timestamp': 1721961307.6453283}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0038016241511407618, '_timestamp': 1721961307.645514}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.885769747098287, '_timestamp': 1721961307.6455824}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14666806161403656, '_timestamp': 1721961307.6456838}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9066888689994812, '_timestamp': 1721961307.6459608}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'ratio': 0.9998089075088501, '_timestamp': 1721961307.6460643}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721961307.6462054}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961307.6463068}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.99964213371277, '_timestamp': 1721961307.646366}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.41236722306525037, '_timestamp': 1721961307.647379}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'train_goal': 0.2938163884673748, '_timestamp': 1721961307.647744}).
wandb: WARNING (User provided step: 2518 is less than current step: 12030. Dropping entry: {'train_WDL': -0.41236722306525037, '_timestamp': 1721961307.648126}).
Env Football Algo jrpo Exp base_JRPO updates 2518/100000000000.0 steps in 52.00
total episode rewards is -80.0
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'value_loss': 0.24926411809011673, '_timestamp': 1721961396.5594602}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008198310158525905, '_timestamp': 1721961396.559627}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8848341353734335, '_timestamp': 1721961396.559694}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13524261116981506, '_timestamp': 1721961396.5597906}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19894611835479736, '_timestamp': 1721961396.5600836}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'ratio': 1.0008429288864136, '_timestamp': 1721961396.5601926}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961396.5603387}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961396.5608397}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.91055011749268, '_timestamp': 1721961396.5609012}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3492133835586085, '_timestamp': 1721961396.561586}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'train_goal': 0.3253933082206958, '_timestamp': 1721961396.5621066}).
wandb: WARNING (User provided step: 5974 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3492133835586085, '_timestamp': 1721961396.5626447}).
Env Football Algo jrpo Exp base_JRPO updates 5974/100000000000.0 steps in 88.91
total episode rewards is -20.0
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'value_loss': 0.25359728749589217, '_timestamp': 1721961487.9186938}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005205427079151074, '_timestamp': 1721961487.918873}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8810937468210858, '_timestamp': 1721961487.9189396}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1311895102262497, '_timestamp': 1721961487.9190347}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1809309870004654, '_timestamp': 1721961487.919309}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'ratio': 1.0001521110534668, '_timestamp': 1721961487.9194145}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721961487.9195626}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961487.9196594}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.35520029067993, '_timestamp': 1721961487.9197161}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961487.9210906}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961487.9217582}).
wandb: WARNING (User provided step: 8135 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961487.9224465}).
Env Football Algo jrpo Exp base_JRPO updates 8135/100000000000.0 steps in 91.36
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4329/100000000000.0 steps in 45.53
total episode rewards is -110.0
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'value_loss': 0.6531950847245753, '_timestamp': 1721961533.4554136}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0012634188130808373, '_timestamp': 1721961533.455582}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8802163871129354, '_timestamp': 1721961533.455648}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14714519679546356, '_timestamp': 1721961533.455743}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7757830619812012, '_timestamp': 1721961533.45602}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'ratio': 0.9993606805801392, '_timestamp': 1721961533.4561267}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721961533.4562802}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961533.456568}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'Episode_Time': 45.532127380371094, '_timestamp': 1721961533.4566317}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961533.4569588}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961533.4571877}).
wandb: WARNING (User provided step: 4329 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961533.457398}).
Env Football Algo jrpo Exp base_JRPO updates 9666/100000000000.0 steps in 81.48
total episode rewards is -80.0
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'value_loss': 0.4600591816039135, '_timestamp': 1721961614.9351456}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013457084030960686, '_timestamp': 1721961614.9353254}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.873989338874817, '_timestamp': 1721961614.9353921}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14112432301044464, '_timestamp': 1721961614.9354875}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.48006415367126465, '_timestamp': 1721961614.9357517}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'ratio': 0.9994545578956604, '_timestamp': 1721961614.935852}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721961614.9360096}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961614.9363081}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.47673416137695, '_timestamp': 1721961614.9363685}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961614.936882}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961614.9371846}).
wandb: WARNING (User provided step: 9666 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961614.9374878}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'value_loss': 0.6772251283501586, '_timestamp': 1721961674.3663118}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005083594750612974, '_timestamp': 1721961674.3665204}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8755860805511473, '_timestamp': 1721961674.3665905}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14849360287189484, '_timestamp': 1721961674.3666918}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.665285587310791, '_timestamp': 1721961674.3669558}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'ratio': 0.9993986487388611, '_timestamp': 1721961674.3670607}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721961674.3673072}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961674.3678114}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.42774295806885, '_timestamp': 1721961674.367876}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.25849094976611753, '_timestamp': 1721961674.3696046}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'train_goal': 0.37075452511694124, '_timestamp': 1721961674.3700159}).
wandb: WARNING (User provided step: 4263 is less than current step: 12030. Dropping entry: {'train_WDL': -0.25849094976611753, '_timestamp': 1721961674.3705215}).
Env Football Algo jrpo Exp base_JRPO updates 4263/100000000000.0 steps in 59.43
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 7641/100000000000.0 steps in 81.54
total episode rewards is -50.0
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'value_loss': 0.42685788867374264, '_timestamp': 1721961755.920174}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005771888413776954, '_timestamp': 1721961755.9213743}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.872352153460185, '_timestamp': 1721961755.9214482}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14700601994991302, '_timestamp': 1721961755.9219928}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.45669540762901306, '_timestamp': 1721961755.922404}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'ratio': 0.9998168349266052, '_timestamp': 1721961755.9225109}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721961755.922687}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961755.9235768}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.54390215873718, '_timestamp': 1721961755.9236388}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.03228285933897002, '_timestamp': 1721961755.9249666}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'train_goal': 0.483858570330515, '_timestamp': 1721961755.9253633}).
wandb: WARNING (User provided step: 7641 is less than current step: 12030. Dropping entry: {'train_WDL': -0.03228285933897002, '_timestamp': 1721961755.9257352}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'value_loss': 0.2576648173760623, '_timestamp': 1721961837.499846}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016874055552762001, '_timestamp': 1721961837.500052}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8678108739852903, '_timestamp': 1721961837.50012}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1452718824148178, '_timestamp': 1721961837.5002127}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13478553295135498, '_timestamp': 1721961837.5004587}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'ratio': 1.00121009349823, '_timestamp': 1721961837.5005577}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721961837.5010028}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961837.5010986}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.57288932800293, '_timestamp': 1721961837.5011568}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961837.501886}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961837.5024004}).
wandb: WARNING (User provided step: 6120 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961837.5032666}).
Env Football Algo jrpo Exp base_JRPO updates 6120/100000000000.0 steps in 81.57
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5110/100000000000.0 steps in 80.51
total episode rewards is -40.0
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'value_loss': 0.402033881735988, '_timestamp': 1721961918.0131204}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0024641219458620372, '_timestamp': 1721961918.0132897}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.872195504506429, '_timestamp': 1721961918.013364}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1474020630121231, '_timestamp': 1721961918.0134592}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5227712988853455, '_timestamp': 1721961918.0137122}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'ratio': 0.9993051290512085, '_timestamp': 1721961918.0138144}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721961918.0141642}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961918.0142581}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.50893378257751, '_timestamp': 1721961918.0143178}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.35413771320277954, '_timestamp': 1721961918.0149093}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'train_goal': 0.32293114339861023, '_timestamp': 1721961918.0157542}).
wandb: WARNING (User provided step: 5110 is less than current step: 12030. Dropping entry: {'train_WDL': -0.35413771320277954, '_timestamp': 1721961918.016251}).
Env Football Algo jrpo Exp base_JRPO updates 10619/100000000000.0 steps in 79.93
total episode rewards is -20.0
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'value_loss': 0.1284645267793288, '_timestamp': 1721961997.9486327}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013408152984144787, '_timestamp': 1721961997.948797}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8768046220143635, '_timestamp': 1721961997.9488635}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12419900298118591, '_timestamp': 1721961997.9489584}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18695874512195587, '_timestamp': 1721961997.9492097}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'ratio': 0.9996934533119202, '_timestamp': 1721961997.9493158}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961997.94969}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961997.9497817}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.93142127990723, '_timestamp': 1721961997.9498382}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961997.9502456}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961997.9505427}).
wandb: WARNING (User provided step: 10619 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961997.9508495}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'value_loss': 0.27154179135958356, '_timestamp': 1721962082.8488483}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0004445679562437969, '_timestamp': 1721962082.8490055}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.876721607844035, '_timestamp': 1721962082.8490715}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13606451451778412, '_timestamp': 1721962082.849164}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.36617788672447205, '_timestamp': 1721962082.8493974}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'ratio': 1.0006747245788574, '_timestamp': 1721962082.8494985}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962082.8498297}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962082.8499215}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.89712119102478, '_timestamp': 1721962082.8499773}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962082.8504548}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962082.8508325}).
wandb: WARNING (User provided step: 8981 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962082.851227}).
Env Football Algo jrpo Exp base_JRPO updates 8981/100000000000.0 steps in 84.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'value_loss': 0.49680661582698427, '_timestamp': 1721962147.1984978}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004053834549073751, '_timestamp': 1721962147.1986604}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8775123230616253, '_timestamp': 1721962147.1987257}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1366475522518158, '_timestamp': 1721962147.19882}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5203172564506531, '_timestamp': 1721962147.19906}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'ratio': 1.0014855861663818, '_timestamp': 1721962147.199164}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721962147.1994112}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962147.1995027}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.34611797332764, '_timestamp': 1721962147.1995595}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962147.1999962}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962147.2003272}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962147.200662}).
Env Football Algo jrpo Exp base_JRPO updates 4892/100000000000.0 steps in 64.35
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 5475/100000000000.0 steps in 80.78
total episode rewards is -40.0
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'value_loss': 0.23948047925562907, '_timestamp': 1721962227.9812071}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009944856457489853, '_timestamp': 1721962227.981388}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.876413647333781, '_timestamp': 1721962227.9814718}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1330898255109787, '_timestamp': 1721962227.9815829}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17649997770786285, '_timestamp': 1721962227.9818873}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'ratio': 1.0002703666687012, '_timestamp': 1721962227.9820132}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962227.9825354}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962227.9826458}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.77950167655945, '_timestamp': 1721962227.9827163}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962227.983423}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962227.9839861}).
wandb: WARNING (User provided step: 5475 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962227.9845614}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'value_loss': 0.33271517327986655, '_timestamp': 1721962291.0956097}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002114170496352017, '_timestamp': 1721962291.095759}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8724026044209796, '_timestamp': 1721962291.0958245}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1506742686033249, '_timestamp': 1721962291.0959117}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.30569228529930115, '_timestamp': 1721962291.0961664}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'ratio': 1.001217007637024, '_timestamp': 1721962291.096264}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721962291.0963902}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962291.0965812}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.11033535003662, '_timestamp': 1721962291.0966384}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962291.0971284}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962291.0975323}).
wandb: WARNING (User provided step: 3949 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962291.0979428}).
Env Football Algo jrpo Exp base_JRPO updates 3949/100000000000.0 steps in 63.11
total episode rewards is -50.0
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'value_loss': 0.7754602021972339, '_timestamp': 1721962343.806875}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'policy_loss': -0.000695166745960402, '_timestamp': 1721962343.8070288}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.875283473332723, '_timestamp': 1721962343.8070977}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1465207189321518, '_timestamp': 1721962343.8071902}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7899323105812073, '_timestamp': 1721962343.8074327}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'ratio': 1.0025358200073242, '_timestamp': 1721962343.807536}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721962343.807917}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962343.8080258}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.704702377319336, '_timestamp': 1721962343.8080854}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962343.808457}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962343.8087506}).
wandb: WARNING (User provided step: 5061 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962343.809043}).
Env Football Algo jrpo Exp base_JRPO updates 5061/100000000000.0 steps in 52.70
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 8189/100000000000.0 steps in 90.62
total episode rewards is -40.0
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'value_loss': 0.2586619228978331, '_timestamp': 1721962434.4339547}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0019278583225483695, '_timestamp': 1721962434.4342146}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8767292308807373, '_timestamp': 1721962434.4342835}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13179054856300354, '_timestamp': 1721962434.4343865}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17249824106693268, '_timestamp': 1721962434.4346664}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'ratio': 1.000631332397461, '_timestamp': 1721962434.4347672}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962434.4350057}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962434.4356601}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.62381196022034, '_timestamp': 1721962434.4357224}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962434.4366715}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962434.4371448}).
wandb: WARNING (User provided step: 8189 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962434.4375904}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'value_loss': 0.2960138253180776, '_timestamp': 1721962517.2245715}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0014226762291703683, '_timestamp': 1721962517.2258668}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8750882053375246, '_timestamp': 1721962517.22594}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1357874572277069, '_timestamp': 1721962517.226534}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1347540020942688, '_timestamp': 1721962517.2269154}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'ratio': 1.000125765800476, '_timestamp': 1721962517.2277014}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721962517.2278504}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962517.2280865}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.78092217445374, '_timestamp': 1721962517.2281458}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962517.2292864}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962517.229787}).
wandb: WARNING (User provided step: 7788 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962517.2302825}).
Env Football Algo jrpo Exp base_JRPO updates 7788/100000000000.0 steps in 82.78
total episode rewards is -50.0
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'value_loss': 0.4882926966125766, '_timestamp': 1721962581.8447516}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0025117743015289308, '_timestamp': 1721962581.8449383}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.870988260904948, '_timestamp': 1721962581.8450093}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.149447962641716, '_timestamp': 1721962581.8451164}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6050453186035156, '_timestamp': 1721962581.8453526}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'ratio': 0.9999615550041199, '_timestamp': 1721962581.8462117}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721962581.846358}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962581.8464596}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'Episode_Time': 64.61344599723816, '_timestamp': 1721962581.8465188}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962581.847004}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962581.847358}).
wandb: WARNING (User provided step: 5206 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962581.8476946}).
Env Football Algo jrpo Exp base_JRPO updates 5206/100000000000.0 steps in 64.61
total episode rewards is -80.0
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'value_loss': 0.2554701031558216, '_timestamp': 1721962665.6827905}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003917054116269961, '_timestamp': 1721962665.6839726}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8717331457138062, '_timestamp': 1721962665.684042}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1404590755701065, '_timestamp': 1721962665.6846244}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.29383230209350586, '_timestamp': 1721962665.685294}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'ratio': 1.0007071495056152, '_timestamp': 1721962665.6855752}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962665.6857393}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962665.6859334}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.82952761650085, '_timestamp': 1721962665.6859934}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962665.6871536}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962665.6876912}).
wandb: WARNING (User provided step: 6801 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962665.6883051}).
Env Football Algo jrpo Exp base_JRPO updates 6801/100000000000.0 steps in 83.83
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 7863/100000000000.0 steps in 77.44
total episode rewards is -50.0
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'value_loss': 0.30539800753506524, '_timestamp': 1721962743.1331768}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005224051990468676, '_timestamp': 1721962743.1333625}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.863761404355367, '_timestamp': 1721962743.1334298}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14030151069164276, '_timestamp': 1721962743.1335285}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2617684304714203, '_timestamp': 1721962743.1338081}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'ratio': 0.999459445476532, '_timestamp': 1721962743.1344833}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721962743.1346333}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962743.1347303}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.44388842582703, '_timestamp': 1721962743.1347876}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962743.1352508}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962743.135602}).
wandb: WARNING (User provided step: 7863 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962743.1359398}).
Env Football Algo jrpo Exp base_JRPO updates 5949/100000000000.0 steps in 89.29
total episode rewards is -40.0
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'value_loss': 0.25968385948062256, '_timestamp': 1721962832.4384782}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0038968928179626042, '_timestamp': 1721962832.4386585}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8606809997558593, '_timestamp': 1721962832.4387264}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13024753332138062, '_timestamp': 1721962832.438825}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.33479252457618713, '_timestamp': 1721962832.4390879}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'ratio': 0.9998890161514282, '_timestamp': 1721962832.4399073}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962832.44406}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962832.4441671}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.29222226142883, '_timestamp': 1721962832.4442315}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962832.4451225}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962832.4456754}).
wandb: WARNING (User provided step: 5949 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962832.446238}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'value_loss': 0.19319955738067315, '_timestamp': 1721962916.6280267}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004349488214744876, '_timestamp': 1721962916.6282053}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.861817145347595, '_timestamp': 1721962916.6282735}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1266956776380539, '_timestamp': 1721962916.6283722}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.08234553784132004, '_timestamp': 1721962916.6286333}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'ratio': 1.0009548664093018, '_timestamp': 1721962916.6292713}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721962916.6294148}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962916.629511}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.18073272705078, '_timestamp': 1721962916.6295667}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962916.6301622}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962916.630581}).
wandb: WARNING (User provided step: 8385 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962916.6310031}).
Env Football Algo jrpo Exp base_JRPO updates 8385/100000000000.0 steps in 84.18
total episode rewards is -30.0
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'value_loss': 0.2873058367605942, '_timestamp': 1721963004.639849}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0051472238134980825, '_timestamp': 1721963004.6400306}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.862577344576518, '_timestamp': 1721963004.6401033}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13470801711082458, '_timestamp': 1721963004.640198}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3152504563331604, '_timestamp': 1721963004.6404607}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'ratio': 0.9996398091316223, '_timestamp': 1721963004.6411965}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721963004.6413403}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963004.6414347}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.00801920890808, '_timestamp': 1721963004.6414936}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3231814454726485, '_timestamp': 1721963004.6421309}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'train_goal': 0.33840927726367576, '_timestamp': 1721963004.6426404}).
wandb: WARNING (User provided step: 6463 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3231814454726485, '_timestamp': 1721963004.6431668}).
Env Football Algo jrpo Exp base_JRPO updates 6463/100000000000.0 steps in 88.01
total episode rewards is -20.0
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'value_loss': 0.25235158593781915, '_timestamp': 1721963092.6760633}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005083932919660583, '_timestamp': 1721963092.6762745}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8541207710901895, '_timestamp': 1721963092.676366}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14083491265773773, '_timestamp': 1721963092.676468}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16026221215724945, '_timestamp': 1721963092.6767695}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'ratio': 1.0000249147415161, '_timestamp': 1721963092.6769137}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963092.6777804}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963092.6778877}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.0316743850708, '_timestamp': 1721963092.677947}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963092.6785438}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963092.6790116}).
wandb: WARNING (User provided step: 7973 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963092.6794765}).
Env Football Algo jrpo Exp base_JRPO updates 7973/100000000000.0 steps in 88.03
total episode rewards is -30.0
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'value_loss': 0.18904646861405733, '_timestamp': 1721963179.0103998}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001048804547948142, '_timestamp': 1721963179.0106268}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.857317719459534, '_timestamp': 1721963179.0106988}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12602484226226807, '_timestamp': 1721963179.0107987}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3279254138469696, '_timestamp': 1721963179.011023}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'ratio': 0.9994633197784424, '_timestamp': 1721963179.0118985}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963179.012064}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963179.0121593}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.32721257209778, '_timestamp': 1721963179.0122159}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963179.0128174}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963179.0132372}).
wandb: WARNING (User provided step: 8478 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963179.0173504}).
Env Football Algo jrpo Exp base_JRPO updates 8478/100000000000.0 steps in 86.33
total episode rewards is -30.0
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'value_loss': 0.2943606743298005, '_timestamp': 1721963270.1730092}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004813911399105563, '_timestamp': 1721963270.1732008}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8564229599634805, '_timestamp': 1721963270.1732688}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13317714631557465, '_timestamp': 1721963270.173362}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.26970064640045166, '_timestamp': 1721963270.1736207}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'ratio': 1.0006306171417236, '_timestamp': 1721963270.1737242}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963270.1744244}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963270.1745229}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.1546106338501, '_timestamp': 1721963270.1745808}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963270.175424}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963270.1758788}).
wandb: WARNING (User provided step: 8141 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963270.1763694}).
Env Football Algo jrpo Exp base_JRPO updates 8141/100000000000.0 steps in 91.15
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6899/100000000000.0 steps in 83.26
total episode rewards is -20.0
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'value_loss': 0.28737595051759857, '_timestamp': 1721963353.441667}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0016835933454179516, '_timestamp': 1721963353.4418342}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.851530111630758, '_timestamp': 1721963353.4419081}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1351490318775177, '_timestamp': 1721963353.4420002}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35928791761398315, '_timestamp': 1721963353.4422438}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'ratio': 1.001691460609436, '_timestamp': 1721963353.4423604}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721963353.4427927}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963353.4428873}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.26444292068481, '_timestamp': 1721963353.442946}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3714356252314529, '_timestamp': 1721963353.4435441}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'train_goal': 0.31428218738427355, '_timestamp': 1721963353.4440541}).
wandb: WARNING (User provided step: 6899 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3714356252314529, '_timestamp': 1721963353.4445531}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'value_loss': 0.8359014026820659, '_timestamp': 1721963386.0890505}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00280078323657411, '_timestamp': 1721963386.0892017}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8532700459162395, '_timestamp': 1721963386.0892677}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1545778512954712, '_timestamp': 1721963386.0893557}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9565727710723877, '_timestamp': 1721963386.089579}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'ratio': 1.000558853149414, '_timestamp': 1721963386.0896754}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721963386.0898066}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963386.0898952}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'Episode_Time': 32.6436722278595, '_timestamp': 1721963386.0899503}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963386.0901637}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963386.0903046}).
wandb: WARNING (User provided step: 2812 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963386.0904443}).
Env Football Algo jrpo Exp base_JRPO updates 2812/100000000000.0 steps in 32.64
total episode rewards is -120.0
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'value_loss': 0.6165964146951834, '_timestamp': 1721963446.1033878}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0035210676107089965, '_timestamp': 1721963446.1037648}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8533971611658733, '_timestamp': 1721963446.1038675}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15612763166427612, '_timestamp': 1721963446.1040235}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7926586866378784, '_timestamp': 1721963446.1043718}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'ratio': 0.9996541738510132, '_timestamp': 1721963446.1045232}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721963446.1055958}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963446.1057208}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.01178979873657, '_timestamp': 1721963446.1057844}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.24394184168012925, '_timestamp': 1721963446.106735}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'train_goal': 0.6219709208400647, '_timestamp': 1721963446.107643}).
wandb: WARNING (User provided step: 3495 is less than current step: 12030. Dropping entry: {'train_WDL': 0.24394184168012925, '_timestamp': 1721963446.1081095}).
Env Football Algo jrpo Exp base_JRPO updates 3495/100000000000.0 steps in 60.01
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 4401/100000000000.0 steps in 59.72
total episode rewards is -70.0
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'value_loss': 0.5614883586764335, '_timestamp': 1721963505.8270938}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0024988698585305734, '_timestamp': 1721963505.8272734}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8535284678141277, '_timestamp': 1721963505.8273404}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1607244461774826, '_timestamp': 1721963505.827438}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.584132730960846, '_timestamp': 1721963505.8277087}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'ratio': 0.9985643625259399, '_timestamp': 1721963505.827817}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721963505.8279674}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963505.8287027}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.71790599822998, '_timestamp': 1721963505.8287635}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.19980764606876653, '_timestamp': 1721963505.8291893}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'train_goal': 0.4000961769656167, '_timestamp': 1721963505.8294892}).
wandb: WARNING (User provided step: 4401 is less than current step: 12030. Dropping entry: {'train_WDL': -0.19980764606876653, '_timestamp': 1721963505.8297896}).
Env Football Algo jrpo Exp base_JRPO updates 7135/100000000000.0 steps in 86.11
total episode rewards is -10.0
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'value_loss': 0.2120093546419715, '_timestamp': 1721963591.9452841}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0004729342427647983, '_timestamp': 1721963591.9454832}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8531024662653603, '_timestamp': 1721963591.9455545}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13929857313632965, '_timestamp': 1721963591.9456587}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16138118505477905, '_timestamp': 1721963591.9459462}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'ratio': 1.0011414289474487, '_timestamp': 1721963591.9460478}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721963591.9469376}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963591.9470458}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.11289072036743, '_timestamp': 1721963591.9471028}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.24297520661157024, '_timestamp': 1721963591.947917}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'train_goal': 0.3785123966942149, '_timestamp': 1721963591.948433}).
wandb: WARNING (User provided step: 7135 is less than current step: 12030. Dropping entry: {'train_WDL': -0.24297520661157024, '_timestamp': 1721963591.9489162}).
Env Football Algo jrpo Exp base_JRPO updates 9406/100000000000.0 steps in 87.10
total episode rewards is -50.0
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'value_loss': 0.31315709387534296, '_timestamp': 1721963679.0548902}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022782954712359544, '_timestamp': 1721963679.0550766}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.85321991443634, '_timestamp': 1721963679.0551457}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15569210052490234, '_timestamp': 1721963679.055241}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2294478863477707, '_timestamp': 1721963679.0554838}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'ratio': 1.0002553462982178, '_timestamp': 1721963679.0555859}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721963679.055811}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963679.0560772}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.10490274429321, '_timestamp': 1721963679.056135}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963679.056883}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963679.0572178}).
wandb: WARNING (User provided step: 9406 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963679.0575633}).
Env Football Algo jrpo Exp base_JRPO updates 10372/100000000000.0 steps in 90.97
total episode rewards is -40.0
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'value_loss': 0.2404780950595159, '_timestamp': 1721963770.0294263}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013589126314036547, '_timestamp': 1721963770.0296016}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8442693106333414, '_timestamp': 1721963770.0296714}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12475693970918655, '_timestamp': 1721963770.0297728}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3814525306224823, '_timestamp': 1721963770.030056}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'ratio': 0.999725878238678, '_timestamp': 1721963770.0301588}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963770.0303032}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963770.0303986}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.96882152557373, '_timestamp': 1721963770.0304575}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963770.0310261}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963770.031351}).
wandb: WARNING (User provided step: 10372 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963770.0316732}).
Env Football Algo jrpo Exp base_JRPO updates 7436/100000000000.0 steps in 85.87
total episode rewards is -40.0
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'value_loss': 0.2771070760721341, '_timestamp': 1721963855.9030273}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013032552499013643, '_timestamp': 1721963855.9033003}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8374544541041056, '_timestamp': 1721963855.9033692}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14656002819538116, '_timestamp': 1721963855.903593}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.34472596645355225, '_timestamp': 1721963855.9042258}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'ratio': 0.9991213083267212, '_timestamp': 1721963855.9043424}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963855.904646}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963855.9054856}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.86978316307068, '_timestamp': 1721963855.905546}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963855.906537}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963855.9070358}).
wandb: WARNING (User provided step: 7436 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963855.907548}).
Env Football Algo jrpo Exp base_JRPO updates 8706/100000000000.0 steps in 86.31
total episode rewards is -40.0
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'value_loss': 0.2647709421424467, '_timestamp': 1721963942.218456}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001810057705345874, '_timestamp': 1721963942.218599}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8408344650268553, '_timestamp': 1721963942.218663}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1431366354227066, '_timestamp': 1721963942.2187474}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.23207645118236542, '_timestamp': 1721963942.2189834}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'ratio': 1.0002422332763672, '_timestamp': 1721963942.2191806}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963942.219313}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963942.2193992}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.3098828792572, '_timestamp': 1721963942.219455}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963942.219973}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963942.2203715}).
wandb: WARNING (User provided step: 8706 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963942.2207758}).
Env Football Algo jrpo Exp base_JRPO updates 7639/100000000000.0 steps in 86.42
total episode rewards is -40.0
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'value_loss': 0.2636798022782508, '_timestamp': 1721964028.6421716}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009134817744294802, '_timestamp': 1721964028.642335}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.841894327799479, '_timestamp': 1721964028.642401}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13504837453365326, '_timestamp': 1721964028.642492}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.243046373128891, '_timestamp': 1721964028.6427295}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'ratio': 0.998711884021759, '_timestamp': 1721964028.6428282}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721964028.6429574}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964028.6433258}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.42063927650452, '_timestamp': 1721964028.6433833}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964028.6439388}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964028.64439}).
wandb: WARNING (User provided step: 7639 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964028.644847}).
Env Football Algo jrpo Exp base_JRPO updates 6036/100000000000.0 steps in 84.62
total episode rewards is -20.0
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'value_loss': 0.2809600107911198, '_timestamp': 1721964113.2695801}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0009928419984256227, '_timestamp': 1721964113.2697704}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.848531136512756, '_timestamp': 1721964113.2698414}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14220543205738068, '_timestamp': 1721964113.269944}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2779689431190491, '_timestamp': 1721964113.2703013}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'ratio': 1.0008740425109863, '_timestamp': 1721964113.2708354}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964113.271062}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964113.2711594}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.6236617565155, '_timestamp': 1721964113.2712162}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3525211958946899, '_timestamp': 1721964113.2719724}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'train_goal': 0.32373940205265506, '_timestamp': 1721964113.272556}).
wandb: WARNING (User provided step: 6036 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3525211958946899, '_timestamp': 1721964113.2730958}).
Env Football Algo jrpo Exp base_JRPO updates 6920/100000000000.0 steps in 89.29
total episode rewards is -40.0
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'value_loss': 0.23682472060531534, '_timestamp': 1721964202.5706506}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'policy_loss': -0.000785156896066231, '_timestamp': 1721964202.572114}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8563940048217775, '_timestamp': 1721964202.572229}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1356559842824936, '_timestamp': 1721964202.5728827}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12429701536893845, '_timestamp': 1721964202.573324}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'ratio': 0.9974690079689026, '_timestamp': 1721964202.5734465}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721964202.5742855}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964202.574838}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.29111099243164, '_timestamp': 1721964202.5749023}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964202.5763004}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964202.5769186}).
wandb: WARNING (User provided step: 6920 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964202.5774715}).
Env Football Algo jrpo Exp base_JRPO updates 6118/100000000000.0 steps in 87.00
total episode rewards is -40.0
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'value_loss': 0.2640811313092126, '_timestamp': 1721964289.5768845}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004059832113222607, '_timestamp': 1721964289.5771}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8566725047429404, '_timestamp': 1721964289.5771692}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14381389319896698, '_timestamp': 1721964289.5772698}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.26262912154197693, '_timestamp': 1721964289.5775304}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'ratio': 0.9994057416915894, '_timestamp': 1721964289.5776293}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721964289.5777638}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964289.5778573}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.99783444404602, '_timestamp': 1721964289.577914}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964289.5786166}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964289.579131}).
wandb: WARNING (User provided step: 6118 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964289.5796764}).
Env Football Algo jrpo Exp base_JRPO updates 4001/100000000000.0 steps in 89.06
total episode rewards is -20.0
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'value_loss': 0.3080564837078176, '_timestamp': 1721964378.647986}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0005312592392632116, '_timestamp': 1721964378.6491323}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8583695395787556, '_timestamp': 1721964378.649203}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14439542591571808, '_timestamp': 1721964378.649735}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.171046644449234, '_timestamp': 1721964378.6501114}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'ratio': 1.0000979900360107, '_timestamp': 1721964378.6502142}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964378.6507394}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964378.650929}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.06281995773315, '_timestamp': 1721964378.6509888}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.45685971451950175, '_timestamp': 1721964378.652207}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'train_goal': 0.2715701427402491, '_timestamp': 1721964378.6531255}).
wandb: WARNING (User provided step: 4001 is less than current step: 12030. Dropping entry: {'train_WDL': -0.45685971451950175, '_timestamp': 1721964378.6537354}).
Env Football Algo jrpo Exp base_JRPO updates 3406/100000000000.0 steps in 57.34
total episode rewards is -110.0
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'value_loss': 0.6838647649126748, '_timestamp': 1721964435.9953053}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013666058712018033, '_timestamp': 1721964435.995483}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8597170035044353, '_timestamp': 1721964435.9955509}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15289659798145294, '_timestamp': 1721964435.99566}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7445043325424194, '_timestamp': 1721964435.9959774}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'ratio': 0.999830961227417, '_timestamp': 1721964435.9960914}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721964435.9965851}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964435.9966848}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.34064197540283, '_timestamp': 1721964435.9967427}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964435.9972186}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964435.997579}).
wandb: WARNING (User provided step: 3406 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964435.9979498}).
Env Football Algo jrpo Exp base_JRPO updates 6870/100000000000.0 steps in 83.26
total episode rewards is -40.0
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'value_loss': 0.2433874337518743, '_timestamp': 1721964519.2628045}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'policy_loss': 0.01027462501777336, '_timestamp': 1721964519.262955}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8618118794759115, '_timestamp': 1721964519.2630208}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12832672894001007, '_timestamp': 1721964519.2631106}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.11198034882545471, '_timestamp': 1721964519.2633376}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'ratio': 0.9982154369354248, '_timestamp': 1721964519.2634366}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721964519.2636836}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964519.263773}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.26401925086975, '_timestamp': 1721964519.26383}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964519.2644098}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964519.2648883}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964519.2653856}).
Env Football Algo jrpo Exp base_JRPO updates 7220/100000000000.0 steps in 90.31
total episode rewards is -20.0
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'value_loss': 0.2620390275058647, '_timestamp': 1721964609.5803657}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002622657947552701, '_timestamp': 1721964609.5805478}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8566298786799114, '_timestamp': 1721964609.5806181}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13731656968593597, '_timestamp': 1721964609.5807235}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.25718191266059875, '_timestamp': 1721964609.5809958}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'ratio': 1.0002037286758423, '_timestamp': 1721964609.581098}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964609.5815995}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964609.581701}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.31405782699585, '_timestamp': 1721964609.5817585}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.23316195372750642, '_timestamp': 1721964609.5823963}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'train_goal': 0.38341902313624676, '_timestamp': 1721964609.582906}).
wandb: WARNING (User provided step: 7220 is less than current step: 12030. Dropping entry: {'train_WDL': -0.23316195372750642, '_timestamp': 1721964609.5833948}).
Env Football Algo jrpo Exp base_JRPO updates 8441/100000000000.0 steps in 84.52
total episode rewards is -10.0
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'value_loss': 0.23194962085864973, '_timestamp': 1721964694.1072476}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0006509076474079241, '_timestamp': 1721964694.1077542}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.856002326011658, '_timestamp': 1721964694.1078293}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13748213648796082, '_timestamp': 1721964694.1080582}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20880478620529175, '_timestamp': 1721964694.1083746}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'ratio': 0.9990695714950562, '_timestamp': 1721964694.109149}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721964694.1093905}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964694.1095123}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.52145385742188, '_timestamp': 1721964694.1095712}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.09132489708797073, '_timestamp': 1721964694.110467}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'train_goal': 0.4543375514560146, '_timestamp': 1721964694.1116333}).
wandb: WARNING (User provided step: 8441 is less than current step: 12030. Dropping entry: {'train_WDL': -0.09132489708797073, '_timestamp': 1721964694.1120718}).
Env Football Algo jrpo Exp base_JRPO updates 8166/100000000000.0 steps in 90.00
total episode rewards is -10.0
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'value_loss': 0.1973574336459084, '_timestamp': 1721964784.1121557}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004537692293912793, '_timestamp': 1721964784.1123447}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8650553242365517, '_timestamp': 1721964784.1124158}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12447072565555573, '_timestamp': 1721964784.1125243}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19983384013175964, '_timestamp': 1721964784.112798}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'ratio': 1.0011928081512451, '_timestamp': 1721964784.1129024}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721964784.1136904}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964784.113788}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.998948097229, '_timestamp': 1721964784.113848}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.13198712320749195, '_timestamp': 1721964784.1144876}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'train_goal': 0.434006438396254, '_timestamp': 1721964784.114958}).
wandb: WARNING (User provided step: 8166 is less than current step: 12030. Dropping entry: {'train_WDL': -0.13198712320749195, '_timestamp': 1721964784.1154642}).
Env Football Algo jrpo Exp base_JRPO updates 3797/100000000000.0 steps in 51.29
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'value_loss': 0.4367767178080976, '_timestamp': 1721964835.4113567}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0010212023500935175, '_timestamp': 1721964835.411544}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.869318191210429, '_timestamp': 1721964835.4116104}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1435529589653015, '_timestamp': 1721964835.4117067}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4990178048610687, '_timestamp': 1721964835.4119608}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'ratio': 0.998308539390564, '_timestamp': 1721964835.4120595}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721964835.4121974}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964835.4122903}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.29484796524048, '_timestamp': 1721964835.4123464}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1643192488262911, '_timestamp': 1721964835.412733}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'train_goal': 0.41784037558685444, '_timestamp': 1721964835.4129941}).
wandb: WARNING (User provided step: 3797 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1643192488262911, '_timestamp': 1721964835.4132578}).
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7845/100000000000.0 steps in 86.95
total episode rewards is -30.0
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'value_loss': 0.1855326301823758, '_timestamp': 1721964922.3626611}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001306322129870144, '_timestamp': 1721964922.362884}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8713083203633625, '_timestamp': 1721964922.3629737}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1298869401216507, '_timestamp': 1721964922.3630831}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2002546638250351, '_timestamp': 1721964922.3634055}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'ratio': 1.0000373125076294, '_timestamp': 1721964922.3642716}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721964922.364474}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964922.364581}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.94850611686707, '_timestamp': 1721964922.3646488}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964922.3653188}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964922.3658173}).
wandb: WARNING (User provided step: 7845 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964922.3663106}).
Env Football Algo jrpo Exp base_JRPO updates 7555/100000000000.0 steps in 92.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'value_loss': 0.28300174036761744, '_timestamp': 1721965014.5490346}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016315674360400105, '_timestamp': 1721965014.549216}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8763730080922443, '_timestamp': 1721965014.549289}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13281875848770142, '_timestamp': 1721965014.549388}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.29999542236328125, '_timestamp': 1721965014.5496416}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'ratio': 0.9977836608886719, '_timestamp': 1721965014.5498643}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721965014.5500002}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965014.5500944}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'Episode_Time': 92.18165278434753, '_timestamp': 1721965014.5501509}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965014.550927}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965014.5513875}).
wandb: WARNING (User provided step: 7555 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965014.5518582}).
Env Football Algo jrpo Exp base_JRPO updates 6489/100000000000.0 steps in 90.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'value_loss': 0.29494547100252627, '_timestamp': 1721965105.4560263}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00039512923792547856, '_timestamp': 1721965105.4562645}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8737494977315268, '_timestamp': 1721965105.456335}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14161303639411926, '_timestamp': 1721965105.4564497}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2557370066642761, '_timestamp': 1721965105.4567344}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'ratio': 1.0004603862762451, '_timestamp': 1721965105.4568367}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721965105.4576519}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965105.4577544}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.90298533439636, '_timestamp': 1721965105.457814}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965105.4585838}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965105.4591641}).
wandb: WARNING (User provided step: 6489 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965105.4597116}).
Env Football Algo jrpo Exp base_JRPO updates 7879/100000000000.0 steps in 89.47
total episode rewards is -30.0
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'value_loss': 0.21018410192084655, '_timestamp': 1721965194.9337256}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002219722844893113, '_timestamp': 1721965194.9339132}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8737477032343546, '_timestamp': 1721965194.9339824}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1373857706785202, '_timestamp': 1721965194.934084}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.22813832759857178, '_timestamp': 1721965194.9343624}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'ratio': 0.9990448355674744, '_timestamp': 1721965194.9344661}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965194.934607}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965194.9349995}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.47294306755066, '_timestamp': 1721965194.9350584}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965194.935756}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965194.9362485}).
wandb: WARNING (User provided step: 7879 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965194.936713}).
Env Football Algo jrpo Exp base_JRPO updates 7306/100000000000.0 steps in 76.91
total episode rewards is -70.0
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'value_loss': 0.43801705644776423, '_timestamp': 1721965271.8494983}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001102212428425749, '_timestamp': 1721965271.84966}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8712205330530804, '_timestamp': 1721965271.849729}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14866913855075836, '_timestamp': 1721965271.8498323}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5020714402198792, '_timestamp': 1721965271.8501089}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'ratio': 0.9995532631874084, '_timestamp': 1721965271.8502204}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721965271.8503659}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965271.851158}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.91142225265503, '_timestamp': 1721965271.8512268}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965271.8516977}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965271.8520615}).
wandb: WARNING (User provided step: 7306 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965271.8524165}).
Env Football Algo jrpo Exp base_JRPO updates 3845/100000000000.0 steps in 56.37
total episode rewards is -110.0
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'value_loss': 0.6824504865892231, '_timestamp': 1721965328.2282398}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022271574800834058, '_timestamp': 1721965328.2284164}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8719645071029665, '_timestamp': 1721965328.228482}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1551920473575592, '_timestamp': 1721965328.228585}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9130452871322632, '_timestamp': 1721965328.2288706}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'ratio': 0.9988976120948792, '_timestamp': 1721965328.2289748}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721965328.229112}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965328.2295325}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.37485337257385, '_timestamp': 1721965328.2295916}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965328.2300546}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965328.2304845}).
wandb: WARNING (User provided step: 3845 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965328.230854}).
Env Football Algo jrpo Exp base_JRPO updates 9111/100000000000.0 steps in 91.95
total episode rewards is -30.0
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'value_loss': 0.20059955408563837, '_timestamp': 1721965420.1769772}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0072067126614274455, '_timestamp': 1721965420.1771395}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8708709335327147, '_timestamp': 1721965420.177205}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1283082365989685, '_timestamp': 1721965420.1772964}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14946086704730988, '_timestamp': 1721965420.1775327}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'ratio': 0.999347984790802, '_timestamp': 1721965420.1776297}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965420.177868}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965420.1779652}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.94536399841309, '_timestamp': 1721965420.1780229}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965420.1785314}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965420.1789103}).
wandb: WARNING (User provided step: 9111 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965420.1792953}).
Env Football Algo jrpo Exp base_JRPO updates 5445/100000000000.0 steps in 85.51
total episode rewards is -40.0
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'value_loss': 0.27816009052097795, '_timestamp': 1721965505.6939769}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005698910274853309, '_timestamp': 1721965505.694144}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8721535634994506, '_timestamp': 1721965505.694208}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13392792642116547, '_timestamp': 1721965505.6943045}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2522674798965454, '_timestamp': 1721965505.6945453}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'ratio': 0.9989204406738281, '_timestamp': 1721965505.6946485}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721965505.6947744}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965505.6948674}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.51378917694092, '_timestamp': 1721965505.694923}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965505.69558}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965505.6961603}).
wandb: WARNING (User provided step: 5445 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965505.6967485}).
Env Football Algo jrpo Exp base_JRPO updates 6530/100000000000.0 steps in 87.85
total episode rewards is 0.0
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'value_loss': 0.27850067541003226, '_timestamp': 1721965593.5460794}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'policy_loss': 0.010540417474694551, '_timestamp': 1721965593.5462608}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.870107649167379, '_timestamp': 1721965593.5463283}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13423025608062744, '_timestamp': 1721965593.5464315}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20922867953777313, '_timestamp': 1721965593.546698}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'ratio': 0.9984824657440186, '_timestamp': 1721965593.5468025}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721965593.5473592}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965593.5474586}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.84831047058105, '_timestamp': 1721965593.5475163}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.15962219598583235, '_timestamp': 1721965593.5482457}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'train_goal': 0.5798110979929162, '_timestamp': 1721965593.5487757}).
wandb: WARNING (User provided step: 6530 is less than current step: 12030. Dropping entry: {'train_WDL': 0.15962219598583235, '_timestamp': 1721965593.549292}).
Env Football Algo jrpo Exp base_JRPO updates 4070/100000000000.0 steps in 39.45
total episode rewards is -100.0
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'value_loss': 0.7318808755030235, '_timestamp': 1721965633.002605}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011484654480591416, '_timestamp': 1721965633.0030074}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.868672564824422, '_timestamp': 1721965633.0030868}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15106354653835297, '_timestamp': 1721965633.0033035}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9578468799591064, '_timestamp': 1721965633.003544}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'ratio': 0.9999871253967285, '_timestamp': 1721965633.003646}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721965633.004399}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965633.004528}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'Episode_Time': 39.45117664337158, '_timestamp': 1721965633.0045898}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965633.004958}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965633.005116}).
wandb: WARNING (User provided step: 4070 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965633.0053592}).
Env Football Algo jrpo Exp base_JRPO updates 5047/100000000000.0 steps in 82.19
total episode rewards is -60.0
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'value_loss': 0.5117394361396631, '_timestamp': 1721965715.1914592}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005858110611249382, '_timestamp': 1721965715.191632}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.869670106569926, '_timestamp': 1721965715.1917045}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.150928795337677, '_timestamp': 1721965715.191799}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.48569154739379883, '_timestamp': 1721965715.1920931}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'ratio': 0.998971164226532, '_timestamp': 1721965715.1922133}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721965715.1929}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965715.1929965}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.18517541885376, '_timestamp': 1721965715.1930554}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.37358838442037334, '_timestamp': 1721965715.1937854}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'train_goal': 0.31320580778981333, '_timestamp': 1721965715.1943278}).
wandb: WARNING (User provided step: 5047 is less than current step: 12030. Dropping entry: {'train_WDL': -0.37358838442037334, '_timestamp': 1721965715.19487}).
Env Football Algo jrpo Exp base_JRPO updates 8612/100000000000.0 steps in 89.40
total episode rewards is -30.0
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'value_loss': 0.21424933592788875, '_timestamp': 1721965804.5978258}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007389106073921236, '_timestamp': 1721965804.5979815}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.869474685986837, '_timestamp': 1721965804.598047}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13888123631477356, '_timestamp': 1721965804.5981379}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18712931871414185, '_timestamp': 1721965804.598376}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'ratio': 1.0009799003601074, '_timestamp': 1721965804.5984786}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965804.5987961}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965804.5988886}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.40172576904297, '_timestamp': 1721965804.5989442}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965804.5995476}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965804.599967}).
wandb: WARNING (User provided step: 8612 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965804.6003828}).
Env Football Algo jrpo Exp base_JRPO updates 3913/100000000000.0 steps in 79.69
total episode rewards is -20.0
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'value_loss': 0.283457862737899, '_timestamp': 1721965884.2889237}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0037460947722623436, '_timestamp': 1721965884.2890732}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8705671707789104, '_timestamp': 1721965884.2891378}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14339257776737213, '_timestamp': 1721965884.289226}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1474156677722931, '_timestamp': 1721965884.2894657}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'ratio': 0.9988632202148438, '_timestamp': 1721965884.2898126}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965884.2899497}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965884.29004}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.68713045120239, '_timestamp': 1721965884.2900982}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.46189230630468114, '_timestamp': 1721965884.2908494}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'train_goal': 0.26905384684765943, '_timestamp': 1721965884.291467}).
wandb: WARNING (User provided step: 3913 is less than current step: 12030. Dropping entry: {'train_WDL': -0.46189230630468114, '_timestamp': 1721965884.2921286}).
Env Football Algo jrpo Exp base_JRPO updates 2693/100000000000.0 steps in 58.37
total episode rewards is -40.0
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'value_loss': 0.5232399904852112, '_timestamp': 1721965942.6620657}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0017823965503581955, '_timestamp': 1721965942.6623142}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.866929833094279, '_timestamp': 1721965942.6623988}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15405896306037903, '_timestamp': 1721965942.6625118}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5781798958778381, '_timestamp': 1721965942.6628225}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'ratio': 0.9983258247375488, '_timestamp': 1721965942.6629577}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721965942.6639018}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965942.6681376}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'Episode_Time': 58.36875128746033, '_timestamp': 1721965942.6682127}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.15711252653927812, '_timestamp': 1721965942.668879}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'train_goal': 0.578556263269639, '_timestamp': 1721965942.6693332}).
wandb: WARNING (User provided step: 2693 is less than current step: 12030. Dropping entry: {'train_WDL': 0.15711252653927812, '_timestamp': 1721965942.6697218}).
Env Football Algo jrpo Exp base_JRPO updates 6124/100000000000.0 steps in 50.35
total episode rewards is -80.0
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'value_loss': 0.6730392594759663, '_timestamp': 1721965993.0212772}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0026441808645419466, '_timestamp': 1721965993.0214322}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.867786626815796, '_timestamp': 1721965993.0214968}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15288196504116058, '_timestamp': 1721965993.0215883}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7668654918670654, '_timestamp': 1721965993.021823}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'ratio': 0.9999514818191528, '_timestamp': 1721965993.0219216}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721965993.0222273}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965993.0223167}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.35043501853943, '_timestamp': 1721965993.022375}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965993.0226429}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965993.0228267}).
wandb: WARNING (User provided step: 6124 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965993.0230107}).
Env Football Algo jrpo Exp base_JRPO updates 4630/100000000000.0 steps in 66.25
total episode rewards is -70.0
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'value_loss': 0.7966729227577647, '_timestamp': 1721966059.2785206}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005798081991573175, '_timestamp': 1721966059.2788403}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8678359603881836, '_timestamp': 1721966059.2789102}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14193113148212433, '_timestamp': 1721966059.2790122}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7503082156181335, '_timestamp': 1721966059.2792819}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'ratio': 0.9991883635520935, '_timestamp': 1721966059.2797837}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721966059.2801423}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966059.280248}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'Episode_Time': 66.25447106361389, '_timestamp': 1721966059.2803082}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966059.2811308}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966059.2817066}).
wandb: WARNING (User provided step: 4630 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966059.2821617}).
Env Football Algo jrpo Exp base_JRPO updates 2911/100000000000.0 steps in 50.65
total episode rewards is -120.0
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'value_loss': 0.8557228462646405, '_timestamp': 1721966109.9343462}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013926315916857372, '_timestamp': 1721966109.9356072}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.86747731367747, '_timestamp': 1721966109.9356813}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1453106552362442, '_timestamp': 1721966109.936268}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9947687983512878, '_timestamp': 1721966109.9366488}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'ratio': 0.9992717504501343, '_timestamp': 1721966109.9367518}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721966109.9368775}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966109.9370708}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'Episode_Time': 50.64623737335205, '_timestamp': 1721966109.9371297}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966109.9381325}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966109.938464}).
wandb: WARNING (User provided step: 2911 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966109.9387813}).
Env Football Algo jrpo Exp base_JRPO updates 8866/100000000000.0 steps in 80.54
total episode rewards is -60.0
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'value_loss': 0.37485702079410355, '_timestamp': 1721966190.4787161}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004626613475071887, '_timestamp': 1721966190.478922}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871931349436442, '_timestamp': 1721966190.479014}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14017176628112793, '_timestamp': 1721966190.4791205}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4266459047794342, '_timestamp': 1721966190.4794097}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'ratio': 1.0011500120162964, '_timestamp': 1721966190.4795392}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721966190.4801672}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966190.480271}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.53899884223938, '_timestamp': 1721966190.4803314}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966190.481185}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966190.481557}).
wandb: WARNING (User provided step: 8866 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966190.4819264}).
Env Football Algo jrpo Exp base_JRPO updates 5638/100000000000.0 steps in 72.76
total episode rewards is -30.0
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'value_loss': 0.45111636001306277, '_timestamp': 1721966263.2417371}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022809214868660397, '_timestamp': 1721966263.242078}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8646111726760863, '_timestamp': 1721966263.2421832}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14831461012363434, '_timestamp': 1721966263.242291}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5318730473518372, '_timestamp': 1721966263.2425716}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'ratio': 1.0013272762298584, '_timestamp': 1721966263.243101}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966263.2433753}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966263.243478}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.75829315185547, '_timestamp': 1721966263.2435389}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.039584032203958404, '_timestamp': 1721966263.2445016}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'train_goal': 0.5197920161019792, '_timestamp': 1721966263.2449284}).
wandb: WARNING (User provided step: 5638 is less than current step: 12030. Dropping entry: {'train_WDL': 0.039584032203958404, '_timestamp': 1721966263.2453887}).
Env Football Algo jrpo Exp base_JRPO updates 3635/100000000000.0 steps in 42.37
total episode rewards is -80.0
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'value_loss': 0.7476007103795806, '_timestamp': 1721966305.6136057}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016603360369723912, '_timestamp': 1721966305.613776}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8619947242736816, '_timestamp': 1721966305.6138427}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15713872015476227, '_timestamp': 1721966305.6139379}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7369030714035034, '_timestamp': 1721966305.614219}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'ratio': 0.9994618892669678, '_timestamp': 1721966305.6149678}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721966305.6151013}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966305.6152}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'Episode_Time': 42.36719036102295, '_timestamp': 1721966305.615256}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.12121212121212122, '_timestamp': 1721966305.6156523}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'train_goal': 0.4393939393939394, '_timestamp': 1721966305.6159034}).
wandb: WARNING (User provided step: 3635 is less than current step: 12030. Dropping entry: {'train_WDL': -0.12121212121212122, '_timestamp': 1721966305.6161828}).
Env Football Algo jrpo Exp base_JRPO updates 8327/100000000000.0 steps in 80.61
total episode rewards is -70.0
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'value_loss': 0.43611549540112415, '_timestamp': 1721966386.2244952}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013012164815639456, '_timestamp': 1721966386.2248368}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.866188832918803, '_timestamp': 1721966386.2249146}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14314788579940796, '_timestamp': 1721966386.225013}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.42136910557746887, '_timestamp': 1721966386.2253046}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'ratio': 1.0002068281173706, '_timestamp': 1721966386.2257671}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721966386.2260284}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966386.2261312}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.6073694229126, '_timestamp': 1721966386.2261882}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966386.2267807}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966386.2271707}).
wandb: WARNING (User provided step: 8327 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966386.227531}).
Env Football Algo jrpo Exp base_JRPO updates 2396/100000000000.0 steps in 29.04
total episode rewards is -140.0
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'value_loss': 0.8338746318407356, '_timestamp': 1721966415.274375}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0018066309363348409, '_timestamp': 1721966415.274593}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8636544307072955, '_timestamp': 1721966415.2746623}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15846092998981476, '_timestamp': 1721966415.2747612}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8784804344177246, '_timestamp': 1721966415.275026}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'ratio': 0.9991228580474854, '_timestamp': 1721966415.2751338}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721966415.2758386}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966415.2759385}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'Episode_Time': 29.042003393173218, '_timestamp': 1721966415.2760108}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966415.2762825}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966415.2764678}).
wandb: WARNING (User provided step: 2396 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966415.27661}).
Env Football Algo jrpo Exp base_JRPO updates 5587/100000000000.0 steps in 92.44
total episode rewards is -20.0
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'value_loss': 0.28900864003847043, '_timestamp': 1721966507.7161489}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0008991490777892371, '_timestamp': 1721966507.716328}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8615519428253173, '_timestamp': 1721966507.7164001}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1573847234249115, '_timestamp': 1721966507.7165008}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16213248670101166, '_timestamp': 1721966507.7167659}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'ratio': 1.0010406970977783, '_timestamp': 1721966507.7168694}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721966507.7170105}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966507.7171056}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'Episode_Time': 92.43825793266296, '_timestamp': 1721966507.7171683}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.38128120684160205, '_timestamp': 1721966507.7182848}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'train_goal': 0.309359396579199, '_timestamp': 1721966507.7193067}).
wandb: WARNING (User provided step: 5587 is less than current step: 12030. Dropping entry: {'train_WDL': -0.38128120684160205, '_timestamp': 1721966507.7202327}).
Env Football Algo jrpo Exp base_JRPO updates 1170/100000000000.0 steps in 21.64
total episode rewards is -80.0
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'value_loss': 0.7124272409453988, '_timestamp': 1721966529.366607}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0031194309451772523, '_timestamp': 1721966529.3677623}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.861831022898356, '_timestamp': 1721966529.3678339}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1499371975660324, '_timestamp': 1721966529.368411}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7467740178108215, '_timestamp': 1721966529.3688695}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'ratio': 1.0012096166610718, '_timestamp': 1721966529.3694057}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721966529.3698237}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966529.3700078}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'Episode_Time': 21.640806198120117, '_timestamp': 1721966529.3700674}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3641025641025641, '_timestamp': 1721966529.3708904}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'train_goal': 0.31794871794871793, '_timestamp': 1721966529.371058}).
wandb: WARNING (User provided step: 1170 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3641025641025641, '_timestamp': 1721966529.371219}).
Env Football Algo jrpo Exp base_JRPO updates 9662/100000000000.0 steps in 83.87
total episode rewards is -30.0
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'value_loss': 0.2118252909121414, '_timestamp': 1721966613.2424088}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'policy_loss': 0.01929065553646069, '_timestamp': 1721966613.2425616}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.854429095586141, '_timestamp': 1721966613.242627}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1358528733253479, '_timestamp': 1721966613.2427197}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12729763984680176, '_timestamp': 1721966613.2429523}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'ratio': 0.9981334805488586, '_timestamp': 1721966613.2431731}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966613.2433054}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966613.2433946}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.87028765678406, '_timestamp': 1721966613.2434516}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966613.2439015}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966613.2442715}).
wandb: WARNING (User provided step: 9662 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966613.2446337}).
Env Football Algo jrpo Exp base_JRPO updates 6342/100000000000.0 steps in 87.04
total episode rewards is -40.0
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'value_loss': 0.26836169240064917, '_timestamp': 1721966700.2889879}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008480868433252908, '_timestamp': 1721966700.2891788}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8605909172693886, '_timestamp': 1721966700.289248}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13193179666996002, '_timestamp': 1721966700.289355}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.17287978529930115, '_timestamp': 1721966700.28962}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'ratio': 0.9996016621589661, '_timestamp': 1721966700.2900562}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721966700.2902036}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966700.2903035}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.04341840744019, '_timestamp': 1721966700.2903585}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966700.2912512}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966700.291773}).
wandb: WARNING (User provided step: 6342 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966700.2923415}).
Env Football Algo jrpo Exp base_JRPO updates 6506/100000000000.0 steps in 90.75
total episode rewards is -20.0
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'value_loss': 0.2968054217674459, '_timestamp': 1721966791.0387745}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007739406777206265, '_timestamp': 1721966791.0389533}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8527008199691775, '_timestamp': 1721966791.0390227}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13884520530700684, '_timestamp': 1721966791.039118}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1974722445011139, '_timestamp': 1721966791.039613}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'ratio': 0.999013364315033, '_timestamp': 1721966791.0397322}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721966791.0398676}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966791.0399723}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.74538397789001, '_timestamp': 1721966791.0400333}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.298563692017895, '_timestamp': 1721966791.0407093}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'train_goal': 0.3507181539910525, '_timestamp': 1721966791.041225}).
wandb: WARNING (User provided step: 6506 is less than current step: 12030. Dropping entry: {'train_WDL': -0.298563692017895, '_timestamp': 1721966791.0417461}).
Env Football Algo jrpo Exp base_JRPO updates 4353/100000000000.0 steps in 75.54
total episode rewards is -30.0
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'value_loss': 0.44612521726793297, '_timestamp': 1721966866.584214}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006720483049539325, '_timestamp': 1721966866.5844119}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8490901088714597, '_timestamp': 1721966866.5844812}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14157675206661224, '_timestamp': 1721966866.5845726}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3545910120010376, '_timestamp': 1721966866.584836}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'ratio': 0.9983580708503723, '_timestamp': 1721966866.585456}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966866.5857353}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966866.5858355}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'Episode_Time': 75.54131531715393, '_timestamp': 1721966866.5858943}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.1801560498427856, '_timestamp': 1721966866.5869203}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'train_goal': 0.5900780249213928, '_timestamp': 1721966866.5874474}).
wandb: WARNING (User provided step: 4353 is less than current step: 12030. Dropping entry: {'train_WDL': 0.1801560498427856, '_timestamp': 1721966866.5879889}).
Env Football Algo jrpo Exp base_JRPO updates 4892/100000000000.0 steps in 86.68
total episode rewards is -40.0
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'value_loss': 0.2906428512640802, '_timestamp': 1721966953.2731795}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00223335699023058, '_timestamp': 1721966953.2733366}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8505195347468057, '_timestamp': 1721966953.2734017}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1351761519908905, '_timestamp': 1721966953.2734923}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19313310086727142, '_timestamp': 1721966953.2737222}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'ratio': 1.0000131130218506, '_timestamp': 1721966953.2738328}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721966953.2740705}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966953.2741604}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.68413782119751, '_timestamp': 1721966953.2742167}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966953.2749064}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966953.2754738}).
wandb: WARNING (User provided step: 4892 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966953.2760894}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'value_loss': 0.30150835604096454, '_timestamp': 1721967040.1329703}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0025245244001659253, '_timestamp': 1721967040.1331198}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.853494760195414, '_timestamp': 1721967040.1331856}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14444001019001007, '_timestamp': 1721967040.133274}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18422280251979828, '_timestamp': 1721967040.1335106}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'ratio': 0.9993262887001038, '_timestamp': 1721967040.1337898}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721967040.1339061}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967040.1339989}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.85600161552429, '_timestamp': 1721967040.1340559}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.33161838720501063, '_timestamp': 1721967040.134666}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'train_goal': 0.3341908063974947, '_timestamp': 1721967040.1351922}).
wandb: WARNING (User provided step: 6059 is less than current step: 12030. Dropping entry: {'train_WDL': -0.33161838720501063, '_timestamp': 1721967040.1357214}).
Env Football Algo jrpo Exp base_JRPO updates 6059/100000000000.0 steps in 86.86
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 4711/100000000000.0 steps in 81.61
total episode rewards is -20.0
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'value_loss': 0.2999828078182569, '_timestamp': 1721967121.7483585}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004138320499138596, '_timestamp': 1721967121.7485068}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8511187585194904, '_timestamp': 1721967121.748572}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13993071019649506, '_timestamp': 1721967121.7486587}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1400194764137268, '_timestamp': 1721967121.7488778}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'ratio': 1.000815987586975, '_timestamp': 1721967121.748975}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721967121.7492032}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967121.7492914}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.61194658279419, '_timestamp': 1721967121.7493472}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4234619496549713, '_timestamp': 1721967121.7500215}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'train_goal': 0.28826902517251435, '_timestamp': 1721967121.7505963}).
wandb: WARNING (User provided step: 4711 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4234619496549713, '_timestamp': 1721967121.7511983}).
Env Football Algo jrpo Exp base_JRPO updates 8263/100000000000.0 steps in 81.40
total episode rewards is -50.0
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'value_loss': 0.40761172820969177, '_timestamp': 1721967203.1504972}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0037346222968335494, '_timestamp': 1721967203.1506553}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8524533541997275, '_timestamp': 1721967203.1507223}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1445697546005249, '_timestamp': 1721967203.1508126}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3189639747142792, '_timestamp': 1721967203.1513698}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'ratio': 0.9998059272766113, '_timestamp': 1721967203.1514716}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721967203.1516075}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967203.1516988}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.39838480949402, '_timestamp': 1721967203.1517556}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967203.152245}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967203.1526291}).
wandb: WARNING (User provided step: 8263 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967203.1530209}).
Env Football Algo jrpo Exp base_JRPO updates 3067/100000000000.0 steps in 43.86
total episode rewards is -90.0
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'value_loss': 0.7697896051406861, '_timestamp': 1721967247.0236623}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0031640514777973292, '_timestamp': 1721967247.0238318}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8502914810180666, '_timestamp': 1721967247.0238998}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15569336712360382, '_timestamp': 1721967247.0240061}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8164834380149841, '_timestamp': 1721967247.0242581}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'ratio': 1.0017626285552979, '_timestamp': 1721967247.0243611}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721967247.024501}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967247.0245957}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'Episode_Time': 43.864887714385986, '_timestamp': 1721967247.0251346}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2604611443210931, '_timestamp': 1721967247.0255175}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'train_goal': 0.36976942783945344, '_timestamp': 1721967247.0257835}).
wandb: WARNING (User provided step: 3067 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2604611443210931, '_timestamp': 1721967247.0260465}).
Env Football Algo jrpo Exp base_JRPO updates 7798/100000000000.0 steps in 84.21
total episode rewards is -40.0
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'value_loss': 0.2467806561376589, '_timestamp': 1721967331.2333174}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0030253569723572584, '_timestamp': 1721967331.2334712}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.851498196919759, '_timestamp': 1721967331.2335374}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14243438839912415, '_timestamp': 1721967331.2336261}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.25512221455574036, '_timestamp': 1721967331.2338548}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'ratio': 1.000937819480896, '_timestamp': 1721967331.2341166}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721967331.2342587}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967331.2343483}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.2063901424408, '_timestamp': 1721967331.2344048}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967331.234933}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967331.2353628}).
wandb: WARNING (User provided step: 7798 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967331.2358103}).
Env Football Algo jrpo Exp base_JRPO updates 2404/100000000000.0 steps in 29.45
total episode rewards is -90.0
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'value_loss': 0.5447098105990639, '_timestamp': 1721967360.6892052}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00200515389306626, '_timestamp': 1721967360.6893637}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.847417057355245, '_timestamp': 1721967360.6894307}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14366234838962555, '_timestamp': 1721967360.68953}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6651057600975037, '_timestamp': 1721967360.6897628}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'ratio': 1.0004931688308716, '_timestamp': 1721967360.6898642}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721967360.6899965}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967360.6903107}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'Episode_Time': 29.452494859695435, '_timestamp': 1721967360.6903703}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967360.6906073}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967360.6907532}).
wandb: WARNING (User provided step: 2404 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967360.6908958}).
Env Football Algo jrpo Exp base_JRPO updates 8733/100000000000.0 steps in 81.78
total episode rewards is -40.0
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'value_loss': 0.2602685170682768, '_timestamp': 1721967442.4709601}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0020075111494710046, '_timestamp': 1721967442.4711235}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8499779876073204, '_timestamp': 1721967442.4711905}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15117496252059937, '_timestamp': 1721967442.4712856}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1298433095216751, '_timestamp': 1721967442.4715235}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'ratio': 0.9998073577880859, '_timestamp': 1721967442.4717426}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721967442.4718804}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967442.4719846}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.77568650245667, '_timestamp': 1721967442.472045}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967442.4725678}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967442.4729745}).
wandb: WARNING (User provided step: 8733 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967442.4733832}).
Env Football Algo jrpo Exp base_JRPO updates 5041/100000000000.0 steps in 56.39
total episode rewards is -70.0
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'value_loss': 0.5790762171397607, '_timestamp': 1721967498.8672643}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001673118190956302, '_timestamp': 1721967498.867427}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.847422768274943, '_timestamp': 1721967498.8674922}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15213710069656372, '_timestamp': 1721967498.8675838}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7561540007591248, '_timestamp': 1721967498.8678124}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'ratio': 1.0001840591430664, '_timestamp': 1721967498.867912}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721967498.8680484}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967498.8682435}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.392932176589966, '_timestamp': 1721967498.8683028}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.19442131557035802, '_timestamp': 1721967498.8687449}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'train_goal': 0.402789342214821, '_timestamp': 1721967498.8690686}).
wandb: WARNING (User provided step: 5041 is less than current step: 12030. Dropping entry: {'train_WDL': -0.19442131557035802, '_timestamp': 1721967498.8693924}).
Env Football Algo jrpo Exp base_JRPO updates 6496/100000000000.0 steps in 83.49
total episode rewards is -40.0
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'value_loss': 0.29040128828026357, '_timestamp': 1721967582.3624463}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008246055307487647, '_timestamp': 1721967582.3625982}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8497438716888426, '_timestamp': 1721967582.362662}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13735315203666687, '_timestamp': 1721967582.36275}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20327134430408478, '_timestamp': 1721967582.3629742}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'ratio': 1.0011383295059204, '_timestamp': 1721967582.3630722}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721967582.3633282}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967582.3634202}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.49233770370483, '_timestamp': 1721967582.3634784}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967582.3640985}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967582.3645918}).
wandb: WARNING (User provided step: 6496 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967582.36511}).
Env Football Algo jrpo Exp base_JRPO updates 5069/100000000000.0 steps in 78.43
total episode rewards is -50.0
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'value_loss': 0.389728767607982, '_timestamp': 1721967660.7981493}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005514144585370862, '_timestamp': 1721967660.7983043}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8541796032587685, '_timestamp': 1721967660.7983696}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14714299142360687, '_timestamp': 1721967660.7984586}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.389469176530838, '_timestamp': 1721967660.7986913}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'ratio': 1.0007824897766113, '_timestamp': 1721967660.7987933}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721967660.7989228}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967660.7992845}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.43214845657349, '_timestamp': 1721967660.7993429}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3830662624512776, '_timestamp': 1721967660.8000054}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_goal': 0.3084668687743612, '_timestamp': 1721967660.8005345}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3830662624512776, '_timestamp': 1721967660.8010783}).
Env Football Algo jrpo Exp base_JRPO updates 4457/100000000000.0 steps in 56.24
total episode rewards is -100.0
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'value_loss': 0.5659011592778067, '_timestamp': 1721967717.0447185}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0007173740184710671, '_timestamp': 1721967717.0448735}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8540449364980063, '_timestamp': 1721967717.0449402}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15268297493457794, '_timestamp': 1721967717.0450308}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5568805932998657, '_timestamp': 1721967717.045267}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'ratio': 0.9988859295845032, '_timestamp': 1721967717.0454936}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721967717.0456247}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967717.0457144}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.242695331573486, '_timestamp': 1721967717.0457711}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967717.0461583}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967717.0464432}).
wandb: WARNING (User provided step: 4457 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967717.0467405}).
Env Football Algo jrpo Exp base_JRPO updates 8014/100000000000.0 steps in 87.03
total episode rewards is -20.0
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'value_loss': 0.26360551403524973, '_timestamp': 1721967804.0782347}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0012119722513792416, '_timestamp': 1721967804.0784292}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.848873119354248, '_timestamp': 1721967804.07852}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1361270248889923, '_timestamp': 1721967804.078632}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2893620729446411, '_timestamp': 1721967804.0789018}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'ratio': 1.0008026361465454, '_timestamp': 1721967804.0790381}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721967804.079542}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967804.0796561}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.03067278862, '_timestamp': 1721967804.0797284}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.14600629831090753, '_timestamp': 1721967804.0803878}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'train_goal': 0.42699685084454625, '_timestamp': 1721967804.080916}).
wandb: WARNING (User provided step: 8014 is less than current step: 12030. Dropping entry: {'train_WDL': -0.14600629831090753, '_timestamp': 1721967804.081452}).
Env Football Algo jrpo Exp base_JRPO updates 3753/100000000000.0 steps in 54.99
total episode rewards is -40.0
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'value_loss': 0.490059759185339, '_timestamp': 1721967859.0755076}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002943802477869516, '_timestamp': 1721967859.0756588}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.849090286890666, '_timestamp': 1721967859.075724}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13641995191574097, '_timestamp': 1721967859.0758138}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6942852139472961, '_timestamp': 1721967859.076053}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'ratio': 1.0007891654968262, '_timestamp': 1721967859.0762975}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721967859.0764341}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967859.0765274}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'Episode_Time': 54.99316692352295, '_timestamp': 1721967859.0765872}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3779051257561286, '_timestamp': 1721967859.0770922}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'train_goal': 0.31104743712193567, '_timestamp': 1721967859.077486}).
wandb: WARNING (User provided step: 3753 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3779051257561286, '_timestamp': 1721967859.077882}).
Env Football Algo jrpo Exp base_JRPO updates 4229/100000000000.0 steps in 69.60
total episode rewards is -70.0
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'value_loss': 0.45277314154586445, '_timestamp': 1721967928.6770308}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0001474380330182612, '_timestamp': 1721967928.6771824}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8529712851842244, '_timestamp': 1721967928.6772478}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13999982178211212, '_timestamp': 1721967928.677338}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4066005349159241, '_timestamp': 1721967928.677569}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'ratio': 1.0017997026443481, '_timestamp': 1721967928.6777933}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721967928.6779287}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967928.6780174}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'Episode_Time': 69.59804248809814, '_timestamp': 1721967928.6780741}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967928.6786118}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967928.679028}).
wandb: WARNING (User provided step: 4229 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967928.6794596}).
Env Football Algo jrpo Exp base_JRPO updates 4503/100000000000.0 steps in 45.21
total episode rewards is -80.0
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'value_loss': 0.5786817158417156, '_timestamp': 1721967973.894925}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001994064003326154, '_timestamp': 1721967973.8950868}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.85024698416392, '_timestamp': 1721967973.8951523}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15831705927848816, '_timestamp': 1721967973.8952463}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8568832874298096, '_timestamp': 1721967973.8956752}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'ratio': 0.999162495136261, '_timestamp': 1721967973.8957787}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721967973.8959107}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967973.8960185}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'Episode_Time': 45.21447420120239, '_timestamp': 1721967973.8960755}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.046992481203007516, '_timestamp': 1721967973.8964577}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'train_goal': 0.47650375939849626, '_timestamp': 1721967973.8967032}).
wandb: WARNING (User provided step: 4503 is less than current step: 12030. Dropping entry: {'train_WDL': -0.046992481203007516, '_timestamp': 1721967973.8969407}).
Env Football Algo jrpo Exp base_JRPO updates 6390/100000000000.0 steps in 59.79
total episode rewards is -100.0
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'value_loss': 0.6338498785967628, '_timestamp': 1721968033.6860392}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0033990957553032787, '_timestamp': 1721968033.686232}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8490089813868207, '_timestamp': 1721968033.6863022}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14478053152561188, '_timestamp': 1721968033.6864104}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7800092101097107, '_timestamp': 1721968033.6866498}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'ratio': 0.9968218207359314, '_timestamp': 1721968033.6867542}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721968033.6874251}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968033.6875248}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.78820610046387, '_timestamp': 1721968033.687585}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968033.688019}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968033.6883128}).
wandb: WARNING (User provided step: 6390 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968033.6886117}).
Env Football Algo jrpo Exp base_JRPO updates 2490/100000000000.0 steps in 44.25
total episode rewards is -150.0
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'value_loss': 0.90767422914505, '_timestamp': 1721968077.939756}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003088582460574495, '_timestamp': 1721968077.9410806}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.846233097712199, '_timestamp': 1721968077.9411511}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1592336893081665, '_timestamp': 1721968077.9417446}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.000303030014038, '_timestamp': 1721968077.942498}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'ratio': 0.9985262155532837, '_timestamp': 1721968077.9426026}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721968077.9427252}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968077.9429228}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'Episode_Time': 44.24513483047485, '_timestamp': 1721968077.9429822}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968077.943824}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968077.9441032}).
wandb: WARNING (User provided step: 2490 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968077.9443605}).
Env Football Algo jrpo Exp base_JRPO updates 6034/100000000000.0 steps in 81.42
total episode rewards is -50.0
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'value_loss': 0.46438843886678416, '_timestamp': 1721968159.3649764}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0027284185082923312, '_timestamp': 1721968159.3652298}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8460259183247882, '_timestamp': 1721968159.3652983}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13704314827919006, '_timestamp': 1721968159.3654022}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.48352286219596863, '_timestamp': 1721968159.3656616}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'ratio': 0.9993507266044617, '_timestamp': 1721968159.365764}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721968159.3664649}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968159.3665648}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.41961932182312, '_timestamp': 1721968159.3666227}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2844265705172653, '_timestamp': 1721968159.367242}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'train_goal': 0.35778671474136736, '_timestamp': 1721968159.3678722}).
wandb: WARNING (User provided step: 6034 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2844265705172653, '_timestamp': 1721968159.3683484}).
Env Football Algo jrpo Exp base_JRPO updates 6488/100000000000.0 steps in 76.85
total episode rewards is -40.0
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'value_loss': 0.24519161828483144, '_timestamp': 1721968236.2238653}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002889679283058892, '_timestamp': 1721968236.225087}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8455720361073813, '_timestamp': 1721968236.2251606}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16343992948532104, '_timestamp': 1721968236.2257502}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21913933753967285, '_timestamp': 1721968236.2261238}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'ratio': 1.0003303289413452, '_timestamp': 1721968236.2262294}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968236.2269156}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968236.2271144}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'Episode_Time': 76.84994292259216, '_timestamp': 1721968236.227176}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968236.228333}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968236.2288578}).
wandb: WARNING (User provided step: 6488 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968236.2293801}).
Env Football Algo jrpo Exp base_JRPO updates 9166/100000000000.0 steps in 87.09
total episode rewards is -20.0
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'value_loss': 0.2545049128867686, '_timestamp': 1721968323.325705}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0006622178026009351, '_timestamp': 1721968323.3260114}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8402768770853677, '_timestamp': 1721968323.3260825}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14119063317775726, '_timestamp': 1721968323.3262136}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1528855860233307, '_timestamp': 1721968323.3265421}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'ratio': 1.0016469955444336, '_timestamp': 1721968323.3266797}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721968323.3273027}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968323.3274355}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.09396123886108, '_timestamp': 1721968323.3274982}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.024682893383613302, '_timestamp': 1721968323.3280864}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'train_goal': 0.5123414466918067, '_timestamp': 1721968323.3284762}).
wandb: WARNING (User provided step: 9166 is less than current step: 12030. Dropping entry: {'train_WDL': 0.024682893383613302, '_timestamp': 1721968323.328876}).
Env Football Algo jrpo Exp base_JRPO updates 2502/100000000000.0 steps in 45.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'value_loss': 0.6196172921732068, '_timestamp': 1721968368.5118961}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0025910636512950684, '_timestamp': 1721968368.5132287}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845338546435038, '_timestamp': 1721968368.5133004}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14185109734535217, '_timestamp': 1721968368.5138564}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6766690611839294, '_timestamp': 1721968368.5142357}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'ratio': 1.001420497894287, '_timestamp': 1721968368.5143406}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968368.514646}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968368.5148327}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'Episode_Time': 45.1768114566803, '_timestamp': 1721968368.5149012}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.3104013104013104, '_timestamp': 1721968368.5160708}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'train_goal': 0.6552006552006552, '_timestamp': 1721968368.516499}).
wandb: WARNING (User provided step: 2502 is less than current step: 12030. Dropping entry: {'train_WDL': 0.3104013104013104, '_timestamp': 1721968368.5167794}).
Env Football Algo jrpo Exp base_JRPO updates 3017/100000000000.0 steps in 31.43
total episode rewards is -40.0
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'value_loss': 1.0206474409252406, '_timestamp': 1721968399.9525433}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001711674453690648, '_timestamp': 1721968399.952752}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8424160925547284, '_timestamp': 1721968399.9528315}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1485130488872528, '_timestamp': 1721968399.952939}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 1.1403716802597046, '_timestamp': 1721968399.9532056}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'ratio': 1.0003242492675781, '_timestamp': 1721968399.9533267}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968399.9541538}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968399.9542546}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'Episode_Time': 31.43487572669983, '_timestamp': 1721968399.9543145}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.18695941450432468, '_timestamp': 1721968399.954636}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'train_goal': 0.5934797072521624, '_timestamp': 1721968399.9548085}).
wandb: WARNING (User provided step: 3017 is less than current step: 12030. Dropping entry: {'train_WDL': 0.18695941450432468, '_timestamp': 1721968399.9549687}).
Env Football Algo jrpo Exp base_JRPO updates 5870/100000000000.0 steps in 88.05
total episode rewards is -50.0
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'value_loss': 0.4703893168643117, '_timestamp': 1721968488.0011978}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0025759947307718296, '_timestamp': 1721968488.001372}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.844068725903829, '_timestamp': 1721968488.0014408}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13672734797000885, '_timestamp': 1721968488.0015419}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.47216081619262695, '_timestamp': 1721968488.0018172}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'ratio': 0.999690055847168, '_timestamp': 1721968488.0019221}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721968488.0020626}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968488.0029013}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.0454466342926, '_timestamp': 1721968488.0029652}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32098616957306075, '_timestamp': 1721968488.0036497}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'train_goal': 0.33950691521346965, '_timestamp': 1721968488.0042171}).
wandb: WARNING (User provided step: 5870 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32098616957306075, '_timestamp': 1721968488.0047245}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'value_loss': 0.18638795155721405, '_timestamp': 1721968571.4238942}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0023283273384246666, '_timestamp': 1721968571.4241982}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.836087605158488, '_timestamp': 1721968571.4242668}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13668495416641235, '_timestamp': 1721968571.424369}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1500551402568817, '_timestamp': 1721968571.4246342}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'ratio': 1.000662088394165, '_timestamp': 1721968571.4252095}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721968571.425411}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968571.4255114}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.4180896282196, '_timestamp': 1721968571.4255688}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968571.426492}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968571.4269092}).
wandb: WARNING (User provided step: 8239 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968571.4273388}).
Env Football Algo jrpo Exp base_JRPO updates 8239/100000000000.0 steps in 83.42
total episode rewards is -30.0
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'value_loss': 0.3828830134682357, '_timestamp': 1721968631.5047164}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0019785312155727298, '_timestamp': 1721968631.5059495}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8359282191594444, '_timestamp': 1721968631.5060194}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15746647119522095, '_timestamp': 1721968631.5066059}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.35252055525779724, '_timestamp': 1721968631.5069666}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'ratio': 0.9996364712715149, '_timestamp': 1721968631.5070677}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968631.5077727}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968631.5079923}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.07156443595886, '_timestamp': 1721968631.5080514}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.12404358914908416, '_timestamp': 1721968631.509043}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'train_goal': 0.4379782054254579, '_timestamp': 1721968631.5093546}).
wandb: WARNING (User provided step: 5207 is less than current step: 12030. Dropping entry: {'train_WDL': -0.12404358914908416, '_timestamp': 1721968631.5096653}).
Env Football Algo jrpo Exp base_JRPO updates 5207/100000000000.0 steps in 60.07
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8081/100000000000.0 steps in 87.27
total episode rewards is -20.0
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'value_loss': 0.24602761837032935, '_timestamp': 1721968718.7841542}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022572520341782366, '_timestamp': 1721968718.7843153}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8364638614654543, '_timestamp': 1721968718.7843812}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1370759904384613, '_timestamp': 1721968718.784471}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12780967354774475, '_timestamp': 1721968718.7847345}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'ratio': 0.9995584487915039, '_timestamp': 1721968718.7848344}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721968718.7849736}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968718.785139}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.27351093292236, '_timestamp': 1721968718.785198}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.13918196271137448, '_timestamp': 1721968718.7858117}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'train_goal': 0.43040901864431275, '_timestamp': 1721968718.7862322}).
wandb: WARNING (User provided step: 8081 is less than current step: 12030. Dropping entry: {'train_WDL': -0.13918196271137448, '_timestamp': 1721968718.7866638}).
Env Football Algo jrpo Exp base_JRPO updates 4297/100000000000.0 steps in 65.93
total episode rewards is -30.0
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'value_loss': 0.3156216773064807, '_timestamp': 1721968784.7162604}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0028974976955214514, '_timestamp': 1721968784.7164497}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83229976495107, '_timestamp': 1721968784.716522}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14891895651817322, '_timestamp': 1721968784.7166295}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.3569425046443939, '_timestamp': 1721968784.716928}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'ratio': 0.9998724460601807, '_timestamp': 1721968784.7178552}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721968784.7180195}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968784.7181232}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.92864871025085, '_timestamp': 1721968784.7181823}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4060414897488778, '_timestamp': 1721968784.7188513}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_goal': 0.29697925512556106, '_timestamp': 1721968784.7193859}).
wandb: WARNING (User provided step: 4297 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4060414897488778, '_timestamp': 1721968784.719909}).
Env Football Algo jrpo Exp base_JRPO updates 7780/100000000000.0 steps in 86.49
total episode rewards is -10.0
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'value_loss': 0.21547242548704768, '_timestamp': 1721968871.2081099}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0012466095556737855, '_timestamp': 1721968871.2082572}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83267111937205, '_timestamp': 1721968871.208324}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1464453637599945, '_timestamp': 1721968871.2084117}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2371951788663864, '_timestamp': 1721968871.208645}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'ratio': 1.0008453130722046, '_timestamp': 1721968871.2087457}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721968871.2089908}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968871.2090816}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.48730254173279, '_timestamp': 1721968871.2091415}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.17534626038781165, '_timestamp': 1721968871.2097154}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'train_goal': 0.4123268698060942, '_timestamp': 1721968871.2101512}).
wandb: WARNING (User provided step: 7780 is less than current step: 12030. Dropping entry: {'train_WDL': -0.17534626038781165, '_timestamp': 1721968871.2105923}).
Env Football Algo jrpo Exp base_JRPO updates 5935/100000000000.0 steps in 81.38
total episode rewards is -20.0
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'value_loss': 0.271898215249336, '_timestamp': 1721968952.5890076}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'policy_loss': 0.000875381405154864, '_timestamp': 1721968952.5892048}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83481995900472, '_timestamp': 1721968952.5942407}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1471107006072998, '_timestamp': 1721968952.5945282}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2394542247056961, '_timestamp': 1721968952.5949166}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'ratio': 0.9985889792442322, '_timestamp': 1721968952.5960329}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721968952.5962946}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968952.596425}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.37751293182373, '_timestamp': 1721968952.596493}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.36105901820187536, '_timestamp': 1721968952.597332}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'train_goal': 0.3194704908990623, '_timestamp': 1721968952.5979414}).
wandb: WARNING (User provided step: 5935 is less than current step: 12030. Dropping entry: {'train_WDL': -0.36105901820187536, '_timestamp': 1721968952.5985231}).
Env Football Algo jrpo Exp base_JRPO updates 7750/100000000000.0 steps in 86.76
total episode rewards is -20.0
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'value_loss': 0.28166335152306904, '_timestamp': 1721969039.3646488}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0030637498624855653, '_timestamp': 1721969039.365716}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.829582282702128, '_timestamp': 1721969039.3657897}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13473516702651978, '_timestamp': 1721969039.3662686}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2685650885105133, '_timestamp': 1721969039.3666675}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'ratio': 1.0010734796524048, '_timestamp': 1721969039.366774}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969039.3669186}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969039.3679237}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.7612202167511, '_timestamp': 1721969039.3680189}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.1793103448275862, '_timestamp': 1721969039.3691385}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'train_goal': 0.4103448275862069, '_timestamp': 1721969039.3696918}).
wandb: WARNING (User provided step: 7750 is less than current step: 12030. Dropping entry: {'train_WDL': -0.1793103448275862, '_timestamp': 1721969039.3701792}).
Env Football Algo jrpo Exp base_JRPO updates 6484/100000000000.0 steps in 86.42
total episode rewards is -20.0
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'value_loss': 0.27821813376271165, '_timestamp': 1721969125.789164}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005156387889292091, '_timestamp': 1721969125.7893562}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8346943855285645, '_timestamp': 1721969125.789436}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.11927344650030136, '_timestamp': 1721969125.789535}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1809152066707611, '_timestamp': 1721969125.789773}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'ratio': 1.0020155906677246, '_timestamp': 1721969125.7900054}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969125.7901342}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969125.790228}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.41796350479126, '_timestamp': 1721969125.7902858}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.31000469704086425, '_timestamp': 1721969125.7909052}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_goal': 0.34499765147956785, '_timestamp': 1721969125.7917192}).
wandb: WARNING (User provided step: 6484 is less than current step: 12030. Dropping entry: {'train_WDL': -0.31000469704086425, '_timestamp': 1721969125.7922564}).
Env Football Algo jrpo Exp base_JRPO updates 7757/100000000000.0 steps in 68.65
total episode rewards is -50.0
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'value_loss': 0.5547468202343832, '_timestamp': 1721969194.4431345}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0026553920345031654, '_timestamp': 1721969194.4441934}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.83730527083079, '_timestamp': 1721969194.4442654}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14608128368854523, '_timestamp': 1721969194.4447608}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7112522125244141, '_timestamp': 1721969194.4451003}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'ratio': 1.000708818435669, '_timestamp': 1721969194.4452016}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721969194.4458396}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969194.4460206}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'Episode_Time': 68.64589500427246, '_timestamp': 1721969194.446078}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.03024026512013256, '_timestamp': 1721969194.4469504}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'train_goal': 0.5151201325600663, '_timestamp': 1721969194.447289}).
wandb: WARNING (User provided step: 7757 is less than current step: 12030. Dropping entry: {'train_WDL': 0.03024026512013256, '_timestamp': 1721969194.447613}).
Env Football Algo jrpo Exp base_JRPO updates 6690/100000000000.0 steps in 78.80
total episode rewards is -60.0
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'value_loss': 0.5056440316792578, '_timestamp': 1721969273.2502105}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002465385700003632, '_timestamp': 1721969273.2503598}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8388772122065227, '_timestamp': 1721969273.250426}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1407272219657898, '_timestamp': 1721969273.2505157}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.42452141642570496, '_timestamp': 1721969273.250857}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'ratio': 1.000654935836792, '_timestamp': 1721969273.25096}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721969273.251089}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969273.2511778}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.80172729492188, '_timestamp': 1721969273.251234}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.2162528216704289, '_timestamp': 1721969273.2517781}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'train_goal': 0.39187358916478554, '_timestamp': 1721969273.2522137}).
wandb: WARNING (User provided step: 6690 is less than current step: 12030. Dropping entry: {'train_WDL': -0.2162528216704289, '_timestamp': 1721969273.2526274}).
Env Football Algo jrpo Exp base_JRPO updates 7667/100000000000.0 steps in 84.49
total episode rewards is -30.0
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'value_loss': 0.20717843166048017, '_timestamp': 1721969357.7462254}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'policy_loss': 0.006622418427529434, '_timestamp': 1721969357.7463753}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839166210492452, '_timestamp': 1721969357.7464397}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1317250281572342, '_timestamp': 1721969357.7465289}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12212362885475159, '_timestamp': 1721969357.746764}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'ratio': 0.9984844326972961, '_timestamp': 1721969357.7469676}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721969357.7471054}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969357.7471933}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.49291586875916, '_timestamp': 1721969357.7472491}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969357.747791}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969357.7482367}).
wandb: WARNING (User provided step: 7667 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969357.748696}).
Env Football Algo jrpo Exp base_JRPO updates 6172/100000000000.0 steps in 65.82
total episode rewards is -50.0
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'value_loss': 0.4392142012746384, '_timestamp': 1721969423.5696006}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011864258232526482, '_timestamp': 1721969423.569748}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8350762494405113, '_timestamp': 1721969423.5698152}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15433426201343536, '_timestamp': 1721969423.5699015}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6646280288696289, '_timestamp': 1721969423.570129}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'ratio': 0.9999681115150452, '_timestamp': 1721969423.5703564}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721969423.57048}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969423.570575}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.82022905349731, '_timestamp': 1721969423.5706334}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.13848568065908198, '_timestamp': 1721969423.571093}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'train_goal': 0.430757159670459, '_timestamp': 1721969423.5714297}).
wandb: WARNING (User provided step: 6172 is less than current step: 12030. Dropping entry: {'train_WDL': -0.13848568065908198, '_timestamp': 1721969423.5717654}).
Env Football Algo jrpo Exp base_JRPO updates 4115/100000000000.0 steps in 60.37
total episode rewards is -70.0
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'value_loss': 0.5687071308866143, '_timestamp': 1721969483.941667}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00042098639377703267, '_timestamp': 1721969483.9418151}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8315729824701945, '_timestamp': 1721969483.9418805}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1467139720916748, '_timestamp': 1721969483.9419687}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.620168924331665, '_timestamp': 1721969483.9423301}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'ratio': 1.0007377862930298, '_timestamp': 1721969483.9424314}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721969483.94256}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969483.9426472}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'Episode_Time': 60.36909294128418, '_timestamp': 1721969483.9427037}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3361842105263158, '_timestamp': 1721969483.9433424}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'train_goal': 0.3319078947368421, '_timestamp': 1721969483.9438412}).
wandb: WARNING (User provided step: 4115 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3361842105263158, '_timestamp': 1721969483.9442523}).
Env Football Algo jrpo Exp base_JRPO updates 7777/100000000000.0 steps in 81.52
total episode rewards is -70.0
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'value_loss': 0.44058818922688564, '_timestamp': 1721969565.4673555}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0017688168088595072, '_timestamp': 1721969565.4675245}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8328041315078734, '_timestamp': 1721969565.4675925}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.16205070912837982, '_timestamp': 1721969565.4676871}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.49623826146125793, '_timestamp': 1721969565.4679368}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'ratio': 1.000943660736084, '_timestamp': 1721969565.4684458}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721969565.4685853}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969565.4686809}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.52211141586304, '_timestamp': 1721969565.4687393}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969565.4692569}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969565.4696512}).
wandb: WARNING (User provided step: 7777 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969565.47006}).
Env Football Algo jrpo Exp base_JRPO updates 8202/100000000000.0 steps in 84.37
total episode rewards is -40.0
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'value_loss': 0.2614623314452668, '_timestamp': 1721969649.844032}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0026949218563580265, '_timestamp': 1721969649.8441997}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8337528721491494, '_timestamp': 1721969649.8442676}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14138762652873993, '_timestamp': 1721969649.8443594}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.26582643389701843, '_timestamp': 1721969649.8448236}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'ratio': 1.0012834072113037, '_timestamp': 1721969649.8449352}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721969649.8450704}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969649.8451645}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.37306261062622, '_timestamp': 1721969649.845223}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969649.8457975}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969649.8462343}).
wandb: WARNING (User provided step: 8202 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969649.846676}).
Env Football Algo jrpo Exp base_JRPO updates 5959/100000000000.0 steps in 84.63
total episode rewards is -40.0
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'value_loss': 0.27809300490344563, '_timestamp': 1721969734.4826782}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015170986236383518, '_timestamp': 1721969734.4828465}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8360948451360066, '_timestamp': 1721969734.4829133}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14942695200443268, '_timestamp': 1721969734.48301}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.14003486931324005, '_timestamp': 1721969734.483253}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'ratio': 1.0000871419906616, '_timestamp': 1721969734.483356}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721969734.483814}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969734.483914}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.626638174057, '_timestamp': 1721969734.485687}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969734.4863975}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969734.4869769}).
wandb: WARNING (User provided step: 5959 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969734.4875524}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'value_loss': 0.2867738312917451, '_timestamp': 1721969814.8255365}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0018188209565899644, '_timestamp': 1721969814.8256924}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.84037889957428, '_timestamp': 1721969814.8257594}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14562085270881653, '_timestamp': 1721969814.8258498}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2899967133998871, '_timestamp': 1721969814.8261065}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'ratio': 1.0002390146255493, '_timestamp': 1721969814.8264177}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969814.8265603}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969814.8266525}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.33704090118408, '_timestamp': 1721969814.826711}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.6101973684210527, '_timestamp': 1721969814.827199}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'train_goal': 0.19490131578947367, '_timestamp': 1721969814.827578}).
wandb: WARNING (User provided step: 8920 is less than current step: 12030. Dropping entry: {'train_WDL': -0.6101973684210527, '_timestamp': 1721969814.8279989}).
Env Football Algo jrpo Exp base_JRPO updates 8920/100000000000.0 steps in 80.34
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5069/100000000000.0 steps in 63.03
total episode rewards is -100.0
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'value_loss': 0.7264172587543726, '_timestamp': 1721969877.8624814}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00264293900943206, '_timestamp': 1721969877.8626633}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8351392952601113, '_timestamp': 1721969877.8627315}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15394757688045502, '_timestamp': 1721969877.8628333}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8460344076156616, '_timestamp': 1721969877.8631015}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'ratio': 0.9992688298225403, '_timestamp': 1721969877.8634357}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721969877.8635771}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969877.863673}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'Episode_Time': 63.033644676208496, '_timestamp': 1721969877.8637302}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969877.8642337}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969877.8645718}).
wandb: WARNING (User provided step: 5069 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969877.8649077}).
Env Football Algo jrpo Exp base_JRPO updates 8209/100000000000.0 steps in 79.84
total episode rewards is -20.0
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'value_loss': 0.2537179059535265, '_timestamp': 1721969957.7076805}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007067327277133397, '_timestamp': 1721969957.7091022}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.834890907605489, '_timestamp': 1721969957.709186}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13965751230716705, '_timestamp': 1721969957.7098012}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.28229910135269165, '_timestamp': 1721969957.7102137}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'ratio': 1.001065731048584, '_timestamp': 1721969957.710325}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969957.7112682}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969957.7114885}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'Episode_Time': 79.83661985397339, '_timestamp': 1721969957.7115533}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.12030628773376528, '_timestamp': 1721969957.712843}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'train_goal': 0.43984685613311736, '_timestamp': 1721969957.7133052}).
wandb: WARNING (User provided step: 8209 is less than current step: 12030. Dropping entry: {'train_WDL': -0.12030628773376528, '_timestamp': 1721969957.713742}).
Env Football Algo jrpo Exp base_JRPO updates 4786/100000000000.0 steps in 61.35
total episode rewards is -70.0
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'value_loss': 0.5857737115770578, '_timestamp': 1721970019.0681913}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0021727545250905676, '_timestamp': 1721970019.0683718}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.84043834845225, '_timestamp': 1721970019.068439}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1432306468486786, '_timestamp': 1721970019.068543}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5806934833526611, '_timestamp': 1721970019.0688112}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'ratio': 1.0003210306167603, '_timestamp': 1721970019.0689175}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721970019.0690544}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970019.0694304}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'Episode_Time': 61.353379011154175, '_timestamp': 1721970019.0694892}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.16590284142988085, '_timestamp': 1721970019.0699344}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'train_goal': 0.41704857928505956, '_timestamp': 1721970019.070234}).
wandb: WARNING (User provided step: 4786 is less than current step: 12030. Dropping entry: {'train_WDL': -0.16590284142988085, '_timestamp': 1721970019.070534}).
Env Football Algo jrpo Exp base_JRPO updates 9019/100000000000.0 steps in 78.33
total episode rewards is -20.0
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'value_loss': 0.2648368559808781, '_timestamp': 1721970097.3983328}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'policy_loss': 0.013624322550410094, '_timestamp': 1721970097.398521}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.837417788505554, '_timestamp': 1721970097.3985913}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1464896947145462, '_timestamp': 1721970097.3986936}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.24912109971046448, '_timestamp': 1721970097.3990128}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'ratio': 0.9999929070472717, '_timestamp': 1721970097.399115}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721970097.399868}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970097.3999975}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.32688307762146, '_timestamp': 1721970097.4000602}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.02624979100484869, '_timestamp': 1721970097.4006412}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'train_goal': 0.48687510449757565, '_timestamp': 1721970097.4010305}).
wandb: WARNING (User provided step: 9019 is less than current step: 12030. Dropping entry: {'train_WDL': -0.02624979100484869, '_timestamp': 1721970097.4014373}).
Env Football Algo jrpo Exp base_JRPO updates 3440/100000000000.0 steps in 89.71
total episode rewards is 20.0
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'value_loss': 0.26089732274529526, '_timestamp': 1721970187.1109061}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002266715120252532, '_timestamp': 1721970187.1110811}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8385182126363118, '_timestamp': 1721970187.1111488}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1271408051252365, '_timestamp': 1721970187.1112492}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.16635359823703766, '_timestamp': 1721970187.1115177}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'ratio': 1.002189040184021, '_timestamp': 1721970187.111621}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721970187.1123009}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970187.1124036}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.70859813690186, '_timestamp': 1721970187.1124623}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.5411764705882353, '_timestamp': 1721970187.113433}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'train_goal': 0.7705882352941177, '_timestamp': 1721970187.1140974}).
wandb: WARNING (User provided step: 3440 is less than current step: 12030. Dropping entry: {'train_WDL': 0.5411764705882353, '_timestamp': 1721970187.1147444}).
Env Football Algo jrpo Exp base_JRPO updates 6594/100000000000.0 steps in 91.37
total episode rewards is -40.0
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'value_loss': 0.2542264571141762, '_timestamp': 1721970278.4903123}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0023927975471209114, '_timestamp': 1721970278.490491}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.838002772331238, '_timestamp': 1721970278.4905586}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12861110270023346, '_timestamp': 1721970278.4906578}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2034241408109665, '_timestamp': 1721970278.4909267}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'ratio': 1.0002305507659912, '_timestamp': 1721970278.4910266}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721970278.4911675}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970278.4917147}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.37463283538818, '_timestamp': 1721970278.4917767}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970278.4924428}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970278.492946}).
wandb: WARNING (User provided step: 6594 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970278.4934657}).
Env Football Algo jrpo Exp base_JRPO updates 3749/100000000000.0 steps in 56.60
total episode rewards is -50.0
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'value_loss': 0.4531409256765619, '_timestamp': 1721970335.093749}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013734858747435888, '_timestamp': 1721970335.0940194}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.839538087844849, '_timestamp': 1721970335.0940893}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13535217940807343, '_timestamp': 1721970335.0941894}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5354064106941223, '_timestamp': 1721970335.0944426}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'ratio': 1.0003470182418823, '_timestamp': 1721970335.0945468}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721970335.094746}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970335.0951643}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'Episode_Time': 56.599111795425415, '_timestamp': 1721970335.0952249}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.33260353950009125, '_timestamp': 1721970335.0958664}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'train_goal': 0.3336982302499544, '_timestamp': 1721970335.0962558}).
wandb: WARNING (User provided step: 3749 is less than current step: 12030. Dropping entry: {'train_WDL': -0.33260353950009125, '_timestamp': 1721970335.0966282}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'value_loss': 0.7456514112402995, '_timestamp': 1721970373.6276054}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003126300107687712, '_timestamp': 1721970373.6278727}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.836074392000834, '_timestamp': 1721970373.6279416}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13970303535461426, '_timestamp': 1721970373.6280675}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7345547080039978, '_timestamp': 1721970373.6283314}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'ratio': 1.000284194946289, '_timestamp': 1721970373.628434}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721970373.6289587}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970373.6290581}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'Episode_Time': 38.52970361709595, '_timestamp': 1721970373.629117}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970373.6296139}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970373.6298368}).
wandb: WARNING (User provided step: 3437 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970373.6300619}).
Env Football Algo jrpo Exp base_JRPO updates 3437/100000000000.0 steps in 38.53
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 8029/100000000000.0 steps in 89.55
total episode rewards is -40.0
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'value_loss': 0.27135172026387105, '_timestamp': 1721970463.1802058}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'policy_loss': 0.009982639192603528, '_timestamp': 1721970463.1803746}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8387446053822836, '_timestamp': 1721970463.1804414}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12848183512687683, '_timestamp': 1721970463.1805425}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18878713250160217, '_timestamp': 1721970463.180796}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'ratio': 0.9974820017814636, '_timestamp': 1721970463.1808987}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721970463.1812603}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970463.1813557}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.54928040504456, '_timestamp': 1721970463.1814148}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970463.1819756}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970463.182402}).
wandb: WARNING (User provided step: 8029 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970463.1828434}).
Env Football Algo jrpo Exp base_JRPO updates 4714/100000000000.0 steps in 91.78
total episode rewards is 0.0
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'value_loss': 0.30387994672346397, '_timestamp': 1721970554.966195}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'policy_loss': 0.003342548726165357, '_timestamp': 1721970554.9664996}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.844352038701375, '_timestamp': 1721970554.9665675}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13657790422439575, '_timestamp': 1721970554.9666684}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2120548039674759, '_timestamp': 1721970554.9669342}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'ratio': 0.9997742176055908, '_timestamp': 1721970554.9670677}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721970554.9677465}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970554.9680305}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.7820680141449, '_timestamp': 1721970554.9680893}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.1335796227882559, '_timestamp': 1721970554.9692316}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'train_goal': 0.566789811394128, '_timestamp': 1721970554.969855}).
wandb: WARNING (User provided step: 4714 is less than current step: 12030. Dropping entry: {'train_WDL': 0.1335796227882559, '_timestamp': 1721970554.9704888}).
Env Football Algo jrpo Exp base_JRPO updates 5088/100000000000.0 steps in 77.63
total episode rewards is -20.0
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'value_loss': 0.2984261152916588, '_timestamp': 1721970632.5997992}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002551456850487739, '_timestamp': 1721970632.600005}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8419550482432046, '_timestamp': 1721970632.6000764}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12784075736999512, '_timestamp': 1721970632.6001797}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.11430639028549194, '_timestamp': 1721970632.6004786}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'ratio': 1.000646710395813, '_timestamp': 1721970632.6014566}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721970632.6016192}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970632.6017241}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.62822675704956, '_timestamp': 1721970632.6017823}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4096045197740113, '_timestamp': 1721970632.6025977}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'train_goal': 0.2951977401129944, '_timestamp': 1721970632.6032448}).
wandb: WARNING (User provided step: 5088 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4096045197740113, '_timestamp': 1721970632.603851}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'value_loss': 0.28426032621141833, '_timestamp': 1721970722.143318}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008333012338456076, '_timestamp': 1721970722.143509}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8363754177093505, '_timestamp': 1721970722.1435795}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13862374424934387, '_timestamp': 1721970722.1436834}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.15795288980007172, '_timestamp': 1721970722.14401}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'ratio': 0.9996148943901062, '_timestamp': 1721970722.1441212}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721970722.1443212}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970722.1444285}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.53785705566406, '_timestamp': 1721970722.1444867}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3293358977259871, '_timestamp': 1721970722.1455038}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'train_goal': 0.3353320511370064, '_timestamp': 1721970722.146074}).
wandb: WARNING (User provided step: 6161 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3293358977259871, '_timestamp': 1721970722.146618}).
Env Football Algo jrpo Exp base_JRPO updates 6161/100000000000.0 steps in 89.54
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 9293/100000000000.0 steps in 80.48
total episode rewards is -40.0
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'value_loss': 0.3672384729826202, '_timestamp': 1721970802.6304572}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0030019451684105054, '_timestamp': 1721970802.630628}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8434937095642088, '_timestamp': 1721970802.630694}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14348085224628448, '_timestamp': 1721970802.6307878}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.44866126775741577, '_timestamp': 1721970802.6310334}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'ratio': 0.9990582466125488, '_timestamp': 1721970802.631134}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721970802.6314526}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970802.6315434}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.48283410072327, '_timestamp': 1721970802.6316001}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.46196123806768874, '_timestamp': 1721970802.632194}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'train_goal': 0.7309806190338444, '_timestamp': 1721970802.6325512}).
wandb: WARNING (User provided step: 9293 is less than current step: 12030. Dropping entry: {'train_WDL': 0.46196123806768874, '_timestamp': 1721970802.6329374}).
Env Football Algo jrpo Exp base_JRPO updates 8372/100000000000.0 steps in 84.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'value_loss': 0.26800388530828056, '_timestamp': 1721970887.2201912}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0035924425652804834, '_timestamp': 1721970887.2203765}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845463730494181, '_timestamp': 1721970887.2204459}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.11817600578069687, '_timestamp': 1721970887.2205503}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.291074275970459, '_timestamp': 1721970887.2208056}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'ratio': 1.0019726753234863, '_timestamp': 1721970887.220911}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721970887.2210531}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970887.22142}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.58634233474731, '_timestamp': 1721970887.2214818}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970887.2220385}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970887.2224607}).
wandb: WARNING (User provided step: 8372 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970887.2228918}).
Env Football Algo jrpo Exp base_JRPO updates 4305/100000000000.0 steps in 54.84
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'value_loss': 0.6357465618786713, '_timestamp': 1721970942.0719228}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'policy_loss': -4.0030340848412986e-05, '_timestamp': 1721970942.0732353}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8461468982696534, '_timestamp': 1721970942.0733142}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14217180013656616, '_timestamp': 1721970942.0739036}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8585874438285828, '_timestamp': 1721970942.0742753}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'ratio': 1.001646876335144, '_timestamp': 1721970942.07483}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721970942.0749757}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970942.0751708}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'Episode_Time': 54.84295868873596, '_timestamp': 1721970942.0752316}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970942.076136}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970942.0763872}).
wandb: WARNING (User provided step: 4305 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970942.076638}).
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 4999/100000000000.0 steps in 65.37
total episode rewards is -50.0
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'value_loss': 0.6007597567389409, '_timestamp': 1721971007.4454055}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022876297523422785, '_timestamp': 1721971007.44557}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.849386278788249, '_timestamp': 1721971007.4456358}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14035309851169586, '_timestamp': 1721971007.4457266}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.5570042133331299, '_timestamp': 1721971007.445975}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'ratio': 0.9996776580810547, '_timestamp': 1721971007.4460747}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721971007.4461942}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971007.4467282}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'Episode_Time': 65.36781048774719, '_timestamp': 1721971007.4467869}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.33848966390099844, '_timestamp': 1721971007.447347}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'train_goal': 0.6692448319504992, '_timestamp': 1721971007.4477818}).
wandb: WARNING (User provided step: 4999 is less than current step: 12030. Dropping entry: {'train_WDL': 0.33848966390099844, '_timestamp': 1721971007.44823}).
Env Football Algo jrpo Exp base_JRPO updates 2649/100000000000.0 steps in 47.32
total episode rewards is -120.0
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'value_loss': 0.8255390799418092, '_timestamp': 1721971054.7709224}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0015984450961938517, '_timestamp': 1721971054.7710736}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8511736726760866, '_timestamp': 1721971054.7711394}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14638681709766388, '_timestamp': 1721971054.7712266}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7121754288673401, '_timestamp': 1721971054.7714038}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'ratio': 0.9990906119346619, '_timestamp': 1721971054.7715006}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721971054.771741}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971054.7718296}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'Episode_Time': 47.322001695632935, '_timestamp': 1721971054.7718863}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971054.7723134}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971054.77261}).
wandb: WARNING (User provided step: 2649 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971054.7729135}).
Env Football Algo jrpo Exp base_JRPO updates 3454/100000000000.0 steps in 52.19
total episode rewards is -110.0
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'value_loss': 0.7737762071440617, '_timestamp': 1721971106.963463}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0024381254852050916, '_timestamp': 1721971106.963618}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8548333406448365, '_timestamp': 1721971106.9636834}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15103311836719513, '_timestamp': 1721971106.9637737}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6942734718322754, '_timestamp': 1721971106.9640248}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'ratio': 0.9992731809616089, '_timestamp': 1721971106.9641263}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721971106.9645495}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971106.9646444}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.18940472602844, '_timestamp': 1721971106.9647033}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.33479386576379205, '_timestamp': 1721971106.96516}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'train_goal': 0.33260306711810395, '_timestamp': 1721971106.9654891}).
wandb: WARNING (User provided step: 3454 is less than current step: 12030. Dropping entry: {'train_WDL': -0.33479386576379205, '_timestamp': 1721971106.9658272}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'value_loss': 0.2732563564165806, '_timestamp': 1721971195.099266}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0036831622729854036, '_timestamp': 1721971195.0994155}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8503535413742065, '_timestamp': 1721971195.0994804}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13420270383358002, '_timestamp': 1721971195.0995672}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20749413967132568, '_timestamp': 1721971195.0998027}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'ratio': 0.9998390078544617, '_timestamp': 1721971195.0999153}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721971195.1002765}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971195.10037}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.1327064037323, '_timestamp': 1721971195.1004264}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971195.100975}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971195.1014404}).
wandb: WARNING (User provided step: 7291 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971195.1019173}).
Env Football Algo jrpo Exp base_JRPO updates 7291/100000000000.0 steps in 88.13
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4680/100000000000.0 steps in 66.64
total episode rewards is -50.0
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'value_loss': 0.42315465815365316, '_timestamp': 1721971261.7425075}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013160037332757687, '_timestamp': 1721971261.7426984}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.853500320116679, '_timestamp': 1721971261.7427685}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15733057260513306, '_timestamp': 1721971261.7428703}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4745052754878998, '_timestamp': 1721971261.743139}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'ratio': 0.998619794845581, '_timestamp': 1721971261.7432473}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721971261.7434547}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971261.7438972}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'Episode_Time': 66.63965606689453, '_timestamp': 1721971261.7439773}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971261.7446687}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971261.7451313}).
wandb: WARNING (User provided step: 4680 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971261.7455919}).
Env Football Algo jrpo Exp base_JRPO updates 4806/100000000000.0 steps in 59.89
total episode rewards is -50.0
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'value_loss': 0.537026144930472, '_timestamp': 1721971321.64476}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009805548711058995, '_timestamp': 1721971321.6455388}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8523001225789386, '_timestamp': 1721971321.6456394}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14881613850593567, '_timestamp': 1721971321.6458972}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6660938858985901, '_timestamp': 1721971321.6462462}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'ratio': 1.0005749464035034, '_timestamp': 1721971321.6463711}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721971321.646564}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971321.6467142}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.8897647857666, '_timestamp': 1721971321.646788}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.13584531482399603, '_timestamp': 1721971321.647534}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'train_goal': 0.43207734258800196, '_timestamp': 1721971321.6478968}).
wandb: WARNING (User provided step: 4806 is less than current step: 12030. Dropping entry: {'train_WDL': -0.13584531482399603, '_timestamp': 1721971321.6482785}).
Env Football Algo jrpo Exp base_JRPO updates 8654/100000000000.0 steps in 89.81
total episode rewards is -30.0
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'value_loss': 0.22201585762241544, '_timestamp': 1721971411.454893}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0029098823414339375, '_timestamp': 1721971411.4550579}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8551053841908773, '_timestamp': 1721971411.4551234}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1325802356004715, '_timestamp': 1721971411.4552152}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12005358934402466, '_timestamp': 1721971411.4554682}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'ratio': 0.9991893768310547, '_timestamp': 1721971411.4555686}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721971411.4556909}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971411.456026}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.80570268630981, '_timestamp': 1721971411.456086}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971411.4566154}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971411.4570532}).
wandb: WARNING (User provided step: 8654 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971411.4574661}).
Env Football Algo jrpo Exp base_JRPO updates 4648/100000000000.0 steps in 87.17
total episode rewards is -20.0
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'value_loss': 0.2718456909036225, '_timestamp': 1721971498.6292155}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016358377397106476, '_timestamp': 1721971498.6293902}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.859569482803345, '_timestamp': 1721971498.6294596}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12835074961185455, '_timestamp': 1721971498.6295583}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20995178818702698, '_timestamp': 1721971498.6298106}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'ratio': 0.9997072815895081, '_timestamp': 1721971498.6299117}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971498.6302023}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971498.6302958}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.17097282409668, '_timestamp': 1721971498.6303535}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.4281298299845441, '_timestamp': 1721971498.6311097}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'train_goal': 0.28593508500772796, '_timestamp': 1721971498.6317112}).
wandb: WARNING (User provided step: 4648 is less than current step: 12030. Dropping entry: {'train_WDL': -0.4281298299845441, '_timestamp': 1721971498.6323252}).
Env Football Algo jrpo Exp base_JRPO updates 2446/100000000000.0 steps in 31.23
total episode rewards is -80.0
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'value_loss': 0.6033042219902078, '_timestamp': 1721971529.8674014}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00170756482014743, '_timestamp': 1721971529.868668}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.863886586825053, '_timestamp': 1721971529.8687394}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14515334367752075, '_timestamp': 1721971529.8693326}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6387313604354858, '_timestamp': 1721971529.869705}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'ratio': 0.999269962310791, '_timestamp': 1721971529.869809}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721971529.8699453}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971529.8703961}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'Episode_Time': 31.22923183441162, '_timestamp': 1721971529.8704545}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.08584422967595225, '_timestamp': 1721971529.87122}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'train_goal': 0.45707788516202386, '_timestamp': 1721971529.8713984}).
wandb: WARNING (User provided step: 2446 is less than current step: 12030. Dropping entry: {'train_WDL': -0.08584422967595225, '_timestamp': 1721971529.8715706}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'value_loss': 0.7934034116814533, '_timestamp': 1721971570.9225142}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016701308362341175, '_timestamp': 1721971570.922667}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.865151127179464, '_timestamp': 1721971570.922734}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14069953560829163, '_timestamp': 1721971570.922824}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7552318572998047, '_timestamp': 1721971570.923024}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'ratio': 1.0003068447113037, '_timestamp': 1721971570.9231222}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721971570.9234955}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971570.9235883}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.050246477127075, '_timestamp': 1721971570.9236484}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971570.9240072}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971570.9242575}).
wandb: WARNING (User provided step: 3344 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971570.9245145}).
Env Football Algo jrpo Exp base_JRPO updates 3344/100000000000.0 steps in 41.05
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 3561/100000000000.0 steps in 57.23
total episode rewards is -90.0
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'value_loss': 0.6786961260686318, '_timestamp': 1721971628.1536574}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0035902922567523396, '_timestamp': 1721971628.153812}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.869611627260844, '_timestamp': 1721971628.1538782}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13985762000083923, '_timestamp': 1721971628.1539724}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6113382577896118, '_timestamp': 1721971628.1541839}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'ratio': 1.0020045042037964, '_timestamp': 1721971628.1542845}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721971628.1545975}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971628.1546912}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'Episode_Time': 57.22834348678589, '_timestamp': 1721971628.154748}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.37202328452989947, '_timestamp': 1721971628.1551864}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'train_goal': 0.3139883577350503, '_timestamp': 1721971628.1555457}).
wandb: WARNING (User provided step: 3561 is less than current step: 12030. Dropping entry: {'train_WDL': -0.37202328452989947, '_timestamp': 1721971628.1559162}).
Env Football Algo jrpo Exp base_JRPO updates 5927/100000000000.0 steps in 81.79
total episode rewards is -20.0
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'value_loss': 0.32259304214967416, '_timestamp': 1721971709.9490316}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005037521584502732, '_timestamp': 1721971709.949184}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8671168247858683, '_timestamp': 1721971709.9492495}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1460978090763092, '_timestamp': 1721971709.9493384}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18454471230506897, '_timestamp': 1721971709.9495664}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'ratio': 0.9985931515693665, '_timestamp': 1721971709.9496677}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971709.9497914}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971709.949879}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.79221963882446, '_timestamp': 1721971709.9499362}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.350600683346192, '_timestamp': 1721971709.9505777}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'train_goal': 0.324699658326904, '_timestamp': 1721971709.9510984}).
wandb: WARNING (User provided step: 5927 is less than current step: 12030. Dropping entry: {'train_WDL': -0.350600683346192, '_timestamp': 1721971709.951633}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'value_loss': 0.26808154576069987, '_timestamp': 1721971796.9107842}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00828634797265598, '_timestamp': 1721971796.9110491}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.867479615211487, '_timestamp': 1721971796.9111178}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13463720679283142, '_timestamp': 1721971796.9112213}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.23535025119781494, '_timestamp': 1721971796.9114947}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'ratio': 1.0007447004318237, '_timestamp': 1721971796.911599}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721971796.9124749}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971796.9125834}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.95797061920166, '_timestamp': 1721971796.9126444}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971796.9134533}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971796.9138768}).
wandb: WARNING (User provided step: 8581 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971796.9143083}).
Env Football Algo jrpo Exp base_JRPO updates 8581/100000000000.0 steps in 86.96
total episode rewards is -40.0
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'value_loss': 0.3027273183102564, '_timestamp': 1721971885.3845763}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004305369777527327, '_timestamp': 1721971885.3847325}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8701444244384766, '_timestamp': 1721971885.384797}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13679879903793335, '_timestamp': 1721971885.384887}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2513726055622101, '_timestamp': 1721971885.3850703}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'ratio': 0.9977520704269409, '_timestamp': 1721971885.3852842}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971885.3854103}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971885.3855007}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.46916246414185, '_timestamp': 1721971885.3855572}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3071910635326972, '_timestamp': 1721971885.3861578}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'train_goal': 0.3464044682336514, '_timestamp': 1721971885.386656}).
wandb: WARNING (User provided step: 6406 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3071910635326972, '_timestamp': 1721971885.3871663}).
Env Football Algo jrpo Exp base_JRPO updates 6406/100000000000.0 steps in 88.47
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5589/100000000000.0 steps in 82.70
total episode rewards is -20.0
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'value_loss': 0.24716246018729482, '_timestamp': 1721971968.090318}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'policy_loss': 0.014473049271230897, '_timestamp': 1721971968.0904992}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8653333965937295, '_timestamp': 1721971968.0905662}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12238684296607971, '_timestamp': 1721971968.0906632}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19455428421497345, '_timestamp': 1721971968.091192}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'ratio': 1.0011568069458008, '_timestamp': 1721971968.0915344}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971968.0916839}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971968.0917811}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.70226573944092, '_timestamp': 1721971968.091839}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3649984061204973, '_timestamp': 1721971968.0925932}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'train_goal': 0.31750079693975136, '_timestamp': 1721971968.0931435}).
wandb: WARNING (User provided step: 5589 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3649984061204973, '_timestamp': 1721971968.0936968}).
Env Football Algo jrpo Exp base_JRPO updates 4826/100000000000.0 steps in 86.80
total episode rewards is -20.0
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'value_loss': 0.28013236485344045, '_timestamp': 1721972054.8898015}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007907309102204938, '_timestamp': 1721972054.8900685}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.864172890981038, '_timestamp': 1721972054.8901367}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12125084549188614, '_timestamp': 1721972054.8902347}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.31710121035575867, '_timestamp': 1721972054.8905063}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'ratio': 0.9993209838867188, '_timestamp': 1721972054.890626}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972054.8911967}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972054.8912976}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.79511284828186, '_timestamp': 1721972054.8913608}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.42500491448791033, '_timestamp': 1721972054.8921652}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'train_goal': 0.28749754275604483, '_timestamp': 1721972054.8928008}).
wandb: WARNING (User provided step: 4826 is less than current step: 12030. Dropping entry: {'train_WDL': -0.42500491448791033, '_timestamp': 1721972054.8934371}).
Env Football Algo jrpo Exp base_JRPO updates 4737/100000000000.0 steps in 47.92
total episode rewards is -60.0
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'value_loss': 0.5143162741512061, '_timestamp': 1721972102.8191268}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0035633920492546167, '_timestamp': 1721972102.819314}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.858436190287272, '_timestamp': 1721972102.819386}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14564041793346405, '_timestamp': 1721972102.8194928}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.585512101650238, '_timestamp': 1721972102.819811}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'ratio': 1.0000331401824951, '_timestamp': 1721972102.8199148}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721972102.8209462}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972102.8210638}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'Episode_Time': 47.924487829208374, '_timestamp': 1721972102.821124}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.15122342559165664, '_timestamp': 1721972102.8216665}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'train_goal': 0.5756117127958283, '_timestamp': 1721972102.821892}).
wandb: WARNING (User provided step: 4737 is less than current step: 12030. Dropping entry: {'train_WDL': 0.15122342559165664, '_timestamp': 1721972102.8221166}).
Env Football Algo jrpo Exp base_JRPO updates 5211/100000000000.0 steps in 84.18
total episode rewards is -20.0
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'value_loss': 0.28019343015388587, '_timestamp': 1721972186.9991367}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013153274960738296, '_timestamp': 1721972186.9993236}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871390345891317, '_timestamp': 1721972186.9993904}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12315623462200165, '_timestamp': 1721972186.9994824}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18877491354942322, '_timestamp': 1721972186.9997165}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'ratio': 0.9984709024429321, '_timestamp': 1721972186.9998167}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972187.0002706}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972187.0003653}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.1760663986206, '_timestamp': 1721972187.0004232}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.39953008478904894, '_timestamp': 1721972187.0012329}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'train_goal': 0.3002349576054755, '_timestamp': 1721972187.0017943}).
wandb: WARNING (User provided step: 5211 is less than current step: 12030. Dropping entry: {'train_WDL': -0.39953008478904894, '_timestamp': 1721972187.0023675}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'value_loss': 0.6878868189826608, '_timestamp': 1721972223.3430882}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013102775693793472, '_timestamp': 1721972223.34324}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.859665223757426, '_timestamp': 1721972223.3433063}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14939479529857635, '_timestamp': 1721972223.3433948}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8381600379943848, '_timestamp': 1721972223.3436146}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'ratio': 1.0001083612442017, '_timestamp': 1721972223.3437152}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721972223.3438444}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972223.3440557}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'Episode_Time': 36.339831829071045, '_timestamp': 1721972223.3441155}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.37254901960784315, '_timestamp': 1721972223.3444695}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'train_goal': 0.3137254901960784, '_timestamp': 1721972223.344714}).
wandb: WARNING (User provided step: 2146 is less than current step: 12030. Dropping entry: {'train_WDL': -0.37254901960784315, '_timestamp': 1721972223.3449621}).
Env Football Algo jrpo Exp base_JRPO updates 2146/100000000000.0 steps in 36.34
total episode rewards is -90.0
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'value_loss': 0.40215443121890226, '_timestamp': 1721972305.3000634}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'policy_loss': -0.004229481345585858, '_timestamp': 1721972305.3002295}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8647864643732706, '_timestamp': 1721972305.3002973}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13938480615615845, '_timestamp': 1721972305.300393}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.34678220748901367, '_timestamp': 1721972305.3006406}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'ratio': 0.9988313913345337, '_timestamp': 1721972305.3007414}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721972305.3011794}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972305.3012733}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.95422768592834, '_timestamp': 1721972305.3013308}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972305.30191}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972305.3023798}).
wandb: WARNING (User provided step: 6112 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972305.3028743}).
Env Football Algo jrpo Exp base_JRPO updates 6112/100000000000.0 steps in 81.95
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 7272/100000000000.0 steps in 77.60
total episode rewards is -20.0
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'value_loss': 0.246821391939496, '_timestamp': 1721972382.9059858}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0010104296752251685, '_timestamp': 1721972382.9061422}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.860926178296407, '_timestamp': 1721972382.9062088}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14062458276748657, '_timestamp': 1721972382.906301}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.15287736058235168, '_timestamp': 1721972382.9065547}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'ratio': 1.0000805854797363, '_timestamp': 1721972382.9066532}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972382.9069629}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972382.9070551}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'Episode_Time': 77.6022400856018, '_timestamp': 1721972382.907113}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.22696687370600413, '_timestamp': 1721972382.9077172}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'train_goal': 0.38651656314699795, '_timestamp': 1721972382.9082}).
wandb: WARNING (User provided step: 7272 is less than current step: 12030. Dropping entry: {'train_WDL': -0.22696687370600413, '_timestamp': 1721972382.9086714}).
Env Football Algo jrpo Exp base_JRPO updates 6614/100000000000.0 steps in 69.72
total episode rewards is -70.0
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'value_loss': 0.44881672647471227, '_timestamp': 1721972452.630654}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'policy_loss': -0.003166933557173858, '_timestamp': 1721972452.6308122}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.863451150258382, '_timestamp': 1721972452.6308784}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14047230780124664, '_timestamp': 1721972452.6309695}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6074477434158325, '_timestamp': 1721972452.6312156}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'ratio': 0.9998129606246948, '_timestamp': 1721972452.631511}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721972452.63165}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972452.631743}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'Episode_Time': 69.72126626968384, '_timestamp': 1721972452.6318016}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972452.6322176}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972452.632516}).
wandb: WARNING (User provided step: 6614 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972452.632825}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'value_loss': 0.8120604588339726, '_timestamp': 1721972485.8746438}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0033529148049031695, '_timestamp': 1721972485.8748512}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8635297377904254, '_timestamp': 1721972485.8749216}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1405155062675476, '_timestamp': 1721972485.875026}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8967430591583252, '_timestamp': 1721972485.8752873}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'ratio': 0.9988417029380798, '_timestamp': 1721972485.8753924}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721972485.8755317}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972485.8759341}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'Episode_Time': 33.24079775810242, '_timestamp': 1721972485.8760152}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.2571046472751588, '_timestamp': 1721972485.8767233}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'train_goal': 0.6285523236375794, '_timestamp': 1721972485.877085}).
wandb: WARNING (User provided step: 1889 is less than current step: 12030. Dropping entry: {'train_WDL': 0.2571046472751588, '_timestamp': 1721972485.8773274}).
Env Football Algo jrpo Exp base_JRPO updates 1889/100000000000.0 steps in 33.24
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 1828/100000000000.0 steps in 26.79
total episode rewards is -110.0
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'value_loss': 1.1138125888009867, '_timestamp': 1721972512.6724482}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0035605087569759537, '_timestamp': 1721972512.6733618}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8665356636047363, '_timestamp': 1721972512.673433}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14779074490070343, '_timestamp': 1721972512.6738489}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9979809522628784, '_timestamp': 1721972512.6741896}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'ratio': 0.9999746680259705, '_timestamp': 1721972512.6745794}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721972512.6747234}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972512.6788006}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'Episode_Time': 26.791001081466675, '_timestamp': 1721972512.6788743}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.14720110573600553, '_timestamp': 1721972512.6795404}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'train_goal': 0.42639944713199723, '_timestamp': 1721972512.6797118}).
wandb: WARNING (User provided step: 1828 is less than current step: 12030. Dropping entry: {'train_WDL': -0.14720110573600553, '_timestamp': 1721972512.6798797}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'value_loss': 0.26638648920382063, '_timestamp': 1721972604.3020637}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'policy_loss': 0.014389340996276588, '_timestamp': 1721972604.302241}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8674406147003175, '_timestamp': 1721972604.3023086}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14102885127067566, '_timestamp': 1721972604.3024087}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2122933566570282, '_timestamp': 1721972604.302649}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'ratio': 1.0001205205917358, '_timestamp': 1721972604.302755}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721972604.3028905}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972604.3031366}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.62113523483276, '_timestamp': 1721972604.3031967}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972604.303898}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972604.3044364}).
wandb: WARNING (User provided step: 6162 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972604.3049905}).
Env Football Algo jrpo Exp base_JRPO updates 6162/100000000000.0 steps in 91.62
total episode rewards is -40.0
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'value_loss': 0.2523441386851482, '_timestamp': 1721972690.2496548}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'policy_loss': 0.010899088816950097, '_timestamp': 1721972690.2509215}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.863995219866435, '_timestamp': 1721972690.250992}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1310596913099289, '_timestamp': 1721972690.2515752}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.131375253200531, '_timestamp': 1721972690.251941}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'ratio': 1.0003081560134888, '_timestamp': 1721972690.2520578}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721972690.252764}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972690.2529728}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.93899488449097, '_timestamp': 1721972690.2530336}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972690.2544467}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972690.2548847}).
wandb: WARNING (User provided step: 8243 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972690.2553217}).
Env Football Algo jrpo Exp base_JRPO updates 8243/100000000000.0 steps in 85.94
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 3745/100000000000.0 steps in 41.00
total episode rewards is -90.0
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'value_loss': 0.5541356293670833, '_timestamp': 1721972731.2580183}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'policy_loss': 0.001418288748827763, '_timestamp': 1721972731.2581713}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.866575662295024, '_timestamp': 1721972731.2582383}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1470331996679306, '_timestamp': 1721972731.2583275}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.47801804542541504, '_timestamp': 1721972731.2585843}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'ratio': 1.0002185106277466, '_timestamp': 1721972731.258682}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721972731.259083}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972731.2591724}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'Episode_Time': 41.0018093585968, '_timestamp': 1721972731.2592287}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972731.2595127}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972731.2597055}).
wandb: WARNING (User provided step: 3745 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972731.2598963}).
Env Football Algo jrpo Exp base_JRPO updates 6135/100000000000.0 steps in 82.50
total episode rewards is -20.0
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'value_loss': 0.2609395477036014, '_timestamp': 1721972813.7582974}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007176893133825312, '_timestamp': 1721972813.7584484}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.867232918739319, '_timestamp': 1721972813.7585137}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13067707419395447, '_timestamp': 1721972813.7586052}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.166218101978302, '_timestamp': 1721972813.7588506}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'ratio': 0.9976962804794312, '_timestamp': 1721972813.7589493}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972813.7594132}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972813.7595077}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.49756050109863, '_timestamp': 1721972813.759565}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32588832487309644, '_timestamp': 1721972813.760229}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'train_goal': 0.33705583756345175, '_timestamp': 1721972813.7607412}).
wandb: WARNING (User provided step: 6135 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32588832487309644, '_timestamp': 1721972813.7612677}).
Env Football Algo jrpo Exp base_JRPO updates 4782/100000000000.0 steps in 53.02
total episode rewards is -70.0
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'value_loss': 0.4344513591254751, '_timestamp': 1721972866.7804224}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'policy_loss': 0.00034065031446516513, '_timestamp': 1721972866.7805781}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8714317337671917, '_timestamp': 1721972866.780644}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14084753394126892, '_timestamp': 1721972866.7807376}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4784999191761017, '_timestamp': 1721972866.781158}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'ratio': 0.999220073223114, '_timestamp': 1721972866.7813203}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721972866.7814534}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972866.7815425}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'Episode_Time': 53.01824927330017, '_timestamp': 1721972866.7815993}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972866.7820125}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972866.782328}).
wandb: WARNING (User provided step: 4782 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972866.782641}).
Env Football Algo jrpo Exp base_JRPO updates 4311/100000000000.0 steps in 52.63
total episode rewards is -80.0
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'value_loss': 0.6442866819103559, '_timestamp': 1721972919.4141}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009541075686380888, '_timestamp': 1721972919.4142585}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.872031707763672, '_timestamp': 1721972919.4143255}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14639703929424286, '_timestamp': 1721972919.4144177}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.6069872975349426, '_timestamp': 1721972919.4146743}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'ratio': 1.0003352165222168, '_timestamp': 1721972919.414773}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721972919.4152257}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972919.415318}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'Episode_Time': 52.6305787563324, '_timestamp': 1721972919.4153745}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.13336992316136115, '_timestamp': 1721972919.4157636}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'train_goal': 0.43331503841931945, '_timestamp': 1721972919.4160407}).
wandb: WARNING (User provided step: 4311 is less than current step: 12030. Dropping entry: {'train_WDL': -0.13336992316136115, '_timestamp': 1721972919.416306}).
Env Football Algo jrpo Exp base_JRPO updates 6577/100000000000.0 steps in 84.48
total episode rewards is -20.0
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'value_loss': 0.29751880397399266, '_timestamp': 1721973003.8944652}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011009255319368095, '_timestamp': 1721973003.8946512}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.87468732992808, '_timestamp': 1721973003.8947208}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1307966709136963, '_timestamp': 1721973003.8948255}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1578608751296997, '_timestamp': 1721973003.895096}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'ratio': 0.9995055198669434, '_timestamp': 1721973003.8955448}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973003.8957274}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973003.8958223}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.4771819114685, '_timestamp': 1721973003.8958786}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.29953698207289564, '_timestamp': 1721973003.8965912}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'train_goal': 0.35023150896355215, '_timestamp': 1721973003.8971083}).
wandb: WARNING (User provided step: 6577 is less than current step: 12030. Dropping entry: {'train_WDL': -0.29953698207289564, '_timestamp': 1721973003.8976235}).
Env Football Algo jrpo Exp base_JRPO updates 7075/100000000000.0 steps in 87.25
total episode rewards is -40.0
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'value_loss': 0.2739429298772787, '_timestamp': 1721973091.1568317}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'policy_loss': 0.002236213700574202, '_timestamp': 1721973091.158124}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.874605669975281, '_timestamp': 1721973091.1581995}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1310804933309555, '_timestamp': 1721973091.158822}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2656608521938324, '_timestamp': 1721973091.1592236}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'ratio': 1.0002890825271606, '_timestamp': 1721973091.160257}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721973091.1604187}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973091.16064}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'Episode_Time': 87.25305128097534, '_timestamp': 1721973091.160699}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973091.1618538}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973091.1623478}).
wandb: WARNING (User provided step: 7075 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973091.1628578}).
Env Football Algo jrpo Exp base_JRPO updates 5369/100000000000.0 steps in 81.67
total episode rewards is -20.0
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'value_loss': 0.27315317957972485, '_timestamp': 1721973172.8294723}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0029050821426790207, '_timestamp': 1721973172.8296354}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8715810600916543, '_timestamp': 1721973172.8296978}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14528445899486542, '_timestamp': 1721973172.8297882}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.09174171090126038, '_timestamp': 1721973172.8300228}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'ratio': 0.9997580051422119, '_timestamp': 1721973172.8301225}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973172.8303857}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973172.8304758}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.66554307937622, '_timestamp': 1721973172.8305323}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3880178589969889, '_timestamp': 1721973172.8312213}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'train_goal': 0.30599107050150554, '_timestamp': 1721973172.8317673}).
wandb: WARNING (User provided step: 5369 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3880178589969889, '_timestamp': 1721973172.832352}).
Env Football Algo jrpo Exp base_JRPO updates 10122/100000000000.0 steps in 81.59
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'value_loss': 0.3791387715625266, '_timestamp': 1721973254.424961}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0002731668599881232, '_timestamp': 1721973254.426101}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.866903624534607, '_timestamp': 1721973254.42617}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12968116998672485, '_timestamp': 1721973254.4266984}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.33005931973457336, '_timestamp': 1721973254.427028}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'ratio': 1.0006816387176514, '_timestamp': 1721973254.4271286}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721973254.4273803}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973254.4275591}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.58707284927368, '_timestamp': 1721973254.4276168}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973254.4284537}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973254.4287767}).
wandb: WARNING (User provided step: 10122 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973254.4290853}).
total episode rewards is -60.0
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'value_loss': 0.3896298671506035, '_timestamp': 1721973336.8538098}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0013184561108937488, '_timestamp': 1721973336.853971}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8674941778182985, '_timestamp': 1721973336.854037}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13995707035064697, '_timestamp': 1721973336.8541286}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4330175518989563, '_timestamp': 1721973336.8543687}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'ratio': 1.0008175373077393, '_timestamp': 1721973336.8548858}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721973336.855027}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973336.8551228}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'Episode_Time': 82.42382478713989, '_timestamp': 1721973336.8551798}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973336.8556266}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973336.855971}).
wandb: WARNING (User provided step: 9526 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973336.8563082}).
Env Football Algo jrpo Exp base_JRPO updates 9526/100000000000.0 steps in 82.42
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 1780/100000000000.0 steps in 24.96
total episode rewards is -120.0
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'value_loss': 0.8482855888207753, '_timestamp': 1721973361.816804}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00231521934173846, '_timestamp': 1721973361.816951}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8667889229456582, '_timestamp': 1721973361.8170168}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15356823801994324, '_timestamp': 1721973361.817101}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.8116199374198914, '_timestamp': 1721973361.8172708}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'ratio': 1.0000969171524048, '_timestamp': 1721973361.8173673}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721973361.8174894}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973361.8176816}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'Episode_Time': 24.959854125976562, '_timestamp': 1721973361.8177392}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973361.8179426}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973361.818087}).
wandb: WARNING (User provided step: 1780 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973361.818229}).
Env Football Algo jrpo Exp base_JRPO updates 5308/100000000000.0 steps in 80.02
total episode rewards is -40.0
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'value_loss': 0.27236319726333025, '_timestamp': 1721973441.843787}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0007781172314813981, '_timestamp': 1721973441.8439393}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.862469245592753, '_timestamp': 1721973441.8440375}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1418153941631317, '_timestamp': 1721973441.8441277}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.19578227400779724, '_timestamp': 1721973441.844362}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'ratio': 1.0006030797958374, '_timestamp': 1721973441.844622}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721973441.8447554}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973441.8448439}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'Episode_Time': 80.02491068840027, '_timestamp': 1721973441.8448994}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973441.8455539}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973441.8460994}).
wandb: WARNING (User provided step: 5308 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973441.8466756}).
Env Football Algo jrpo Exp base_JRPO updates 4931/100000000000.0 steps in 86.81
total episode rewards is -20.0
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'value_loss': 0.2996052351562927, '_timestamp': 1721973528.662377}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0010928167560875105, '_timestamp': 1721973528.6625252}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8635906918843586, '_timestamp': 1721973528.6625934}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13637495040893555, '_timestamp': 1721973528.6626813}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1513672024011612, '_timestamp': 1721973528.6629066}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'ratio': 0.9994877576828003, '_timestamp': 1721973528.663005}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973528.6632667}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973528.6633554}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.81499934196472, '_timestamp': 1721973528.6634138}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.41702254444334097, '_timestamp': 1721973528.6641529}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'train_goal': 0.2914887277783295, '_timestamp': 1721973528.6647205}).
wandb: WARNING (User provided step: 4931 is less than current step: 12030. Dropping entry: {'train_WDL': -0.41702254444334097, '_timestamp': 1721973528.6653068}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'value_loss': 0.2671381372927378, '_timestamp': 1721973615.0073826}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'policy_loss': -0.00030232371607174477, '_timestamp': 1721973615.0075476}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8626073948542277, '_timestamp': 1721973615.0076187}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13257387280464172, '_timestamp': 1721973615.0077133}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20429272949695587, '_timestamp': 1721973615.0079784}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'ratio': 0.9999126195907593, '_timestamp': 1721973615.0080814}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721973615.00822}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973615.0083137}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'Episode_Time': 86.34050631523132, '_timestamp': 1721973615.0083709}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973615.009046}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973615.009526}).
wandb: WARNING (User provided step: 7073 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973615.010022}).
Env Football Algo jrpo Exp base_JRPO updates 7073/100000000000.0 steps in 86.34
total episode rewards is -40.0
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'value_loss': 0.24636423613565664, '_timestamp': 1721973693.2078328}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'policy_loss': -0.001376796004284794, '_timestamp': 1721973693.208019}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8597660938898724, '_timestamp': 1721973693.2080886}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1406281292438507, '_timestamp': 1721973693.2081785}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1905573457479477, '_timestamp': 1721973693.2084155}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'ratio': 0.9996549487113953, '_timestamp': 1721973693.208514}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973693.2088072}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973693.2088957}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'Episode_Time': 78.19696426391602, '_timestamp': 1721973693.2089534}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.0258008658008658, '_timestamp': 1721973693.2094886}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'train_goal': 0.5129004329004329, '_timestamp': 1721973693.2098489}).
wandb: WARNING (User provided step: 9225 is less than current step: 12030. Dropping entry: {'train_WDL': 0.0258008658008658, '_timestamp': 1721973693.2102191}).
Env Football Algo jrpo Exp base_JRPO updates 9225/100000000000.0 steps in 78.20
total episode rewards is -20.0
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'value_loss': 0.30242804521073896, '_timestamp': 1721973781.528968}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0009108768046523133, '_timestamp': 1721973781.5293465}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.859822783470154, '_timestamp': 1721973781.5294168}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14919574558734894, '_timestamp': 1721973781.529519}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.26396915316581726, '_timestamp': 1721973781.5305645}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'ratio': 0.9989242553710938, '_timestamp': 1721973781.5306728}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721973781.5308099}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973781.5309076}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.31742906570435, '_timestamp': 1721973781.5309665}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973781.5318804}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973781.5324788}).
wandb: WARNING (User provided step: 5286 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973781.5330713}).
Env Football Algo jrpo Exp base_JRPO updates 5286/100000000000.0 steps in 88.32
total episode rewards is -40.0
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'value_loss': 0.17739555202734966, '_timestamp': 1721973867.260739}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0015102871323081975, '_timestamp': 1721973867.2608967}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.855032917658488, '_timestamp': 1721973867.2609656}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14023412764072418, '_timestamp': 1721973867.2610598}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.20314234495162964, '_timestamp': 1721973867.2612946}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'ratio': 1.0017131567001343, '_timestamp': 1721973867.2614005}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721973867.2616532}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973867.2617447}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.72676181793213, '_timestamp': 1721973867.2618015}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973867.2622201}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973867.262551}).
wandb: WARNING (User provided step: 10200 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973867.2628913}).
Env Football Algo jrpo Exp base_JRPO updates 10200/100000000000.0 steps in 85.73
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 2607/100000000000.0 steps in 28.64
total episode rewards is -80.0
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'value_loss': 0.4682314039161429, '_timestamp': 1721973895.9010425}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0025214987540978957, '_timestamp': 1721973895.9011917}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.854952917098999, '_timestamp': 1721973895.9012597}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1460646539926529, '_timestamp': 1721973895.9013486}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.47871634364128113, '_timestamp': 1721973895.901752}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'ratio': 1.0012271404266357, '_timestamp': 1721973895.9018555}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721973895.9019809}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973895.90207}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'Episode_Time': 28.637468338012695, '_timestamp': 1721973895.9021268}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973895.9023385}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973895.9024847}).
wandb: WARNING (User provided step: 2607 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973895.9026275}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'value_loss': 0.621168579844137, '_timestamp': 1721973955.5542438}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'policy_loss': 0.005467884019938841, '_timestamp': 1721973955.55445}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8562065092722575, '_timestamp': 1721973955.5545213}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14945612847805023, '_timestamp': 1721973955.5546343}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7094995975494385, '_timestamp': 1721973955.5549083}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'ratio': 1.0007535219192505, '_timestamp': 1721973955.555016}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721973955.556118}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973955.5562396}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'Episode_Time': 59.65052580833435, '_timestamp': 1721973955.556301}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973955.5569682}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973955.5573058}).
wandb: WARNING (User provided step: 5881 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973955.5576508}).
Env Football Algo jrpo Exp base_JRPO updates 5881/100000000000.0 steps in 59.65
total episode rewards is -100.0
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'value_loss': 0.23899488262832164, '_timestamp': 1721974041.0224438}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0006705003254076777, '_timestamp': 1721974041.0226011}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8621300888061523, '_timestamp': 1721974041.0226693}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14449164271354675, '_timestamp': 1721974041.022759}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.18725977838039398, '_timestamp': 1721974041.0234785}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'ratio': 0.9990175366401672, '_timestamp': 1721974041.0235994}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974041.0237312}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974041.0238364}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.4636697769165, '_timestamp': 1721974041.023903}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974041.0245326}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974041.024975}).
wandb: WARNING (User provided step: 7618 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974041.0254383}).
Env Football Algo jrpo Exp base_JRPO updates 7618/100000000000.0 steps in 85.46
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 6901/100000000000.0 steps in 83.39
total episode rewards is -10.0
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'value_loss': 0.238132281464835, '_timestamp': 1721974124.4120677}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'policy_loss': -0.000964575115746508, '_timestamp': 1721974124.4122298}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.86698779741923, '_timestamp': 1721974124.4122956}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14160852134227753, '_timestamp': 1721974124.4123843}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.1531783640384674, '_timestamp': 1721974124.4126244}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'ratio': 1.0002000331878662, '_timestamp': 1721974124.4127243}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721974124.4128566}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974124.41323}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.38545894622803, '_timestamp': 1721974124.4132898}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.26608223237436723, '_timestamp': 1721974124.4139016}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'train_goal': 0.3669588838128164, '_timestamp': 1721974124.4143906}).
wandb: WARNING (User provided step: 6901 is less than current step: 12030. Dropping entry: {'train_WDL': -0.26608223237436723, '_timestamp': 1721974124.4148839}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'value_loss': 0.3719518180564046, '_timestamp': 1721974205.8247485}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0007384311275867125, '_timestamp': 1721974205.824903}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.867991051673889, '_timestamp': 1721974205.8249688}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1451830118894577, '_timestamp': 1721974205.8250606}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13971206545829773, '_timestamp': 1721974205.8252537}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'ratio': 0.9986820816993713, '_timestamp': 1721974205.825511}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974205.8256383}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974205.8257287}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'Episode_Time': 81.40896010398865, '_timestamp': 1721974205.825785}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.3969943644333125, '_timestamp': 1721974205.82644}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'train_goal': 0.30150281778334376, '_timestamp': 1721974205.8269866}).
wandb: WARNING (User provided step: 5203 is less than current step: 12030. Dropping entry: {'train_WDL': -0.3969943644333125, '_timestamp': 1721974205.82755}).
Env Football Algo jrpo Exp base_JRPO updates 5203/100000000000.0 steps in 81.41
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 5611/100000000000.0 steps in 69.06
total episode rewards is -40.0
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'value_loss': 0.41309588932121794, '_timestamp': 1721974274.8930378}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0014559936593286694, '_timestamp': 1721974274.8932414}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.864536509513855, '_timestamp': 1721974274.8933153}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14779731631278992, '_timestamp': 1721974274.8934224}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.36693328619003296, '_timestamp': 1721974274.8937218}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'ratio': 0.998145341873169, '_timestamp': 1721974274.8938332}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974274.893981}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974274.8949995}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'Episode_Time': 69.0645215511322, '_timestamp': 1721974274.8950636}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.20350109409190373, '_timestamp': 1721974274.8958502}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'train_goal': 0.3982494529540481, '_timestamp': 1721974274.8962765}).
wandb: WARNING (User provided step: 5611 is less than current step: 12030. Dropping entry: {'train_WDL': -0.20350109409190373, '_timestamp': 1721974274.8967211}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'value_loss': 0.6784262821823358, '_timestamp': 1721974326.139921}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0011548304522875697, '_timestamp': 1721974326.141297}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8665651353200277, '_timestamp': 1721974326.1413722}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1510925143957138, '_timestamp': 1721974326.141984}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7573696374893188, '_timestamp': 1721974326.1424065}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'ratio': 1.0011465549468994, '_timestamp': 1721974326.1425185}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721974326.142664}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974326.1428611}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'Episode_Time': 51.23682117462158, '_timestamp': 1721974326.1429186}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.32253762621451704, '_timestamp': 1721974326.1440146}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'train_goal': 0.33873118689274145, '_timestamp': 1721974326.1443827}).
wandb: WARNING (User provided step: 3691 is less than current step: 12030. Dropping entry: {'train_WDL': -0.32253762621451704, '_timestamp': 1721974326.1447473}).
Env Football Algo jrpo Exp base_JRPO updates 3691/100000000000.0 steps in 51.24
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 4304/100000000000.0 steps in 91.12
total episode rewards is -40.0
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'value_loss': 0.2469316949074467, '_timestamp': 1721974417.2652016}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'policy_loss': 0.07216725014937159, '_timestamp': 1721974417.265368}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8605886379877727, '_timestamp': 1721974417.265435}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13590653240680695, '_timestamp': 1721974417.2655277}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.13986515998840332, '_timestamp': 1721974417.2657917}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'ratio': 0.9998643398284912, '_timestamp': 1721974417.265904}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974417.2660406}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974417.2661326}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.11964130401611, '_timestamp': 1721974417.2663436}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974417.2671273}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974417.2677453}).
wandb: WARNING (User provided step: 4304 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974417.26841}).
Env Football Algo jrpo Exp base_JRPO updates 2917/100000000000.0 steps in 47.92
total episode rewards is -20.0
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'value_loss': 0.4183346466471752, '_timestamp': 1721974465.1929584}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'policy_loss': 0.008542573062586599, '_timestamp': 1721974465.19327}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.854807046254476, '_timestamp': 1721974465.1933417}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14357084035873413, '_timestamp': 1721974465.193443}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.713640034198761, '_timestamp': 1721974465.1937184}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'ratio': 0.9995819330215454, '_timestamp': 1721974465.1938183}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721974465.19443}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974465.1945317}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'Episode_Time': 47.92340016365051, '_timestamp': 1721974465.1945908}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'train_goal_diff': 0.1888263317453443, '_timestamp': 1721974465.1950881}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'train_goal': 0.5944131658726721, '_timestamp': 1721974465.195412}).
wandb: WARNING (User provided step: 2917 is less than current step: 12030. Dropping entry: {'train_WDL': 0.1888263317453443, '_timestamp': 1721974465.1957285}).
Env Football Algo jrpo Exp base_JRPO updates 8498/100000000000.0 steps in 90.11
total episode rewards is -30.0
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'value_loss': 0.20662333060405216, '_timestamp': 1721974555.3035948}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0017180059008145084, '_timestamp': 1721974555.3037698}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.849742329915365, '_timestamp': 1721974555.3038373}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1311904937028885, '_timestamp': 1721974555.3039303}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.09640160202980042, '_timestamp': 1721974555.308088}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'ratio': 1.0007706880569458, '_timestamp': 1721974555.3082402}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974555.3083868}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974555.3084898}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.10707974433899, '_timestamp': 1721974555.3097138}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974555.3102767}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974555.310694}).
wandb: WARNING (User provided step: 8498 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974555.311122}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'value_loss': 0.3868222694533567, '_timestamp': 1721974604.7479148}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0016088558993457506, '_timestamp': 1721974604.7481792}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.847694687843323, '_timestamp': 1721974604.748249}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1463480144739151, '_timestamp': 1721974604.748348}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.42675086855888367, '_timestamp': 1721974604.748603}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'ratio': 0.99942946434021, '_timestamp': 1721974604.7487068}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974604.7490773}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974604.74964}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'Episode_Time': 49.43582582473755, '_timestamp': 1721974604.749703}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.23802577194262095, '_timestamp': 1721974604.7502003}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'train_goal': 0.3809871140286895, '_timestamp': 1721974604.750513}).
wandb: WARNING (User provided step: 3867 is less than current step: 12030. Dropping entry: {'train_WDL': -0.23802577194262095, '_timestamp': 1721974604.7508204}).
Env Football Algo jrpo Exp base_JRPO updates 3867/100000000000.0 steps in 49.44
total episode rewards is -40.0
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'value_loss': 0.24766682692764638, '_timestamp': 1721974696.2844274}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'policy_loss': 0.007853035884036217, '_timestamp': 1721974696.2845967}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8500750160217283, '_timestamp': 1721974696.2846665}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.13113629817962646, '_timestamp': 1721974696.2847655}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.21901439130306244, '_timestamp': 1721974696.2850273}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'ratio': 1.0015137195587158, '_timestamp': 1721974696.2851408}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974696.285643}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974696.2857385}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'Episode_Time': 91.53277015686035, '_timestamp': 1721974696.2857964}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974696.2863255}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974696.2867749}).
wandb: WARNING (User provided step: 9229 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974696.287176}).
Env Football Algo jrpo Exp base_JRPO updates 9229/100000000000.0 steps in 91.53
total episode rewards is -40.0
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'value_loss': 0.26122925448192597, '_timestamp': 1721974780.7704446}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0013694485758120815, '_timestamp': 1721974780.770625}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.843720258076986, '_timestamp': 1721974780.7706938}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1384197324514389, '_timestamp': 1721974780.7707922}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.27476418018341064, '_timestamp': 1721974780.7710645}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'ratio': 0.9983554482460022, '_timestamp': 1721974780.7711654}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974780.7714844}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974780.7715816}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'Episode_Time': 84.48233556747437, '_timestamp': 1721974780.7716386}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974780.772324}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974780.772721}).
wandb: WARNING (User provided step: 8940 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974780.7731159}).
Env Football Algo jrpo Exp base_JRPO updates 8940/100000000000.0 steps in 84.48
total episode rewards is -40.0
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'value_loss': 0.7398163696626822, '_timestamp': 1721974818.5650828}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0014595685454939181, '_timestamp': 1721974818.5652564}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.845164295832316, '_timestamp': 1721974818.5653238}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15636514127254486, '_timestamp': 1721974818.565422}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7604818940162659, '_timestamp': 1721974818.5656722}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'ratio': 0.9991905689239502, '_timestamp': 1721974818.565785}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721974818.5659149}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974818.5663803}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'Episode_Time': 37.79114556312561, '_timestamp': 1721974818.56644}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974818.5666788}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974818.5668197}).
wandb: WARNING (User provided step: 3237 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974818.5669596}).
Env Football Algo jrpo Exp base_JRPO updates 3237/100000000000.0 steps in 37.79
total episode rewards is -120.0
Env Football Algo jrpo Exp base_JRPO updates 4541/100000000000.0 steps in 83.31
total episode rewards is -20.0
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'value_loss': 0.2760605595097877, '_timestamp': 1721974901.8781972}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0052363115983704725, '_timestamp': 1721974901.8783712}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8554975159962974, '_timestamp': 1721974901.8784394}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.12817372381687164, '_timestamp': 1721974901.8785412}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.12023694813251495, '_timestamp': 1721974901.8788047}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'ratio': 1.000760555267334, '_timestamp': 1721974901.878908}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721974901.879468}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974901.8795676}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'Episode_Time': 83.3104739189148, '_timestamp': 1721974901.879626}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.42824361793670523, '_timestamp': 1721974901.8804111}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'train_goal': 0.2858781910316474, '_timestamp': 1721974901.8810227}).
wandb: WARNING (User provided step: 4541 is less than current step: 12030. Dropping entry: {'train_WDL': -0.42824361793670523, '_timestamp': 1721974901.8816504}).
Env Football Algo jrpo Exp base_JRPO updates 6870/100000000000.0 steps in 90.16
total episode rewards is -40.0
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'value_loss': 0.3038364906896216, '_timestamp': 1721974992.0451765}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0022596680792048573, '_timestamp': 1721974992.0453482}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.858696255683899, '_timestamp': 1721974992.045416}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.1325112283229828, '_timestamp': 1721974992.0455132}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.11610694974660873, '_timestamp': 1721974992.045711}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'ratio': 0.9991073608398438, '_timestamp': 1721974992.0458133}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974992.045946}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974992.046331}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'Episode_Time': 90.16255617141724, '_timestamp': 1721974992.046391}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974992.0469975}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974992.047482}).
wandb: WARNING (User provided step: 6870 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974992.0480125}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'value_loss': 0.2246128692140337, '_timestamp': 1721975080.621423}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'policy_loss': -0.0005100560511345975, '_timestamp': 1721975080.6216054}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.865575000445048, '_timestamp': 1721975080.6216772}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.10063914954662323, '_timestamp': 1721975080.6217804}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.195153146982193, '_timestamp': 1721975080.622063}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'ratio': 0.9993988275527954, '_timestamp': 1721975080.6221693}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721975080.623008}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975080.627057}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'Episode_Time': 88.57245469093323, '_timestamp': 1721975080.6271596}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975080.6279957}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975080.6284456}).
wandb: WARNING (User provided step: 8185 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975080.6289022}).
Env Football Algo jrpo Exp base_JRPO updates 8185/100000000000.0 steps in 88.57
total episode rewards is -30.0
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'value_loss': 0.3296577247674577, '_timestamp': 1721975153.1853654}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0040923630469478665, '_timestamp': 1721975153.1855378}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8696955251693725, '_timestamp': 1721975153.1856055}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14752863347530365, '_timestamp': 1721975153.1857052}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.2289574295282364, '_timestamp': 1721975153.1859581}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'ratio': 0.9992734789848328, '_timestamp': 1721975153.186059}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721975153.186193}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975153.1864567}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'Episode_Time': 72.55515003204346, '_timestamp': 1721975153.1865158}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975153.187087}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975153.1875265}).
wandb: WARNING (User provided step: 5696 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975153.1879914}).
Env Football Algo jrpo Exp base_JRPO updates 5696/100000000000.0 steps in 72.56
total episode rewards is -50.0
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'value_loss': 0.40659344467955333, '_timestamp': 1721975238.5916226}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'policy_loss': 0.004736671063583344, '_timestamp': 1721975238.592863}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.8724268213907878, '_timestamp': 1721975238.592939}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15595459938049316, '_timestamp': 1721975238.5935264}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.4347120225429535, '_timestamp': 1721975238.5938969}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'ratio': 0.9992629289627075, '_timestamp': 1721975238.5946584}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721975238.5948484}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975238.5950396}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'Episode_Time': 85.3968448638916, '_timestamp': 1721975238.5951052}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975238.5965338}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975238.5971236}).
wandb: WARNING (User provided step: 5724 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975238.5976717}).
Env Football Algo jrpo Exp base_JRPO updates 5724/100000000000.0 steps in 85.40
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 4092/100000000000.0 steps in 43.40
total episode rewards is -110.0
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'value_loss': 0.6892154828024407, '_timestamp': 1721975281.9945416}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0020511180106162403, '_timestamp': 1721975281.9946926}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871911047299703, '_timestamp': 1721975281.9947565}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14811323583126068, '_timestamp': 1721975281.994846}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.7073266506195068, '_timestamp': 1721975281.9950786}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'ratio': 1.0007691383361816, '_timestamp': 1721975281.9951775}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721975281.9953074}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975281.9954}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'Episode_Time': 43.39575123786926, '_timestamp': 1721975281.9954584}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975281.995858}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975281.9961643}).
wandb: WARNING (User provided step: 4092 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975281.9965792}).
Env Football Algo jrpo Exp base_JRPO updates 6924/100000000000.0 steps in 89.65
total episode rewards is -60.0
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'value_loss': 0.4003801556676626, '_timestamp': 1721975371.6490204}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'policy_loss': 0.0026690361842823525, '_timestamp': 1721975371.6492107}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.868394425710042, '_timestamp': 1721975371.649284}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.14415594935417175, '_timestamp': 1721975371.649388}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.31446054577827454, '_timestamp': 1721975371.6496549}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'ratio': 0.998735249042511, '_timestamp': 1721975371.649757}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721975371.6498969}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975371.650594}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'Episode_Time': 89.65159940719604, '_timestamp': 1721975371.6506534}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975371.6512625}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975371.6517622}).
wandb: WARNING (User provided step: 6924 is less than current step: 12030. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975371.6522841}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'value_loss': 0.813765779522558, '_timestamp': 1721975406.9173348}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'policy_loss': -0.002219350907447127, '_timestamp': 1721975406.9186075}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'dist_entropy': 2.871539397239685, '_timestamp': 1721975406.9186804}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'actor_grad_norm': 0.15673106908798218, '_timestamp': 1721975406.9192488}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'critic_grad_norm': 0.9546785950660706, '_timestamp': 1721975406.919592}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'ratio': 1.0016047954559326, '_timestamp': 1721975406.9197013}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721975406.9206545}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975406.920864}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'Episode_Time': 35.25908851623535, '_timestamp': 1721975406.9209225}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'train_goal_diff': -0.7779578606158833, '_timestamp': 1721975406.9216628}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'train_goal': 0.11102106969205834, '_timestamp': 1721975406.921823}).
wandb: WARNING (User provided step: 3916 is less than current step: 12030. Dropping entry: {'train_WDL': -0.7779578606158833, '_timestamp': 1721975406.9219792}).
Env Football Algo jrpo Exp base_JRPO updates 3916/100000000000.0 steps in 35.26
