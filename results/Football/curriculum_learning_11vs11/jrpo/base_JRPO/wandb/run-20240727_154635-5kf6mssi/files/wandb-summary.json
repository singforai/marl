{"value_loss": 0.4220755389953653, "_timestamp": 1722068059.535235, "policy_loss": 0.08058838170953095, "dist_entropy": 2.7398486121495567, "actor_grad_norm": 0.21062304079532623, "critic_grad_norm": 0.432267963886261, "ratio": 0.4906120002269745, "total_episode_rewards": -90.0, "Difficulty_level": 1, "Episode_Time": 89.10273838043213, "train_goal_diff": -1.0, "train_goal": 0.0, "train_WDL": -1.0, "_runtime": 5264.012961864471, "_step": 71384}