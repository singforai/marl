{"value_loss": 0.30988665054241815, "_timestamp": 1721995138.8117466, "policy_loss": 0.016454688887218558, "dist_entropy": 2.867770457267761, "actor_grad_norm": 0.13062003254890442, "critic_grad_norm": 0.2533099055290222, "ratio": 0.9994775652885437, "total_episode_rewards": -90.0, "Difficulty_level": 1, "Episode_Time": 113.2704827785492, "train_goal_diff": -1.0, "train_goal": 0.0, "train_WDL": -1.0, "_runtime": 16918.163747549057, "_step": 217071}