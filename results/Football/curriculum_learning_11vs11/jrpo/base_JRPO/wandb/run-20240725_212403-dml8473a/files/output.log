
사용 가능한 CPU Thread: 128
Env Football Algo jrpo Exp base_JRPO updates 6055/100000000000.0 steps in 97.10
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5380/100000000000.0 steps in 63.27
total episode rewards is -80.0
wandb: WARNING Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'value_loss': 0.742811930924654, '_timestamp': 1721910415.615504}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'policy_loss': 0.024018741927090255, '_timestamp': 1721910415.615683}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'dist_entropy': 2.935207173029582, '_timestamp': 1721910415.615753}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'actor_grad_norm': 1.2808620929718018, '_timestamp': 1721910415.6158512}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'critic_grad_norm': 5.853081703186035, '_timestamp': 1721910415.6169481}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'ratio': 1.0206007957458496, '_timestamp': 1721910415.617058}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721910415.6171918}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910415.617288}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'Episode_Time': 63.27474570274353, '_timestamp': 1721910415.6173491}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910415.6177773}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910415.618069}).
wandb: WARNING (User provided step: 5380 is less than current step: 6055. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910415.6183636}).
Env Football Algo jrpo Exp base_JRPO updates 6413/100000000000.0 steps in 56.55
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5875/100000000000.0 steps in 71.45
total episode rewards is -90.0
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'value_loss': 0.47933255300546684, '_timestamp': 1721910543.6244605}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'policy_loss': -0.0034657132633340855, '_timestamp': 1721910543.6246262}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'dist_entropy': 2.930342575709025, '_timestamp': 1721910543.6246977}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'actor_grad_norm': 0.9475202560424805, '_timestamp': 1721910543.6247957}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'critic_grad_norm': 1.3487086296081543, '_timestamp': 1721910543.625057}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'ratio': 1.0218602418899536, '_timestamp': 1721910543.6251755}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721910543.6253128}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910543.6254153}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'Episode_Time': 71.44832134246826, '_timestamp': 1721910543.625479}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910543.6259363}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910543.626289}).
wandb: WARNING (User provided step: 5875 is less than current step: 6413. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910543.6266325}).
Env Football Algo jrpo Exp base_JRPO updates 4752/100000000000.0 steps in 70.75
total episode rewards is -110.0
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'value_loss': 0.571486571803689, '_timestamp': 1721910614.381776}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'policy_loss': 0.003689785020033014, '_timestamp': 1721910614.3819542}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'dist_entropy': 2.915394622484843, '_timestamp': 1721910614.382026}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'actor_grad_norm': 1.2901313304901123, '_timestamp': 1721910614.3821232}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'critic_grad_norm': 1.4316989183425903, '_timestamp': 1721910614.3823564}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'ratio': 1.0052412748336792, '_timestamp': 1721910614.382472}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721910614.3826058}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910614.3826997}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'Episode_Time': 70.75428938865662, '_timestamp': 1721910614.3827708}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910614.383266}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910614.383595}).
wandb: WARNING (User provided step: 4752 is less than current step: 6413. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910614.383939}).
Env Football Algo jrpo Exp base_JRPO updates 4714/100000000000.0 steps in 57.45
total episode rewards is -90.0
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'value_loss': 0.5960050900032123, '_timestamp': 1721910671.830485}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'policy_loss': -0.00501169352636983, '_timestamp': 1721910671.8306503}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'dist_entropy': 2.91577929019928, '_timestamp': 1721910671.8307219}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'actor_grad_norm': 1.1079601049423218, '_timestamp': 1721910671.8308225}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'critic_grad_norm': 1.9700181484222412, '_timestamp': 1721910671.8310804}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'ratio': 1.0190093517303467, '_timestamp': 1721910671.8311925}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721910671.8313322}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910671.831449}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'Episode_Time': 57.44574522972107, '_timestamp': 1721910671.831519}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910671.831918}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910671.8322468}).
wandb: WARNING (User provided step: 4714 is less than current step: 6413. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910671.8325322}).
Env Football Algo jrpo Exp base_JRPO updates 5416/100000000000.0 steps in 88.95
total episode rewards is -80.0
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'value_loss': 0.3991589832678437, '_timestamp': 1721910760.7804863}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'policy_loss': 0.004649893563206812, '_timestamp': 1721910760.7806625}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'dist_entropy': 2.9052130762736, '_timestamp': 1721910760.7807312}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'actor_grad_norm': 0.5485770106315613, '_timestamp': 1721910760.7808304}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'critic_grad_norm': 1.149070143699646, '_timestamp': 1721910760.7810597}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'ratio': 1.0150197744369507, '_timestamp': 1721910760.7811692}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721910760.781296}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910760.7814016}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'Episode_Time': 88.94711756706238, '_timestamp': 1721910760.7814672}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910760.7820458}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910760.7824962}).
wandb: WARNING (User provided step: 5416 is less than current step: 6413. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910760.782974}).
Env Football Algo jrpo Exp base_JRPO updates 7068/100000000000.0 steps in 79.67
total episode rewards is -60.0
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'value_loss': 0.49692604303359983, '_timestamp': 1721910927.6039157}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'policy_loss': -0.018873091398272663, '_timestamp': 1721910927.604127}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.8051643578211465, '_timestamp': 1721910927.6042013}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.6151118874549866, '_timestamp': 1721910927.6043105}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 1.3219337463378906, '_timestamp': 1721910927.604608}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'ratio': 0.8969785571098328, '_timestamp': 1721910927.6047206}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721910927.6048667}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910927.6049688}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'Episode_Time': 87.15135216712952, '_timestamp': 1721910927.6050327}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910927.605679}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910927.6061678}).
wandb: WARNING (User provided step: 4294 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910927.6066735}).
Env Football Algo jrpo Exp base_JRPO updates 4294/100000000000.0 steps in 87.15
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 4663/100000000000.0 steps in 61.28
total episode rewards is -90.0
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'value_loss': 0.43289429306983945, '_timestamp': 1721910988.894481}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'policy_loss': 0.007790368724284538, '_timestamp': 1721910988.8957236}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.5021350685755412, '_timestamp': 1721910988.895799}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.7445782423019409, '_timestamp': 1721910988.8963747}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 1.1241122484207153, '_timestamp': 1721910988.8967178}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'ratio': 1.17002272605896, '_timestamp': 1721910988.8968298}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721910988.8969686}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721910988.8972}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'Episode_Time': 61.28162908554077, '_timestamp': 1721910988.897263}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721910988.898459}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721910988.8988552}).
wandb: WARNING (User provided step: 4663 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721910988.8992467}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'value_loss': 0.30410871849705773, '_timestamp': 1721911090.1623373}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'policy_loss': 0.07089681792538613, '_timestamp': 1721911090.1625042}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.567371172904968, '_timestamp': 1721911090.162574}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.5091197490692139, '_timestamp': 1721911090.162669}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 0.8962090015411377, '_timestamp': 1721911090.1629214}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'ratio': 0.5346723198890686, '_timestamp': 1721911090.1631064}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721911090.1632504}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911090.1723495}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'Episode_Time': 101.26183271408081, '_timestamp': 1721911090.1725068}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'train_goal_diff': -0.31628856079702317, '_timestamp': 1721911090.1733313}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'train_goal': 0.3418557196014884, '_timestamp': 1721911090.173934}).
wandb: WARNING (User provided step: 6114 is less than current step: 7068. Dropping entry: {'train_WDL': -0.31628856079702317, '_timestamp': 1721911090.174507}).
Env Football Algo jrpo Exp base_JRPO updates 6114/100000000000.0 steps in 101.26
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5793/100000000000.0 steps in 94.80
total episode rewards is -40.0
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'value_loss': 0.22125418620184065, '_timestamp': 1721911184.973109}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'policy_loss': 0.05022723391690912, '_timestamp': 1721911184.973282}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.3017918793360392, '_timestamp': 1721911184.97335}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.5427051186561584, '_timestamp': 1721911184.9734483}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 0.44175079464912415, '_timestamp': 1721911184.9736757}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'ratio': 0.5001994371414185, '_timestamp': 1721911184.9737885}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721911184.9739234}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911184.9740202}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'Episode_Time': 94.79756379127502, '_timestamp': 1721911184.974082}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911184.9747515}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911184.9752915}).
wandb: WARNING (User provided step: 5793 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911184.975844}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'value_loss': 0.32194786285981536, '_timestamp': 1721911246.2092764}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'policy_loss': 0.054108050976101364, '_timestamp': 1721911246.2094984}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.3075877912839253, '_timestamp': 1721911246.2095695}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.4553907513618469, '_timestamp': 1721911246.2096772}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 0.8607646822929382, '_timestamp': 1721911246.2099395}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'ratio': 0.4255119860172272, '_timestamp': 1721911246.2100484}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721911246.2101831}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911246.210317}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'Episode_Time': 61.23223638534546, '_timestamp': 1721911246.2103784}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911246.21111}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911246.2113817}).
wandb: WARNING (User provided step: 5314 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911246.2116346}).
Env Football Algo jrpo Exp base_JRPO updates 5314/100000000000.0 steps in 61.23
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 2595/100000000000.0 steps in 51.07
total episode rewards is -120.0
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'value_loss': 0.71305355489254, '_timestamp': 1721911297.2845325}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'policy_loss': 0.06620707277247372, '_timestamp': 1721911297.284819}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.262633256117503, '_timestamp': 1721911297.2849176}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.556506335735321, '_timestamp': 1721911297.2850945}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 2.1799206733703613, '_timestamp': 1721911297.2854872}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'ratio': 0.6291490793228149, '_timestamp': 1721911297.285678}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721911297.2858975}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911297.2860634}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'Episode_Time': 51.07142996788025, '_timestamp': 1721911297.2861555}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'train_goal_diff': -0.313595166163142, '_timestamp': 1721911297.2865875}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'train_goal': 0.343202416918429, '_timestamp': 1721911297.2868547}).
wandb: WARNING (User provided step: 2595 is less than current step: 7068. Dropping entry: {'train_WDL': -0.313595166163142, '_timestamp': 1721911297.2871156}).
Env Football Algo jrpo Exp base_JRPO updates 4129/100000000000.0 steps in 64.38
total episode rewards is -100.0
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'value_loss': 0.5444624398152034, '_timestamp': 1721911361.6635294}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'policy_loss': 0.028009014709386975, '_timestamp': 1721911361.6637104}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.074382868607839, '_timestamp': 1721911361.6637805}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.7742547988891602, '_timestamp': 1721911361.663882}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 1.255554437637329, '_timestamp': 1721911361.664177}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'ratio': 0.6550019383430481, '_timestamp': 1721911361.6642878}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721911361.6644244}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911361.6645315}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'Episode_Time': 64.37550902366638, '_timestamp': 1721911361.6645947}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911361.6651356}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911361.6655467}).
wandb: WARNING (User provided step: 4129 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911361.6659305}).
Env Football Algo jrpo Exp base_JRPO updates 2782/100000000000.0 steps in 50.13
total episode rewards is -150.0
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'value_loss': 0.8990029838184516, '_timestamp': 1721911411.8019412}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'policy_loss': 0.0990213718645585, '_timestamp': 1721911411.8033102}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'dist_entropy': 1.7962707948684693, '_timestamp': 1721911411.8033915}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.43655410408973694, '_timestamp': 1721911411.803935}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 2.456958770751953, '_timestamp': 1721911411.80428}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'ratio': 0.4505436420440674, '_timestamp': 1721911411.8043902}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721911411.8046422}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911411.8048382}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'Episode_Time': 50.129960775375366, '_timestamp': 1721911411.8049023}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'train_goal_diff': -0.3006099331977926, '_timestamp': 1721911411.8062577}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'train_goal': 0.3496950334011037, '_timestamp': 1721911411.8065572}).
wandb: WARNING (User provided step: 2782 is less than current step: 7068. Dropping entry: {'train_WDL': -0.3006099331977926, '_timestamp': 1721911411.8068728}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'value_loss': 0.4467608582476775, '_timestamp': 1721911488.2909994}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'policy_loss': 0.11832562907288471, '_timestamp': 1721911488.291264}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'dist_entropy': 2.085531853834788, '_timestamp': 1721911488.291335}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'actor_grad_norm': 0.20200558006763458, '_timestamp': 1721911488.2914708}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'critic_grad_norm': 1.1992942094802856, '_timestamp': 1721911488.291748}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'ratio': 0.1129542663693428, '_timestamp': 1721911488.2918549}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721911488.2920136}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911488.2921095}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'Episode_Time': 76.48299145698547, '_timestamp': 1721911488.2921698}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911488.2928185}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911488.2931561}).
wandb: WARNING (User provided step: 6811 is less than current step: 7068. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911488.2935328}).
Env Football Algo jrpo Exp base_JRPO updates 6811/100000000000.0 steps in 76.48
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 8131/100000000000.0 steps in 90.09
total episode rewards is 10.0
Env Football Algo jrpo Exp base_JRPO updates 9208/100000000000.0 steps in 96.75
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 7928/100000000000.0 steps in 96.66
total episode rewards is -40.0
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'value_loss': 0.19787328418111427, '_timestamp': 1721911771.808574}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'policy_loss': 0.060511217746631395, '_timestamp': 1721911771.8087485}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.265312264760335, '_timestamp': 1721911771.8088214}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.5070716738700867, '_timestamp': 1721911771.8089218}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.31225064396858215, '_timestamp': 1721911771.8091893}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'ratio': 0.8035714626312256, '_timestamp': 1721911771.809307}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721911771.809442}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911771.80954}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'Episode_Time': 96.66350889205933, '_timestamp': 1721911771.809599}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721911771.810171}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721911771.8106182}).
wandb: WARNING (User provided step: 7928 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721911771.8110619}).
Env Football Algo jrpo Exp base_JRPO updates 3345/100000000000.0 steps in 35.53
total episode rewards is -50.0
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'value_loss': 0.42207026593387126, '_timestamp': 1721911807.3375819}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'policy_loss': 0.05571212389904152, '_timestamp': 1721911807.337827}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.7609899004300436, '_timestamp': 1721911807.3379555}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.7027096152305603, '_timestamp': 1721911807.3381333}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.2455164194107056, '_timestamp': 1721911807.33845}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'ratio': 1.0044875144958496, '_timestamp': 1721911807.338635}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721911807.3388457}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911807.3389993}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'Episode_Time': 35.52535629272461, '_timestamp': 1721911807.3391218}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'train_goal_diff': -0.13813333333333333, '_timestamp': 1721911807.3394752}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'train_goal': 0.43093333333333333, '_timestamp': 1721911807.3397267}).
wandb: WARNING (User provided step: 3345 is less than current step: 9208. Dropping entry: {'train_WDL': -0.13813333333333333, '_timestamp': 1721911807.33999}).
Env Football Algo jrpo Exp base_JRPO updates 1588/100000000000.0 steps in 36.06
total episode rewards is -60.0
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'value_loss': 0.7240946405629317, '_timestamp': 1721911843.4022193}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'policy_loss': 0.06065927655125658, '_timestamp': 1721911843.4023793}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.2874999419848123, '_timestamp': 1721911843.402449}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.41806620359420776, '_timestamp': 1721911843.4025414}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.513922929763794, '_timestamp': 1721911843.4027805}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'ratio': 0.5482049584388733, '_timestamp': 1721911843.4028854}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721911843.4030147}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911843.4031076}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'Episode_Time': 36.06148171424866, '_timestamp': 1721911843.403166}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'train_goal_diff': 0.2551342812006319, '_timestamp': 1721911843.4034905}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'train_goal': 0.6275671406003159, '_timestamp': 1721911843.4037144}).
wandb: WARNING (User provided step: 1588 is less than current step: 9208. Dropping entry: {'train_WDL': 0.2551342812006319, '_timestamp': 1721911843.4039304}).
Env Football Algo jrpo Exp base_JRPO updates 8413/100000000000.0 steps in 96.58
total episode rewards is -20.0
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'value_loss': 0.22382658300649685, '_timestamp': 1721911939.9869714}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'policy_loss': 0.009169257297956696, '_timestamp': 1721911939.9871333}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.2611917066574097, '_timestamp': 1721911939.9872012}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.4444437623023987, '_timestamp': 1721911939.9872913}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.6347659230232239, '_timestamp': 1721911939.9875379}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'ratio': 0.7958064675331116, '_timestamp': 1721911939.9876482}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721911939.987778}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721911939.9878697}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'Episode_Time': 96.58130431175232, '_timestamp': 1721911939.9879308}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'train_goal_diff': -0.10368908456049795, '_timestamp': 1721911939.988495}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'train_goal': 0.448155457719751, '_timestamp': 1721911939.9889565}).
wandb: WARNING (User provided step: 8413 is less than current step: 9208. Dropping entry: {'train_WDL': -0.10368908456049795, '_timestamp': 1721911939.9893725}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'value_loss': 0.39116283126485846, '_timestamp': 1721912008.860731}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'policy_loss': 0.004721242106364419, '_timestamp': 1721912008.8608928}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.31494637966156, '_timestamp': 1721912008.8609622}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.4919724762439728, '_timestamp': 1721912008.8610604}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.9231175780296326, '_timestamp': 1721912008.861305}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'ratio': 0.9256693720817566, '_timestamp': 1721912008.8614073}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721912008.8615348}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912008.8616252}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'Episode_Time': 68.8705701828003, '_timestamp': 1721912008.861682}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912008.8621767}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912008.8625681}).
wandb: WARNING (User provided step: 5047 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912008.8629727}).
Env Football Algo jrpo Exp base_JRPO updates 5047/100000000000.0 steps in 68.87
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 5262/100000000000.0 steps in 101.42
total episode rewards is -40.0
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'value_loss': 0.21928419165895321, '_timestamp': 1721912110.2883348}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'policy_loss': 0.01058961332232381, '_timestamp': 1721912110.2884934}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.243565993309021, '_timestamp': 1721912110.2885616}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.4398937523365021, '_timestamp': 1721912110.2886543}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.42861196398735046, '_timestamp': 1721912110.2888868}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'ratio': 0.8819597363471985, '_timestamp': 1721912110.2889922}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912110.2891166}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912110.289203}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'Episode_Time': 101.42462372779846, '_timestamp': 1721912110.289263}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912110.289919}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912110.2904656}).
wandb: WARNING (User provided step: 5262 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912110.2910461}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'value_loss': 0.3367690647719428, '_timestamp': 1721912190.8081121}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'policy_loss': 0.023219050180729634, '_timestamp': 1721912190.8082888}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.8557438270250957, '_timestamp': 1721912190.8083591}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.6006598472595215, '_timestamp': 1721912190.8084548}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.149441123008728, '_timestamp': 1721912190.8086956}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'ratio': 1.4287173748016357, '_timestamp': 1721912190.808803}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912190.8089433}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912190.8090372}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'Episode_Time': 80.51621460914612, '_timestamp': 1721912190.8091006}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'train_goal_diff': -0.2433304016417473, '_timestamp': 1721912190.8096921}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'train_goal': 0.3783347991791264, '_timestamp': 1721912190.8101265}).
wandb: WARNING (User provided step: 6338 is less than current step: 9208. Dropping entry: {'train_WDL': -0.2433304016417473, '_timestamp': 1721912190.8105676}).
Env Football Algo jrpo Exp base_JRPO updates 6338/100000000000.0 steps in 80.52
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6998/100000000000.0 steps in 83.14
total episode rewards is -80.0
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'value_loss': 0.44326192900538447, '_timestamp': 1721912273.950654}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'policy_loss': 0.05760100817734686, '_timestamp': 1721912273.9509652}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.9154387903213501, '_timestamp': 1721912273.9510505}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.44284170866012573, '_timestamp': 1721912273.9513156}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.319006323814392, '_timestamp': 1721912273.9517024}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'ratio': 0.853363037109375, '_timestamp': 1721912273.9519207}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721912273.952111}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912273.952311}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'Episode_Time': 83.13890314102173, '_timestamp': 1721912273.9524548}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912273.953207}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912273.9536486}).
wandb: WARNING (User provided step: 6998 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912273.9541159}).
Env Football Algo jrpo Exp base_JRPO updates 8393/100000000000.0 steps in 100.66
total episode rewards is -40.0
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'value_loss': 0.20947658704322142, '_timestamp': 1721912374.622867}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'policy_loss': 0.04404283570862996, '_timestamp': 1721912374.6240797}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.1025929919878643, '_timestamp': 1721912374.6241548}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.2998068928718567, '_timestamp': 1721912374.6246645}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.5055496096611023, '_timestamp': 1721912374.6249995}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'ratio': 0.9596214890480042, '_timestamp': 1721912374.6251075}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912374.625254}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912374.6254454}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'Episode_Time': 100.66279435157776, '_timestamp': 1721912374.6255047}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912374.6264439}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912374.6268716}).
wandb: WARNING (User provided step: 8393 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912374.6273055}).
Env Football Algo jrpo Exp base_JRPO updates 7932/100000000000.0 steps in 94.43
total episode rewards is -40.0
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'value_loss': 0.24284611789354435, '_timestamp': 1721912469.0589666}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'policy_loss': 0.05431944546833013, '_timestamp': 1721912469.0592487}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.4523634707927704, '_timestamp': 1721912469.0594158}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.2809283435344696, '_timestamp': 1721912469.059548}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.6647355556488037, '_timestamp': 1721912469.0598917}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'ratio': 0.4737169146537781, '_timestamp': 1721912469.0601416}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912469.0602987}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912469.0603957}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'Episode_Time': 94.43057084083557, '_timestamp': 1721912469.0604548}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912469.0609996}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912469.0614252}).
wandb: WARNING (User provided step: 7932 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912469.0618694}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'value_loss': 0.34034395713048676, '_timestamp': 1721912560.0109854}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'policy_loss': 0.05302190542259874, '_timestamp': 1721912560.0112176}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.9210322642326354, '_timestamp': 1721912560.0112872}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.43398189544677734, '_timestamp': 1721912560.0114176}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.9186490178108215, '_timestamp': 1721912560.0116682}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'ratio': 0.8616039156913757, '_timestamp': 1721912560.0117757}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721912560.0119112}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912560.0120454}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'Episode_Time': 90.94812393188477, '_timestamp': 1721912560.0121057}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912560.0128834}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912560.013339}).
wandb: WARNING (User provided step: 6975 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912560.0138054}).
Env Football Algo jrpo Exp base_JRPO updates 6975/100000000000.0 steps in 90.95
total episode rewards is -60.0
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'value_loss': 0.6186937529593706, '_timestamp': 1721912601.789312}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'policy_loss': 0.07354455202352256, '_timestamp': 1721912601.7907116}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.6995073135693868, '_timestamp': 1721912601.7907882}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.6670773029327393, '_timestamp': 1721912601.791338}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 2.144360303878784, '_timestamp': 1721912601.7917051}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'ratio': 0.8326650857925415, '_timestamp': 1721912601.7918231}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721912601.791981}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912601.7921965}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'Episode_Time': 41.76922941207886, '_timestamp': 1721912601.7922568}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912601.7931383}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912601.79338}).
wandb: WARNING (User provided step: 3250 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912601.7936137}).
Env Football Algo jrpo Exp base_JRPO updates 3250/100000000000.0 steps in 41.77
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 5388/100000000000.0 steps in 59.57
total episode rewards is -150.0
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'value_loss': 0.824672439545393, '_timestamp': 1721912661.364653}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'policy_loss': 0.04794340777008377, '_timestamp': 1721912661.3648992}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.9416736960411072, '_timestamp': 1721912661.364971}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.455642968416214, '_timestamp': 1721912661.3651052}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.7126046419143677, '_timestamp': 1721912661.3653781}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'ratio': 0.6211884021759033, '_timestamp': 1721912661.3654866}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721912661.365625}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912661.3657196}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'Episode_Time': 59.57005763053894, '_timestamp': 1721912661.365779}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912661.36627}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912661.3665404}).
wandb: WARNING (User provided step: 5388 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912661.3668013}).
Env Football Algo jrpo Exp base_JRPO updates 5684/100000000000.0 steps in 68.09
total episode rewards is -130.0
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'value_loss': 0.7143081661065419, '_timestamp': 1721912729.4619217}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'policy_loss': 0.0710404620366171, '_timestamp': 1721912729.4621913}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.7222802495956422, '_timestamp': 1721912729.4622633}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.44867897033691406, '_timestamp': 1721912729.4623928}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 2.438035011291504, '_timestamp': 1721912729.4626555}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'ratio': 0.6992287635803223, '_timestamp': 1721912729.4627666}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721912729.462993}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912729.4631202}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'Episode_Time': 68.09400820732117, '_timestamp': 1721912729.4631813}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912729.4641256}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912729.4646773}).
wandb: WARNING (User provided step: 5684 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912729.4650974}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'value_loss': 0.24077141500078142, '_timestamp': 1721912824.171585}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'policy_loss': 0.10810740796228249, '_timestamp': 1721912824.1718473}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'dist_entropy': 2.2371204431851703, '_timestamp': 1721912824.1719196}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.34232017397880554, '_timestamp': 1721912824.172043}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.5006898641586304, '_timestamp': 1721912824.1723106}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'ratio': 0.19908764958381653, '_timestamp': 1721912824.172416}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912824.1726944}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912824.1727962}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'Episode_Time': 94.70500040054321, '_timestamp': 1721912824.1728563}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912824.1737754}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912824.1743383}).
wandb: WARNING (User provided step: 6274 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912824.1748734}).
Env Football Algo jrpo Exp base_JRPO updates 6274/100000000000.0 steps in 94.71
total episode rewards is -40.0
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'value_loss': 0.43723040755217274, '_timestamp': 1721912895.9671247}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'policy_loss': 0.0799485407071188, '_timestamp': 1721912895.9683752}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.8566069356600443, '_timestamp': 1721912895.9684484}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.35949188470840454, '_timestamp': 1721912895.9689991}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 1.0320602655410767, '_timestamp': 1721912895.969315}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'ratio': 0.20306195318698883, '_timestamp': 1721912895.9694288}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721912895.9695582}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912895.9697487}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'Episode_Time': 71.7862319946289, '_timestamp': 1721912895.969807}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912895.970734}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912895.9711707}).
wandb: WARNING (User provided step: 4605 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912895.9715867}).
Env Football Algo jrpo Exp base_JRPO updates 4605/100000000000.0 steps in 71.79
total episode rewards is -80.0
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'value_loss': 0.20641341792729995, '_timestamp': 1721912994.4618123}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'policy_loss': 0.056273832534013, '_timestamp': 1721912994.461994}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'dist_entropy': 1.472730627854665, '_timestamp': 1721912994.462064}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'actor_grad_norm': 0.4280734956264496, '_timestamp': 1721912994.462164}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'critic_grad_norm': 0.5453438758850098, '_timestamp': 1721912994.46243}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'ratio': 0.26707759499549866, '_timestamp': 1721912994.4625385}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721912994.4626732}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721912994.4627798}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'Episode_Time': 98.48927903175354, '_timestamp': 1721912994.462839}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721912994.4633389}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721912994.463728}).
wandb: WARNING (User provided step: 8703 is less than current step: 9208. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721912994.4641607}).
Env Football Algo jrpo Exp base_JRPO updates 8703/100000000000.0 steps in 98.49
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 11612/100000000000.0 steps in 88.92
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 9931/100000000000.0 steps in 88.66
total episode rewards is -60.0
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'value_loss': 0.352796937112386, '_timestamp': 1721913172.0440736}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'policy_loss': 0.05280756302313724, '_timestamp': 1721913172.0443215}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'dist_entropy': 1.626249282360077, '_timestamp': 1721913172.0444078}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.40801674127578735, '_timestamp': 1721913172.0445213}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 1.0311644077301025, '_timestamp': 1721913172.0447834}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'ratio': 0.3039105534553528, '_timestamp': 1721913172.0448897}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721913172.045026}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913172.0451624}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'Episode_Time': 88.659006357193, '_timestamp': 1721913172.0452237}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913172.0459638}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913172.046261}).
wandb: WARNING (User provided step: 9931 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913172.0465572}).
Env Football Algo jrpo Exp base_JRPO updates 7272/100000000000.0 steps in 95.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'value_loss': 0.23691987136223663, '_timestamp': 1721913267.9572666}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'policy_loss': 0.07402836644779502, '_timestamp': 1721913267.9584432}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'dist_entropy': 2.1196144715944927, '_timestamp': 1721913267.958518}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.20569628477096558, '_timestamp': 1721913267.9589977}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 0.7387837171554565, '_timestamp': 1721913267.9593716}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'ratio': 0.3985176086425781, '_timestamp': 1721913267.9594934}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913267.9596293}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913267.959823}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'Episode_Time': 95.90482831001282, '_timestamp': 1721913267.9598856}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913267.9608603}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913267.9613495}).
wandb: WARNING (User provided step: 7272 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913267.961824}).
Env Football Algo jrpo Exp base_JRPO updates 3460/100000000000.0 steps in 49.27
total episode rewards is -90.0
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'value_loss': 0.5074093465010325, '_timestamp': 1721913317.233172}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'policy_loss': 0.0413764479275172, '_timestamp': 1721913317.233334}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'dist_entropy': 1.7831988469759623, '_timestamp': 1721913317.2334082}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.41283413767814636, '_timestamp': 1721913317.2335074}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 1.305859088897705, '_timestamp': 1721913317.2337506}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'ratio': 0.3095402717590332, '_timestamp': 1721913317.2338564}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721913317.2340045}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913317.234098}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'Episode_Time': 49.27051496505737, '_timestamp': 1721913317.2341583}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913317.2345543}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913317.2348545}).
wandb: WARNING (User provided step: 3460 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913317.2351508}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'value_loss': 0.6097111372401317, '_timestamp': 1721913378.5827837}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'policy_loss': 0.05330723312644598, '_timestamp': 1721913378.5829504}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'dist_entropy': 1.784744263490041, '_timestamp': 1721913378.583017}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 1.2466939687728882, '_timestamp': 1721913378.5831165}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 1.687106966972351, '_timestamp': 1721913378.5833337}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'ratio': 0.9726389050483704, '_timestamp': 1721913378.583437}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721913378.5835664}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913378.5836568}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'Episode_Time': 61.346890926361084, '_timestamp': 1721913378.583715}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913378.5841253}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913378.584436}).
wandb: WARNING (User provided step: 4405 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913378.5847511}).
Env Football Algo jrpo Exp base_JRPO updates 4405/100000000000.0 steps in 61.35
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 8635/100000000000.0 steps in 87.35
total episode rewards is -30.0
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'value_loss': 0.17444287578264872, '_timestamp': 1721913465.937222}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'policy_loss': 0.0197755601965279, '_timestamp': 1721913465.9373796}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'dist_entropy': 1.8030633489290873, '_timestamp': 1721913465.9374468}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.4978102743625641, '_timestamp': 1721913465.9375384}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 0.31690266728401184, '_timestamp': 1721913465.9377732}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'ratio': 0.4834422469139099, '_timestamp': 1721913465.9378767}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721913465.9380023}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913465.9380922}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'Episode_Time': 87.35174942016602, '_timestamp': 1721913465.93815}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913465.9386654}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913465.9390998}).
wandb: WARNING (User provided step: 8635 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913465.9395077}).
Env Football Algo jrpo Exp base_JRPO updates 10416/100000000000.0 steps in 92.89
total episode rewards is -20.0
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'value_loss': 0.11849488904078802, '_timestamp': 1721913558.8271265}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'policy_loss': 0.031712412621903545, '_timestamp': 1721913558.8272943}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'dist_entropy': 2.097776535352071, '_timestamp': 1721913558.8273633}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.5915767550468445, '_timestamp': 1721913558.8274565}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 0.39164748787879944, '_timestamp': 1721913558.827716}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'ratio': 0.3742925822734833, '_timestamp': 1721913558.8278244}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721913558.827988}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913558.8280845}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'Episode_Time': 92.8868682384491, '_timestamp': 1721913558.8281517}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913558.8285718}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913558.828903}).
wandb: WARNING (User provided step: 10416 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913558.838262}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'value_loss': 0.2459719684161246, '_timestamp': 1721913651.0313282}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'policy_loss': 0.07478776247551044, '_timestamp': 1721913651.03149}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'dist_entropy': 1.954529225031535, '_timestamp': 1721913651.0315585}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'actor_grad_norm': 0.24854803085327148, '_timestamp': 1721913651.0316532}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'critic_grad_norm': 0.3442538380622864, '_timestamp': 1721913651.0318866}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'ratio': 0.2036626935005188, '_timestamp': 1721913651.0400312}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913651.0402284}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913651.0403395}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'Episode_Time': 92.19221377372742, '_timestamp': 1721913651.0404}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913651.040998}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913651.041453}).
wandb: WARNING (User provided step: 8442 is less than current step: 11612. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913651.0419054}).
Env Football Algo jrpo Exp base_JRPO updates 8442/100000000000.0 steps in 92.19
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 13608/100000000000.0 steps in 84.56
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 11296/100000000000.0 steps in 96.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'value_loss': 0.24717356397615126, '_timestamp': 1721913832.5822132}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'policy_loss': 0.07325621083553414, '_timestamp': 1721913832.582782}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'dist_entropy': 1.8739890480041503, '_timestamp': 1721913832.5830326}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'actor_grad_norm': 0.7557668685913086, '_timestamp': 1721913832.5833933}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'critic_grad_norm': 0.31909647583961487, '_timestamp': 1721913832.5838695}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'ratio': 0.1333775520324707, '_timestamp': 1721913832.584043}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721913832.584223}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913832.5843358}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'Episode_Time': 96.97789669036865, '_timestamp': 1721913832.584498}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913832.5854807}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913832.5859666}).
wandb: WARNING (User provided step: 11296 is less than current step: 13608. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913832.5864453}).
Env Football Algo jrpo Exp base_JRPO updates 9063/100000000000.0 steps in 95.77
total episode rewards is -30.0
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'value_loss': 0.17620928653826315, '_timestamp': 1721913928.3554773}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'policy_loss': 0.02015230907680234, '_timestamp': 1721913928.3556688}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'dist_entropy': 1.8161599906285604, '_timestamp': 1721913928.35574}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'actor_grad_norm': 0.5840231776237488, '_timestamp': 1721913928.355865}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'critic_grad_norm': 0.30734241008758545, '_timestamp': 1721913928.3561013}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'ratio': 0.4301377832889557, '_timestamp': 1721913928.3562074}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721913928.3563304}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721913928.356456}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'Episode_Time': 95.76802897453308, '_timestamp': 1721913928.3565152}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721913928.3572304}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721913928.3576205}).
wandb: WARNING (User provided step: 9063 is less than current step: 13608. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721913928.3581696}).
Env Football Algo jrpo Exp base_JRPO updates 14326/100000000000.0 steps in 82.53
total episode rewards is -20.0
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'value_loss': 0.4690190640060852, '_timestamp': 1721914087.3521955}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'policy_loss': 0.017925078387682637, '_timestamp': 1721914087.3540838}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.093392330010732, '_timestamp': 1721914087.3541842}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5198692679405212, '_timestamp': 1721914087.3547838}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9928094744682312, '_timestamp': 1721914087.3551333}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'ratio': 0.4837028980255127, '_timestamp': 1721914087.3553185}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721914087.3554885}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914087.3557537}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'Episode_Time': 76.43885326385498, '_timestamp': 1721914087.3558426}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914087.356656}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914087.3569508}).
wandb: WARNING (User provided step: 7295 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914087.357255}).
Env Football Algo jrpo Exp base_JRPO updates 7295/100000000000.0 steps in 76.44
total episode rewards is -50.0
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'value_loss': 0.1377554165533123, '_timestamp': 1721914167.8372474}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04099587805181121, '_timestamp': 1721914167.8374217}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8507166862487794, '_timestamp': 1721914167.8374891}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.337721049785614, '_timestamp': 1721914167.8375847}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4284099340438843, '_timestamp': 1721914167.8378458}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'ratio': 0.33117133378982544, '_timestamp': 1721914167.8379471}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721914167.8380811}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914167.8381722}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'Episode_Time': 80.47893595695496, '_timestamp': 1721914167.8382292}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914167.8386607}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914167.8389583}).
wandb: WARNING (User provided step: 10794 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914167.839258}).
Env Football Algo jrpo Exp base_JRPO updates 10794/100000000000.0 steps in 80.48
total episode rewards is -20.0
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'value_loss': 0.38004624568857254, '_timestamp': 1721914231.6195247}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'policy_loss': 0.040528928342925305, '_timestamp': 1721914231.619722}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.004990613460541, '_timestamp': 1721914231.6197891}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.26482030749320984, '_timestamp': 1721914231.6198838}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6800762414932251, '_timestamp': 1721914231.620171}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'ratio': 0.5087703466415405, '_timestamp': 1721914231.620279}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914231.6206021}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914231.6207037}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'Episode_Time': 63.77931189537048, '_timestamp': 1721914231.6207647}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.29192815407920364, '_timestamp': 1721914231.62135}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'train_goal': 0.3540359229603982, '_timestamp': 1721914231.6216662}).
wandb: WARNING (User provided step: 3804 is less than current step: 14326. Dropping entry: {'train_WDL': -0.29192815407920364, '_timestamp': 1721914231.6219814}).
Env Football Algo jrpo Exp base_JRPO updates 3804/100000000000.0 steps in 63.78
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 11492/100000000000.0 steps in 93.72
total episode rewards is -30.0
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'value_loss': 0.19010466864720607, '_timestamp': 1721914325.3421662}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0026062986949303498, '_timestamp': 1721914325.3423266}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.203180019060771, '_timestamp': 1721914325.342396}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3389870226383209, '_timestamp': 1721914325.34249}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.24064192175865173, '_timestamp': 1721914325.3428075}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'ratio': 0.3449419438838959, '_timestamp': 1721914325.342915}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721914325.3430476}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914325.3431456}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.71927213668823, '_timestamp': 1721914325.3432038}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914325.3435721}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914325.3438299}).
wandb: WARNING (User provided step: 11492 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914325.3441036}).
Env Football Algo jrpo Exp base_JRPO updates 10136/100000000000.0 steps in 89.29
total episode rewards is -20.0
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'value_loss': 0.12967044511887554, '_timestamp': 1721914414.637447}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'policy_loss': 0.007010619833211725, '_timestamp': 1721914414.6377141}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8088716888427734, '_timestamp': 1721914414.637788}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7362866401672363, '_timestamp': 1721914414.6379268}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.23625469207763672, '_timestamp': 1721914414.6382105}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'ratio': 0.37902843952178955, '_timestamp': 1721914414.6383235}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721914414.6384597}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914414.6385987}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.29231357574463, '_timestamp': 1721914414.6386585}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914414.6395023}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914414.6398664}).
wandb: WARNING (User provided step: 10136 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914414.6402278}).
Env Football Algo jrpo Exp base_JRPO updates 1845/100000000000.0 steps in 38.93
total episode rewards is -30.0
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'value_loss': 0.5287112592843671, '_timestamp': 1721914453.5762115}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0249470319172057, '_timestamp': 1721914453.577506}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1994540747006734, '_timestamp': 1721914453.5775802}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.41249707341194153, '_timestamp': 1721914453.578086}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5344208478927612, '_timestamp': 1721914453.578394}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'ratio': 1.1164666414260864, '_timestamp': 1721914453.5785015}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721914453.5787554}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914453.5789475}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'Episode_Time': 38.92938685417175, '_timestamp': 1721914453.5790074}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.45498783454987834, '_timestamp': 1721914453.57992}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'train_goal': 0.7274939172749392, '_timestamp': 1721914453.580146}).
wandb: WARNING (User provided step: 1845 is less than current step: 14326. Dropping entry: {'train_WDL': 0.45498783454987834, '_timestamp': 1721914453.5803592}).
Env Football Algo jrpo Exp base_JRPO updates 9151/100000000000.0 steps in 91.71
total episode rewards is -40.0
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'value_loss': 0.2549878525470073, '_timestamp': 1721914545.2922406}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05760734618854864, '_timestamp': 1721914545.292402}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2214297374089558, '_timestamp': 1721914545.2924705}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.19720743596553802, '_timestamp': 1721914545.2925642}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5219219923019409, '_timestamp': 1721914545.2928066}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'ratio': 0.6367550492286682, '_timestamp': 1721914545.29291}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914545.2930381}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914545.2931323}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.71110081672668, '_timestamp': 1721914545.2931948}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914545.2936668}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914545.2940443}).
wandb: WARNING (User provided step: 9151 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914545.29443}).
Env Football Algo jrpo Exp base_JRPO updates 5675/100000000000.0 steps in 86.62
total episode rewards is -40.0
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'value_loss': 0.38236481946582596, '_timestamp': 1721914631.9134986}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'policy_loss': 0.063376170033589, '_timestamp': 1721914631.9136636}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8728211688995362, '_timestamp': 1721914631.9137316}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4846888482570648, '_timestamp': 1721914631.9138246}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0608714818954468, '_timestamp': 1721914631.9140635}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'ratio': 0.538988471031189, '_timestamp': 1721914631.914167}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914631.9142978}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914631.9144015}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.61832070350647, '_timestamp': 1721914631.914462}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2673178061607814, '_timestamp': 1721914631.9153104}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'train_goal': 0.3663410969196093, '_timestamp': 1721914631.9160435}).
wandb: WARNING (User provided step: 5675 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2673178061607814, '_timestamp': 1721914631.916758}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'value_loss': 0.13016279594026856, '_timestamp': 1721914715.779568}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'policy_loss': 0.002199549632690226, '_timestamp': 1721914715.779719}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1784101327260337, '_timestamp': 1721914715.7797878}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3013199269771576, '_timestamp': 1721914715.7798777}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.321293443441391, '_timestamp': 1721914715.780126}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'ratio': 0.8935854434967041, '_timestamp': 1721914715.780238}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721914715.7803643}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914715.7804663}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'Episode_Time': 83.86209607124329, '_timestamp': 1721914715.7805245}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914715.7808516}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914715.781033}).
wandb: WARNING (User provided step: 13222 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914715.7812066}).
Env Football Algo jrpo Exp base_JRPO updates 13222/100000000000.0 steps in 83.86
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 3682/100000000000.0 steps in 57.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'value_loss': 0.4461083027906716, '_timestamp': 1721914773.5882366}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'policy_loss': -0.004865671585236366, '_timestamp': 1721914773.5884655}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.157821420033773, '_timestamp': 1721914773.5885375}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6858267188072205, '_timestamp': 1721914773.588696}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.220543622970581, '_timestamp': 1721914773.588936}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'ratio': 0.9530885815620422, '_timestamp': 1721914773.5890467}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914773.5891767}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914773.5892773}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'Episode_Time': 57.80557107925415, '_timestamp': 1721914773.5893395}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.20619983393301966, '_timestamp': 1721914773.5899944}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'train_goal': 0.39690008303349017, '_timestamp': 1721914773.5902674}).
wandb: WARNING (User provided step: 3682 is less than current step: 14326. Dropping entry: {'train_WDL': -0.20619983393301966, '_timestamp': 1721914773.590542}).
Env Football Algo jrpo Exp base_JRPO updates 2195/100000000000.0 steps in 58.11
total episode rewards is -30.0
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'value_loss': 0.5597274033461387, '_timestamp': 1721914831.709997}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0002787030895706266, '_timestamp': 1721914831.7113552}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2428390391667685, '_timestamp': 1721914831.7114367}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8726547360420227, '_timestamp': 1721914831.7120035}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5939834117889404, '_timestamp': 1721914831.7123501}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'ratio': 0.9432436227798462, '_timestamp': 1721914831.7124605}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721914831.7126005}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914831.7128198}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'Episode_Time': 58.11311173439026, '_timestamp': 1721914831.713008}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.5414114513981358, '_timestamp': 1721914831.714029}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'train_goal': 0.7707057256990679, '_timestamp': 1721914831.7144883}).
wandb: WARNING (User provided step: 2195 is less than current step: 14326. Dropping entry: {'train_WDL': 0.5414114513981358, '_timestamp': 1721914831.7149417}).
Env Football Algo jrpo Exp base_JRPO updates 7406/100000000000.0 steps in 97.40
total episode rewards is -40.0
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'value_loss': 0.2829928559703209, '_timestamp': 1721914929.1128106}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04974551436879362, '_timestamp': 1721914929.1129754}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0737443494796755, '_timestamp': 1721914929.1130426}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.40925443172454834, '_timestamp': 1721914929.1131365}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5536215901374817, '_timestamp': 1721914929.1133988}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'ratio': 0.8086491823196411, '_timestamp': 1721914929.1135032}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721914929.1136396}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721914929.1137333}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'Episode_Time': 97.39659833908081, '_timestamp': 1721914929.1138308}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721914929.114401}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721914929.1148672}).
wandb: WARNING (User provided step: 7406 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721914929.1153383}).
Env Football Algo jrpo Exp base_JRPO updates 6944/100000000000.0 steps in 81.91
total episode rewards is -20.0
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'value_loss': 0.26893034075619654, '_timestamp': 1721915011.0227346}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0325459308483308, '_timestamp': 1721915011.022894}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1848910601933795, '_timestamp': 1721915011.0229602}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.488860547542572, '_timestamp': 1721915011.0230522}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3694700598716736, '_timestamp': 1721915011.0233057}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'ratio': 0.9420947432518005, '_timestamp': 1721915011.023409}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721915011.0235407}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915011.0236304}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'Episode_Time': 81.90646076202393, '_timestamp': 1721915011.0237207}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2576961271102284, '_timestamp': 1721915011.0243187}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'train_goal': 0.3711519364448858, '_timestamp': 1721915011.0248013}).
wandb: WARNING (User provided step: 6944 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2576961271102284, '_timestamp': 1721915011.0252843}).
Env Football Algo jrpo Exp base_JRPO updates 7474/100000000000.0 steps in 92.11
total episode rewards is -40.0
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'value_loss': 0.2981305448090037, '_timestamp': 1721915103.1405911}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'policy_loss': 0.037874366605149895, '_timestamp': 1721915103.1407454}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2065309286117554, '_timestamp': 1721915103.1408126}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.32183167338371277, '_timestamp': 1721915103.140902}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5708029270172119, '_timestamp': 1721915103.141138}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'ratio': 0.8855838179588318, '_timestamp': 1721915103.1412401}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915103.1413717}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915103.1414623}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.11439204216003, '_timestamp': 1721915103.1415193}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915103.142112}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915103.1425629}).
wandb: WARNING (User provided step: 7474 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915103.1430416}).
Env Football Algo jrpo Exp base_JRPO updates 3633/100000000000.0 steps in 41.11
total episode rewards is -50.0
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'value_loss': 0.6916817931706707, '_timestamp': 1721915144.2517}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'policy_loss': 0.061579686432475376, '_timestamp': 1721915144.2519405}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.3509089668591816, '_timestamp': 1721915144.2520444}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.44741201400756836, '_timestamp': 1721915144.2521496}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.8292672634124756, '_timestamp': 1721915144.2523973}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'ratio': 0.6374257802963257, '_timestamp': 1721915144.252504}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721915144.252779}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915144.2528782}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'Episode_Time': 41.10770058631897, '_timestamp': 1721915144.2530017}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.13202527435982708, '_timestamp': 1721915144.2536802}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'train_goal': 0.4339873628200865, '_timestamp': 1721915144.2539294}).
wandb: WARNING (User provided step: 3633 is less than current step: 14326. Dropping entry: {'train_WDL': -0.13202527435982708, '_timestamp': 1721915144.2541747}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'value_loss': 0.19556568579127392, '_timestamp': 1721915244.7784133}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0758736857935825, '_timestamp': 1721915244.7796433}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.258309965133667, '_timestamp': 1721915244.7797174}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.1755335330963135, '_timestamp': 1721915244.7802215}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4358398914337158, '_timestamp': 1721915244.7805245}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'ratio': 0.6035792231559753, '_timestamp': 1721915244.780633}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721915244.78077}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915244.7809553}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'Episode_Time': 100.51860356330872, '_timestamp': 1721915244.781018}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915244.7821474}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915244.782653}).
wandb: WARNING (User provided step: 7950 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915244.7831578}).
Env Football Algo jrpo Exp base_JRPO updates 7950/100000000000.0 steps in 100.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'value_loss': 0.2145324656345959, '_timestamp': 1721915333.1608891}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05560978641655917, '_timestamp': 1721915333.1611369}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2568946576118467, '_timestamp': 1721915333.1612363}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.13468557596206665, '_timestamp': 1721915333.1613524}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9216505289077759, '_timestamp': 1721915333.1616333}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'ratio': 0.6227498054504395, '_timestamp': 1721915333.1617403}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721915333.1618698}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915333.1619768}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.3767478466034, '_timestamp': 1721915333.1621127}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915333.1626873}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915333.1631193}).
wandb: WARNING (User provided step: 8152 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915333.163561}).
Env Football Algo jrpo Exp base_JRPO updates 8152/100000000000.0 steps in 88.38
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 5832/100000000000.0 steps in 91.08
total episode rewards is -60.0
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'value_loss': 0.3983252030839988, '_timestamp': 1721915424.2450414}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02850490313100939, '_timestamp': 1721915424.2452233}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0469798962275187, '_timestamp': 1721915424.2452924}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22841939330101013, '_timestamp': 1721915424.245392}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5396880507469177, '_timestamp': 1721915424.2456434}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'ratio': 0.8133159875869751, '_timestamp': 1721915424.2457495}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721915424.2458837}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915424.2459893}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.0806314945221, '_timestamp': 1721915424.246159}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915424.2468016}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915424.247328}).
wandb: WARNING (User provided step: 5832 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915424.2478526}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'value_loss': 0.5450929361612846, '_timestamp': 1721915481.3418932}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05828946345834993, '_timestamp': 1721915481.3421268}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.033481244246165, '_timestamp': 1721915481.3421988}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5133326053619385, '_timestamp': 1721915481.342303}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.6024771928787231, '_timestamp': 1721915481.342568}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'ratio': 0.3230016231536865, '_timestamp': 1721915481.342672}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721915481.3428082}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915481.3429058}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'Episode_Time': 57.09280323982239, '_timestamp': 1721915481.342966}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915481.3434498}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915481.3438013}).
wandb: WARNING (User provided step: 5161 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915481.3441358}).
Env Football Algo jrpo Exp base_JRPO updates 5161/100000000000.0 steps in 57.09
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 5354/100000000000.0 steps in 57.35
total episode rewards is -120.0
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'value_loss': 0.9146772697071235, '_timestamp': 1721915538.7106333}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'policy_loss': 0.10377908326918259, '_timestamp': 1721915538.7115538}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.3162794216473896, '_timestamp': 1721915538.7116275}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3974612057209015, '_timestamp': 1721915538.719406}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.0586376190185547, '_timestamp': 1721915538.7198143}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'ratio': 0.4677827060222626, '_timestamp': 1721915538.7199285}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721915538.7200894}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915538.7202835}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'Episode_Time': 57.35137057304382, '_timestamp': 1721915538.7206843}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915538.721299}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915538.721524}).
wandb: WARNING (User provided step: 5354 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915538.7217157}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'value_loss': 0.7340131108090282, '_timestamp': 1721915597.891992}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05889806053348972, '_timestamp': 1721915597.8921597}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.08006729443868, '_timestamp': 1721915597.892228}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.49311813712120056, '_timestamp': 1721915597.892322}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.643428921699524, '_timestamp': 1721915597.8925724}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'ratio': 0.5671296715736389, '_timestamp': 1721915597.8926785}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721915597.8928113}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915597.8929653}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'Episode_Time': 59.16894865036011, '_timestamp': 1721915597.893025}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915597.8934493}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915597.8937523}).
wandb: WARNING (User provided step: 6031 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915597.8940613}).
Env Football Algo jrpo Exp base_JRPO updates 6031/100000000000.0 steps in 59.17
total episode rewards is -110.0
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'value_loss': 0.3175215314902986, '_timestamp': 1721915691.3284078}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04225878034439423, '_timestamp': 1721915691.328576}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.387816392580668, '_timestamp': 1721915691.3286412}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3339264392852783, '_timestamp': 1721915691.328734}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4758618175983429, '_timestamp': 1721915691.328984}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'ratio': 0.6131440997123718, '_timestamp': 1721915691.3290856}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721915691.3292165}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915691.3293684}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.43333506584167, '_timestamp': 1721915691.3294263}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915691.3300536}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915691.330536}).
wandb: WARNING (User provided step: 6834 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915691.3310401}).
Env Football Algo jrpo Exp base_JRPO updates 6834/100000000000.0 steps in 93.43
total episode rewards is -40.0
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'value_loss': 0.29943308532664864, '_timestamp': 1721915784.0143652}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07093464659216503, '_timestamp': 1721915784.0145307}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7558608873685202, '_timestamp': 1721915784.0145977}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.45723390579223633, '_timestamp': 1721915784.0146916}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.38404056429862976, '_timestamp': 1721915784.0148985}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'ratio': 0.35194045305252075, '_timestamp': 1721915784.0150082}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721915784.015139}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915784.015236}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.68236517906189, '_timestamp': 1721915784.0153437}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.013675213675213675, '_timestamp': 1721915784.015883}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'train_goal': 0.5068376068376068, '_timestamp': 1721915784.0162666}).
wandb: WARNING (User provided step: 9150 is less than current step: 14326. Dropping entry: {'train_WDL': 0.013675213675213675, '_timestamp': 1721915784.0166416}).
Env Football Algo jrpo Exp base_JRPO updates 9150/100000000000.0 steps in 92.68
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6107/100000000000.0 steps in 64.59
total episode rewards is -90.0
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'value_loss': 0.5858252980497977, '_timestamp': 1721915848.6026042}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07483035389023522, '_timestamp': 1721915848.6027632}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9248797527949015, '_timestamp': 1721915848.6028302}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.26541033387184143, '_timestamp': 1721915848.6029215}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1366465091705322, '_timestamp': 1721915848.603124}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'ratio': 0.5830877423286438, '_timestamp': 1721915848.603226}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721915848.6033483}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915848.6034358}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'Episode_Time': 64.58510184288025, '_timestamp': 1721915848.603541}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721915848.603983}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721915848.6043239}).
wandb: WARNING (User provided step: 6107 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721915848.6046672}).
Env Football Algo jrpo Exp base_JRPO updates 5907/100000000000.0 steps in 91.81
total episode rewards is -20.0
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'value_loss': 0.28393719972188897, '_timestamp': 1721915940.4165473}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06110614259208281, '_timestamp': 1721915940.4167025}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3095372239748637, '_timestamp': 1721915940.4167702}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6187839508056641, '_timestamp': 1721915940.4168603}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5793876051902771, '_timestamp': 1721915940.4171062}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'ratio': 0.6731968522071838, '_timestamp': 1721915940.4172113}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721915940.4173431}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721915940.4174347}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.81102728843689, '_timestamp': 1721915940.4174957}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3432310568569229, '_timestamp': 1721915940.4181333}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'train_goal': 0.32838447157153855, '_timestamp': 1721915940.4186566}).
wandb: WARNING (User provided step: 5907 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3432310568569229, '_timestamp': 1721915940.4191973}).
Env Football Algo jrpo Exp base_JRPO updates 3532/100000000000.0 steps in 64.21
total episode rewards is -80.0
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'value_loss': 0.5286725481102864, '_timestamp': 1721916004.6283238}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08358359728202534, '_timestamp': 1721916004.6284876}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.527957661151886, '_timestamp': 1721916004.6285563}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8380865454673767, '_timestamp': 1721916004.628651}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3117071390151978, '_timestamp': 1721916004.6289158}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'ratio': 0.6933110356330872, '_timestamp': 1721916004.62902}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721916004.6291556}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916004.6293013}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'Episode_Time': 64.2081789970398, '_timestamp': 1721916004.6293619}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916004.6298623}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916004.6302502}).
wandb: WARNING (User provided step: 3532 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916004.630652}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'value_loss': 0.8604185055196285, '_timestamp': 1721916050.206266}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1208413552865386, '_timestamp': 1721916050.206438}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7661093020439147, '_timestamp': 1721916050.206506}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.13245931267738342, '_timestamp': 1721916050.206603}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5861413478851318, '_timestamp': 1721916050.206854}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'ratio': 2.157839298248291, '_timestamp': 1721916050.2069619}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721916050.2070966}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916050.2071881}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'Episode_Time': 45.57431650161743, '_timestamp': 1721916050.2072468}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.35002721829069133, '_timestamp': 1721916050.2077281}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'train_goal': 0.3249863908546543, '_timestamp': 1721916050.208008}).
wandb: WARNING (User provided step: 2346 is less than current step: 14326. Dropping entry: {'train_WDL': -0.35002721829069133, '_timestamp': 1721916050.2083242}).
Env Football Algo jrpo Exp base_JRPO updates 2346/100000000000.0 steps in 45.57
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 4034/100000000000.0 steps in 44.86
total episode rewards is -110.0
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'value_loss': 0.8512867013613383, '_timestamp': 1721916095.0676625}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'policy_loss': 0.10787914212793112, '_timestamp': 1721916095.0678256}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8262859813372294, '_timestamp': 1721916095.067893}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.37761473655700684, '_timestamp': 1721916095.0680072}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.076521396636963, '_timestamp': 1721916095.0682635}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'ratio': 4.265626907348633, '_timestamp': 1721916095.0683665}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721916095.0684967}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916095.0685847}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'Episode_Time': 44.85857152938843, '_timestamp': 1721916095.0687075}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916095.0690324}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916095.0692692}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916095.069505}).
Env Football Algo jrpo Exp base_JRPO updates 4608/100000000000.0 steps in 94.04
total episode rewards is -20.0
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'value_loss': 0.2978662077223028, '_timestamp': 1721916189.1123643}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07524031648412347, '_timestamp': 1721916189.112559}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1511271897951763, '_timestamp': 1721916189.1126313}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.1601446270942688, '_timestamp': 1721916189.1127386}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4900442063808441, '_timestamp': 1721916189.113012}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'ratio': 0.712040364742279, '_timestamp': 1721916189.1131184}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721916189.113255}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916189.1136312}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.04200077056885, '_timestamp': 1721916189.113693}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.44361046959199385, '_timestamp': 1721916189.114473}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'train_goal': 0.2781947652040031, '_timestamp': 1721916189.1150744}).
wandb: WARNING (User provided step: 4608 is less than current step: 14326. Dropping entry: {'train_WDL': -0.44361046959199385, '_timestamp': 1721916189.1157105}).
Env Football Algo jrpo Exp base_JRPO updates 8512/100000000000.0 steps in 87.68
total episode rewards is -40.0
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'value_loss': 0.2892087934492156, '_timestamp': 1721916276.7970905}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'policy_loss': 0.043107856205630624, '_timestamp': 1721916276.7983787}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2735603857040405, '_timestamp': 1721916276.7984557}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.29656314849853516, '_timestamp': 1721916276.7990017}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5457204580307007, '_timestamp': 1721916276.7993338}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'ratio': 2.6945533752441406, '_timestamp': 1721916276.7994442}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916276.7995825}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916276.8002434}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.67553091049194, '_timestamp': 1721916276.800309}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916276.8012953}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916276.8017502}).
wandb: WARNING (User provided step: 8512 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916276.8022177}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'value_loss': 0.3048235707260513, '_timestamp': 1721916366.0029435}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01618059428874403, '_timestamp': 1721916366.003166}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.359760193824768, '_timestamp': 1721916366.0032334}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4087706208229065, '_timestamp': 1721916366.0033302}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5703724026679993, '_timestamp': 1721916366.0150876}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'ratio': 0.7915297746658325, '_timestamp': 1721916366.0153463}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721916366.015784}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916366.015893}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.19957661628723, '_timestamp': 1721916366.0159671}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.39933461034378465, '_timestamp': 1721916366.0167823}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'train_goal': 0.30033269482810765, '_timestamp': 1721916366.0173476}).
wandb: WARNING (User provided step: 5081 is less than current step: 14326. Dropping entry: {'train_WDL': -0.39933461034378465, '_timestamp': 1721916366.0179331}).
Env Football Algo jrpo Exp base_JRPO updates 5081/100000000000.0 steps in 89.20
total episode rewards is -20.0
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'value_loss': 0.8387582633333902, '_timestamp': 1721916414.0487382}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'policy_loss': 0.10747686540261688, '_timestamp': 1721916414.0504267}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.115245714187622, '_timestamp': 1721916414.050531}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.161881685256958, '_timestamp': 1721916414.0511231}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.8605068922042847, '_timestamp': 1721916414.0514927}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'ratio': 0.28440243005752563, '_timestamp': 1721916414.0516183}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721916414.051765}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916414.0520144}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'Episode_Time': 48.02105093002319, '_timestamp': 1721916414.0524106}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916414.05322}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916414.0535033}).
wandb: WARNING (User provided step: 3271 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916414.0537736}).
Env Football Algo jrpo Exp base_JRPO updates 3271/100000000000.0 steps in 48.02
total episode rewards is -130.0
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'value_loss': 0.7081287913769484, '_timestamp': 1721916482.0454574}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'policy_loss': 0.10054585977147022, '_timestamp': 1721916482.0457227}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7201965800921122, '_timestamp': 1721916482.0457928}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07037416845560074, '_timestamp': 1721916482.0458987}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.386927604675293, '_timestamp': 1721916482.0461242}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'ratio': 0.04504939541220665, '_timestamp': 1721916482.0462344}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721916482.0464034}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916482.0465355}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'Episode_Time': 67.9907214641571, '_timestamp': 1721916482.0466897}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3992248062015504, '_timestamp': 1721916482.0475059}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'train_goal': 0.3003875968992248, '_timestamp': 1721916482.0479393}).
wandb: WARNING (User provided step: 3602 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3992248062015504, '_timestamp': 1721916482.0484035}).
Env Football Algo jrpo Exp base_JRPO updates 3602/100000000000.0 steps in 67.99
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 583/100000000000.0 steps in 21.71
total episode rewards is -90.0
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'value_loss': 1.0801238747437796, '_timestamp': 1721916503.7645185}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0933167501181985, '_timestamp': 1721916503.7652478}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1218590033054352, '_timestamp': 1721916503.765323}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4128590226173401, '_timestamp': 1721916503.7656212}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.390387535095215, '_timestamp': 1721916503.7658684}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'ratio': 0.13402020931243896, '_timestamp': 1721916503.765976}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721916503.766105}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916503.7666676}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'Episode_Time': 21.71127486228943, '_timestamp': 1721916503.7667303}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6595067621320605, '_timestamp': 1721916503.7672334}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'train_goal': 0.8297533810660302, '_timestamp': 1721916503.7673929}).
wandb: WARNING (User provided step: 583 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6595067621320605, '_timestamp': 1721916503.7675467}).
Env Football Algo jrpo Exp base_JRPO updates 5120/100000000000.0 steps in 93.78
total episode rewards is 0.0
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'value_loss': 0.2973041217867285, '_timestamp': 1721916597.5503342}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'policy_loss': 0.11211184727648894, '_timestamp': 1721916597.5505602}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.3570115741093955, '_timestamp': 1721916597.5506296}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.13848476111888885, '_timestamp': 1721916597.5507305}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3689596354961395, '_timestamp': 1721916597.5510042}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'ratio': 0.08887684345245361, '_timestamp': 1721916597.5511081}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721916597.5512426}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916597.5513396}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.78164458274841, '_timestamp': 1721916597.5516636}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.06477732793522267, '_timestamp': 1721916597.5525362}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'train_goal': 0.4676113360323887, '_timestamp': 1721916597.553452}).
wandb: WARNING (User provided step: 5120 is less than current step: 14326. Dropping entry: {'train_WDL': -0.06477732793522267, '_timestamp': 1721916597.5543838}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'value_loss': 0.2942597319961836, '_timestamp': 1721916687.1867218}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1072443768257896, '_timestamp': 1721916687.1869898}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.3994078477223715, '_timestamp': 1721916687.1870644}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.050720032304525375, '_timestamp': 1721916687.1871917}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2579502761363983, '_timestamp': 1721916687.1874554}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'ratio': 0.1323414444923401, '_timestamp': 1721916687.187566}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916687.1877103}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916687.1878119}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.63121676445007, '_timestamp': 1721916687.1878731}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916687.1896055}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916687.1904294}).
wandb: WARNING (User provided step: 6313 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916687.191281}).
Env Football Algo jrpo Exp base_JRPO updates 6313/100000000000.0 steps in 89.63
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 6454/100000000000.0 steps in 74.55
total episode rewards is -10.0
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'value_loss': 0.47048366323734325, '_timestamp': 1721916761.7396472}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04217880610415402, '_timestamp': 1721916761.7398975}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4994991167386373, '_timestamp': 1721916761.7399793}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5375890731811523, '_timestamp': 1721916761.7401116}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0238245725631714, '_timestamp': 1721916761.7403781}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'ratio': 0.32034972310066223, '_timestamp': 1721916761.7404835}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721916761.7407055}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916761.7408028}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'Episode_Time': 74.54701662063599, '_timestamp': 1721916761.7409258}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3607286591823766, '_timestamp': 1721916761.7416105}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'train_goal': 0.6803643295911883, '_timestamp': 1721916761.741987}).
wandb: WARNING (User provided step: 6454 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3607286591823766, '_timestamp': 1721916761.7423286}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'value_loss': 0.28081007599985847, '_timestamp': 1721916848.6328328}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0452028171143805, '_timestamp': 1721916848.633843}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5445205545425416, '_timestamp': 1721916848.6339154}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22794365882873535, '_timestamp': 1721916848.6346622}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3487931787967682, '_timestamp': 1721916848.634987}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'ratio': 0.3233955502510071, '_timestamp': 1721916848.6350954}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721916848.6352324}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916848.6354296}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.88558268547058, '_timestamp': 1721916848.6354904}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721916848.6364036}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721916848.6368003}).
wandb: WARNING (User provided step: 8998 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721916848.6371999}).
Env Football Algo jrpo Exp base_JRPO updates 8998/100000000000.0 steps in 86.89
total episode rewards is -40.0
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'value_loss': 0.39537313018615045, '_timestamp': 1721916934.6575708}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0354361163348464, '_timestamp': 1721916934.6577508}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2685187164942424, '_timestamp': 1721916934.657828}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5658122301101685, '_timestamp': 1721916934.6579378}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7353751063346863, '_timestamp': 1721916934.6582112}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'ratio': 0.3002292811870575, '_timestamp': 1721916934.658325}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721916934.6584604}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721916934.6585686}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.0195152759552, '_timestamp': 1721916934.6595905}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.01331893448524118, '_timestamp': 1721916934.6601706}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'train_goal': 0.5066594672426206, '_timestamp': 1721916934.6605594}).
wandb: WARNING (User provided step: 8644 is less than current step: 14326. Dropping entry: {'train_WDL': 0.01331893448524118, '_timestamp': 1721916934.6609416}).
Env Football Algo jrpo Exp base_JRPO updates 8644/100000000000.0 steps in 86.02
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 10508/100000000000.0 steps in 95.26
total episode rewards is -30.0
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'value_loss': 0.2223998533860625, '_timestamp': 1721917029.918429}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05178939995258891, '_timestamp': 1721917029.9185896}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5125008567174276, '_timestamp': 1721917029.918658}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.17355483770370483, '_timestamp': 1721917029.9187484}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6019512414932251, '_timestamp': 1721917029.9190173}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'ratio': 0.475281685590744, '_timestamp': 1721917029.9191217}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721917029.9192562}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917029.9193497}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'Episode_Time': 95.25657153129578, '_timestamp': 1721917029.9196815}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917029.9201288}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917029.9204428}).
wandb: WARNING (User provided step: 10508 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917029.9207606}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'value_loss': 0.4312454006595848, '_timestamp': 1721917113.6574502}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0725598828929166, '_timestamp': 1721917113.657612}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7434386106332144, '_timestamp': 1721917113.6576788}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.49595245718955994, '_timestamp': 1721917113.6577713}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7944344878196716, '_timestamp': 1721917113.6580322}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'ratio': 0.2529670298099518, '_timestamp': 1721917113.658136}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721917113.658269}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917113.6583593}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'Episode_Time': 83.7359516620636, '_timestamp': 1721917113.658574}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917113.6589866}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917113.6593065}).
wandb: WARNING (User provided step: 9764 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917113.6596172}).
Env Football Algo jrpo Exp base_JRPO updates 9764/100000000000.0 steps in 83.74
total episode rewards is -50.0
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'value_loss': 0.503343336203446, '_timestamp': 1721917189.2423415}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'policy_loss': 0.014877242062163228, '_timestamp': 1721917189.2425191}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.743868987162908, '_timestamp': 1721917189.2425876}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.344606876373291, '_timestamp': 1721917189.2426848}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9972881078720093, '_timestamp': 1721917189.242946}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'ratio': 0.7585805654525757, '_timestamp': 1721917189.243049}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721917189.24318}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917189.2432747}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'Episode_Time': 75.58186507225037, '_timestamp': 1721917189.2433336}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3340282948622487, '_timestamp': 1721917189.2440884}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'train_goal': 0.33298585256887564, '_timestamp': 1721917189.2445722}).
wandb: WARNING (User provided step: 4710 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3340282948622487, '_timestamp': 1721917189.2450078}).
Env Football Algo jrpo Exp base_JRPO updates 4710/100000000000.0 steps in 75.58
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 7193/100000000000.0 steps in 93.08
total episode rewards is 30.0
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'value_loss': 0.2612745163733295, '_timestamp': 1721917282.3298552}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0004898682434577495, '_timestamp': 1721917282.3300889}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5953255867958069, '_timestamp': 1721917282.330218}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7470037937164307, '_timestamp': 1721917282.3303788}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7832484841346741, '_timestamp': 1721917282.3307135}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'ratio': 0.9963410496711731, '_timestamp': 1721917282.3308897}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721917282.3310933}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917282.3312483}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.0833101272583, '_timestamp': 1721917282.3315928}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721917282.3327596}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721917282.3335938}).
wandb: WARNING (User provided step: 7193 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721917282.3344178}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'value_loss': 0.2789086262893397, '_timestamp': 1721917373.4439735}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'policy_loss': -0.002733646300427305, '_timestamp': 1721917373.4441683}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5753029942512512, '_timestamp': 1721917373.4442458}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4629468321800232, '_timestamp': 1721917373.4443693}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.45247137546539307, '_timestamp': 1721917373.44461}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'ratio': 0.9835865497589111, '_timestamp': 1721917373.4447157}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721917373.444861}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917373.4449782}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.10857129096985, '_timestamp': 1721917373.4450545}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.5729456384323641, '_timestamp': 1721917373.4458432}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'train_goal': 0.21352718078381794, '_timestamp': 1721917373.446349}).
wandb: WARNING (User provided step: 7090 is less than current step: 14326. Dropping entry: {'train_WDL': -0.5729456384323641, '_timestamp': 1721917373.4468582}).
Env Football Algo jrpo Exp base_JRPO updates 7090/100000000000.0 steps in 91.11
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8657/100000000000.0 steps in 93.84
total episode rewards is -40.0
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'value_loss': 0.2636588279681746, '_timestamp': 1721917467.290443}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'policy_loss': -0.002247526019345969, '_timestamp': 1721917467.29066}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5890785423914592, '_timestamp': 1721917467.290734}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2602270245552063, '_timestamp': 1721917467.2908335}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2581402361392975, '_timestamp': 1721917467.291121}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'ratio': 0.9775705337524414, '_timestamp': 1721917467.291237}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917467.291544}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917467.291649}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.84258198738098, '_timestamp': 1721917467.2922554}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917467.2929857}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917467.2936363}).
wandb: WARNING (User provided step: 8657 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917467.2942843}).
Env Football Algo jrpo Exp base_JRPO updates 9833/100000000000.0 steps in 98.15
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'value_loss': 0.2604910759975125, '_timestamp': 1721917565.4437613}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'policy_loss': 0.055649391909440356, '_timestamp': 1721917565.4439313}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.3368924906849861, '_timestamp': 1721917565.4440281}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3208942413330078, '_timestamp': 1721917565.4441226}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7082028985023499, '_timestamp': 1721917565.444397}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'ratio': 0.4188532829284668, '_timestamp': 1721917565.4445026}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721917565.4446461}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917565.4450774}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'Episode_Time': 98.14844489097595, '_timestamp': 1721917565.4451385}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.8610412231468938, '_timestamp': 1721917565.4459798}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'train_goal': 0.9305206115734469, '_timestamp': 1721917565.4463503}).
wandb: WARNING (User provided step: 9833 is less than current step: 14326. Dropping entry: {'train_WDL': 0.8610412231468938, '_timestamp': 1721917565.4466913}).
total episode rewards is 20.0
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'value_loss': 0.3532909932200952, '_timestamp': 1721917639.703824}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'policy_loss': 0.033452629654978715, '_timestamp': 1721917639.704011}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.41382976492245993, '_timestamp': 1721917639.7040782}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3548893928527832, '_timestamp': 1721917639.704175}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5913075804710388, '_timestamp': 1721917639.7044554}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'ratio': 0.8107607960700989, '_timestamp': 1721917639.7045588}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721917639.70469}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917639.704786}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'Episode_Time': 74.25369381904602, '_timestamp': 1721917639.705018}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917639.7055619}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917639.705985}).
wandb: WARNING (User provided step: 6820 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917639.7064168}).
Env Football Algo jrpo Exp base_JRPO updates 6820/100000000000.0 steps in 74.25
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 3332/100000000000.0 steps in 46.63
total episode rewards is -100.0
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'value_loss': 0.7725491740927101, '_timestamp': 1721917686.334897}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'policy_loss': 0.052996124234050514, '_timestamp': 1721917686.3350763}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5715141173203786, '_timestamp': 1721917686.3351467}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7282322645187378, '_timestamp': 1721917686.335245}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.7391101121902466, '_timestamp': 1721917686.3355203}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'ratio': 0.7222524285316467, '_timestamp': 1721917686.3356357}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721917686.3357701}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917686.3358662}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'Episode_Time': 46.6275897026062, '_timestamp': 1721917686.3359234}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1415460642428521, '_timestamp': 1721917686.336756}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'train_goal': 0.42922696787857395, '_timestamp': 1721917686.336996}).
wandb: WARNING (User provided step: 3332 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1415460642428521, '_timestamp': 1721917686.33723}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'value_loss': 0.2092461409117095, '_timestamp': 1721917768.6376102}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0054849175930333635, '_timestamp': 1721917768.6377587}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5685777332385381, '_timestamp': 1721917768.6378233}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7935593724250793, '_timestamp': 1721917768.6379085}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3046196699142456, '_timestamp': 1721917768.6381438}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'ratio': 0.9956470131874084, '_timestamp': 1721917768.638244}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721917768.6383734}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917768.6384623}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.29947996139526, '_timestamp': 1721917768.6386592}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917768.639095}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917768.639425}).
wandb: WARNING (User provided step: 9939 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917768.6397688}).
Env Football Algo jrpo Exp base_JRPO updates 9939/100000000000.0 steps in 82.30
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7137/100000000000.0 steps in 82.61
total episode rewards is -40.0
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'value_loss': 0.42419739633216524, '_timestamp': 1721917851.2542207}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'policy_loss': 0.006868992184172385, '_timestamp': 1721917851.254426}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6530137403806051, '_timestamp': 1721917851.2545152}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7467495203018188, '_timestamp': 1721917851.2546198}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9644773602485657, '_timestamp': 1721917851.254866}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'ratio': 0.9808475971221924, '_timestamp': 1721917851.2549975}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721917851.255149}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917851.2557526}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.61364579200745, '_timestamp': 1721917851.2558162}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.05923210495851823, '_timestamp': 1721917851.2563539}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'train_goal': 0.47038394752074086, '_timestamp': 1721917851.2567246}).
wandb: WARNING (User provided step: 7137 is less than current step: 14326. Dropping entry: {'train_WDL': -0.05923210495851823, '_timestamp': 1721917851.257084}).
Env Football Algo jrpo Exp base_JRPO updates 10351/100000000000.0 steps in 98.23
total episode rewards is -20.0
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'value_loss': 0.14060444319504314, '_timestamp': 1721917949.4897466}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'policy_loss': 0.005527452715468826, '_timestamp': 1721917949.4899316}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7518926767508188, '_timestamp': 1721917949.4900093}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.45959246158599854, '_timestamp': 1721917949.4901118}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.26769953966140747, '_timestamp': 1721917949.490397}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'ratio': 1.0064929723739624, '_timestamp': 1721917949.4905045}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721917949.4906375}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721917949.4907336}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'Episode_Time': 98.23173713684082, '_timestamp': 1721917949.4911332}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721917949.4916058}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721917949.491986}).
wandb: WARNING (User provided step: 10351 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721917949.4923482}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'value_loss': 0.20070251283526885, '_timestamp': 1721918036.0910068}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'policy_loss': 0.007250295673729852, '_timestamp': 1721918036.0911674}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7774649572372436, '_timestamp': 1721918036.0912352}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5670175552368164, '_timestamp': 1721918036.0913258}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.45707032084465027, '_timestamp': 1721918036.091586}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'ratio': 1.280259370803833, '_timestamp': 1721918036.0916977}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721918036.0918357}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918036.0919316}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.59755897521973, '_timestamp': 1721918036.0920243}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.19509738079247818, '_timestamp': 1721918036.0927534}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'train_goal': 0.4024513096037609, '_timestamp': 1721918036.0933843}).
wandb: WARNING (User provided step: 9044 is less than current step: 14326. Dropping entry: {'train_WDL': -0.19509738079247818, '_timestamp': 1721918036.094015}).
Env Football Algo jrpo Exp base_JRPO updates 9044/100000000000.0 steps in 86.60
total episode rewards is -10.0
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'value_loss': 0.2416087911427894, '_timestamp': 1721918121.8249831}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0018136264799007524, '_timestamp': 1721918121.825185}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8135712476571401, '_timestamp': 1721918121.8252518}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.20928092300891876, '_timestamp': 1721918121.825342}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.27231746912002563, '_timestamp': 1721918121.825537}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'ratio': 0.9313645362854004, '_timestamp': 1721918121.8256407}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721918121.8258443}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918121.8259354}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.7299370765686, '_timestamp': 1721918121.825993}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918121.8265827}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918121.8270316}).
wandb: WARNING (User provided step: 7475 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918121.8274982}).
Env Football Algo jrpo Exp base_JRPO updates 7475/100000000000.0 steps in 85.73
total episode rewards is -30.0
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'value_loss': 0.16907958283734237, '_timestamp': 1721918216.1519294}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'policy_loss': 0.009737127042996386, '_timestamp': 1721918216.152137}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9867981946468354, '_timestamp': 1721918216.1522133}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6115032434463501, '_timestamp': 1721918216.1523132}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5499036908149719, '_timestamp': 1721918216.1525836}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'ratio': 0.815310537815094, '_timestamp': 1721918216.1526945}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721918216.1528304}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918216.153506}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.32342457771301, '_timestamp': 1721918216.153571}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721918216.1544633}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721918216.1550667}).
wandb: WARNING (User provided step: 9708 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721918216.155428}).
Env Football Algo jrpo Exp base_JRPO updates 9708/100000000000.0 steps in 94.32
total episode rewards is 20.0
Env Football Algo jrpo Exp base_JRPO updates 3545/100000000000.0 steps in 47.30
total episode rewards is -60.0
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'value_loss': 0.5474284758185968, '_timestamp': 1721918263.4550889}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0077059059066232295, '_timestamp': 1721918263.4552524}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7978377056121826, '_timestamp': 1721918263.455319}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5662044286727905, '_timestamp': 1721918263.4554088}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.204403042793274, '_timestamp': 1721918263.455675}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'ratio': 0.9511409997940063, '_timestamp': 1721918263.4557786}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721918263.4559097}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918263.456231}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'Episode_Time': 47.2986536026001, '_timestamp': 1721918263.45629}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1773095623987034, '_timestamp': 1721918263.456671}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'train_goal': 0.4113452188006483, '_timestamp': 1721918263.4569101}).
wandb: WARNING (User provided step: 3545 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1773095623987034, '_timestamp': 1721918263.4571462}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'value_loss': 0.8731066937744617, '_timestamp': 1721918316.8968377}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'policy_loss': 0.009253240475275865, '_timestamp': 1721918316.896994}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8704988634586335, '_timestamp': 1721918316.8970597}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.9456472992897034, '_timestamp': 1721918316.8971436}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.9258804321289062, '_timestamp': 1721918316.897386}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'ratio': 0.9225126504898071, '_timestamp': 1721918316.8974884}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721918316.8977082}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918316.8977985}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'Episode_Time': 53.43899440765381, '_timestamp': 1721918316.8978546}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2079731027857829, '_timestamp': 1721918316.8982623}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'train_goal': 0.3960134486071086, '_timestamp': 1721918316.8985493}).
wandb: WARNING (User provided step: 4181 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2079731027857829, '_timestamp': 1721918316.898841}).
Env Football Algo jrpo Exp base_JRPO updates 4181/100000000000.0 steps in 53.44
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 9164/100000000000.0 steps in 94.54
total episode rewards is -30.0
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'value_loss': 0.20489529378925606, '_timestamp': 1721918411.4378047}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'policy_loss': 0.019402485052875514, '_timestamp': 1721918411.4379737}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3977181963125864, '_timestamp': 1721918411.438041}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3195371925830841, '_timestamp': 1721918411.4381328}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3802742063999176, '_timestamp': 1721918411.4383996}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'ratio': 0.7514063119888306, '_timestamp': 1721918411.4385052}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721918411.4386394}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918411.4387343}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.53735303878784, '_timestamp': 1721918411.4389856}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918411.4394758}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918411.4398508}).
wandb: WARNING (User provided step: 9164 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918411.440246}).
Env Football Algo jrpo Exp base_JRPO updates 8687/100000000000.0 steps in 74.30
total episode rewards is -60.0
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'value_loss': 0.4120274628799719, '_timestamp': 1721918485.7460904}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'policy_loss': 0.046650915284020204, '_timestamp': 1721918485.7462697}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7696400205294291, '_timestamp': 1721918485.746339}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.19676318764686584, '_timestamp': 1721918485.7464397}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8973536491394043, '_timestamp': 1721918485.7467027}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'ratio': 0.7893058061599731, '_timestamp': 1721918485.7471683}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721918485.747304}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918485.7474015}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'Episode_Time': 74.30499768257141, '_timestamp': 1721918485.7474594}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918485.7479258}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918485.74827}).
wandb: WARNING (User provided step: 8687 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918485.748592}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'value_loss': 0.8350052876522144, '_timestamp': 1721918530.6318176}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07263701784240159, '_timestamp': 1721918530.6331184}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.576631360054016, '_timestamp': 1721918530.6331925}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.29113349318504333, '_timestamp': 1721918530.641641}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.6015666723251343, '_timestamp': 1721918530.6420567}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'ratio': 0.6677196621894836, '_timestamp': 1721918530.6421697}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721918530.6423123}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918530.6429753}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'Episode_Time': 44.878488063812256, '_timestamp': 1721918530.643039}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.35545023696682465, '_timestamp': 1721918530.6437428}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'train_goal': 0.3222748815165877, '_timestamp': 1721918530.6466224}).
wandb: WARNING (User provided step: 2511 is less than current step: 14326. Dropping entry: {'train_WDL': -0.35545023696682465, '_timestamp': 1721918530.6469388}).
Env Football Algo jrpo Exp base_JRPO updates 2511/100000000000.0 steps in 44.88
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 5621/100000000000.0 steps in 83.33
total episode rewards is -30.0
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'value_loss': 0.4667384279984981, '_timestamp': 1721918613.9741468}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04463345915117922, '_timestamp': 1721918613.9743142}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5771807869275412, '_timestamp': 1721918613.9743803}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5018317103385925, '_timestamp': 1721918613.9744728}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9891396164894104, '_timestamp': 1721918613.974705}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'ratio': 0.9128783345222473, '_timestamp': 1721918613.974894}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721918613.9750223}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918613.9751468}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'Episode_Time': 83.3263030052185, '_timestamp': 1721918613.9752047}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.35753176043557167, '_timestamp': 1721918613.976081}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'train_goal': 0.6787658802177858, '_timestamp': 1721918613.9765453}).
wandb: WARNING (User provided step: 5621 is less than current step: 14326. Dropping entry: {'train_WDL': 0.35753176043557167, '_timestamp': 1721918613.9770045}).
Env Football Algo jrpo Exp base_JRPO updates 4152/100000000000.0 steps in 98.00
total episode rewards is -20.0
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'value_loss': 0.32697380615087845, '_timestamp': 1721918711.976852}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'policy_loss': 0.026010977437642094, '_timestamp': 1721918711.977021}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5871370967229208, '_timestamp': 1721918711.9770885}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5392128825187683, '_timestamp': 1721918711.9771833}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.40912771224975586, '_timestamp': 1721918711.9774308}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'ratio': 0.5823151469230652, '_timestamp': 1721918711.977536}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721918711.9776635}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918711.9777555}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'Episode_Time': 97.99891018867493, '_timestamp': 1721918711.9779725}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4592551622418879, '_timestamp': 1721918711.9787307}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'train_goal': 0.27037241887905605, '_timestamp': 1721918711.9793417}).
wandb: WARNING (User provided step: 4152 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4592551622418879, '_timestamp': 1721918711.9799902}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'value_loss': 0.34071736109443007, '_timestamp': 1721918805.2249606}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01631102455915728, '_timestamp': 1721918805.2251906}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6960504992802938, '_timestamp': 1721918805.2252595}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.34016600251197815, '_timestamp': 1721918805.2253604}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9095752239227295, '_timestamp': 1721918805.2257066}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'ratio': 0.6056562662124634, '_timestamp': 1721918805.2258158}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721918805.2259903}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918805.2261202}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.24375629425049, '_timestamp': 1721918805.226179}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721918805.2268977}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721918805.2274246}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721918805.22799}).
Env Football Algo jrpo Exp base_JRPO updates 6124/100000000000.0 steps in 93.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'value_loss': 0.45098286446804803, '_timestamp': 1721918880.9694965}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'policy_loss': 0.025405210363290583, '_timestamp': 1721918880.9696906}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.747096499602, '_timestamp': 1721918880.9697578}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5897292494773865, '_timestamp': 1721918880.9698505}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7523583173751831, '_timestamp': 1721918880.970096}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'ratio': 0.5827618837356567, '_timestamp': 1721918880.970199}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721918880.9703279}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918880.9704516}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'Episode_Time': 75.74059844017029, '_timestamp': 1721918880.9706256}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.21870455308200024, '_timestamp': 1721918880.9716346}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'train_goal': 0.6093522765410001, '_timestamp': 1721918880.9722128}).
wandb: WARNING (User provided step: 4786 is less than current step: 14326. Dropping entry: {'train_WDL': 0.21870455308200024, '_timestamp': 1721918880.972752}).
Env Football Algo jrpo Exp base_JRPO updates 4786/100000000000.0 steps in 75.74
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 4805/100000000000.0 steps in 61.84
total episode rewards is -70.0
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'value_loss': 0.7050785633673271, '_timestamp': 1721918942.813881}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'policy_loss': 0.056117186784783064, '_timestamp': 1721918942.8141341}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5971612532933552, '_timestamp': 1721918942.8142016}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.16464444994926453, '_timestamp': 1721918942.8143826}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.51970636844635, '_timestamp': 1721918942.81465}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'ratio': 0.5291282534599304, '_timestamp': 1721918942.8147545}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721918942.8151488}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721918942.8152816}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'Episode_Time': 61.83976745605469, '_timestamp': 1721918942.81534}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.10196592398427261, '_timestamp': 1721918942.8162174}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'train_goal': 0.4490170380078637, '_timestamp': 1721918942.8165112}).
wandb: WARNING (User provided step: 4805 is less than current step: 14326. Dropping entry: {'train_WDL': -0.10196592398427261, '_timestamp': 1721918942.8169339}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'value_loss': 0.5230721092286209, '_timestamp': 1721919015.7717032}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'policy_loss': 0.00538477447660019, '_timestamp': 1721919015.7736833}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0855632201830545, '_timestamp': 1721919015.7737548}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3049246668815613, '_timestamp': 1721919015.7741494}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.274247407913208, '_timestamp': 1721919015.7744846}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'ratio': 0.6592403650283813, '_timestamp': 1721919015.774593}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721919015.774729}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919015.7749038}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'Episode_Time': 72.93906903266907, '_timestamp': 1721919015.7753894}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919015.7762098}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919015.7766328}).
wandb: WARNING (User provided step: 6618 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919015.7770638}).
Env Football Algo jrpo Exp base_JRPO updates 6618/100000000000.0 steps in 72.94
total episode rewards is -80.0
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'value_loss': 0.46712183800836404, '_timestamp': 1721919112.2966785}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'policy_loss': -0.010723150031796346, '_timestamp': 1721919112.2969275}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8284782481193542, '_timestamp': 1721919112.2969964}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6668223738670349, '_timestamp': 1721919112.297172}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6437734365463257, '_timestamp': 1721919112.2974284}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'ratio': 0.6573339104652405, '_timestamp': 1721919112.2975335}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721919112.2976677}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919112.2977984}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'Episode_Time': 96.5185866355896, '_timestamp': 1721919112.2982774}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919112.2993815}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919112.3000293}).
wandb: WARNING (User provided step: 4896 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919112.3007276}).
Env Football Algo jrpo Exp base_JRPO updates 4896/100000000000.0 steps in 96.52
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 5230/100000000000.0 steps in 74.82
total episode rewards is -80.0
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'value_loss': 0.5884930958598852, '_timestamp': 1721919187.1244242}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1275358279546102, '_timestamp': 1721919187.12464}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4699723450342814, '_timestamp': 1721919187.1247098}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2564438581466675, '_timestamp': 1721919187.1248467}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9727370142936707, '_timestamp': 1721919187.1251252}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'ratio': 0.09636809676885605, '_timestamp': 1721919187.1252325}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721919187.1253717}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919187.1254663}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'Episode_Time': 74.82232522964478, '_timestamp': 1721919187.1255252}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919187.126221}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919187.126685}).
wandb: WARNING (User provided step: 5230 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919187.1271687}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'value_loss': 0.3361965813115239, '_timestamp': 1721919277.5508876}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'policy_loss': 0.12850449072817963, '_timestamp': 1721919277.5511138}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7789947009086609, '_timestamp': 1721919277.5512395}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14825187623500824, '_timestamp': 1721919277.5513952}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7060819268226624, '_timestamp': 1721919277.551706}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'ratio': 0.05307991802692413, '_timestamp': 1721919277.551886}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919277.5520713}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919277.5521748}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.4225001335144, '_timestamp': 1721919277.5522346}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919277.5529394}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919277.5535622}).
wandb: WARNING (User provided step: 6871 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919277.554133}).
Env Football Algo jrpo Exp base_JRPO updates 6871/100000000000.0 steps in 90.42
total episode rewards is -40.0
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'value_loss': 0.8466610083480676, '_timestamp': 1721919323.7577546}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08250311821699143, '_timestamp': 1721919323.757918}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5505946453412374, '_timestamp': 1721919323.7579825}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.30985379219055176, '_timestamp': 1721919323.7580752}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.6358872652053833, '_timestamp': 1721919323.7583003}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'ratio': 0.34943291544914246, '_timestamp': 1721919323.7584016}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721919323.7585306}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919323.7586246}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'Episode_Time': 46.202646255493164, '_timestamp': 1721919323.758682}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919323.7590833}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919323.7593057}).
wandb: WARNING (User provided step: 2679 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919323.7595296}).
Env Football Algo jrpo Exp base_JRPO updates 2679/100000000000.0 steps in 46.20
total episode rewards is -130.0
Env Football Algo jrpo Exp base_JRPO updates 4707/100000000000.0 steps in 81.57
total episode rewards is -20.0
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'value_loss': 0.3411251145772015, '_timestamp': 1721919405.329967}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03557065151418404, '_timestamp': 1721919405.3301878}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6633702445030212, '_timestamp': 1721919405.3302622}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.32252296805381775, '_timestamp': 1721919405.330365}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4143904745578766, '_timestamp': 1721919405.3306375}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'ratio': 1.042678952217102, '_timestamp': 1721919405.3307421}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721919405.3314373}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919405.3315833}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'Episode_Time': 81.56937956809998, '_timestamp': 1721919405.3316438}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.41941125036432525, '_timestamp': 1721919405.3328547}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'train_goal': 0.2902943748178374, '_timestamp': 1721919405.3334503}).
wandb: WARNING (User provided step: 4707 is less than current step: 14326. Dropping entry: {'train_WDL': -0.41941125036432525, '_timestamp': 1721919405.334025}).
Env Football Algo jrpo Exp base_JRPO updates 3272/100000000000.0 steps in 45.57
total episode rewards is -150.0
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'value_loss': 1.1962284268935521, '_timestamp': 1721919450.9129772}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'policy_loss': 0.09196735768850582, '_timestamp': 1721919450.9141376}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.076747738520304, '_timestamp': 1721919450.9142091}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3408537805080414, '_timestamp': 1721919450.914656}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.628584384918213, '_timestamp': 1721919450.9149845}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'ratio': 0.5688202977180481, '_timestamp': 1721919450.9150908}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721919450.9153082}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919450.9154978}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'Episode_Time': 45.57342576980591, '_timestamp': 1721919450.9158485}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1194620253164557, '_timestamp': 1721919450.9168348}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'train_goal': 0.44026898734177217, '_timestamp': 1721919450.9170651}).
wandb: WARNING (User provided step: 3272 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1194620253164557, '_timestamp': 1721919450.917349}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'value_loss': 1.5722339578469595, '_timestamp': 1721919478.4532695}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'policy_loss': 0.10189747090179783, '_timestamp': 1721919478.4535563}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.106884603500366, '_timestamp': 1721919478.4536262}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5249813199043274, '_timestamp': 1721919478.4537632}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.0780727863311768, '_timestamp': 1721919478.4539843}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'ratio': 0.5470877289772034, '_timestamp': 1721919478.4540887}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -190.0, '_timestamp': 1721919478.4543266}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919478.4546208}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'Episode_Time': 27.531302213668823, '_timestamp': 1721919478.454682}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.12373737373737374, '_timestamp': 1721919478.455257}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'train_goal': 0.43813131313131315, '_timestamp': 1721919478.4554183}).
wandb: WARNING (User provided step: 1223 is less than current step: 14326. Dropping entry: {'train_WDL': -0.12373737373737374, '_timestamp': 1721919478.4555402}).
Env Football Algo jrpo Exp base_JRPO updates 1223/100000000000.0 steps in 27.53
total episode rewards is -190.0
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'value_loss': 0.9813330859442552, '_timestamp': 1721919542.2339034}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04671120526366091, '_timestamp': 1721919542.2352233}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8211712662378947, '_timestamp': 1721919542.2352974}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5781541466712952, '_timestamp': 1721919542.2358196}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.7729073762893677, '_timestamp': 1721919542.2362196}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'ratio': 0.7512423396110535, '_timestamp': 1721919542.23633}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721919542.236473}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919542.2366948}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'Episode_Time': 63.771806955337524, '_timestamp': 1721919542.2371554}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.30337775023241403, '_timestamp': 1721919542.2381332}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'train_goal': 0.348311124883793, '_timestamp': 1721919542.238556}).
wandb: WARNING (User provided step: 4846 is less than current step: 14326. Dropping entry: {'train_WDL': -0.30337775023241403, '_timestamp': 1721919542.238965}).
Env Football Algo jrpo Exp base_JRPO updates 4846/100000000000.0 steps in 63.77
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 3628/100000000000.0 steps in 52.80
total episode rewards is -70.0
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'value_loss': 0.5802029524743557, '_timestamp': 1721919595.0407584}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'policy_loss': 0.09867163016150395, '_timestamp': 1721919595.0409148}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9695697188377381, '_timestamp': 1721919595.0409799}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3232223689556122, '_timestamp': 1721919595.0410688}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8778054118156433, '_timestamp': 1721919595.0413108}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'ratio': 0.1807563751935959, '_timestamp': 1721919595.0414126}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721919595.0416296}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919595.0417216}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'Episode_Time': 52.800891160964966, '_timestamp': 1721919595.0417778}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919595.0421839}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919595.0424957}).
wandb: WARNING (User provided step: 3628 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919595.042811}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'value_loss': 0.30413728426831466, '_timestamp': 1721919686.8175604}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05439125151761497, '_timestamp': 1721919686.8178408}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6213898682594299, '_timestamp': 1721919686.8179119}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.41079533100128174, '_timestamp': 1721919686.8180158}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3331965208053589, '_timestamp': 1721919686.8182838}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'ratio': 0.5900409817695618, '_timestamp': 1721919686.8183928}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919686.8186593}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919686.8188016}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.77335834503174, '_timestamp': 1721919686.818865}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919686.8198218}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919686.8203542}).
wandb: WARNING (User provided step: 6750 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919686.8208773}).
Env Football Algo jrpo Exp base_JRPO updates 6750/100000000000.0 steps in 91.77
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 7056/100000000000.0 steps in 95.18
total episode rewards is -40.0
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'value_loss': 0.26406024428550157, '_timestamp': 1721919782.0057983}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'policy_loss': 0.049969848192995416, '_timestamp': 1721919782.0069342}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.865670803586642, '_timestamp': 1721919782.0070033}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6111593246459961, '_timestamp': 1721919782.0074565}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.20164303481578827, '_timestamp': 1721919782.0077682}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'ratio': 0.9729447960853577, '_timestamp': 1721919782.0078697}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919782.0081005}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919782.0082912}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'Episode_Time': 95.17930197715759, '_timestamp': 1721919782.0083501}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919782.0096722}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919782.0101912}).
wandb: WARNING (User provided step: 7056 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919782.0106955}).
Env Football Algo jrpo Exp base_JRPO updates 8312/100000000000.0 steps in 79.23
total episode rewards is -60.0
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'value_loss': 0.39977384922405085, '_timestamp': 1721919861.2422574}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02334678443420368, '_timestamp': 1721919861.242534}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7547455930709839, '_timestamp': 1721919861.2426076}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8443633913993835, '_timestamp': 1721919861.2427373}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5790621638298035, '_timestamp': 1721919861.2430165}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'ratio': 0.7916197180747986, '_timestamp': 1721919861.2431207}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721919861.2433872}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919861.2435837}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'Episode_Time': 79.22984862327576, '_timestamp': 1721919861.2439344}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919861.2448292}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919861.2453918}).
wandb: WARNING (User provided step: 8312 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919861.245837}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'value_loss': 0.24421437955151, '_timestamp': 1721919950.350305}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'policy_loss': 0.11776884369552136, '_timestamp': 1721919950.3516068}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.057243390083313, '_timestamp': 1721919950.351678}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.06569189578294754, '_timestamp': 1721919950.3522234}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.26652851700782776, '_timestamp': 1721919950.3525898}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'ratio': 0.017851941287517548, '_timestamp': 1721919950.3526964}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721919950.353248}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721919950.353454}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.09830451011658, '_timestamp': 1721919950.3535128}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721919950.3546364}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721919950.3552492}).
wandb: WARNING (User provided step: 6076 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721919950.3557906}).
Env Football Algo jrpo Exp base_JRPO updates 6076/100000000000.0 steps in 89.10
total episode rewards is -40.0
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'value_loss': 0.14596449209998053, '_timestamp': 1721920040.5959916}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'policy_loss': 0.12411072122553984, '_timestamp': 1721920040.5961838}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8398364818096161, '_timestamp': 1721920040.5962536}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2288568913936615, '_timestamp': 1721920040.5963533}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.20850612223148346, '_timestamp': 1721920040.5966444}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'ratio': 0.2591250538825989, '_timestamp': 1721920040.596772}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721920040.5969138}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920040.5970125}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.23688006401062, '_timestamp': 1721920040.5975614}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920040.597972}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920040.5982683}).
wandb: WARNING (User provided step: 10799 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920040.5985637}).
Env Football Algo jrpo Exp base_JRPO updates 10799/100000000000.0 steps in 90.24
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5247/100000000000.0 steps in 87.63
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'value_loss': 0.30443750888109206, '_timestamp': 1721920128.2248187}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1621575003117323, '_timestamp': 1721920128.2250543}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7878208522001903, '_timestamp': 1721920128.2251222}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.25967541337013245, '_timestamp': 1721920128.2252924}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.35897737741470337, '_timestamp': 1721920128.22554}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'ratio': 0.2367473840713501, '_timestamp': 1721920128.2256439}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920128.2257762}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920128.2259982}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.62529397010803, '_timestamp': 1721920128.2260568}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920128.2268393}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920128.2274337}).
wandb: WARNING (User provided step: 5247 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920128.2280264}).
total episode rewards is -40.0
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'value_loss': 0.23579745411872863, '_timestamp': 1721920221.691224}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'policy_loss': 0.21283865466713905, '_timestamp': 1721920221.6913908}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9355950971444448, '_timestamp': 1721920221.6914573}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.27415627241134644, '_timestamp': 1721920221.6915483}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.49836665391921997, '_timestamp': 1721920221.691779}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'ratio': 0.5698275566101074, '_timestamp': 1721920221.6918836}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721920221.6920242}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920221.6921985}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.46231365203857, '_timestamp': 1721920221.692257}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1476829796448679, '_timestamp': 1721920221.6928325}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'train_goal': 0.42615851017756606, '_timestamp': 1721920221.6932576}).
wandb: WARNING (User provided step: 8073 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1476829796448679, '_timestamp': 1721920221.6936953}).
Env Football Algo jrpo Exp base_JRPO updates 8073/100000000000.0 steps in 93.46
total episode rewards is -10.0
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'value_loss': 0.305157416810592, '_timestamp': 1721920301.3811378}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'policy_loss': 0.21451336279511451, '_timestamp': 1721920301.381317}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6200530034303665, '_timestamp': 1721920301.3813825}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.597783625125885, '_timestamp': 1721920301.381477}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.601017415523529, '_timestamp': 1721920301.3817341}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'ratio': 0.8559889197349548, '_timestamp': 1721920301.3818395}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920301.3819785}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920301.382331}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'Episode_Time': 79.68662643432617, '_timestamp': 1721920301.3823917}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920301.3829844}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920301.38346}).
wandb: WARNING (User provided step: 7294 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920301.3839428}).
Env Football Algo jrpo Exp base_JRPO updates 7294/100000000000.0 steps in 79.69
total episode rewards is -40.0
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'value_loss': 0.5476987393697103, '_timestamp': 1721920356.0614538}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'policy_loss': 0.11322215067843597, '_timestamp': 1721920356.0625186}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0225800736745199, '_timestamp': 1721920356.0625951}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07652248442173004, '_timestamp': 1721920356.0629842}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.156308650970459, '_timestamp': 1721920356.0633078}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'ratio': 0.04071371629834175, '_timestamp': 1721920356.0634158}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721920356.0635493}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920356.0642028}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'Episode_Time': 54.67267179489136, '_timestamp': 1721920356.0642667}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920356.0650787}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920356.065402}).
wandb: WARNING (User provided step: 3473 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920356.0657172}).
Env Football Algo jrpo Exp base_JRPO updates 3473/100000000000.0 steps in 54.67
total episode rewards is -80.0
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'value_loss': 0.9456273884077867, '_timestamp': 1721920411.3008826}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08414301995032777, '_timestamp': 1721920411.301044}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1255120420455933, '_timestamp': 1721920411.3011103}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14636819064617157, '_timestamp': 1721920411.3012037}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.0537028312683105, '_timestamp': 1721920411.301533}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'ratio': 0.35763418674468994, '_timestamp': 1721920411.301642}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721920411.3017745}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920411.3023083}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'Episode_Time': 55.23433780670166, '_timestamp': 1721920411.3023698}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.26103968697596425, '_timestamp': 1721920411.302855}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'train_goal': 0.3694801565120179, '_timestamp': 1721920411.303203}).
wandb: WARNING (User provided step: 4618 is less than current step: 14326. Dropping entry: {'train_WDL': -0.26103968697596425, '_timestamp': 1721920411.3035572}).
Env Football Algo jrpo Exp base_JRPO updates 4618/100000000000.0 steps in 55.23
total episode rewards is -130.0
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'value_loss': 0.680000572502613, '_timestamp': 1721920448.6981914}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'policy_loss': 0.09009796311457952, '_timestamp': 1721920448.6983767}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.895168829758962, '_timestamp': 1721920448.6984572}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.27542224526405334, '_timestamp': 1721920448.6985629}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.205087661743164, '_timestamp': 1721920448.6988196}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'ratio': 0.2175140380859375, '_timestamp': 1721920448.6989377}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721920448.6990798}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920448.6994026}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'Episode_Time': 37.39380741119385, '_timestamp': 1721920448.6994715}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3685131195335277, '_timestamp': 1721920448.6998544}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'train_goal': 0.31574344023323614, '_timestamp': 1721920448.700165}).
wandb: WARNING (User provided step: 2035 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3685131195335277, '_timestamp': 1721920448.7004402}).
Env Football Algo jrpo Exp base_JRPO updates 2035/100000000000.0 steps in 37.39
total episode rewards is -90.0
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'value_loss': 0.9010292272269725, '_timestamp': 1721920508.8671038}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08719462437788024, '_timestamp': 1721920508.8673587}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7197174843152363, '_timestamp': 1721920508.867446}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.21391937136650085, '_timestamp': 1721920508.8676643}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.437132716178894, '_timestamp': 1721920508.8680408}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'ratio': 0.41691645979881287, '_timestamp': 1721920508.8682344}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721920508.8684533}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920508.8689377}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'Episode_Time': 60.16529297828674, '_timestamp': 1721920508.869067}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.24940954180444025, '_timestamp': 1721920508.8695514}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'train_goal': 0.3752952290977799, '_timestamp': 1721920508.8699281}).
wandb: WARNING (User provided step: 4321 is less than current step: 14326. Dropping entry: {'train_WDL': -0.24940954180444025, '_timestamp': 1721920508.870304}).
Env Football Algo jrpo Exp base_JRPO updates 4321/100000000000.0 steps in 60.17
total episode rewards is -90.0
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'value_loss': 0.7940057039260864, '_timestamp': 1721920563.9968586}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'policy_loss': 0.010432551526852574, '_timestamp': 1721920563.9981234}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3623281462987265, '_timestamp': 1721920563.9981961}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8716732859611511, '_timestamp': 1721920564.0044472}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.171434760093689, '_timestamp': 1721920564.0048575}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'ratio': 0.46852046251296997, '_timestamp': 1721920564.004979}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721920564.0051117}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920564.005826}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'Episode_Time': 55.119563579559326, '_timestamp': 1721920564.005889}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4442620504402328, '_timestamp': 1721920564.0069497}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'train_goal': 0.2778689747798836, '_timestamp': 1721920564.007508}).
wandb: WARNING (User provided step: 2814 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4442620504402328, '_timestamp': 1721920564.0079436}).
Env Football Algo jrpo Exp base_JRPO updates 2814/100000000000.0 steps in 55.12
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 8556/100000000000.0 steps in 90.22
total episode rewards is -30.0
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'value_loss': 0.22789294903477034, '_timestamp': 1721920654.2323766}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1440804599225521, '_timestamp': 1721920654.2325337}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7598615932464599, '_timestamp': 1721920654.2325985}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.10255551338195801, '_timestamp': 1721920654.2326877}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.598847508430481, '_timestamp': 1721920654.232938}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'ratio': 0.10803629457950592, '_timestamp': 1721920654.2330418}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721920654.233172}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920654.2332604}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.22336959838867, '_timestamp': 1721920654.2334611}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920654.2339597}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920654.2343674}).
wandb: WARNING (User provided step: 8556 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920654.2347758}).
Env Football Algo jrpo Exp base_JRPO updates 9124/100000000000.0 steps in 86.53
total episode rewards is -40.0
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'value_loss': 0.26721469131608805, '_timestamp': 1721920740.7647614}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08663136912354578, '_timestamp': 1721920740.764956}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2347596589724223, '_timestamp': 1721920740.765027}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.37369629740715027, '_timestamp': 1721920740.7651412}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5147669911384583, '_timestamp': 1721920740.7654147}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'ratio': 0.41543617844581604, '_timestamp': 1721920740.7655396}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920740.7656746}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920740.7657719}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.52900743484497, '_timestamp': 1721920740.7662673}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920740.7667935}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920740.7671778}).
wandb: WARNING (User provided step: 9124 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920740.7675722}).
Env Football Algo jrpo Exp base_JRPO updates 6212/100000000000.0 steps in 68.45
total episode rewards is -80.0
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'value_loss': 0.5046191333358486, '_timestamp': 1721920809.215613}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03887623694676828, '_timestamp': 1721920809.2162056}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9209264985720317, '_timestamp': 1721920809.2164571}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2976475954055786, '_timestamp': 1721920809.2167623}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9493707418441772, '_timestamp': 1721920809.217175}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'ratio': 0.2957473695278168, '_timestamp': 1721920809.2174597}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721920809.2177737}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920809.218041}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'Episode_Time': 68.44596934318542, '_timestamp': 1721920809.2183857}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920809.2192855}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920809.2197855}).
wandb: WARNING (User provided step: 6212 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920809.2203012}).
Env Football Algo jrpo Exp base_JRPO updates 2651/100000000000.0 steps in 47.05
total episode rewards is -40.0
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'value_loss': 0.6145219669491052, '_timestamp': 1721920856.2679076}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'policy_loss': 0.09006501966156065, '_timestamp': 1721920856.2681017}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6975323788324992, '_timestamp': 1721920856.2681675}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.13043056428432465, '_timestamp': 1721920856.2682583}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9810224771499634, '_timestamp': 1721920856.2684975}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'ratio': 0.15182754397392273, '_timestamp': 1721920856.2685995}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721920856.2687294}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920856.2689111}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'Episode_Time': 47.046642780303955, '_timestamp': 1721920856.2689698}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.8428990364474236, '_timestamp': 1721920856.269584}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'train_goal': 0.9214495182237118, '_timestamp': 1721920856.269901}).
wandb: WARNING (User provided step: 2651 is less than current step: 14326. Dropping entry: {'train_WDL': 0.8428990364474236, '_timestamp': 1721920856.2702172}).
Env Football Algo jrpo Exp base_JRPO updates 3702/100000000000.0 steps in 70.21
total episode rewards is -50.0
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'value_loss': 0.7607521013915539, '_timestamp': 1721920926.4777863}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'policy_loss': 0.13385556099315485, '_timestamp': 1721920926.478015}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9259037566184998, '_timestamp': 1721920926.4780812}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05652416869997978, '_timestamp': 1721920926.4782062}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3186825513839722, '_timestamp': 1721920926.4784458}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'ratio': 0.018931616097688675, '_timestamp': 1721920926.4785516}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721920926.478677}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920926.4787643}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'Episode_Time': 70.20655369758606, '_timestamp': 1721920926.4788213}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.37647790914747975, '_timestamp': 1721920926.4794428}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'train_goal': 0.3117610454262601, '_timestamp': 1721920926.4798448}).
wandb: WARNING (User provided step: 3702 is less than current step: 14326. Dropping entry: {'train_WDL': -0.37647790914747975, '_timestamp': 1721920926.480268}).
Env Football Algo jrpo Exp base_JRPO updates 5052/100000000000.0 steps in 53.39
total episode rewards is -100.0
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'value_loss': 0.6299385887260238, '_timestamp': 1721920979.8717527}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06386032896970088, '_timestamp': 1721920979.8719764}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7777542773882549, '_timestamp': 1721920979.8720448}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.32839059829711914, '_timestamp': 1721920979.8721387}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9939553141593933, '_timestamp': 1721920979.8723986}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'ratio': 0.4974648654460907, '_timestamp': 1721920979.8725073}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721920979.8727984}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721920979.872891}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'Episode_Time': 53.39031648635864, '_timestamp': 1721920979.8729465}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721920979.873356}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721920979.873656}).
wandb: WARNING (User provided step: 5052 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721920979.8739395}).
Env Football Algo jrpo Exp base_JRPO updates 9037/100000000000.0 steps in 90.37
total episode rewards is -30.0
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'value_loss': 0.19943905295183262, '_timestamp': 1721921070.2426429}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0860690902452916, '_timestamp': 1721921070.2428126}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5767912282546361, '_timestamp': 1721921070.2428777}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2642184793949127, '_timestamp': 1721921070.2429628}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5047483444213867, '_timestamp': 1721921070.2432578}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'ratio': 0.131952702999115, '_timestamp': 1721921070.2433686}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721921070.243502}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921070.2436485}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.36771321296692, '_timestamp': 1721921070.243818}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921070.244322}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921070.244707}).
wandb: WARNING (User provided step: 9037 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921070.2452807}).
Env Football Algo jrpo Exp base_JRPO updates 5290/100000000000.0 steps in 90.50
total episode rewards is -40.0
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'value_loss': 0.33394616420613604, '_timestamp': 1721921160.7430801}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0555299132472525, '_timestamp': 1721921160.743261}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6903860749801, '_timestamp': 1721921160.7433298}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.070774793624878, '_timestamp': 1721921160.7434354}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.422658771276474, '_timestamp': 1721921160.7437134}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'ratio': 1.0059293508529663, '_timestamp': 1721921160.7438314}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721921160.7439754}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921160.7445107}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.49693369865417, '_timestamp': 1721921160.7445765}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921160.74534}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921160.7459524}).
wandb: WARNING (User provided step: 5290 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921160.7465448}).
Env Football Algo jrpo Exp base_JRPO updates 4154/100000000000.0 steps in 50.40
total episode rewards is -130.0
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'value_loss': 0.8045382051666577, '_timestamp': 1721921211.1540627}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06462822780037338, '_timestamp': 1721921211.1553135}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4814313236872356, '_timestamp': 1721921211.155388}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7105734944343567, '_timestamp': 1721921211.1558685}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.7783937454223633, '_timestamp': 1721921211.1562655}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'ratio': 0.5153960585594177, '_timestamp': 1721921211.1564038}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721921211.1565423}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921211.1573493}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'Episode_Time': 50.40177583694458, '_timestamp': 1721921211.1574116}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921211.1584334}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921211.1587398}).
wandb: WARNING (User provided step: 4154 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921211.1590505}).
Env Football Algo jrpo Exp base_JRPO updates 7156/100000000000.0 steps in 72.28
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'value_loss': 0.526253558807075, '_timestamp': 1721921283.4408147}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04850030955392867, '_timestamp': 1721921283.4409792}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.215203427473704, '_timestamp': 1721921283.4410465}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3562225103378296, '_timestamp': 1721921283.4411407}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0717403888702393, '_timestamp': 1721921283.4413838}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'ratio': 0.3813599646091461, '_timestamp': 1721921283.44149}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721921283.4416728}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921283.4419067}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'Episode_Time': 72.28083610534668, '_timestamp': 1721921283.4419656}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921283.442475}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921283.4428089}).
wandb: WARNING (User provided step: 7156 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921283.4431481}).
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 7540/100000000000.0 steps in 85.94
total episode rewards is -90.0
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'value_loss': 0.5777519034718474, '_timestamp': 1721921369.383802}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'policy_loss': 0.051122692399003425, '_timestamp': 1721921369.3840008}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.116964172522227, '_timestamp': 1721921369.3840735}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4478081464767456, '_timestamp': 1721921369.384166}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0086497068405151, '_timestamp': 1721921369.3845215}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'ratio': 0.534568190574646, '_timestamp': 1721921369.384636}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721921369.3847718}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921369.38487}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.93933463096619, '_timestamp': 1721921369.3849337}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921369.3854752}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921369.385871}).
wandb: WARNING (User provided step: 7540 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921369.3862634}).
Env Football Algo jrpo Exp base_JRPO updates 2739/100000000000.0 steps in 30.14
total episode rewards is -150.0
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'value_loss': 0.9251710501809914, '_timestamp': 1721921399.5259855}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1320993225990484, '_timestamp': 1721921399.5262177}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1629356185595197, '_timestamp': 1721921399.5262892}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.253437340259552, '_timestamp': 1721921399.5264297}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.8384206295013428, '_timestamp': 1721921399.526706}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'ratio': 0.13905425369739532, '_timestamp': 1721921399.526813}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721921399.5269582}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921399.5273035}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'Episode_Time': 30.1387779712677, '_timestamp': 1721921399.5273635}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921399.5276818}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921399.527855}).
wandb: WARNING (User provided step: 2739 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921399.528051}).
Env Football Algo jrpo Exp base_JRPO updates 6124/100000000000.0 steps in 75.46
total episode rewards is -110.0
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'value_loss': 0.6870717247575522, '_timestamp': 1721921474.9900336}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0801138186454773, '_timestamp': 1721921474.9902794}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.278633606036504, '_timestamp': 1721921474.9903486}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2772112488746643, '_timestamp': 1721921474.9904988}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3333669900894165, '_timestamp': 1721921474.990823}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'ratio': 0.276641845703125, '_timestamp': 1721921474.9909332}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721921474.9910684}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921474.9915662}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'Episode_Time': 75.46076679229736, '_timestamp': 1721921474.9916348}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921474.992191}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921474.992523}).
wandb: WARNING (User provided step: 6124 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921474.992858}).
Env Football Algo jrpo Exp base_JRPO updates 4189/100000000000.0 steps in 83.63
total episode rewards is -80.0
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'value_loss': 0.5420210387433568, '_timestamp': 1721921558.6273277}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0895157089169758, '_timestamp': 1721921558.6279056}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.628585181236267, '_timestamp': 1721921558.6281848}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3272944390773773, '_timestamp': 1721921558.62847}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8845751881599426, '_timestamp': 1721921558.6289065}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'ratio': 0.6247674822807312, '_timestamp': 1721921558.6291952}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721921558.6299014}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921558.6301656}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'Episode_Time': 83.63275647163391, '_timestamp': 1721921558.6304028}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921558.6311684}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921558.6318595}).
wandb: WARNING (User provided step: 4189 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921558.6325805}).
Env Football Algo jrpo Exp base_JRPO updates 3222/100000000000.0 steps in 43.38
total episode rewards is -140.0
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'value_loss': 0.8813725885748863, '_timestamp': 1721921602.013916}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08830124325118958, '_timestamp': 1721921602.0140727}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.251208469072978, '_timestamp': 1721921602.014139}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5599663257598877, '_timestamp': 1721921602.014228}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0821789503097534, '_timestamp': 1721921602.01448}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'ratio': 2.614856481552124, '_timestamp': 1721921602.014586}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721921602.0147126}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921602.0149093}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'Episode_Time': 43.38039040565491, '_timestamp': 1721921602.0149698}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921602.0155287}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921602.0157871}).
wandb: WARNING (User provided step: 3222 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921602.0160677}).
Env Football Algo jrpo Exp base_JRPO updates 3713/100000000000.0 steps in 50.65
total episode rewards is -170.0
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'value_loss': 1.0529371833801269, '_timestamp': 1721921652.6650085}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'policy_loss': 0.1350890875980258, '_timestamp': 1721921652.6652355}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8313125594456992, '_timestamp': 1721921652.665306}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22640645503997803, '_timestamp': 1721921652.665407}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.7705070972442627, '_timestamp': 1721921652.6657503}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'ratio': 1.1841778755187988, '_timestamp': 1721921652.6658628}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -170.0, '_timestamp': 1721921652.6662343}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921652.6663308}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'Episode_Time': 50.64793872833252, '_timestamp': 1721921652.6663883}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921652.6669328}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921652.6672785}).
wandb: WARNING (User provided step: 3713 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921652.6676192}).
Env Football Algo jrpo Exp base_JRPO updates 2653/100000000000.0 steps in 48.95
total episode rewards is -190.0
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'value_loss': 1.1408587824304899, '_timestamp': 1721921701.6231117}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'policy_loss': 0.12254263245966285, '_timestamp': 1721921701.6245277}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9501915009816487, '_timestamp': 1721921701.624604}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2949017286300659, '_timestamp': 1721921701.625133}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.982645869255066, '_timestamp': 1721921701.6255178}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'ratio': 0.23476290702819824, '_timestamp': 1721921701.625629}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -190.0, '_timestamp': 1721921701.6258764}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921701.6266832}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'Episode_Time': 48.94898867607117, '_timestamp': 1721921701.626751}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921701.6277344}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921701.638177}).
wandb: WARNING (User provided step: 2653 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921701.6386747}).
Env Football Algo jrpo Exp base_JRPO updates 3177/100000000000.0 steps in 45.22
total episode rewards is -180.0
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'value_loss': 1.0622230474154155, '_timestamp': 1721921746.8578377}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'policy_loss': 0.14376979500055312, '_timestamp': 1721921746.8580348}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2992641631762187, '_timestamp': 1721921746.8581104}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.025359032675623894, '_timestamp': 1721921746.8582096}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.2813823223114014, '_timestamp': 1721921746.858567}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'ratio': 0.06772848963737488, '_timestamp': 1721921746.8587093}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -180.0, '_timestamp': 1721921746.8591294}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921746.859238}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'Episode_Time': 45.21765351295471, '_timestamp': 1721921746.8592963}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921746.859762}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921746.8601649}).
wandb: WARNING (User provided step: 3177 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921746.860489}).
Env Football Algo jrpo Exp base_JRPO updates 2754/100000000000.0 steps in 41.92
total episode rewards is -150.0
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'value_loss': 0.9117702938119571, '_timestamp': 1721921788.7815595}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08729429685607708, '_timestamp': 1721921788.7817585}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3395861140886942, '_timestamp': 1721921788.7818227}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4487725794315338, '_timestamp': 1721921788.781912}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5147384405136108, '_timestamp': 1721921788.7821198}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'ratio': 0.3133155107498169, '_timestamp': 1721921788.782221}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721921788.7823856}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921788.782608}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'Episode_Time': 41.91975116729736, '_timestamp': 1721921788.7826679}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721921788.7830844}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721921788.7833343}).
wandb: WARNING (User provided step: 2754 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721921788.7835882}).
Env Football Algo jrpo Exp base_JRPO updates 4282/100000000000.0 steps in 67.95
total episode rewards is -90.0
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'value_loss': 0.8190259693066279, '_timestamp': 1721921856.7315578}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'policy_loss': 0.11675111674703657, '_timestamp': 1721921856.731924}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4089228773117066, '_timestamp': 1721921856.7320027}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.18640482425689697, '_timestamp': 1721921856.7321384}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.36940336227417, '_timestamp': 1721921856.7324233}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'ratio': 0.17409534752368927, '_timestamp': 1721921856.7325256}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721921856.7328207}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921856.7329586}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'Episode_Time': 67.94682693481445, '_timestamp': 1721921856.7330167}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.454293079516161, '_timestamp': 1721921856.7336504}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'train_goal': 0.7271465397580805, '_timestamp': 1721921856.7339842}).
wandb: WARNING (User provided step: 4282 is less than current step: 14326. Dropping entry: {'train_WDL': 0.454293079516161, '_timestamp': 1721921856.7343147}).
Env Football Algo jrpo Exp base_JRPO updates 4856/100000000000.0 steps in 94.80
total episode rewards is 0.0
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'value_loss': 0.31613657612974444, '_timestamp': 1721921951.5362651}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07583341361954808, '_timestamp': 1721921951.5364308}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6538939356803894, '_timestamp': 1721921951.5364947}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7213746309280396, '_timestamp': 1721921951.5365858}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.29357925057411194, '_timestamp': 1721921951.536846}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'ratio': 0.9484145045280457, '_timestamp': 1721921951.5369468}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721921951.5372639}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721921951.5373561}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.80091881752014, '_timestamp': 1721921951.537412}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.17152996845425866, '_timestamp': 1721921951.538131}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'train_goal': 0.5857649842271293, '_timestamp': 1721921951.538708}).
wandb: WARNING (User provided step: 4856 is less than current step: 14326. Dropping entry: {'train_WDL': 0.17152996845425866, '_timestamp': 1721921951.5392902}).
Env Football Algo jrpo Exp base_JRPO updates 3300/100000000000.0 steps in 54.10
total episode rewards is -110.0
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'value_loss': 0.7652412395427625, '_timestamp': 1721922005.6414654}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'policy_loss': 0.07061347294676427, '_timestamp': 1721922005.6416225}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4756279643376669, '_timestamp': 1721922005.641688}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5447421073913574, '_timestamp': 1721922005.641776}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.084389567375183, '_timestamp': 1721922005.6420476}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'ratio': 0.5578054189682007, '_timestamp': 1721922005.642148}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721922005.6424046}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922005.6424954}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'Episode_Time': 54.10118508338928, '_timestamp': 1721922005.642552}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3786030061892131, '_timestamp': 1721922005.6430352}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'train_goal': 0.3106984969053935, '_timestamp': 1721922005.643401}).
wandb: WARNING (User provided step: 3300 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3786030061892131, '_timestamp': 1721922005.6437705}).
Env Football Algo jrpo Exp base_JRPO updates 2987/100000000000.0 steps in 45.10
total episode rewards is -70.0
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'value_loss': 0.7780483577152093, '_timestamp': 1721922050.7477543}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05639731562579982, '_timestamp': 1721922050.7480462}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3505269742012025, '_timestamp': 1721922050.7481177}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4684443175792694, '_timestamp': 1721922050.7482495}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.2431378364562988, '_timestamp': 1721922050.748548}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'ratio': 0.2777830958366394, '_timestamp': 1721922050.7486546}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721922050.7492838}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922050.7493818}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'Episode_Time': 45.10293245315552, '_timestamp': 1721922050.7494404}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3702696017808558, '_timestamp': 1721922050.7501113}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'train_goal': 0.6851348008904279, '_timestamp': 1721922050.750444}).
wandb: WARNING (User provided step: 2987 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3702696017808558, '_timestamp': 1721922050.7507339}).
Env Football Algo jrpo Exp base_JRPO updates 1811/100000000000.0 steps in 48.48
total episode rewards is 10.0
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'value_loss': 1.2018666872382164, '_timestamp': 1721922099.2333255}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'policy_loss': 0.025627715473917, '_timestamp': 1721922099.2335064}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.317889846165975, '_timestamp': 1721922099.23357}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.141510248184204, '_timestamp': 1721922099.2336626}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.856398105621338, '_timestamp': 1721922099.2339082}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'ratio': 0.804050087928772, '_timestamp': 1721922099.2340117}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721922099.2342863}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922099.2343786}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'Episode_Time': 48.481276512145996, '_timestamp': 1721922099.2344327}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.5629750271444083, '_timestamp': 1721922099.2348392}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'train_goal': 0.7814875135722041, '_timestamp': 1721922099.2351153}).
wandb: WARNING (User provided step: 1811 is less than current step: 14326. Dropping entry: {'train_WDL': 0.5629750271444083, '_timestamp': 1721922099.2353828}).
Env Football Algo jrpo Exp base_JRPO updates 7209/100000000000.0 steps in 79.59
total episode rewards is 20.0
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'value_loss': 0.27195506358752025, '_timestamp': 1721922178.8262432}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03136287029250525, '_timestamp': 1721922178.8264186}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3147495484352112, '_timestamp': 1721922178.8264859}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.0897296667099, '_timestamp': 1721922178.8265784}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5014452338218689, '_timestamp': 1721922178.826839}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'ratio': 0.9811458587646484, '_timestamp': 1721922178.8269453}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721922178.8271985}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922178.8274052}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'Episode_Time': 79.58988118171692, '_timestamp': 1721922178.8274627}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.7969451931716083, '_timestamp': 1721922178.8283825}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'train_goal': 0.8984725965858041, '_timestamp': 1721922178.8288531}).
wandb: WARNING (User provided step: 7209 is less than current step: 14326. Dropping entry: {'train_WDL': 0.7969451931716083, '_timestamp': 1721922178.829311}).
Env Football Algo jrpo Exp base_JRPO updates 3752/100000000000.0 steps in 69.33
total episode rewards is -50.0
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'value_loss': 0.4361942971404642, '_timestamp': 1721922248.164026}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'policy_loss': 0.018666999339572308, '_timestamp': 1721922248.1642864}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.240039427280426, '_timestamp': 1721922248.16436}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.106109619140625, '_timestamp': 1721922248.1644962}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8498833179473877, '_timestamp': 1721922248.1647716}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'ratio': 1.0005218982696533, '_timestamp': 1721922248.164879}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721922248.1654983}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922248.165596}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'Episode_Time': 69.33362627029419, '_timestamp': 1721922248.165655}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.41496173668592845, '_timestamp': 1721922248.1665275}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'train_goal': 0.29251913165703575, '_timestamp': 1721922248.1669772}).
wandb: WARNING (User provided step: 3752 is less than current step: 14326. Dropping entry: {'train_WDL': -0.41496173668592845, '_timestamp': 1721922248.1673932}).
Env Football Algo jrpo Exp base_JRPO updates 3980/100000000000.0 steps in 85.30
total episode rewards is 20.0
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'value_loss': 0.26839082552314114, '_timestamp': 1721922333.4763236}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03110622850401948, '_timestamp': 1721922333.47766}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2652037930488587, '_timestamp': 1721922333.477738}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8674535155296326, '_timestamp': 1721922333.4782376}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.24162918329238892, '_timestamp': 1721922333.4786246}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'ratio': 0.9110389351844788, '_timestamp': 1721922333.4787526}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721922333.4788866}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922333.4798117}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.3030834197998, '_timestamp': 1721922333.4798763}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6228675136116153, '_timestamp': 1721922333.481312}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'train_goal': 0.8114337568058076, '_timestamp': 1721922333.4819818}).
wandb: WARNING (User provided step: 3980 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6228675136116153, '_timestamp': 1721922333.4826212}).
Env Football Algo jrpo Exp base_JRPO updates 1595/100000000000.0 steps in 31.04
total episode rewards is -20.0
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'value_loss': 0.8509744275982182, '_timestamp': 1721922364.5214748}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02155457827883462, '_timestamp': 1721922364.5216515}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2426559535662334, '_timestamp': 1721922364.5217192}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.242046594619751, '_timestamp': 1721922364.521817}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3459635972976685, '_timestamp': 1721922364.5221589}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'ratio': 0.9735321402549744, '_timestamp': 1721922364.5222688}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922364.5224137}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922364.5225482}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'Episode_Time': 31.03731369972229, '_timestamp': 1721922364.5229912}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.718796992481203, '_timestamp': 1721922364.5233614}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'train_goal': 0.8593984962406015, '_timestamp': 1721922364.5235195}).
wandb: WARNING (User provided step: 1595 is less than current step: 14326. Dropping entry: {'train_WDL': 0.718796992481203, '_timestamp': 1721922364.5236688}).
Env Football Algo jrpo Exp base_JRPO updates 6600/100000000000.0 steps in 89.91
total episode rewards is -20.0
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'value_loss': 0.32064167006096495, '_timestamp': 1721922454.431248}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'policy_loss': 0.015228253829506381, '_timestamp': 1721922454.4315126}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.359483126004537, '_timestamp': 1721922454.4315994}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.46542471647262573, '_timestamp': 1721922454.4317503}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.668800950050354, '_timestamp': 1721922454.433388}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'ratio': 0.8998509645462036, '_timestamp': 1721922454.4335213}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922454.433954}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922454.4340906}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.905846118927, '_timestamp': 1721922454.4341505}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3692857142857143, '_timestamp': 1721922454.4350595}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'train_goal': 0.31535714285714284, '_timestamp': 1721922454.4355574}).
wandb: WARNING (User provided step: 6600 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3692857142857143, '_timestamp': 1721922454.4360778}).
Env Football Algo jrpo Exp base_JRPO updates 3567/100000000000.0 steps in 65.19
total episode rewards is -30.0
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'value_loss': 0.6704374567667644, '_timestamp': 1721922519.636998}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02829210856502565, '_timestamp': 1721922519.6382954}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3607940471172333, '_timestamp': 1721922519.6383712}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7524623870849609, '_timestamp': 1721922519.6388853}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.2310928106307983, '_timestamp': 1721922519.6392577}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'ratio': 0.9011073112487793, '_timestamp': 1721922519.6393635}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721922519.6395037}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922519.6403267}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'Episode_Time': 65.1945378780365, '_timestamp': 1721922519.6403892}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.18587515640205757, '_timestamp': 1721922519.6415117}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'train_goal': 0.5929375782010288, '_timestamp': 1721922519.6420226}).
wandb: WARNING (User provided step: 3567 is less than current step: 14326. Dropping entry: {'train_WDL': 0.18587515640205757, '_timestamp': 1721922519.6424687}).
Env Football Algo jrpo Exp base_JRPO updates 2827/100000000000.0 steps in 29.11
total episode rewards is -20.0
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'value_loss': 1.1488916982710362, '_timestamp': 1721922548.750071}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08640038305893541, '_timestamp': 1721922548.7502449}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9027969352404277, '_timestamp': 1721922548.750311}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6294877529144287, '_timestamp': 1721922548.7504044}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.8460277318954468, '_timestamp': 1721922548.7506661}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'ratio': 0.741737961769104, '_timestamp': 1721922548.7507682}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922548.7510996}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922548.7511988}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'Episode_Time': 29.10655975341797, '_timestamp': 1721922548.7512581}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.20176730486008837, '_timestamp': 1721922548.7515793}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'train_goal': 0.6008836524300442, '_timestamp': 1721922548.7517405}).
wandb: WARNING (User provided step: 2827 is less than current step: 14326. Dropping entry: {'train_WDL': 0.20176730486008837, '_timestamp': 1721922548.7519264}).
Env Football Algo jrpo Exp base_JRPO updates 4918/100000000000.0 steps in 87.54
total episode rewards is 0.0
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'value_loss': 0.2433710365810354, '_timestamp': 1721922636.291665}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'policy_loss': 0.015602737930603326, '_timestamp': 1721922636.29182}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8399444456895192, '_timestamp': 1721922636.2918851}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.13301043212413788, '_timestamp': 1721922636.291988}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3673596680164337, '_timestamp': 1721922636.292225}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'ratio': 0.7238728404045105, '_timestamp': 1721922636.2923272}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721922636.292456}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922636.292632}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.5388662815094, '_timestamp': 1721922636.2926896}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.18250347153342591, '_timestamp': 1721922636.293458}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'train_goal': 0.591251735766713, '_timestamp': 1721922636.2940285}).
wandb: WARNING (User provided step: 4918 is less than current step: 14326. Dropping entry: {'train_WDL': 0.18250347153342591, '_timestamp': 1721922636.2946038}).
Env Football Algo jrpo Exp base_JRPO updates 8071/100000000000.0 steps in 85.94
total episode rewards is -20.0
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'value_loss': 0.3025176441390067, '_timestamp': 1721922722.2401972}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'policy_loss': 0.015032778492507835, '_timestamp': 1721922722.2403927}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1602327990531922, '_timestamp': 1721922722.2404587}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.15382595360279083, '_timestamp': 1721922722.2405481}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5517324805259705, '_timestamp': 1721922722.240794}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'ratio': 0.7996176481246948, '_timestamp': 1721922722.2408955}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922722.2411435}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922722.2412355}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.94478178024292, '_timestamp': 1721922722.241293}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.20479145619858566, '_timestamp': 1721922722.2421298}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'train_goal': 0.3976042719007072, '_timestamp': 1721922722.2425559}).
wandb: WARNING (User provided step: 8071 is less than current step: 14326. Dropping entry: {'train_WDL': -0.20479145619858566, '_timestamp': 1721922722.242985}).
Env Football Algo jrpo Exp base_JRPO updates 5764/100000000000.0 steps in 86.71
total episode rewards is -20.0
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'value_loss': 0.2606005612520191, '_timestamp': 1721922808.953481}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'policy_loss': 0.012767511496397977, '_timestamp': 1721922808.9536438}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.29871440410614, '_timestamp': 1721922808.953708}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.28324204683303833, '_timestamp': 1721922808.953799}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3724685311317444, '_timestamp': 1721922808.9540513}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'ratio': 0.7061104774475098, '_timestamp': 1721922808.9541543}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721922808.954411}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922808.954504}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.70963287353516, '_timestamp': 1721922808.9545612}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.42659159809441316, '_timestamp': 1721922808.955216}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'train_goal': 0.2867042009527934, '_timestamp': 1721922808.9557478}).
wandb: WARNING (User provided step: 5764 is less than current step: 14326. Dropping entry: {'train_WDL': -0.42659159809441316, '_timestamp': 1721922808.9563277}).
Env Football Algo jrpo Exp base_JRPO updates 5711/100000000000.0 steps in 86.73
total episode rewards is 10.0
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'value_loss': 0.30622209403353434, '_timestamp': 1721922895.6923792}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'policy_loss': -0.010004469819056491, '_timestamp': 1721922895.6925573}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4199156002203623, '_timestamp': 1721922895.6926227}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.21296830475330353, '_timestamp': 1721922895.6927195}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6093488931655884, '_timestamp': 1721922895.692979}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'ratio': 0.5563198328018188, '_timestamp': 1721922895.6932368}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721922895.6933756}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922895.6934679}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.73493075370789, '_timestamp': 1721922895.6935272}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.492937514962892, '_timestamp': 1721922895.6942177}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'train_goal': 0.746468757481446, '_timestamp': 1721922895.694712}).
wandb: WARNING (User provided step: 5711 is less than current step: 14326. Dropping entry: {'train_WDL': 0.492937514962892, '_timestamp': 1721922895.6952114}).
Env Football Algo jrpo Exp base_JRPO updates 9533/100000000000.0 steps in 86.11
total episode rewards is 10.0
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'value_loss': 0.18565046602045185, '_timestamp': 1721922981.8071253}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0005876789979326228, '_timestamp': 1721922981.807303}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4887051677703858, '_timestamp': 1721922981.80737}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.17449860274791718, '_timestamp': 1721922981.8074634}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4740152060985565, '_timestamp': 1721922981.807724}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'ratio': 0.6680231094360352, '_timestamp': 1721922981.807838}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721922981.8080077}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721922981.8082085}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.11090564727783, '_timestamp': 1721922981.808267}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3305286263032742, '_timestamp': 1721922981.8087816}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'train_goal': 0.6652643131516371, '_timestamp': 1721922981.8091533}).
wandb: WARNING (User provided step: 9533 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3305286263032742, '_timestamp': 1721922981.8095152}).
Env Football Algo jrpo Exp base_JRPO updates 8949/100000000000.0 steps in 85.78
total episode rewards is 0.0
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'value_loss': 0.23732182671393579, '_timestamp': 1721923067.5878608}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0003479191669127128, '_timestamp': 1721923067.5881195}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5773282678922018, '_timestamp': 1721923067.588195}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14605508744716644, '_timestamp': 1721923067.588335}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4491966962814331, '_timestamp': 1721923067.588597}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'ratio': 0.7767903208732605, '_timestamp': 1721923067.5891924}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721923067.5893302}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923067.5894246}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.77731323242188, '_timestamp': 1721923067.589481}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.26590646174186083, '_timestamp': 1721923067.5901732}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'train_goal': 0.6329532308709305, '_timestamp': 1721923067.5905652}).
wandb: WARNING (User provided step: 8949 is less than current step: 14326. Dropping entry: {'train_WDL': 0.26590646174186083, '_timestamp': 1721923067.5909543}).
Env Football Algo jrpo Exp base_JRPO updates 6118/100000000000.0 steps in 92.90
total episode rewards is 0.0
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'value_loss': 0.2403004233991184, '_timestamp': 1721923160.4913473}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'policy_loss': 0.006048986338234196, '_timestamp': 1721923160.4915545}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9177612050374349, '_timestamp': 1721923160.4916205}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.19528338313102722, '_timestamp': 1721923160.4917486}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1893462985754013, '_timestamp': 1721923160.4920151}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'ratio': 0.7224540114402771, '_timestamp': 1721923160.4921181}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721923160.4922552}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923160.4925125}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.89917826652527, '_timestamp': 1721923160.49257}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3321324026120243, '_timestamp': 1721923160.4932406}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'train_goal': 0.6660662013060121, '_timestamp': 1721923160.4937553}).
wandb: WARNING (User provided step: 6118 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3321324026120243, '_timestamp': 1721923160.4942718}).
Env Football Algo jrpo Exp base_JRPO updates 8518/100000000000.0 steps in 80.13
total episode rewards is 0.0
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'value_loss': 0.2885380537303475, '_timestamp': 1721923240.6236527}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'policy_loss': 0.00047789051726188824, '_timestamp': 1721923240.6238065}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3355532232920329, '_timestamp': 1721923240.623873}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14582768082618713, '_timestamp': 1721923240.6239717}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4382346272468567, '_timestamp': 1721923240.6243503}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'ratio': 0.7375684976577759, '_timestamp': 1721923240.6244557}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721923240.6245854}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923240.6246727}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'Episode_Time': 80.12824940681458, '_timestamp': 1721923240.6247292}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.30576982412835546, '_timestamp': 1721923240.6252613}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'train_goal': 0.6528849120641778, '_timestamp': 1721923240.6306527}).
wandb: WARNING (User provided step: 8518 is less than current step: 14326. Dropping entry: {'train_WDL': 0.30576982412835546, '_timestamp': 1721923240.6311991}).
Env Football Algo jrpo Exp base_JRPO updates 11263/100000000000.0 steps in 90.98
total episode rewards is -10.0
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'value_loss': 0.19616632964772482, '_timestamp': 1721923331.612921}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0024225513086033362, '_timestamp': 1721923331.6131475}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8129632266362509, '_timestamp': 1721923331.6132202}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.10961596667766571, '_timestamp': 1721923331.6133204}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.15508536994457245, '_timestamp': 1721923331.613587}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'ratio': 0.8772001266479492, '_timestamp': 1721923331.6136959}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721923331.6138377}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923331.6143322}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.98068976402283, '_timestamp': 1721923331.614396}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.535991436981536, '_timestamp': 1721923331.6149538}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'train_goal': 0.767995718490768, '_timestamp': 1721923331.6152344}).
wandb: WARNING (User provided step: 11263 is less than current step: 14326. Dropping entry: {'train_WDL': 0.535991436981536, '_timestamp': 1721923331.6155102}).
Env Football Algo jrpo Exp base_JRPO updates 4746/100000000000.0 steps in 51.25
total episode rewards is -40.0
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'value_loss': 0.483668511758248, '_timestamp': 1721923382.8713098}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'policy_loss': 0.007876815490890294, '_timestamp': 1721923382.8726046}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8187846863269805, '_timestamp': 1721923382.872679}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07107603549957275, '_timestamp': 1721923382.8731823}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1537106037139893, '_timestamp': 1721923382.873526}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'ratio': 0.763651430606842, '_timestamp': 1721923382.8736324}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923382.8742516}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923382.8744595}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'Episode_Time': 51.25004005432129, '_timestamp': 1721923382.87452}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2222753346080306, '_timestamp': 1721923382.8753335}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'train_goal': 0.6111376673040153, '_timestamp': 1721923382.8756402}).
wandb: WARNING (User provided step: 4746 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2222753346080306, '_timestamp': 1721923382.8759327}).
Env Football Algo jrpo Exp base_JRPO updates 7577/100000000000.0 steps in 92.13
total episode rewards is -40.0
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'value_loss': 0.2516438857879257, '_timestamp': 1721923475.0068808}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04762981520111983, '_timestamp': 1721923475.0070498}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4503027494748433, '_timestamp': 1721923475.0071182}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.1121852770447731, '_timestamp': 1721923475.0072126}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.27217844128608704, '_timestamp': 1721923475.0074694}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'ratio': 0.5008220672607422, '_timestamp': 1721923475.0075781}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721923475.0077043}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923475.008017}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.13010168075562, '_timestamp': 1721923475.0080786}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721923475.0086298}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721923475.0090806}).
wandb: WARNING (User provided step: 7577 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721923475.009539}).
Env Football Algo jrpo Exp base_JRPO updates 5856/100000000000.0 steps in 77.47
total episode rewards is -20.0
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'value_loss': 0.3627489368850365, '_timestamp': 1721923552.4815054}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01827448280683408, '_timestamp': 1721923552.481779}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1760994406541188, '_timestamp': 1721923552.4818497}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.06652054935693741, '_timestamp': 1721923552.482032}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8085113763809204, '_timestamp': 1721923552.482307}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'ratio': 0.5868707299232483, '_timestamp': 1721923552.4824154}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721923552.4825506}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923552.4829304}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'Episode_Time': 77.47058296203613, '_timestamp': 1721923552.4829907}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.17301155676410604, '_timestamp': 1721923552.4838781}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'train_goal': 0.586505778382053, '_timestamp': 1721923552.4844787}).
wandb: WARNING (User provided step: 5856 is less than current step: 14326. Dropping entry: {'train_WDL': 0.17301155676410604, '_timestamp': 1721923552.485046}).
Env Football Algo jrpo Exp base_JRPO updates 2928/100000000000.0 steps in 58.48
total episode rewards is -60.0
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'value_loss': 0.6047906577959656, '_timestamp': 1721923610.9625332}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'policy_loss': 0.054335295103179915, '_timestamp': 1721923610.9627056}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4367529527346292, '_timestamp': 1721923610.9627738}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.24536746740341187, '_timestamp': 1721923610.9628685}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3794834613800049, '_timestamp': 1721923610.9631264}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'ratio': 0.5156632661819458, '_timestamp': 1721923610.9632359}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721923610.963607}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923610.9637022}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'Episode_Time': 58.47657489776611, '_timestamp': 1721923610.9637582}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.12069206083437979, '_timestamp': 1721923610.9644477}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'train_goal': 0.5603460304171899, '_timestamp': 1721923610.9649}).
wandb: WARNING (User provided step: 2928 is less than current step: 14326. Dropping entry: {'train_WDL': 0.12069206083437979, '_timestamp': 1721923610.9653463}).
Env Football Algo jrpo Exp base_JRPO updates 9387/100000000000.0 steps in 95.11
total episode rewards is 10.0
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'value_loss': 0.2124590087410373, '_timestamp': 1721923706.0786033}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'policy_loss': 0.023523499299772085, '_timestamp': 1721923706.0788057}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1878495844205221, '_timestamp': 1721923706.078875}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.21620623767375946, '_timestamp': 1721923706.0789702}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3382491171360016, '_timestamp': 1721923706.0792155}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'ratio': 0.8037613034248352, '_timestamp': 1721923706.0795636}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721923706.079707}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923706.0798008}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'Episode_Time': 95.11222887039185, '_timestamp': 1721923706.079859}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.7270621770889008, '_timestamp': 1721923706.0806503}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'train_goal': 0.8635310885444504, '_timestamp': 1721923706.0810728}).
wandb: WARNING (User provided step: 9387 is less than current step: 14326. Dropping entry: {'train_WDL': 0.7270621770889008, '_timestamp': 1721923706.081486}).
Env Football Algo jrpo Exp base_JRPO updates 3250/100000000000.0 steps in 51.65
total episode rewards is -20.0
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'value_loss': 0.7288196895364671, '_timestamp': 1721923757.73747}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'policy_loss': 0.042581370699917895, '_timestamp': 1721923757.737686}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0294038053353627, '_timestamp': 1721923757.7377548}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.17833387851715088, '_timestamp': 1721923757.7378554}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5638024806976318, '_timestamp': 1721923757.7381349}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'ratio': 0.5796207785606384, '_timestamp': 1721923757.7382405}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721923757.7388031}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923757.7389028}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'Episode_Time': 51.654813289642334, '_timestamp': 1721923757.7389593}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.4216, '_timestamp': 1721923757.73986}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'train_goal': 0.7108, '_timestamp': 1721923757.740371}).
wandb: WARNING (User provided step: 3250 is less than current step: 14326. Dropping entry: {'train_WDL': 0.4216, '_timestamp': 1721923757.7407124}).
Env Football Algo jrpo Exp base_JRPO updates 11250/100000000000.0 steps in 92.99
total episode rewards is 0.0
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'value_loss': 0.1217426004509131, '_timestamp': 1721923850.735802}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02659835760947317, '_timestamp': 1721923850.7372398}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8495550370216369, '_timestamp': 1721923850.7373133}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.09863074123859406, '_timestamp': 1721923850.7378592}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4320911169052124, '_timestamp': 1721923850.738248}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'ratio': 0.7440493702888489, '_timestamp': 1721923850.7383575}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721923850.7391927}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923850.739406}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.9883861541748, '_timestamp': 1721923850.739466}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.42133333333333334, '_timestamp': 1721923850.740641}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'train_goal': 0.28933333333333333, '_timestamp': 1721923850.7409587}).
wandb: WARNING (User provided step: 11250 is less than current step: 14326. Dropping entry: {'train_WDL': -0.42133333333333334, '_timestamp': 1721923850.7412703}).
Env Football Algo jrpo Exp base_JRPO updates 7292/100000000000.0 steps in 63.93
total episode rewards is 10.0
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'value_loss': 0.29943193345835123, '_timestamp': 1721923914.6723}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0002035018764824296, '_timestamp': 1721923914.67247}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5931364218393962, '_timestamp': 1721923914.6725352}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.17696908116340637, '_timestamp': 1721923914.6726265}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3686883747577667, '_timestamp': 1721923914.6728907}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'ratio': 0.8187626600265503, '_timestamp': 1721923914.6729922}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721923914.6732252}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923914.6733184}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'Episode_Time': 63.928123235702515, '_timestamp': 1721923914.6733744}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.7826797385620915, '_timestamp': 1721923914.6737843}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'train_goal': 0.8913398692810458, '_timestamp': 1721923914.6739993}).
wandb: WARNING (User provided step: 7292 is less than current step: 14326. Dropping entry: {'train_WDL': 0.7826797385620915, '_timestamp': 1721923914.674199}).
Env Football Algo jrpo Exp base_JRPO updates 1900/100000000000.0 steps in 43.52
total episode rewards is 50.0
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'value_loss': 0.6690471158300837, '_timestamp': 1721923958.1949139}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'policy_loss': -0.001649500752981415, '_timestamp': 1721923958.195095}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.8549210639794668, '_timestamp': 1721923958.195166}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2423277348279953, '_timestamp': 1721923958.1952639}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3552533388137817, '_timestamp': 1721923958.1955194}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'ratio': 0.7281482219696045, '_timestamp': 1721923958.1957493}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 50.0, '_timestamp': 1721923958.195882}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721923958.1959994}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'Episode_Time': 43.519909620285034, '_timestamp': 1721923958.1960638}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.525398773006135, '_timestamp': 1721923958.1965177}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'train_goal': 0.7626993865030675, '_timestamp': 1721923958.1968477}).
wandb: WARNING (User provided step: 1900 is less than current step: 14326. Dropping entry: {'train_WDL': 0.525398773006135, '_timestamp': 1721923958.1971307}).
Env Football Algo jrpo Exp base_JRPO updates 5733/100000000000.0 steps in 85.63
total episode rewards is 0.0
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'value_loss': 0.2668062944135939, '_timestamp': 1721924043.8239958}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'policy_loss': 0.00317376828713653, '_timestamp': 1721924043.8241718}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8256429481506347, '_timestamp': 1721924043.8242388}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.1782873123884201, '_timestamp': 1721924043.8243315}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.43297892808914185, '_timestamp': 1721924043.8245938}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'ratio': 0.3856763243675232, '_timestamp': 1721924043.8249335}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721924043.825071}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924043.8251662}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.62589263916016, '_timestamp': 1721924043.8252254}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.05600517966979605, '_timestamp': 1721924043.8259103}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'train_goal': 0.528002589834898, '_timestamp': 1721924043.8264427}).
wandb: WARNING (User provided step: 5733 is less than current step: 14326. Dropping entry: {'train_WDL': 0.05600517966979605, '_timestamp': 1721924043.8269868}).
Env Football Algo jrpo Exp base_JRPO updates 6743/100000000000.0 steps in 90.37
total episode rewards is -10.0
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'value_loss': 0.20205800335272214, '_timestamp': 1721924134.2006578}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'policy_loss': 0.017684097269860408, '_timestamp': 1721924134.2008588}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6444962986310323, '_timestamp': 1721924134.2009275}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07429379224777222, '_timestamp': 1721924134.2010465}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2192172110080719, '_timestamp': 1721924134.201286}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'ratio': 0.4373440146446228, '_timestamp': 1721924134.2013893}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721924134.2016728}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924134.2017653}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.37273931503296, '_timestamp': 1721924134.2018223}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.28061039118323844, '_timestamp': 1721924134.2024558}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'train_goal': 0.35969480440838075, '_timestamp': 1721924134.202951}).
wandb: WARNING (User provided step: 6743 is less than current step: 14326. Dropping entry: {'train_WDL': -0.28061039118323844, '_timestamp': 1721924134.2034638}).
Env Football Algo jrpo Exp base_JRPO updates 9943/100000000000.0 steps in 90.36
total episode rewards is -10.0
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'value_loss': 0.18474497004974788, '_timestamp': 1721924224.568141}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'policy_loss': 0.009985901494316446, '_timestamp': 1721924224.5695632}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.041492174466451, '_timestamp': 1721924224.5696387}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05178699269890785, '_timestamp': 1721924224.5701628}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2580799162387848, '_timestamp': 1721924224.570554}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'ratio': 0.6568455100059509, '_timestamp': 1721924224.5711954}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721924224.5713418}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924224.5715697}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.35857462882996, '_timestamp': 1721924224.5716276}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.34743919319754796, '_timestamp': 1721924224.5729184}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'train_goal': 0.32628040340122605, '_timestamp': 1721924224.5734205}).
wandb: WARNING (User provided step: 9943 is less than current step: 14326. Dropping entry: {'train_WDL': -0.34743919319754796, '_timestamp': 1721924224.573851}).
Env Football Algo jrpo Exp base_JRPO updates 9426/100000000000.0 steps in 86.95
total episode rewards is 10.0
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'value_loss': 0.1814117185130211, '_timestamp': 1721924311.522615}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'policy_loss': 0.010120340885284046, '_timestamp': 1721924311.522805}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1394289855162303, '_timestamp': 1721924311.5228775}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.041640281677246094, '_timestamp': 1721924311.522979}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.31188055872917175, '_timestamp': 1721924311.5232575}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'ratio': 0.6188649535179138, '_timestamp': 1721924311.5240624}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721924311.5242274}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924311.5243285}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.94770646095276, '_timestamp': 1721924311.5243886}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.013634732687477575, '_timestamp': 1721924311.5249212}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'train_goal': 0.5068173663437388, '_timestamp': 1721924311.5253808}).
wandb: WARNING (User provided step: 9426 is less than current step: 14326. Dropping entry: {'train_WDL': 0.013634732687477575, '_timestamp': 1721924311.5257597}).
Env Football Algo jrpo Exp base_JRPO updates 7324/100000000000.0 steps in 93.41
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'value_loss': 0.2830208177375607, '_timestamp': 1721924404.942074}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'policy_loss': -8.404527208767831e-05, '_timestamp': 1721924404.9431906}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5392385983467103, '_timestamp': 1721924404.9432669}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.02533879317343235, '_timestamp': 1721924404.9436884}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5697519779205322, '_timestamp': 1721924404.9589405}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'ratio': 0.48668530583381653, '_timestamp': 1721924404.9591992}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721924404.959347}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924404.9596016}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.41091442108154, '_timestamp': 1721924404.9596643}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.37076602397081815, '_timestamp': 1721924404.9607432}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'train_goal': 0.6853830119854091, '_timestamp': 1721924404.961211}).
wandb: WARNING (User provided step: 7324 is less than current step: 14326. Dropping entry: {'train_WDL': 0.37076602397081815, '_timestamp': 1721924404.9616778}).
total episode rewards is 0.0
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'value_loss': 0.5409850265892844, '_timestamp': 1721924483.5279086}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'policy_loss': -0.011845734557524945, '_timestamp': 1721924483.5280962}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.144396108786265, '_timestamp': 1721924483.5281627}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.03465140983462334, '_timestamp': 1721924483.5282524}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9029651284217834, '_timestamp': 1721924483.5285044}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'ratio': 0.6004604697227478, '_timestamp': 1721924483.528721}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721924483.5288563}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924483.5289469}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'Episode_Time': 78.56546926498413, '_timestamp': 1721924483.5290034}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2024669603524229, '_timestamp': 1721924483.5295033}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'train_goal': 0.6012334801762115, '_timestamp': 1721924483.5298662}).
wandb: WARNING (User provided step: 7490 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2024669603524229, '_timestamp': 1721924483.5302298}).
Env Football Algo jrpo Exp base_JRPO updates 7490/100000000000.0 steps in 78.57
total episode rewards is 30.0
Env Football Algo jrpo Exp base_JRPO updates 5129/100000000000.0 steps in 87.65
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'value_loss': 0.23083370143470044, '_timestamp': 1721924571.1837337}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'policy_loss': -0.001636033111423482, '_timestamp': 1721924571.1839032}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9322290023167927, '_timestamp': 1721924571.1839752}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07754004746675491, '_timestamp': 1721924571.1840675}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1953689604997635, '_timestamp': 1721924571.1843054}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'ratio': 0.40402743220329285, '_timestamp': 1721924571.184408}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721924571.1846297}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924571.1847212}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.65229320526123, '_timestamp': 1721924571.1847782}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.12085908215986223, '_timestamp': 1721924571.1854784}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'train_goal': 0.5604295410799311, '_timestamp': 1721924571.1860497}).
wandb: WARNING (User provided step: 5129 is less than current step: 14326. Dropping entry: {'train_WDL': 0.12085908215986223, '_timestamp': 1721924571.186613}).
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 6829/100000000000.0 steps in 87.01
total episode rewards is -20.0
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'value_loss': 0.22775811579893343, '_timestamp': 1721924658.1945827}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0020850690671553214, '_timestamp': 1721924658.1948175}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6124739082654318, '_timestamp': 1721924658.1948915}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.059923216700553894, '_timestamp': 1721924658.1950295}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1377774327993393, '_timestamp': 1721924658.1953063}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'ratio': 0.4912143647670746, '_timestamp': 1721924658.195417}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721924658.1961164}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924658.1962175}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.00696063041687, '_timestamp': 1721924658.1962783}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.26814343409619384, '_timestamp': 1721924658.1970322}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'train_goal': 0.36592828295190305, '_timestamp': 1721924658.19754}).
wandb: WARNING (User provided step: 6829 is less than current step: 14326. Dropping entry: {'train_WDL': -0.26814343409619384, '_timestamp': 1721924658.1980581}).
Env Football Algo jrpo Exp base_JRPO updates 4341/100000000000.0 steps in 86.11
total episode rewards is -10.0
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'value_loss': 0.3524522417892392, '_timestamp': 1721924744.312136}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'policy_loss': -0.010202674535491193, '_timestamp': 1721924744.312562}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9841026878356933, '_timestamp': 1721924744.3126361}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0739375427365303, '_timestamp': 1721924744.3128443}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4880749583244324, '_timestamp': 1721924744.3131502}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'ratio': 0.37940096855163574, '_timestamp': 1721924744.3132713}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721924744.313416}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924744.314125}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.10610914230347, '_timestamp': 1721924744.3141868}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.12248737498762254, '_timestamp': 1721924744.3151445}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'train_goal': 0.5612436874938113, '_timestamp': 1721924744.3157587}).
wandb: WARNING (User provided step: 4341 is less than current step: 14326. Dropping entry: {'train_WDL': 0.12248737498762254, '_timestamp': 1721924744.316391}).
Env Football Algo jrpo Exp base_JRPO updates 6854/100000000000.0 steps in 91.59
total episode rewards is 10.0
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'value_loss': 0.20450344522794087, '_timestamp': 1721924835.906366}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'policy_loss': -0.013237591872845466, '_timestamp': 1721924835.9065847}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6007761295636496, '_timestamp': 1721924835.906659}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.08220268785953522, '_timestamp': 1721924835.9067984}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1972644180059433, '_timestamp': 1721924835.9070232}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'ratio': 0.543168306350708, '_timestamp': 1721924835.907128}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721924835.9075813}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924835.9076767}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.58902263641357, '_timestamp': 1721924835.9077358}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.42646697765774616, '_timestamp': 1721924835.908416}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'train_goal': 0.713233488828873, '_timestamp': 1721924835.9088962}).
wandb: WARNING (User provided step: 6854 is less than current step: 14326. Dropping entry: {'train_WDL': 0.42646697765774616, '_timestamp': 1721924835.9093828}).
Env Football Algo jrpo Exp base_JRPO updates 9634/100000000000.0 steps in 87.29
total episode rewards is -10.0
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'value_loss': 0.18861265918589198, '_timestamp': 1721924923.1959908}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'policy_loss': -0.011471030175065, '_timestamp': 1721924923.1962273}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.07117884516716, '_timestamp': 1721924923.196297}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0946851521730423, '_timestamp': 1721924923.1964905}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.19122593104839325, '_timestamp': 1721924923.1967826}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'ratio': 0.7231598496437073, '_timestamp': 1721924923.196894}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721924923.19702}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924923.197398}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.28556966781616, '_timestamp': 1721924923.1974592}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.11293328363771897, '_timestamp': 1721924923.1985388}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'train_goal': 0.5564666418188595, '_timestamp': 1721924923.1991014}).
wandb: WARNING (User provided step: 9634 is less than current step: 14326. Dropping entry: {'train_WDL': 0.11293328363771897, '_timestamp': 1721924923.1995196}).
Env Football Algo jrpo Exp base_JRPO updates 7085/100000000000.0 steps in 71.51
total episode rewards is -40.0
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'value_loss': 0.4996172585710883, '_timestamp': 1721924994.7075274}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00914965313936894, '_timestamp': 1721924994.7077246}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.7862183312575023, '_timestamp': 1721924994.707793}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04156346246600151, '_timestamp': 1721924994.7078846}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1180217266082764, '_timestamp': 1721924994.708153}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'ratio': 0.6856799125671387, '_timestamp': 1721924994.7082596}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721924994.7083895}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721924994.7085173}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'Episode_Time': 71.50704073905945, '_timestamp': 1721924994.708576}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.9994878361075544, '_timestamp': 1721924994.7092524}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'train_goal': 0.00025608194622279127, '_timestamp': 1721924994.7097232}).
wandb: WARNING (User provided step: 7085 is less than current step: 14326. Dropping entry: {'train_WDL': -0.9994878361075544, '_timestamp': 1721924994.7100444}).
Env Football Algo jrpo Exp base_JRPO updates 1204/100000000000.0 steps in 31.35
total episode rewards is -20.0
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'value_loss': 0.7147715763188899, '_timestamp': 1721925026.0588472}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0007339592035956836, '_timestamp': 1721925026.0590696}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6596749196449916, '_timestamp': 1721925026.059139}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.008230704814195633, '_timestamp': 1721925026.059232}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.4470208883285522, '_timestamp': 1721925026.0594416}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'ratio': 0.7733926773071289, '_timestamp': 1721925026.059544}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925026.0600884}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925026.0601838}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'Episode_Time': 31.34802007675171, '_timestamp': 1721925026.0602415}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6109276493545481, '_timestamp': 1721925026.0608783}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'train_goal': 0.8054638246772741, '_timestamp': 1721925026.0611374}).
wandb: WARNING (User provided step: 1204 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6109276493545481, '_timestamp': 1721925026.0614932}).
Env Football Algo jrpo Exp base_JRPO updates 9652/100000000000.0 steps in 90.07
total episode rewards is -10.0
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'value_loss': 0.20114341733744368, '_timestamp': 1721925116.1340892}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0008649752436516186, '_timestamp': 1721925116.1342993}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0301528056462605, '_timestamp': 1721925116.134368}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22817020118236542, '_timestamp': 1721925116.134526}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5378625392913818, '_timestamp': 1721925116.134774}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'ratio': 0.6360265612602234, '_timestamp': 1721925116.1348763}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721925116.135007}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925116.1352227}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.07170557975769, '_timestamp': 1721925116.1352808}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.34592370979805537, '_timestamp': 1721925116.1358206}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'train_goal': 0.32703814510097234, '_timestamp': 1721925116.1363218}).
wandb: WARNING (User provided step: 9652 is less than current step: 14326. Dropping entry: {'train_WDL': -0.34592370979805537, '_timestamp': 1721925116.1366785}).
Env Football Algo jrpo Exp base_JRPO updates 1455/100000000000.0 steps in 25.01
total episode rewards is -50.0
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'value_loss': 0.6239312452822924, '_timestamp': 1721925141.1439683}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0063021829491481185, '_timestamp': 1721925141.1441305}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.3167062711218993, '_timestamp': 1721925141.1441972}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.005404139403253794, '_timestamp': 1721925141.1442902}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.367148518562317, '_timestamp': 1721925141.1445472}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'ratio': 0.8863447308540344, '_timestamp': 1721925141.1446478}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721925141.1449192}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925141.1450484}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'Episode_Time': 25.006418704986572, '_timestamp': 1721925141.1451051}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.40370370370370373, '_timestamp': 1721925141.1456518}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'train_goal': 0.7018518518518518, '_timestamp': 1721925141.1458247}).
wandb: WARNING (User provided step: 1455 is less than current step: 14326. Dropping entry: {'train_WDL': 0.40370370370370373, '_timestamp': 1721925141.1459897}).
Env Football Algo jrpo Exp base_JRPO updates 3938/100000000000.0 steps in 51.42
total episode rewards is -60.0
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'value_loss': 0.6898400101065636, '_timestamp': 1721925192.5692163}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01767511072025324, '_timestamp': 1721925192.5694566}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.064608115752538, '_timestamp': 1721925192.569525}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14213359355926514, '_timestamp': 1721925192.56962}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0431801080703735, '_timestamp': 1721925192.5698798}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'ratio': 0.8519068360328674, '_timestamp': 1721925192.5699856}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721925192.5704682}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925192.570567}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'Episode_Time': 51.42226266860962, '_timestamp': 1721925192.5706246}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2255253716043055, '_timestamp': 1721925192.57122}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'train_goal': 0.38723731419784724, '_timestamp': 1721925192.5715086}).
wandb: WARNING (User provided step: 3938 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2255253716043055, '_timestamp': 1721925192.5719967}).
Env Football Algo jrpo Exp base_JRPO updates 5075/100000000000.0 steps in 87.80
total episode rewards is 0.0
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'value_loss': 0.26273203615099194, '_timestamp': 1721925280.3747356}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'policy_loss': -0.008281640105027084, '_timestamp': 1721925280.3749275}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9196504020690919, '_timestamp': 1721925280.3749988}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.11962983757257462, '_timestamp': 1721925280.3751135}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.22899965941905975, '_timestamp': 1721925280.3754096}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'ratio': 0.589958667755127, '_timestamp': 1721925280.3755262}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721925280.376231}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925280.3763258}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.8017418384552, '_timestamp': 1721925280.376391}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.16130982367758187, '_timestamp': 1721925280.3771756}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'train_goal': 0.5806549118387909, '_timestamp': 1721925280.3777673}).
wandb: WARNING (User provided step: 5075 is less than current step: 14326. Dropping entry: {'train_WDL': 0.16130982367758187, '_timestamp': 1721925280.3783565}).
Env Football Algo jrpo Exp base_JRPO updates 1527/100000000000.0 steps in 32.97
total episode rewards is -20.0
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'value_loss': 0.5992910230780641, '_timestamp': 1721925313.351304}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'policy_loss': 0.016470008110045457, '_timestamp': 1721925313.3514686}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.421562358935674, '_timestamp': 1721925313.351536}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.009051110595464706, '_timestamp': 1721925313.3516283}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1095454692840576, '_timestamp': 1721925313.351885}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'ratio': 0.6104023456573486, '_timestamp': 1721925313.3520095}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925313.3525372}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925313.3526318}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'Episode_Time': 32.97159671783447, '_timestamp': 1721925313.3526914}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.9990753582986592, '_timestamp': 1721925313.353132}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'train_goal': 0.9995376791493297, '_timestamp': 1721925313.3533628}).
wandb: WARNING (User provided step: 1527 is less than current step: 14326. Dropping entry: {'train_WDL': 0.9990753582986592, '_timestamp': 1721925313.3535585}).
Env Football Algo jrpo Exp base_JRPO updates 1212/100000000000.0 steps in 23.92
total episode rewards is 10.0
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'value_loss': 0.9085399399946134, '_timestamp': 1721925337.277337}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'policy_loss': 0.006758894698771958, '_timestamp': 1721925337.2775545}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.3073180590073268, '_timestamp': 1721925337.2776222}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.01291131041944027, '_timestamp': 1721925337.277756}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 2.0106003284454346, '_timestamp': 1721925337.2780344}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'ratio': 0.6413712501525879, '_timestamp': 1721925337.278142}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721925337.2786977}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925337.278791}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'Episode_Time': 23.922905683517456, '_timestamp': 1721925337.2788475}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.9986559139784946, '_timestamp': 1721925337.2791972}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'train_goal': 0.9993279569892473, '_timestamp': 1721925337.2793665}).
wandb: WARNING (User provided step: 1212 is less than current step: 14326. Dropping entry: {'train_WDL': 0.9986559139784946, '_timestamp': 1721925337.2795289}).
Env Football Algo jrpo Exp base_JRPO updates 5054/100000000000.0 steps in 62.81
total episode rewards is 20.0
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'value_loss': 0.8092709813391169, '_timestamp': 1721925400.0983796}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'policy_loss': -0.002604611770948395, '_timestamp': 1721925400.0994394}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0365444473425547, '_timestamp': 1721925400.0995116}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05971910059452057, '_timestamp': 1721925400.0999298}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1857059001922607, '_timestamp': 1721925400.1046562}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'ratio': 0.47890692949295044, '_timestamp': 1721925400.104769}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721925400.1094258}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925400.1096594}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'Episode_Time': 62.81024146080017, '_timestamp': 1721925400.1097202}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.5903467856418576, '_timestamp': 1721925400.110676}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'train_goal': 0.7951733928209288, '_timestamp': 1721925400.1110451}).
wandb: WARNING (User provided step: 5054 is less than current step: 14326. Dropping entry: {'train_WDL': 0.5903467856418576, '_timestamp': 1721925400.1113708}).
Env Football Algo jrpo Exp base_JRPO updates 6775/100000000000.0 steps in 71.16
total episode rewards is -70.0
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'value_loss': 0.43338905458649, '_timestamp': 1721925471.2709246}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'policy_loss': 0.007456421818351373, '_timestamp': 1721925471.271087}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9981376389662425, '_timestamp': 1721925471.2711525}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07332228869199753, '_timestamp': 1721925471.271242}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6103240847587585, '_timestamp': 1721925471.2714992}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'ratio': 0.6516264081001282, '_timestamp': 1721925471.2716022}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721925471.271859}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925471.2719588}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'Episode_Time': 71.15879344940186, '_timestamp': 1721925471.272017}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925471.2724485}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925471.2727854}).
wandb: WARNING (User provided step: 6775 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925471.2731323}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'value_loss': 0.20115383487660438, '_timestamp': 1721925560.8580296}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0026956689257834417, '_timestamp': 1721925560.858215}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.1372613084316254, '_timestamp': 1721925560.858281}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.09832532703876495, '_timestamp': 1721925560.8583767}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3024134039878845, '_timestamp': 1721925560.8586473}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'ratio': 0.7507263422012329, '_timestamp': 1721925560.8587518}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721925560.8588831}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925560.859318}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.58400678634644, '_timestamp': 1721925560.8593786}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925560.8599935}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925560.8603754}).
wandb: WARNING (User provided step: 9073 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925560.8607945}).
Env Football Algo jrpo Exp base_JRPO updates 9073/100000000000.0 steps in 89.58
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 11460/100000000000.0 steps in 87.49
total episode rewards is 10.0
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'value_loss': 0.19284557889952944, '_timestamp': 1721925648.3551984}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'policy_loss': 0.002233232981476855, '_timestamp': 1721925648.3554633}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6640401315689087, '_timestamp': 1721925648.3555338}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.012918015941977501, '_timestamp': 1721925648.3556323}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.23549723625183105, '_timestamp': 1721925648.3559036}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'ratio': 0.800224244594574, '_timestamp': 1721925648.3560395}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721925648.3567247}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925648.3568256}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.49330544471741, '_timestamp': 1721925648.356884}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6333333333333333, '_timestamp': 1721925648.3574913}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'train_goal': 0.8166666666666667, '_timestamp': 1721925648.357776}).
wandb: WARNING (User provided step: 11460 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6333333333333333, '_timestamp': 1721925648.358061}).
Env Football Algo jrpo Exp base_JRPO updates 12970/100000000000.0 steps in 88.11
total episode rewards is -20.0
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'value_loss': 0.12274856187519617, '_timestamp': 1721925736.476408}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'policy_loss': 0.005455841521422068, '_timestamp': 1721925736.4776175}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.35374554693698884, '_timestamp': 1721925736.4776871}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.01729898899793625, '_timestamp': 1721925736.4781466}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2573697865009308, '_timestamp': 1721925736.478464}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'ratio': 0.8939463496208191, '_timestamp': 1721925736.4787343}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925736.478866}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925736.4790697}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.11305499076843, '_timestamp': 1721925736.47913}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721925736.4797509}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721925736.4799576}).
wandb: WARNING (User provided step: 12970 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721925736.4801495}).
Env Football Algo jrpo Exp base_JRPO updates 8037/100000000000.0 steps in 81.16
total episode rewards is -20.0
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'value_loss': 0.36972409665506956, '_timestamp': 1721925817.6437137}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'policy_loss': 0.020349337085693454, '_timestamp': 1721925817.64389}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0848096525669098, '_timestamp': 1721925817.6486459}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.021723106503486633, '_timestamp': 1721925817.6487865}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5975291728973389, '_timestamp': 1721925817.649079}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'ratio': 0.6959386467933655, '_timestamp': 1721925817.6491861}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925817.6499646}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925817.6500716}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'Episode_Time': 81.16227173805237, '_timestamp': 1721925817.6501293}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.394283858395583, '_timestamp': 1721925817.6507807}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'train_goal': 0.6971419291977915, '_timestamp': 1721925817.6512294}).
wandb: WARNING (User provided step: 8037 is less than current step: 14326. Dropping entry: {'train_WDL': 0.394283858395583, '_timestamp': 1721925817.651639}).
Env Football Algo jrpo Exp base_JRPO updates 5663/100000000000.0 steps in 89.16
total episode rewards is 0.0
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'value_loss': 0.2572578467723603, '_timestamp': 1721925906.8159711}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04515214401362755, '_timestamp': 1721925906.8162587}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3428754222393036, '_timestamp': 1721925906.8163297}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07078298181295395, '_timestamp': 1721925906.8165195}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2575480043888092, '_timestamp': 1721925906.8167875}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'ratio': 0.4296838343143463, '_timestamp': 1721925906.81715}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721925906.8174298}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925906.8175294}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.16314744949341, '_timestamp': 1721925906.817589}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1114919138909714, '_timestamp': 1721925906.8191414}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'train_goal': 0.4442540430545143, '_timestamp': 1721925906.820156}).
wandb: WARNING (User provided step: 5663 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1114919138909714, '_timestamp': 1721925906.821088}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'value_loss': 0.2358700795425102, '_timestamp': 1721925991.0346649}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05521173748779499, '_timestamp': 1721925991.0359318}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9796450285116831, '_timestamp': 1721925991.0360355}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04499109461903572, '_timestamp': 1721925991.03653}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.23093482851982117, '_timestamp': 1721925991.0369072}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'ratio': 0.7053249478340149, '_timestamp': 1721925991.0370102}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721925991.0375056}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721925991.0376987}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.2071738243103, '_timestamp': 1721925991.0377562}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.0051589282742552835, '_timestamp': 1721925991.0387523}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'train_goal': 0.4974205358628724, '_timestamp': 1721925991.0391612}).
wandb: WARNING (User provided step: 8991 is less than current step: 14326. Dropping entry: {'train_WDL': -0.0051589282742552835, '_timestamp': 1721925991.039576}).
Env Football Algo jrpo Exp base_JRPO updates 8991/100000000000.0 steps in 84.21
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 10787/100000000000.0 steps in 89.28
total episode rewards is -30.0
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'value_loss': 0.1909104882798662, '_timestamp': 1721926080.3160863}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'policy_loss': 0.009410928633490887, '_timestamp': 1721926080.3163655}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.13751673534939376, '_timestamp': 1721926080.316435}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.018654728308320045, '_timestamp': 1721926080.3165686}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1988619565963745, '_timestamp': 1721926080.3168309}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'ratio': 0.8732314109802246, '_timestamp': 1721926080.317446}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721926080.3176212}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926080.3177514}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.2753255367279, '_timestamp': 1721926080.3178098}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721926080.3183768}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721926080.3187003}).
wandb: WARNING (User provided step: 10787 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721926080.319016}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'value_loss': 0.18896212086857608, '_timestamp': 1721926167.2431393}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0008211364418578645, '_timestamp': 1721926167.243523}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0003109240106035334, '_timestamp': 1721926167.2435963}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.00036927155451849103, '_timestamp': 1721926167.2437837}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.28185197710990906, '_timestamp': 1721926167.2441041}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'ratio': 0.9998744130134583, '_timestamp': 1721926167.2444196}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721926167.2446556}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926167.2448006}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.92191696166992, '_timestamp': 1721926167.2448645}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721926167.2459378}).
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721926167.2466457}).
Env Football Algo jrpo Exp base_JRPO updates 7594/100000000000.0 steps in 86.92
total episode rewards is 30.0
wandb: WARNING (User provided step: 7594 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721926167.24768}).
Env Football Algo jrpo Exp base_JRPO updates 7793/100000000000.0 steps in 93.23
total episode rewards is 40.0
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'value_loss': 0.2851803122647107, '_timestamp': 1721926260.4799447}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0005749304359778762, '_timestamp': 1721926260.4802246}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0004212303575089512, '_timestamp': 1721926260.4802966}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0005727013340219855, '_timestamp': 1721926260.480393}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.37847310304641724, '_timestamp': 1721926260.4806676}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'ratio': 0.9997448921203613, '_timestamp': 1721926260.4812915}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 40.0, '_timestamp': 1721926260.4816606}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926260.4817944}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.23094248771667, '_timestamp': 1721926260.4818535}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721926260.4832141}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721926260.4836729}).
wandb: WARNING (User provided step: 7793 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721926260.484145}).
Env Football Algo jrpo Exp base_JRPO updates 12383/100000000000.0 steps in 87.82
total episode rewards is 10.0
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'value_loss': 0.18403011601709296, '_timestamp': 1721926348.3012135}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0032700429408093136, '_timestamp': 1721926348.3014615}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.00032245770315057597, '_timestamp': 1721926348.3015304}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.00042150975787080824, '_timestamp': 1721926348.3016658}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.28143107891082764, '_timestamp': 1721926348.3019516}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'ratio': 0.9996737837791443, '_timestamp': 1721926348.3025608}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721926348.3026967}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926348.3027906}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.81536960601807, '_timestamp': 1721926348.3028462}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.27168513565150937, '_timestamp': 1721926348.3032484}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'train_goal': 0.36415743217424534, '_timestamp': 1721926348.3034823}).
wandb: WARNING (User provided step: 12383 is less than current step: 14326. Dropping entry: {'train_WDL': -0.27168513565150937, '_timestamp': 1721926348.3037071}).
Env Football Algo jrpo Exp base_JRPO updates 3135/100000000000.0 steps in 52.74
total episode rewards is 20.0
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'value_loss': 0.4978462307341397, '_timestamp': 1721926401.045944}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0008446792039709787, '_timestamp': 1721926401.047245}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.00034425103154111033, '_timestamp': 1721926401.0473177}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0001654230582062155, '_timestamp': 1721926401.0478234}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0212948322296143, '_timestamp': 1721926401.048157}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'ratio': 0.9996535181999207, '_timestamp': 1721926401.0488741}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721926401.049013}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926401.049213}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'Episode_Time': 52.73635244369507, '_timestamp': 1721926401.0492702}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.594811320754717, '_timestamp': 1721926401.050234}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'train_goal': 0.7974056603773585, '_timestamp': 1721926401.0505412}).
wandb: WARNING (User provided step: 3135 is less than current step: 14326. Dropping entry: {'train_WDL': 0.594811320754717, '_timestamp': 1721926401.050841}).
Env Football Algo jrpo Exp base_JRPO updates 7495/100000000000.0 steps in 87.05
total episode rewards is -20.0
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'value_loss': 0.27609567357925696, '_timestamp': 1721926488.1005626}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00047193319536745546, '_timestamp': 1721926488.1007302}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0003921492138761096, '_timestamp': 1721926488.1008003}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.00020695455896202475, '_timestamp': 1721926488.100892}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.29366999864578247, '_timestamp': 1721926488.1011827}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'ratio': 0.9996618032455444, '_timestamp': 1721926488.1016374}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721926488.1017718}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926488.101865}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.04862189292908, '_timestamp': 1721926488.1019235}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.37295136575616256, '_timestamp': 1721926488.1024783}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'train_goal': 0.3135243171219187, '_timestamp': 1721926488.1029377}).
wandb: WARNING (User provided step: 7495 is less than current step: 14326. Dropping entry: {'train_WDL': -0.37295136575616256, '_timestamp': 1721926488.1034036}).
Env Football Algo jrpo Exp base_JRPO updates 12024/100000000000.0 steps in 84.98
total episode rewards is 10.0
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'value_loss': 0.0695707086470793, '_timestamp': 1721926573.0910327}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00045379406462113064, '_timestamp': 1721926573.0912223}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.00020748890955777217, '_timestamp': 1721926573.0912907}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0008339592022821307, '_timestamp': 1721926573.091387}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.15200361609458923, '_timestamp': 1721926573.091652}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'ratio': 0.9998237490653992, '_timestamp': 1721926573.0936248}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721926573.0937796}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926573.0938761}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.9824857711792, '_timestamp': 1721926573.0939348}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721926573.0944915}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721926573.0947442}).
wandb: WARNING (User provided step: 12024 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721926573.0949693}).
Env Football Algo jrpo Exp base_JRPO updates 8416/100000000000.0 steps in 88.16
total episode rewards is 0.0
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'value_loss': 0.2765337286751795, '_timestamp': 1721926661.2552452}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'policy_loss': -0.002244240970661243, '_timestamp': 1721926661.2554095}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.08823829340826099, '_timestamp': 1721926661.2554762}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.008727764710783958, '_timestamp': 1721926661.255566}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4527386724948883, '_timestamp': 1721926661.255808}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'ratio': 0.882607638835907, '_timestamp': 1721926661.2559114}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721926661.2560527}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926661.256144}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.15900611877441, '_timestamp': 1721926661.2562017}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.1856014580801944, '_timestamp': 1721926661.2567813}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'train_goal': 0.5928007290400972, '_timestamp': 1721926661.2571971}).
wandb: WARNING (User provided step: 8416 is less than current step: 14326. Dropping entry: {'train_WDL': 0.1856014580801944, '_timestamp': 1721926661.2576106}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'value_loss': 0.18138642823983295, '_timestamp': 1721926745.9607391}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00966990715979288, '_timestamp': 1721926745.960997}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.4969189433256785, '_timestamp': 1721926745.9610684}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.018037162721157074, '_timestamp': 1721926745.9611697}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3607305586338043, '_timestamp': 1721926745.961448}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'ratio': 0.6803234815597534, '_timestamp': 1721926745.9615545}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721926745.9620485}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926745.9621484}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.70209741592407, '_timestamp': 1721926745.9622076}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.13031761308950915, '_timestamp': 1721926745.9630282}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'train_goal': 0.5651588065447546, '_timestamp': 1721926745.9634063}).
wandb: WARNING (User provided step: 9805 is less than current step: 14326. Dropping entry: {'train_WDL': 0.13031761308950915, '_timestamp': 1721926745.9637597}).
Env Football Algo jrpo Exp base_JRPO updates 9805/100000000000.0 steps in 84.70
total episode rewards is -10.0
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'value_loss': 0.24563288411435982, '_timestamp': 1721926834.294281}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'policy_loss': -0.007995081732903296, '_timestamp': 1721926834.2952914}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3951048223177591, '_timestamp': 1721926834.2953606}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.029133044183254242, '_timestamp': 1721926834.2957332}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1653970181941986, '_timestamp': 1721926834.2960482}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'ratio': 0.43640848994255066, '_timestamp': 1721926834.2965844}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721926834.2967148}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926834.2968988}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.32573056221008, '_timestamp': 1721926834.2969592}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.07287259050305595, '_timestamp': 1721926834.2979069}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'train_goal': 0.536436295251528, '_timestamp': 1721926834.2984316}).
wandb: WARNING (User provided step: 6492 is less than current step: 14326. Dropping entry: {'train_WDL': 0.07287259050305595, '_timestamp': 1721926834.2989411}).
Env Football Algo jrpo Exp base_JRPO updates 6492/100000000000.0 steps in 88.33
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 7167/100000000000.0 steps in 88.65
total episode rewards is -20.0
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'value_loss': 0.28768912754254417, '_timestamp': 1721926922.9454174}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0027174243305732185, '_timestamp': 1721926922.9456007}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.365701237519582, '_timestamp': 1721926922.945669}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.031697485595941544, '_timestamp': 1721926922.9457672}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3796273171901703, '_timestamp': 1721926922.9460354}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'ratio': 0.518878161907196, '_timestamp': 1721926922.9461398}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721926922.946562}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721926922.9466584}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.64536762237549, '_timestamp': 1721926922.9467146}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2401378782075833, '_timestamp': 1721926922.9473565}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'train_goal': 0.3799310608962084, '_timestamp': 1721926922.947856}).
wandb: WARNING (User provided step: 7167 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2401378782075833, '_timestamp': 1721926922.9483707}).
Env Football Algo jrpo Exp base_JRPO updates 9561/100000000000.0 steps in 82.38
total episode rewards is 10.0
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'value_loss': 0.1977627159631811, '_timestamp': 1721927005.335492}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'policy_loss': -0.016886506866139826, '_timestamp': 1721927005.3418128}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9833646070957184, '_timestamp': 1721927005.3419163}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0032120016403496265, '_timestamp': 1721927005.34245}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.14793488383293152, '_timestamp': 1721927005.3428109}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'ratio': 0.6430544257164001, '_timestamp': 1721927005.343277}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721927005.3434277}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927005.3436341}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.3809700012207, '_timestamp': 1721927005.3436956}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3149476006618864, '_timestamp': 1721927005.3446789}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'train_goal': 0.6574738003309432, '_timestamp': 1721927005.3450868}).
wandb: WARNING (User provided step: 9561 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3149476006618864, '_timestamp': 1721927005.3454845}).
Env Football Algo jrpo Exp base_JRPO updates 6502/100000000000.0 steps in 91.83
total episode rewards is -20.0
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'value_loss': 0.26352716113401886, '_timestamp': 1721927097.1798468}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'policy_loss': -0.005994316393043846, '_timestamp': 1721927097.1800554}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5862024370829264, '_timestamp': 1721927097.1801255}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04201364889740944, '_timestamp': 1721927097.180222}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3670036494731903, '_timestamp': 1721927097.18051}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'ratio': 0.470709890127182, '_timestamp': 1721927097.1813927}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721927097.1815376}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927097.1816323}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.83335947990417, '_timestamp': 1721927097.1816885}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.30477759472817134, '_timestamp': 1721927097.1823826}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'train_goal': 0.34761120263591433, '_timestamp': 1721927097.182894}).
wandb: WARNING (User provided step: 6502 is less than current step: 14326. Dropping entry: {'train_WDL': -0.30477759472817134, '_timestamp': 1721927097.183413}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'value_loss': 0.46602058827256165, '_timestamp': 1721927164.5160298}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01297997917747125, '_timestamp': 1721927164.5162249}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.2640088136990866, '_timestamp': 1721927164.5162914}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0030922398436814547, '_timestamp': 1721927164.516384}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9154896140098572, '_timestamp': 1721927164.5166278}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'ratio': 0.5184217691421509, '_timestamp': 1721927164.5170548}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721927164.5171866}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927164.5172772}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'Episode_Time': 67.33172535896301, '_timestamp': 1721927164.517333}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2621678112869513, '_timestamp': 1721927164.517938}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'train_goal': 0.36891609435652434, '_timestamp': 1721927164.5183785}).
wandb: WARNING (User provided step: 5732 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2621678112869513, '_timestamp': 1721927164.518796}).
Env Football Algo jrpo Exp base_JRPO updates 5732/100000000000.0 steps in 67.33
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 4551/100000000000.0 steps in 90.75
total episode rewards is -20.0
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'value_loss': 0.24217460418158832, '_timestamp': 1721927255.268719}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02689093536901055, '_timestamp': 1721927255.2689004}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9969985127449035, '_timestamp': 1721927255.26897}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07598842680454254, '_timestamp': 1721927255.269068}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.14042501151561737, '_timestamp': 1721927255.2693393}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'ratio': 0.4515555799007416, '_timestamp': 1721927255.2694447}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721927255.2699215}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927255.2700164}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.74899506568909, '_timestamp': 1721927255.2700746}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4275050244042492, '_timestamp': 1721927255.2709503}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'train_goal': 0.2862474877978754, '_timestamp': 1721927255.2715838}).
wandb: WARNING (User provided step: 4551 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4275050244042492, '_timestamp': 1721927255.2722414}).
Env Football Algo jrpo Exp base_JRPO updates 6379/100000000000.0 steps in 75.31
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'value_loss': 0.35099572261717793, '_timestamp': 1721927330.578732}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03440964954439551, '_timestamp': 1721927330.578909}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.152731162259976, '_timestamp': 1721927330.5789733}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0071376715786755085, '_timestamp': 1721927330.5790648}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7049826979637146, '_timestamp': 1721927330.5793262}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'ratio': 0.5049279928207397, '_timestamp': 1721927330.5794337}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721927330.5796921}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927330.5797832}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'Episode_Time': 75.30536985397339, '_timestamp': 1721927330.5798411}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.5102456038366516, '_timestamp': 1721927330.5804114}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'train_goal': 0.24487719808167419, '_timestamp': 1721927330.5808327}).
wandb: WARNING (User provided step: 6379 is less than current step: 14326. Dropping entry: {'train_WDL': -0.5102456038366516, '_timestamp': 1721927330.5812683}).
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 7460/100000000000.0 steps in 85.89
total episode rewards is -20.0
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'value_loss': 0.278092084848322, '_timestamp': 1721927416.476607}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0017339593769672016, '_timestamp': 1721927416.4767733}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.005303573587540692, '_timestamp': 1721927416.476844}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0012678186176344752, '_timestamp': 1721927416.4769354}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3415054678916931, '_timestamp': 1721927416.4772022}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'ratio': 0.9924916625022888, '_timestamp': 1721927416.4773054}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721927416.477437}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927416.4779682}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.89409732818604, '_timestamp': 1721927416.4780276}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.21326259946949602, '_timestamp': 1721927416.4786303}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'train_goal': 0.393368700265252, '_timestamp': 1721927416.479088}).
wandb: WARNING (User provided step: 7460 is less than current step: 14326. Dropping entry: {'train_WDL': -0.21326259946949602, '_timestamp': 1721927416.4795485}).
Env Football Algo jrpo Exp base_JRPO updates 7872/100000000000.0 steps in 94.02
total episode rewards is 30.0
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'value_loss': 0.20866111036312457, '_timestamp': 1721927510.5047922}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0008465352953256418, '_timestamp': 1721927510.504962}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.009811233068467118, '_timestamp': 1721927510.50503}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.004630882292985916, '_timestamp': 1721927510.5051193}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.18156367540359497, '_timestamp': 1721927510.5053682}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'ratio': 0.9928837418556213, '_timestamp': 1721927510.5054705}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721927510.505603}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927510.5059316}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.02424359321594, '_timestamp': 1721927510.5059898}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721927510.5069473}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721927510.5076072}).
wandb: WARNING (User provided step: 7872 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721927510.5080416}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'value_loss': 0.21893914035075188, '_timestamp': 1721927600.7160814}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00035490216614562085, '_timestamp': 1721927600.716263}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.004232411471894011, '_timestamp': 1721927600.7163303}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.004367677494883537, '_timestamp': 1721927600.7164261}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2674303352832794, '_timestamp': 1721927600.716697}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'ratio': 0.9942778944969177, '_timestamp': 1721927600.7168071}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721927600.716942}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927600.7177613}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.20699381828308, '_timestamp': 1721927600.7178235}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.28220442513913396, '_timestamp': 1721927600.7209935}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'train_goal': 0.641102212569567, '_timestamp': 1721927600.7215602}).
wandb: WARNING (User provided step: 7633 is less than current step: 14326. Dropping entry: {'train_WDL': 0.28220442513913396, '_timestamp': 1721927600.7220907}).
Env Football Algo jrpo Exp base_JRPO updates 7633/100000000000.0 steps in 90.21
total episode rewards is 10.0
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'value_loss': 0.20538857228297275, '_timestamp': 1721927690.7431996}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0005284882410584638, '_timestamp': 1721927690.743391}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0012567240204953123, '_timestamp': 1721927690.743461}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.003059982554987073, '_timestamp': 1721927690.7436047}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3350137770175934, '_timestamp': 1721927690.7438946}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'ratio': 0.9985565543174744, '_timestamp': 1721927690.7440183}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721927690.7449164}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927690.745025}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.02019309997559, '_timestamp': 1721927690.7450895}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6092739036664271, '_timestamp': 1721927690.7457783}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'train_goal': 0.8046369518332135, '_timestamp': 1721927690.7461884}).
wandb: WARNING (User provided step: 9436 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6092739036664271, '_timestamp': 1721927690.7465692}).
Env Football Algo jrpo Exp base_JRPO updates 9436/100000000000.0 steps in 90.02
total episode rewards is 10.0
Env Football Algo jrpo Exp base_JRPO updates 4758/100000000000.0 steps in 89.39
total episode rewards is 0.0
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'value_loss': 0.24648176055265747, '_timestamp': 1721927780.1414773}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'policy_loss': -0.001587404498034933, '_timestamp': 1721927780.1416469}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.001712214467843296, '_timestamp': 1721927780.1417162}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0043478552252054214, '_timestamp': 1721927780.1418388}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2243245244026184, '_timestamp': 1721927780.1421123}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'ratio': 0.9979287981987, '_timestamp': 1721927780.1422162}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721927780.142767}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927780.1428597}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.39200139045715, '_timestamp': 1721927780.1429172}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.16442101152118727, '_timestamp': 1721927780.1436815}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'train_goal': 0.5822105057605936, '_timestamp': 1721927780.147168}).
wandb: WARNING (User provided step: 4758 is less than current step: 14326. Dropping entry: {'train_WDL': 0.16442101152118727, '_timestamp': 1721927780.1477628}).
Env Football Algo jrpo Exp base_JRPO updates 7599/100000000000.0 steps in 84.15
total episode rewards is -10.0
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'value_loss': 0.19598780956487946, '_timestamp': 1721927864.294225}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'policy_loss': -0.003495716454150776, '_timestamp': 1721927864.2943912}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.002026679096064375, '_timestamp': 1721927864.294454}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0035504698753356934, '_timestamp': 1721927864.2945447}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4208798408508301, '_timestamp': 1721927864.2947955}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'ratio': 0.9936410784721375, '_timestamp': 1721927864.2948966}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721927864.295024}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927864.2952158}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.14545893669128, '_timestamp': 1721927864.295274}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4714227807053101, '_timestamp': 1721927864.295838}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'train_goal': 0.26428860964734496, '_timestamp': 1721927864.296286}).
wandb: WARNING (User provided step: 7599 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4714227807053101, '_timestamp': 1721927864.2967405}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'value_loss': 0.19381207375011097, '_timestamp': 1721927953.6175382}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0011399324421654455, '_timestamp': 1721927953.6177044}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0037110671970488813, '_timestamp': 1721927953.617774}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0007527898414991796, '_timestamp': 1721927953.617868}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.17413388192653656, '_timestamp': 1721927953.618133}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'ratio': 0.9956768155097961, '_timestamp': 1721927953.6182387}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721927953.6189907}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721927953.6190913}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.31985807418823, '_timestamp': 1721927953.6191502}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721927953.6197476}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721927953.6202552}).
wandb: WARNING (User provided step: 6721 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721927953.6207628}).
Env Football Algo jrpo Exp base_JRPO updates 6721/100000000000.0 steps in 89.32
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 5335/100000000000.0 steps in 80.70
total episode rewards is 0.0
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'value_loss': 0.2573687743138483, '_timestamp': 1721928034.322341}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0005293909716419876, '_timestamp': 1721928034.3225112}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.002804565243568504, '_timestamp': 1721928034.322578}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0016253750072792172, '_timestamp': 1721928034.3226736}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3501221835613251, '_timestamp': 1721928034.3229382}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'ratio': 0.9966228604316711, '_timestamp': 1721928034.3230455}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721928034.3231838}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928034.3234513}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'Episode_Time': 80.70050382614136, '_timestamp': 1721928034.3235219}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2347646145887222, '_timestamp': 1721928034.3242748}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'train_goal': 0.617382307294361, '_timestamp': 1721928034.3252158}).
wandb: WARNING (User provided step: 5335 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2347646145887222, '_timestamp': 1721928034.325797}).
Env Football Algo jrpo Exp base_JRPO updates 5405/100000000000.0 steps in 84.59
total episode rewards is 0.0
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'value_loss': 0.25955676392428967, '_timestamp': 1721928118.9135725}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'policy_loss': 0.000545362924070408, '_timestamp': 1721928118.9137723}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.008189533475136462, '_timestamp': 1721928118.9138558}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0031914750579744577, '_timestamp': 1721928118.913956}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5211441516876221, '_timestamp': 1721928118.9142601}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'ratio': 0.9913555979728699, '_timestamp': 1721928118.9143934}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721928118.9149053}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928118.9150195}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.58687710762024, '_timestamp': 1721928118.9150784}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2433559145388223, '_timestamp': 1721928118.9158688}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'train_goal': 0.6216779572694111, '_timestamp': 1721928118.9164555}).
wandb: WARNING (User provided step: 5405 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2433559145388223, '_timestamp': 1721928118.917194}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'value_loss': 0.2635109644299761, '_timestamp': 1721928211.6022577}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'policy_loss': 1.8422543459261457e-05, '_timestamp': 1721928211.6026204}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.005227038913435535, '_timestamp': 1721928211.6027026}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0006750650936737657, '_timestamp': 1721928211.6028395}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.22299553453922272, '_timestamp': 1721928211.6031375}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'ratio': 0.9970651268959045, '_timestamp': 1721928211.6032448}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721928211.6034071}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928211.604043}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'Episode_Time': 92.68331789970398, '_timestamp': 1721928211.604106}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2987395645768538, '_timestamp': 1721928211.6047976}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'train_goal': 0.3506302177115731, '_timestamp': 1721928211.6052332}).
wandb: WARNING (User provided step: 8891 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2987395645768538, '_timestamp': 1721928211.6056535}).
Env Football Algo jrpo Exp base_JRPO updates 8891/100000000000.0 steps in 92.68
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6591/100000000000.0 steps in 91.74
total episode rewards is -20.0
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'value_loss': 0.27725665240858993, '_timestamp': 1721928303.3460498}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0020168358648758535, '_timestamp': 1721928303.3463054}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.0007081355275052677, '_timestamp': 1721928303.3463757}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0014417574275285006, '_timestamp': 1721928303.3464794}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3034955859184265, '_timestamp': 1721928303.3467746}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'ratio': 0.9992771744728088, '_timestamp': 1721928303.346881}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721928303.3481674}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928303.3482738}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.73865008354187, '_timestamp': 1721928303.348332}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4025448923772149, '_timestamp': 1721928303.3491626}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'train_goal': 0.29872755381139254, '_timestamp': 1721928303.349746}).
wandb: WARNING (User provided step: 6591 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4025448923772149, '_timestamp': 1721928303.3503253}).
Env Football Algo jrpo Exp base_JRPO updates 8296/100000000000.0 steps in 80.29
total episode rewards is -10.0
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'value_loss': 0.1914938169127951, '_timestamp': 1721928383.6388304}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00955213982311155, '_timestamp': 1721928383.6390252}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.1682727531796748, '_timestamp': 1721928383.639108}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.008969387039542198, '_timestamp': 1721928383.639219}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.17264945805072784, '_timestamp': 1721928383.6395078}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'ratio': 0.7571397423744202, '_timestamp': 1721928383.6396296}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721928383.6397817}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928383.6403484}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'Episode_Time': 80.2872793674469, '_timestamp': 1721928383.640422}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.12231503579952267, '_timestamp': 1721928383.6412423}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'train_goal': 0.4388424821002387, '_timestamp': 1721928383.6420038}).
wandb: WARNING (User provided step: 8296 is less than current step: 14326. Dropping entry: {'train_WDL': -0.12231503579952267, '_timestamp': 1721928383.6424975}).
Env Football Algo jrpo Exp base_JRPO updates 5538/100000000000.0 steps in 93.48
total episode rewards is 0.0
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'value_loss': 0.27241997494051856, '_timestamp': 1721928477.1195674}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'policy_loss': 0.021702347836301972, '_timestamp': 1721928477.11984}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.1206863064194719, '_timestamp': 1721928477.11991}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05386761575937271, '_timestamp': 1721928477.1200607}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2557891011238098, '_timestamp': 1721928477.1203384}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'ratio': 0.8940359950065613, '_timestamp': 1721928477.1209347}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721928477.1211917}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928477.1213202}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'Episode_Time': 93.47571134567261, '_timestamp': 1721928477.121378}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2536461636017755, '_timestamp': 1721928477.122511}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'train_goal': 0.6268230818008877, '_timestamp': 1721928477.1231604}).
wandb: WARNING (User provided step: 5538 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2536461636017755, '_timestamp': 1721928477.123795}).
Env Football Algo jrpo Exp base_JRPO updates 4743/100000000000.0 steps in 69.23
total episode rewards is -20.0
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'value_loss': 0.3915595879405737, '_timestamp': 1721928546.3543823}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'policy_loss': 0.012210344723183273, '_timestamp': 1721928546.3552086}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.3114775434633096, '_timestamp': 1721928546.3552775}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.03966841474175453, '_timestamp': 1721928546.3556397}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5672363638877869, '_timestamp': 1721928546.3559332}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'ratio': 0.6482133269309998, '_timestamp': 1721928546.3601847}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721928546.3606021}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928546.3607726}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'Episode_Time': 69.22652411460876, '_timestamp': 1721928546.3608332}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.11307137129109864, '_timestamp': 1721928546.361587}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'train_goal': 0.5565356856455493, '_timestamp': 1721928546.3620467}).
wandb: WARNING (User provided step: 4743 is less than current step: 14326. Dropping entry: {'train_WDL': 0.11307137129109864, '_timestamp': 1721928546.3625014}).
Env Football Algo jrpo Exp base_JRPO updates 9114/100000000000.0 steps in 85.31
total episode rewards is -10.0
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'value_loss': 0.1989440429296034, '_timestamp': 1721928631.6690416}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'policy_loss': 0.020902785274956842, '_timestamp': 1721928631.6692085}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6269323062896728, '_timestamp': 1721928631.6692762}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.031516894698143005, '_timestamp': 1721928631.669369}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.24490755796432495, '_timestamp': 1721928631.6696067}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'ratio': 0.38211721181869507, '_timestamp': 1721928631.669711}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721928631.6700473}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928631.6701417}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.30573892593384, '_timestamp': 1721928631.6701987}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.0061162079510703364, '_timestamp': 1721928631.670711}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'train_goal': 0.4969418960244648, '_timestamp': 1721928631.6710813}).
wandb: WARNING (User provided step: 9114 is less than current step: 14326. Dropping entry: {'train_WDL': -0.0061162079510703364, '_timestamp': 1721928631.671461}).
Env Football Algo jrpo Exp base_JRPO updates 6956/100000000000.0 steps in 91.89
total episode rewards is -20.0
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'value_loss': 0.2753935825110724, '_timestamp': 1721928723.5636568}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03184592335591636, '_timestamp': 1721928723.5638192}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.86252370595932, '_timestamp': 1721928723.5638876}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.060350604355335236, '_timestamp': 1721928723.5640109}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.49068865180015564, '_timestamp': 1721928723.5642629}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'ratio': 0.7684614658355713, '_timestamp': 1721928723.564368}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721928723.564669}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928723.564762}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.89143419265747, '_timestamp': 1721928723.5648222}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.2757334659373446, '_timestamp': 1721928723.5654526}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'train_goal': 0.3621332670313277, '_timestamp': 1721928723.5659425}).
wandb: WARNING (User provided step: 6956 is less than current step: 14326. Dropping entry: {'train_WDL': -0.2757334659373446, '_timestamp': 1721928723.5664294}).
Env Football Algo jrpo Exp base_JRPO updates 7394/100000000000.0 steps in 82.15
total episode rewards is -40.0
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'value_loss': 0.29763809084154974, '_timestamp': 1721928805.7167726}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06346874183781134, '_timestamp': 1721928805.7170465}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7806601858139037, '_timestamp': 1721928805.717118}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.16898848116397858, '_timestamp': 1721928805.7172668}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5271008014678955, '_timestamp': 1721928805.717515}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'ratio': 0.29229873418807983, '_timestamp': 1721928805.7176168}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928805.717887}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928805.71798}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.1492600440979, '_timestamp': 1721928805.7180355}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928805.7186985}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928805.719178}).
wandb: WARNING (User provided step: 7394 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928805.7196546}).
Env Football Algo jrpo Exp base_JRPO updates 7443/100000000000.0 steps in 90.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'value_loss': 0.2942040997863902, '_timestamp': 1721928896.183655}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04343797996911841, '_timestamp': 1721928896.183841}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9546327296892803, '_timestamp': 1721928896.183912}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04958932101726532, '_timestamp': 1721928896.1840365}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.25607192516326904, '_timestamp': 1721928896.1843138}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'ratio': 0.4862448275089264, '_timestamp': 1721928896.1844213}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721928896.1853187}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928896.1854205}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.46308898925781, '_timestamp': 1721928896.1854804}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721928896.1860986}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721928896.1866055}).
wandb: WARNING (User provided step: 7443 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721928896.187103}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'value_loss': 0.20454612586375637, '_timestamp': 1721928984.6443384}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05222615859160821, '_timestamp': 1721928984.6445084}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7736708696683248, '_timestamp': 1721928984.644574}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.09789620339870453, '_timestamp': 1721928984.6446652}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.37323302030563354, '_timestamp': 1721928984.644917}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'ratio': 0.25387662649154663, '_timestamp': 1721928984.6450212}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721928984.645155}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721928984.6452434}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.4561116695404, '_timestamp': 1721928984.6452994}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3350808213193534, '_timestamp': 1721928984.645742}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'train_goal': 0.6675404106596767, '_timestamp': 1721928984.646053}).
wandb: WARNING (User provided step: 10422 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3350808213193534, '_timestamp': 1721928984.6463585}).
Env Football Algo jrpo Exp base_JRPO updates 10422/100000000000.0 steps in 88.46
total episode rewards is 10.0
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'value_loss': 0.33287195415856935, '_timestamp': 1721929074.2977462}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'policy_loss': 0.024525681282781684, '_timestamp': 1721929074.2987225}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7766981681187948, '_timestamp': 1721929074.2987914}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.057180095463991165, '_timestamp': 1721929074.2991705}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7241931557655334, '_timestamp': 1721929074.2994742}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'ratio': 0.4862084984779358, '_timestamp': 1721929074.299575}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721929074.3000317}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929074.3002055}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.64634656906128, '_timestamp': 1721929074.3002627}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.24652956298200515, '_timestamp': 1721929074.3012154}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'train_goal': 0.37673521850899744, '_timestamp': 1721929074.3017015}).
wandb: WARNING (User provided step: 7220 is less than current step: 14326. Dropping entry: {'train_WDL': -0.24652956298200515, '_timestamp': 1721929074.302188}).
Env Football Algo jrpo Exp base_JRPO updates 7220/100000000000.0 steps in 89.65
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8383/100000000000.0 steps in 91.62
total episode rewards is -20.0
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'value_loss': 0.32596548898611216, '_timestamp': 1721929165.926309}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'policy_loss': 0.029841247619478962, '_timestamp': 1721929165.9264908}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8151122736930847, '_timestamp': 1721929165.9265623}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04634895920753479, '_timestamp': 1721929165.926724}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5570551156997681, '_timestamp': 1721929165.9269867}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'ratio': 0.4685508906841278, '_timestamp': 1721929165.927092}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721929165.9276316}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929165.927734}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.6232750415802, '_timestamp': 1721929165.9277928}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.350460933957987, '_timestamp': 1721929165.928599}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'train_goal': 0.3247695330210065, '_timestamp': 1721929165.929086}).
wandb: WARNING (User provided step: 8383 is less than current step: 14326. Dropping entry: {'train_WDL': -0.350460933957987, '_timestamp': 1721929165.9295545}).
Env Football Algo jrpo Exp base_JRPO updates 7588/100000000000.0 steps in 68.38
total episode rewards is -70.0
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'value_loss': 0.7061454157034556, '_timestamp': 1721929234.3140597}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05524071774212644, '_timestamp': 1721929234.315347}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5127418595800797, '_timestamp': 1721929234.3154192}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0821644514799118, '_timestamp': 1721929234.3159122}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.575972318649292, '_timestamp': 1721929234.31627}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'ratio': 0.3918198049068451, '_timestamp': 1721929234.3163755}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721929234.3169918}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929234.3171797}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'Episode_Time': 68.37860584259033, '_timestamp': 1721929234.3172376}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.23941276115189158, '_timestamp': 1721929234.3182487}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'train_goal': 0.6197063805759458, '_timestamp': 1721929234.3185246}).
wandb: WARNING (User provided step: 7588 is less than current step: 14326. Dropping entry: {'train_WDL': 0.23941276115189158, '_timestamp': 1721929234.3187947}).
Env Football Algo jrpo Exp base_JRPO updates 4319/100000000000.0 steps in 65.52
total episode rewards is -60.0
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'value_loss': 0.6681206247055282, '_timestamp': 1721929299.8364336}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00015264223950604597, '_timestamp': 1721929299.8366146}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.05167789776576683, '_timestamp': 1721929299.836683}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.021538015455007553, '_timestamp': 1721929299.8367758}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.317641258239746, '_timestamp': 1721929299.8370256}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'ratio': 0.6910526156425476, '_timestamp': 1721929299.83713}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721929299.8372598}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929299.8376408}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'Episode_Time': 65.51669597625732, '_timestamp': 1721929299.8377008}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.2740483335965882, '_timestamp': 1721929299.8382215}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'train_goal': 0.6370241667982941, '_timestamp': 1721929299.8386264}).
wandb: WARNING (User provided step: 4319 is less than current step: 14326. Dropping entry: {'train_WDL': 0.2740483335965882, '_timestamp': 1721929299.8390274}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'value_loss': 0.4044182837366437, '_timestamp': 1721929379.023612}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'policy_loss': -0.006237742523662746, '_timestamp': 1721929379.0237908}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.1315076624136418, '_timestamp': 1721929379.023856}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.041741933673620224, '_timestamp': 1721929379.0239666}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5468705296516418, '_timestamp': 1721929379.0242345}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'ratio': 0.8196243643760681, '_timestamp': 1721929379.0244682}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721929379.024605}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929379.0247033}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'Episode_Time': 79.1835069656372, '_timestamp': 1721929379.0247602}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6144779140373854, '_timestamp': 1721929379.025528}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'train_goal': 0.8072389570186927, '_timestamp': 1721929379.026029}).
wandb: WARNING (User provided step: 6211 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6144779140373854, '_timestamp': 1721929379.0265284}).
Env Football Algo jrpo Exp base_JRPO updates 6211/100000000000.0 steps in 79.18
total episode rewards is 0.0
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'value_loss': 0.2209015867083023, '_timestamp': 1721929470.9480054}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01248683907634889, '_timestamp': 1721929470.949405}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.05609341486357153, '_timestamp': 1721929470.9494781}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.09128426760435104, '_timestamp': 1721929470.9499953}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.36149391531944275, '_timestamp': 1721929470.950364}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'ratio': 0.9165326952934265, '_timestamp': 1721929470.950477}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721929470.9512534}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929470.9514616}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.91496896743774, '_timestamp': 1721929470.951525}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.02763448784082535, '_timestamp': 1721929470.9530497}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'train_goal': 0.5138172439204127, '_timestamp': 1721929470.953454}).
wandb: WARNING (User provided step: 9572 is less than current step: 14326. Dropping entry: {'train_WDL': 0.02763448784082535, '_timestamp': 1721929470.9539864}).
Env Football Algo jrpo Exp base_JRPO updates 9572/100000000000.0 steps in 91.91
total episode rewards is 10.0
Env Football Algo jrpo Exp base_JRPO updates 7626/100000000000.0 steps in 87.17
total episode rewards is -20.0
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'value_loss': 0.3652346306977173, '_timestamp': 1721929558.1246462}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'policy_loss': -0.00011280376764868076, '_timestamp': 1721929558.1248686}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.2011395874619484, '_timestamp': 1721929558.1249368}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05687624588608742, '_timestamp': 1721929558.1250434}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.28453561663627625, '_timestamp': 1721929558.1252885}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'ratio': 0.7946163415908813, '_timestamp': 1721929558.1260278}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721929558.1262665}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929558.1304395}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.16950416564941, '_timestamp': 1721929558.130506}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3196413074920451, '_timestamp': 1721929558.1316435}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'train_goal': 0.34017934625397744, '_timestamp': 1721929558.1323845}).
wandb: WARNING (User provided step: 7626 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3196413074920451, '_timestamp': 1721929558.1330643}).
Env Football Algo jrpo Exp base_JRPO updates 9934/100000000000.0 steps in 84.57
total episode rewards is 0.0
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'value_loss': 0.2527926678179453, '_timestamp': 1721929642.7024717}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'policy_loss': 0.007904402777639916, '_timestamp': 1721929642.702641}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5719955326120059, '_timestamp': 1721929642.7027075}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.03414582833647728, '_timestamp': 1721929642.7027998}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.47209635376930237, '_timestamp': 1721929642.7030535}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'ratio': 0.5528653860092163, '_timestamp': 1721929642.7031555}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721929642.703482}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929642.703574}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.56833624839783, '_timestamp': 1721929642.7036304}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3379392025266482, '_timestamp': 1721929642.7041569}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'train_goal': 0.6689696012633242, '_timestamp': 1721929642.704492}).
wandb: WARNING (User provided step: 9934 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3379392025266482, '_timestamp': 1721929642.704955}).
Env Football Algo jrpo Exp base_JRPO updates 695/100000000000.0 steps in 25.92
total episode rewards is 10.0
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'value_loss': 0.6005336521317561, '_timestamp': 1721929668.6247308}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0021397673928489286, '_timestamp': 1721929668.6249738}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.06677800533963212, '_timestamp': 1721929668.6250482}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.010785697028040886, '_timestamp': 1721929668.6251874}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.3773895502090454, '_timestamp': 1721929668.6254663}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'ratio': 0.9510919451713562, '_timestamp': 1721929668.6263375}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721929668.6264927}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929668.6265965}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'Episode_Time': 25.918710470199585, '_timestamp': 1721929668.626656}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.8925373134328358, '_timestamp': 1721929668.62699}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'train_goal': 0.9462686567164179, '_timestamp': 1721929668.6271527}).
wandb: WARNING (User provided step: 695 is less than current step: 14326. Dropping entry: {'train_WDL': 0.8925373134328358, '_timestamp': 1721929668.6272962}).
Env Football Algo jrpo Exp base_JRPO updates 10547/100000000000.0 steps in 88.30
total episode rewards is 20.0
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'value_loss': 0.25005042489715074, '_timestamp': 1721929756.9276452}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'policy_loss': 0.005345760766310074, '_timestamp': 1721929756.9278526}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.678210490445296, '_timestamp': 1721929756.9279213}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.15442942082881927, '_timestamp': 1721929756.9280825}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.26614147424697876, '_timestamp': 1721929756.9283462}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'ratio': 0.4893994629383087, '_timestamp': 1721929756.928448}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721929756.9287202}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929756.9288113}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.29952335357666, '_timestamp': 1721929756.92887}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.6927913766000449, '_timestamp': 1721929756.9294043}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'train_goal': 0.8463956883000224, '_timestamp': 1721929756.929713}).
wandb: WARNING (User provided step: 10547 is less than current step: 14326. Dropping entry: {'train_WDL': 0.6927913766000449, '_timestamp': 1721929756.9300134}).
Env Football Algo jrpo Exp base_JRPO updates 8234/100000000000.0 steps in 87.64
total episode rewards is -20.0
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'value_loss': 0.28006949365643474, '_timestamp': 1721929844.5700028}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'policy_loss': -0.0010641177891132733, '_timestamp': 1721929844.5701652}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.5351249754428864, '_timestamp': 1721929844.5702329}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.021093115210533142, '_timestamp': 1721929844.5703242}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2246534824371338, '_timestamp': 1721929844.5705738}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'ratio': 0.699847400188446, '_timestamp': 1721929844.5709252}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721929844.5710618}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929844.5711553}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.63924717903137, '_timestamp': 1721929844.5712116}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.8613656517883536, '_timestamp': 1721929844.5717561}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'train_goal': 0.06931717410582323, '_timestamp': 1721929844.57219}).
wandb: WARNING (User provided step: 8234 is less than current step: 14326. Dropping entry: {'train_WDL': -0.8613656517883536, '_timestamp': 1721929844.5726216}).
Env Football Algo jrpo Exp base_JRPO updates 2885/100000000000.0 steps in 40.45
total episode rewards is -10.0
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'value_loss': 0.778266040806969, '_timestamp': 1721929885.0211313}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'policy_loss': -0.004531712249348251, '_timestamp': 1721929885.0213358}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.37023253420988717, '_timestamp': 1721929885.0214198}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.004519675858318806, '_timestamp': 1721929885.021523}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.168620228767395, '_timestamp': 1721929885.021813}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'ratio': 0.7924813628196716, '_timestamp': 1721929885.0219436}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721929885.0228214}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929885.0229282}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'Episode_Time': 40.44761085510254, '_timestamp': 1721929885.022987}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.14556962025316456, '_timestamp': 1721929885.0233908}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'train_goal': 0.4272151898734177, '_timestamp': 1721929885.0236495}).
wandb: WARNING (User provided step: 2885 is less than current step: 14326. Dropping entry: {'train_WDL': -0.14556962025316456, '_timestamp': 1721929885.0239096}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'value_loss': 0.6482233190598587, '_timestamp': 1721929955.4517155}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01610379364001953, '_timestamp': 1721929955.451987}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.3916741329431534, '_timestamp': 1721929955.4520595}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.06868376582860947, '_timestamp': 1721929955.4522345}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9722642302513123, '_timestamp': 1721929955.4524977}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'ratio': 0.8578768968582153, '_timestamp': 1721929955.4526002}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721929955.4530225}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721929955.4531188}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'Episode_Time': 70.42270946502686, '_timestamp': 1721929955.4531775}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.05268000920174833, '_timestamp': 1721929955.4538589}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'train_goal': 0.47365999539912584, '_timestamp': 1721929955.4541786}).
wandb: WARNING (User provided step: 6243 is less than current step: 14326. Dropping entry: {'train_WDL': -0.05268000920174833, '_timestamp': 1721929955.4544866}).
Env Football Algo jrpo Exp base_JRPO updates 6243/100000000000.0 steps in 70.42
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 9227/100000000000.0 steps in 83.90
total episode rewards is -30.0
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'value_loss': 0.19762853815850878, '_timestamp': 1721930039.3573472}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'policy_loss': -0.010263282730278055, '_timestamp': 1721930039.358591}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.1309375741208593, '_timestamp': 1721930039.3586633}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.016904054209589958, '_timestamp': 1721930039.3591332}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.12836426496505737, '_timestamp': 1721930039.3594713}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'ratio': 0.8458657264709473, '_timestamp': 1721930039.3595784}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721930039.3597124}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930039.360651}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'Episode_Time': 83.89697003364563, '_timestamp': 1721930039.3607137}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930039.361607}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930039.3620317}).
wandb: WARNING (User provided step: 9227 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930039.3624277}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'value_loss': 0.28075755900732474, '_timestamp': 1721930130.4517727}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'policy_loss': -0.01605209624278359, '_timestamp': 1721930130.4519722}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.19196849212050437, '_timestamp': 1721930130.452041}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0063623390160501, '_timestamp': 1721930130.4521375}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.21358849108219147, '_timestamp': 1721930130.4524055}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'ratio': 0.7535496354103088, '_timestamp': 1721930130.4525092}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721930130.452641}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930130.453238}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.08841228485107, '_timestamp': 1721930130.4532993}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.0073302469135802465, '_timestamp': 1721930130.4542387}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'train_goal': 0.4963348765432099, '_timestamp': 1721930130.4548602}).
wandb: WARNING (User provided step: 4632 is less than current step: 14326. Dropping entry: {'train_WDL': -0.0073302469135802465, '_timestamp': 1721930130.4554636}).
Env Football Algo jrpo Exp base_JRPO updates 4632/100000000000.0 steps in 91.09
total episode rewards is 0.0
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'value_loss': 0.2632012453937205, '_timestamp': 1721930222.1653385}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'policy_loss': -0.018270997789998848, '_timestamp': 1721930222.1655273}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.16787963731835287, '_timestamp': 1721930222.1656024}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.05926944315433502, '_timestamp': 1721930222.165699}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1896405965089798, '_timestamp': 1721930222.1659489}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'ratio': 0.7141419053077698, '_timestamp': 1721930222.1660638}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721930222.1662846}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930222.1664193}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.7085931301117, '_timestamp': 1721930222.1664803}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.3405716818081099, '_timestamp': 1721930222.1673229}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'train_goal': 0.32971415909594504, '_timestamp': 1721930222.167868}).
wandb: WARNING (User provided step: 5974 is less than current step: 14326. Dropping entry: {'train_WDL': -0.3405716818081099, '_timestamp': 1721930222.1686463}).
Env Football Algo jrpo Exp base_JRPO updates 5974/100000000000.0 steps in 91.71
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 7806/100000000000.0 steps in 82.81
total episode rewards is 30.0
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'value_loss': 0.36089213226378586, '_timestamp': 1721930304.9826386}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'policy_loss': 0.004686105356280071, '_timestamp': 1721930304.9828277}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.4143638239304225, '_timestamp': 1721930304.9828982}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.09026366472244263, '_timestamp': 1721930304.9829996}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4304729700088501, '_timestamp': 1721930304.9833033}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'ratio': 0.6840802431106567, '_timestamp': 1721930304.9834132}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721930304.98361}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930304.9841917}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.81293678283691, '_timestamp': 1721930304.9842522}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.9996398991717681, '_timestamp': 1721930304.985059}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'train_goal': 0.999819949585884, '_timestamp': 1721930304.985434}).
wandb: WARNING (User provided step: 7806 is less than current step: 14326. Dropping entry: {'train_WDL': 0.9996398991717681, '_timestamp': 1721930304.9858012}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'value_loss': 0.2144428580578339, '_timestamp': 1721930384.234033}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'policy_loss': -0.01689079907819784, '_timestamp': 1721930384.235355}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.6013147064050038, '_timestamp': 1721930384.235426}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.011874455027282238, '_timestamp': 1721930384.2359383}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.15023380517959595, '_timestamp': 1721930384.2363193}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'ratio': 0.5717414617538452, '_timestamp': 1721930384.2364254}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721930384.2371392}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930384.2373528}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'Episode_Time': 79.24183201789856, '_timestamp': 1721930384.2374141}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.27292954264524105, '_timestamp': 1721930384.2384756}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'train_goal': 0.3635352286773795, '_timestamp': 1721930384.2389948}).
wandb: WARNING (User provided step: 6910 is less than current step: 14326. Dropping entry: {'train_WDL': -0.27292954264524105, '_timestamp': 1721930384.2394888}).
Env Football Algo jrpo Exp base_JRPO updates 6910/100000000000.0 steps in 79.24
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 8468/100000000000.0 steps in 89.47
total episode rewards is -10.0
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'value_loss': 0.2124835515769276, '_timestamp': 1721930473.7120554}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01346514839916684, '_timestamp': 1721930473.712248}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.0553490817546844, '_timestamp': 1721930473.712318}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.023608887568116188, '_timestamp': 1721930473.71242}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7830553650856018, '_timestamp': 1721930473.7126894}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'ratio': 0.4487285912036896, '_timestamp': 1721930473.7127955}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721930473.7129302}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930473.7132404}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.4715690612793, '_timestamp': 1721930473.7133033}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.27801592161665645, '_timestamp': 1721930473.7138581}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'train_goal': 0.3609920391916718, '_timestamp': 1721930473.7144701}).
wandb: WARNING (User provided step: 8468 is less than current step: 14326. Dropping entry: {'train_WDL': -0.27801592161665645, '_timestamp': 1721930473.7148895}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'value_loss': 0.28666819996549747, '_timestamp': 1721930562.7102883}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01647689060579675, '_timestamp': 1721930562.711724}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9907100923856099, '_timestamp': 1721930562.7118}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.04140881076455116, '_timestamp': 1721930562.712354}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3834511339664459, '_timestamp': 1721930562.7127523}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'ratio': 0.5904262065887451, '_timestamp': 1721930562.7128665}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721930562.7130117}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930562.71323}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.98925423622131, '_timestamp': 1721930562.7142582}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.4252643294379521, '_timestamp': 1721930562.7155397}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'train_goal': 0.28736783528102394, '_timestamp': 1721930562.7161536}).
wandb: WARNING (User provided step: 6015 is less than current step: 14326. Dropping entry: {'train_WDL': -0.4252643294379521, '_timestamp': 1721930562.7167294}).
Env Football Algo jrpo Exp base_JRPO updates 6015/100000000000.0 steps in 88.99
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 5759/100000000000.0 steps in 63.42
total episode rewards is -70.0
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'value_loss': 0.5713363716891036, '_timestamp': 1721930626.1346252}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03127993920012765, '_timestamp': 1721930626.1347942}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9717409789562226, '_timestamp': 1721930626.1348615}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.0805283784866333, '_timestamp': 1721930626.1349535}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9234837293624878, '_timestamp': 1721930626.1351995}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'ratio': 0.5961549282073975, '_timestamp': 1721930626.1353128}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721930626.1356833}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930626.13578}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'Episode_Time': 63.417041063308716, '_timestamp': 1721930626.135838}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930626.1363463}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930626.1367276}).
wandb: WARNING (User provided step: 5759 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930626.1371071}).
Env Football Algo jrpo Exp base_JRPO updates 5494/100000000000.0 steps in 94.72
total episode rewards is -40.0
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'value_loss': 0.28105495651795837, '_timestamp': 1721930720.8603227}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0853192985212081, '_timestamp': 1721930720.860494}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'dist_entropy': 0.9689843714237213, '_timestamp': 1721930720.8605607}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.07800203561782837, '_timestamp': 1721930720.8606586}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3163769245147705, '_timestamp': 1721930720.860992}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'ratio': 0.43369776010513306, '_timestamp': 1721930720.8610988}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721930720.8615053}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930720.8615985}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'Episode_Time': 94.72240948677063, '_timestamp': 1721930720.8616557}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930720.8623593}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930720.8629138}).
wandb: WARNING (User provided step: 5494 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930720.863799}).
Env Football Algo jrpo Exp base_JRPO updates 8862/100000000000.0 steps in 89.03
total episode rewards is -30.0
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'value_loss': 0.20664652501388142, '_timestamp': 1721930809.8966897}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05047091453879451, '_timestamp': 1721930809.8968542}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9669455178578694, '_timestamp': 1721930809.8969214}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2132771909236908, '_timestamp': 1721930809.8970115}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3991363048553467, '_timestamp': 1721930809.897216}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'ratio': 0.4599018096923828, '_timestamp': 1721930809.89742}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721930809.8975496}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930809.8976417}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.03200030326843, '_timestamp': 1721930809.897701}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930809.8982074}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930809.8986084}).
wandb: WARNING (User provided step: 8862 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930809.899205}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'value_loss': 0.3305259144321705, '_timestamp': 1721930878.733421}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01032539803457136, '_timestamp': 1721930878.7336123}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.099441700776418, '_timestamp': 1721930878.7336812}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4023003578186035, '_timestamp': 1721930878.7337832}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3557501435279846, '_timestamp': 1721930878.7340615}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'ratio': 0.37629738450050354, '_timestamp': 1721930878.7348182}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721930878.734964}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930878.7350616}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'Episode_Time': 68.83315467834473, '_timestamp': 1721930878.735121}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930878.735773}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930878.736207}).
wandb: WARNING (User provided step: 5840 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930878.7366292}).
Env Football Algo jrpo Exp base_JRPO updates 5840/100000000000.0 steps in 68.83
total episode rewards is -50.0
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'value_loss': 0.523109617959708, '_timestamp': 1721930937.109915}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08685914795612916, '_timestamp': 1721930937.110091}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0188988788922626, '_timestamp': 1721930937.1101573}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2782442569732666, '_timestamp': 1721930937.1102514}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9324164986610413, '_timestamp': 1721930937.1104867}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'ratio': 0.49948781728744507, '_timestamp': 1721930937.1105888}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721930937.1108866}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721930937.1109803}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'Episode_Time': 58.37246751785278, '_timestamp': 1721930937.1110396}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721930937.1113636}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721930937.1115832}).
wandb: WARNING (User provided step: 5239 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721930937.1117961}).
Env Football Algo jrpo Exp base_JRPO updates 5239/100000000000.0 steps in 58.37
total episode rewards is -80.0
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'value_loss': 0.13902434836568622, '_timestamp': 1721931018.4834316}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0010014569945633411, '_timestamp': 1721931018.483651}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.284426104227702, '_timestamp': 1721931018.483719}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22726871073246002, '_timestamp': 1721931018.4838183}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3505914807319641, '_timestamp': 1721931018.4840894}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'ratio': 0.5328506231307983, '_timestamp': 1721931018.484339}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721931018.484495}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931018.4846146}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'Episode_Time': 81.3705804347992, '_timestamp': 1721931018.4846728}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931018.4850266}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931018.4852364}).
wandb: WARNING (User provided step: 12733 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931018.4854367}).
Env Football Algo jrpo Exp base_JRPO updates 12733/100000000000.0 steps in 81.37
total episode rewards is -20.0
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'value_loss': 0.19365581299178303, '_timestamp': 1721931106.9009972}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'policy_loss': 0.006471959489863366, '_timestamp': 1721931106.9024024}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0743271652857462, '_timestamp': 1721931106.9026473}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.39265531301498413, '_timestamp': 1721931106.9031982}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3326174020767212, '_timestamp': 1721931106.9036708}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'ratio': 0.37414219975471497, '_timestamp': 1721931106.903791}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721931106.904481}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931106.9046974}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.40853762626648, '_timestamp': 1721931106.904757}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931106.9054756}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931106.905681}).
wandb: WARNING (User provided step: 12779 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931106.9058836}).
Env Football Algo jrpo Exp base_JRPO updates 12779/100000000000.0 steps in 88.41
total episode rewards is -30.0
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'value_loss': 0.3530946604162455, '_timestamp': 1721931195.7167258}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'policy_loss': -0.002584659114169578, '_timestamp': 1721931195.7170048}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9943532419204713, '_timestamp': 1721931195.7170818}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.771492600440979, '_timestamp': 1721931195.717179}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.16447103023529053, '_timestamp': 1721931195.7174385}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'ratio': 0.7406435608863831, '_timestamp': 1721931195.7179472}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721931195.7180965}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931195.7181897}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.80948781967163, '_timestamp': 1721931195.7182477}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.614245480148996, '_timestamp': 1721931195.7193744}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'train_goal': 0.807122740074498, '_timestamp': 1721931195.72012}).
wandb: WARNING (User provided step: 3993 is less than current step: 14326. Dropping entry: {'train_WDL': 0.614245480148996, '_timestamp': 1721931195.7207892}).
Env Football Algo jrpo Exp base_JRPO updates 3993/100000000000.0 steps in 88.81
total episode rewards is 20.0
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'value_loss': 0.16795176674922307, '_timestamp': 1721931283.1877997}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'policy_loss': -0.018817749263059038, '_timestamp': 1721931283.188155}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9423159225781759, '_timestamp': 1721931283.188228}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7017151117324829, '_timestamp': 1721931283.1883595}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.21403633058071136, '_timestamp': 1721931283.188641}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'ratio': 0.2045203447341919, '_timestamp': 1721931283.1887467}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721931283.1895475}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931283.189682}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.46533966064453, '_timestamp': 1721931283.1897428}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721931283.1904917}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721931283.190738}).
wandb: WARNING (User provided step: 12120 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721931283.1909783}).
Env Football Algo jrpo Exp base_JRPO updates 12120/100000000000.0 steps in 87.47
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 4996/100000000000.0 steps in 54.96
total episode rewards is 0.0
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'value_loss': 0.6123420340567827, '_timestamp': 1721931338.154643}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'policy_loss': 0.026519240736573312, '_timestamp': 1721931338.154803}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9143018134435017, '_timestamp': 1721931338.1548674}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8364195227622986, '_timestamp': 1721931338.1549568}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.084604263305664, '_timestamp': 1721931338.155204}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'ratio': 0.6695938110351562, '_timestamp': 1721931338.1554613}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931338.1555946}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931338.1556833}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'Episode_Time': 54.962559938430786, '_timestamp': 1721931338.1557393}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.365891877774876, '_timestamp': 1721931338.1561365}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'train_goal': 0.317054061112562, '_timestamp': 1721931338.1564214}).
wandb: WARNING (User provided step: 4996 is less than current step: 14326. Dropping entry: {'train_WDL': -0.365891877774876, '_timestamp': 1721931338.1567054}).
Env Football Algo jrpo Exp base_JRPO updates 2975/100000000000.0 steps in 42.33
total episode rewards is 0.0
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'value_loss': 1.133492399106423, '_timestamp': 1721931380.4847257}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'policy_loss': 0.01853026749061731, '_timestamp': 1721931380.4848943}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8965947731335957, '_timestamp': 1721931380.4849603}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 1.1563574075698853, '_timestamp': 1721931380.4850528}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.6380279064178467, '_timestamp': 1721931380.4853048}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'ratio': 0.8146972060203552, '_timestamp': 1721931380.4854026}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931380.4855332}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931380.4856253}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'Episode_Time': 42.326931953430176, '_timestamp': 1721931380.4856813}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.36087636932707357, '_timestamp': 1721931380.486049}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'train_goal': 0.6804381846635368, '_timestamp': 1721931380.4862936}).
wandb: WARNING (User provided step: 2975 is less than current step: 14326. Dropping entry: {'train_WDL': 0.36087636932707357, '_timestamp': 1721931380.4865346}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'value_loss': 0.5862536577135324, '_timestamp': 1721931453.0778363}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'policy_loss': -0.013850941362810166, '_timestamp': 1721931453.0779953}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8877139035860697, '_timestamp': 1721931453.0780592}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.9289488196372986, '_timestamp': 1721931453.0781453}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7705652117729187, '_timestamp': 1721931453.0783987}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'ratio': 0.6216035485267639, '_timestamp': 1721931453.0784984}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721931453.0788167}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931453.0789082}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'Episode_Time': 72.59040093421936, '_timestamp': 1721931453.0789635}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.20655513827244792, '_timestamp': 1721931453.0795138}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'train_goal': 0.396722430863776, '_timestamp': 1721931453.0798903}).
wandb: WARNING (User provided step: 5822 is less than current step: 14326. Dropping entry: {'train_WDL': -0.20655513827244792, '_timestamp': 1721931453.0802891}).
Env Football Algo jrpo Exp base_JRPO updates 5822/100000000000.0 steps in 72.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'value_loss': 0.5201013201475143, '_timestamp': 1721931531.8058643}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'policy_loss': 0.00738612190374018, '_timestamp': 1721931531.806031}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8975673198699952, '_timestamp': 1721931531.8060963}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6975041031837463, '_timestamp': 1721931531.8061855}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.6569014191627502, '_timestamp': 1721931531.8064306}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'ratio': 0.6156212687492371, '_timestamp': 1721931531.8065324}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721931531.806776}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931531.8068676}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'Episode_Time': 78.72460865974426, '_timestamp': 1721931531.8069246}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.35989079175974187, '_timestamp': 1721931531.807551}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'train_goal': 0.32005460412012904, '_timestamp': 1721931531.808034}).
wandb: WARNING (User provided step: 4972 is less than current step: 14326. Dropping entry: {'train_WDL': -0.35989079175974187, '_timestamp': 1721931531.8085248}).
Env Football Algo jrpo Exp base_JRPO updates 4972/100000000000.0 steps in 78.72
total episode rewards is -50.0
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'value_loss': 0.3362134167800347, '_timestamp': 1721931613.2591002}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03862521723795605, '_timestamp': 1721931613.2593117}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.147857931057612, '_timestamp': 1721931613.2593799}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.9318035840988159, '_timestamp': 1721931613.2594786}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.4251701831817627, '_timestamp': 1721931613.259741}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'ratio': 0.45915940403938293, '_timestamp': 1721931613.2601826}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931613.2604265}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931613.260523}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'Episode_Time': 81.4496476650238, '_timestamp': 1721931613.2605805}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.20904676718630208, '_timestamp': 1721931613.2613432}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'train_goal': 0.39547661640684895, '_timestamp': 1721931613.261836}).
wandb: WARNING (User provided step: 7174 is less than current step: 14326. Dropping entry: {'train_WDL': -0.20904676718630208, '_timestamp': 1721931613.262319}).
Env Football Algo jrpo Exp base_JRPO updates 7174/100000000000.0 steps in 81.45
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 8306/100000000000.0 steps in 91.91
total episode rewards is -10.0
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'value_loss': 0.3139307370285193, '_timestamp': 1721931705.1736684}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04798106287989261, '_timestamp': 1721931705.175023}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.662385811805725, '_timestamp': 1721931705.175098}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8614335060119629, '_timestamp': 1721931705.1753683}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2267504185438156, '_timestamp': 1721931705.175687}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'ratio': 0.4731290340423584, '_timestamp': 1721931705.1757944}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721931705.1765974}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931705.1767416}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'Episode_Time': 91.90556240081787, '_timestamp': 1721931705.1768012}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1096504332237825, '_timestamp': 1721931705.177569}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'train_goal': 0.44517478338810873, '_timestamp': 1721931705.1780531}).
wandb: WARNING (User provided step: 8306 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1096504332237825, '_timestamp': 1721931705.1784785}).
Env Football Algo jrpo Exp base_JRPO updates 3173/100000000000.0 steps in 39.98
total episode rewards is -90.0
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'value_loss': 0.8481904957195123, '_timestamp': 1721931745.1611648}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'policy_loss': 0.013621776534613066, '_timestamp': 1721931745.1614769}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9915365147590638, '_timestamp': 1721931745.16155}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.8458932042121887, '_timestamp': 1721931745.1617308}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.152726650238037, '_timestamp': 1721931745.1621008}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'ratio': 0.5540181994438171, '_timestamp': 1721931745.1627915}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721931745.1629772}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931745.1631415}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'Episode_Time': 39.98125767707825, '_timestamp': 1721931745.1632016}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1998708427510494, '_timestamp': 1721931745.1637752}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'train_goal': 0.4000645786244753, '_timestamp': 1721931745.1675177}).
wandb: WARNING (User provided step: 3173 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1998708427510494, '_timestamp': 1721931745.1678548}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'value_loss': 0.25493076919578017, '_timestamp': 1721931836.156412}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03970948321667189, '_timestamp': 1721931836.1566591}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0748141256968182, '_timestamp': 1721931836.1567252}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.7832596302032471, '_timestamp': 1721931836.1568224}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2862631380558014, '_timestamp': 1721931836.1570773}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'ratio': 0.9788170456886292, '_timestamp': 1721931836.1572897}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721931836.1574259}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931836.1575215}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.98699474334717, '_timestamp': 1721931836.1575785}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721931836.158842}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721931836.1593869}).
wandb: WARNING (User provided step: 6190 is less than current step: 14326. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721931836.159903}).
Env Football Algo jrpo Exp base_JRPO updates 6190/100000000000.0 steps in 90.99
total episode rewards is 30.0
Env Football Algo jrpo Exp base_JRPO updates 10806/100000000000.0 steps in 86.23
total episode rewards is 0.0
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'value_loss': 0.1422677053359803, '_timestamp': 1721931922.3951278}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'policy_loss': 0.018517983254860156, '_timestamp': 1721931922.395304}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.1429136848449706, '_timestamp': 1721931922.3953705}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.597080409526825, '_timestamp': 1721931922.3954678}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.22108083963394165, '_timestamp': 1721931922.3959138}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'ratio': 0.9512119889259338, '_timestamp': 1721931922.3960364}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721931922.3961687}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721931922.3962598}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.23396301269531, '_timestamp': 1721931922.3963177}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.4220314735336195, '_timestamp': 1721931922.3968399}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'train_goal': 0.7110157367668097, '_timestamp': 1721931922.397149}).
wandb: WARNING (User provided step: 10806 is less than current step: 14326. Dropping entry: {'train_WDL': 0.4220314735336195, '_timestamp': 1721931922.3974595}).
Env Football Algo jrpo Exp base_JRPO updates 7261/100000000000.0 steps in 87.35
total episode rewards is -20.0
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'value_loss': 0.32512002148432656, '_timestamp': 1721932009.7491386}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'policy_loss': 0.013205032750653723, '_timestamp': 1721932009.7493072}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0768194723129274, '_timestamp': 1721932009.7493742}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6153777241706848, '_timestamp': 1721932009.7494652}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.31413811445236206, '_timestamp': 1721932009.7497156}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'ratio': 0.9448606371879578, '_timestamp': 1721932009.750137}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932009.7502804}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932009.7503743}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.35061407089233, '_timestamp': 1721932009.7504323}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.23168368006202353, '_timestamp': 1721932009.7510777}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'train_goal': 0.3841581599689882, '_timestamp': 1721932009.7515595}).
wandb: WARNING (User provided step: 7261 is less than current step: 14326. Dropping entry: {'train_WDL': -0.23168368006202353, '_timestamp': 1721932009.7520614}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'value_loss': 0.9325680908560753, '_timestamp': 1721932060.7553804}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06474021938527585, '_timestamp': 1721932060.7555645}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7474881505966187, '_timestamp': 1721932060.755633}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.436029314994812, '_timestamp': 1721932060.755738}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.5480207204818726, '_timestamp': 1721932060.756046}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'ratio': 1.0685930252075195, '_timestamp': 1721932060.7561572}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721932060.7562935}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932060.7563899}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'Episode_Time': 51.002257108688354, '_timestamp': 1721932060.7564473}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.36321195144724555, '_timestamp': 1721932060.7570922}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'train_goal': 0.3183940242763772, '_timestamp': 1721932060.7575512}).
wandb: WARNING (User provided step: 2656 is less than current step: 14326. Dropping entry: {'train_WDL': -0.36321195144724555, '_timestamp': 1721932060.757865}).
Env Football Algo jrpo Exp base_JRPO updates 2656/100000000000.0 steps in 51.00
total episode rewards is -90.0
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'value_loss': 0.7903500149895748, '_timestamp': 1721932114.0971959}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08867989891363928, '_timestamp': 1721932114.098619}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.5253111990292867, '_timestamp': 1721932114.0986922}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.252308189868927, '_timestamp': 1721932114.0992343}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1204922199249268, '_timestamp': 1721932114.0996032}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'ratio': 0.5980355739593506, '_timestamp': 1721932114.1003215}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721932114.1004667}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932114.1006966}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'Episode_Time': 53.332696199417114, '_timestamp': 1721932114.1007562}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932114.1015692}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932114.1018426}).
wandb: WARNING (User provided step: 5831 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932114.1021137}).
Env Football Algo jrpo Exp base_JRPO updates 5831/100000000000.0 steps in 53.33
total episode rewards is -100.0
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'value_loss': 0.14493175948271528, '_timestamp': 1721932203.2293816}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03589727175121273, '_timestamp': 1721932203.2296028}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6345886890093486, '_timestamp': 1721932203.2296755}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.33657780289649963, '_timestamp': 1721932203.2298105}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1592589169740677, '_timestamp': 1721932203.230075}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'ratio': 0.9992015957832336, '_timestamp': 1721932203.230181}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932203.2306411}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932203.230739}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'Episode_Time': 89.1261739730835, '_timestamp': 1721932203.2307975}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932203.2318149}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932203.2322826}).
wandb: WARNING (User provided step: 9736 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932203.2329135}).
Env Football Algo jrpo Exp base_JRPO updates 9736/100000000000.0 steps in 89.13
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6516/100000000000.0 steps in 88.78
total episode rewards is -40.0
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'value_loss': 0.28392150047254594, '_timestamp': 1721932292.0161386}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03229493840713985, '_timestamp': 1721932292.01721}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7872999858856202, '_timestamp': 1721932292.0172825}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.602223813533783, '_timestamp': 1721932292.0176678}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.23855295777320862, '_timestamp': 1721932292.017996}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'ratio': 0.8337202668190002, '_timestamp': 1721932292.0181062}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721932292.0188022}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932292.0190053}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.77817606925964, '_timestamp': 1721932292.0190644}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932292.0200438}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932292.0205626}).
wandb: WARNING (User provided step: 6516 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932292.0210903}).
Env Football Algo jrpo Exp base_JRPO updates 8389/100000000000.0 steps in 82.15
total episode rewards is -30.0
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'value_loss': 0.2154450642146791, '_timestamp': 1721932374.1689243}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'policy_loss': 0.037638764269455956, '_timestamp': 1721932374.1691902}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7915457638104757, '_timestamp': 1721932374.1692579}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.33668941259384155, '_timestamp': 1721932374.1693847}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.39170968532562256, '_timestamp': 1721932374.1696527}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'ratio': 0.9747155904769897, '_timestamp': 1721932374.1697557}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721932374.1702144}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932374.170337}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.14675831794739, '_timestamp': 1721932374.1703932}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932374.171154}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932374.171647}).
wandb: WARNING (User provided step: 8389 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932374.1722198}).
Env Football Algo jrpo Exp base_JRPO updates 6861/100000000000.0 steps in 85.92
total episode rewards is -40.0
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'value_loss': 0.29939285503894403, '_timestamp': 1721932460.0971317}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02776641912913571, '_timestamp': 1721932460.0973954}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7791505980491638, '_timestamp': 1721932460.0974681}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3891791105270386, '_timestamp': 1721932460.0976021}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2897071838378906, '_timestamp': 1721932460.0978847}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'ratio': 1.0209122896194458, '_timestamp': 1721932460.097993}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721932460.0981243}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932460.0989208}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.92382669448853, '_timestamp': 1721932460.0989802}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932460.0996842}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932460.1002223}).
wandb: WARNING (User provided step: 6861 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932460.1007516}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'value_loss': 0.20266853590340664, '_timestamp': 1721932546.8512707}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03382385606896909, '_timestamp': 1721932546.8515415}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7565754437446595, '_timestamp': 1721932546.85161}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3207882046699524, '_timestamp': 1721932546.8517091}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.31161201000213623, '_timestamp': 1721932546.8519332}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'ratio': 1.2461143732070923, '_timestamp': 1721932546.852061}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721932546.8521895}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932546.852285}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.74868869781494, '_timestamp': 1721932546.8523414}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932546.8529348}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932546.8533578}).
wandb: WARNING (User provided step: 8913 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932546.853766}).
Env Football Algo jrpo Exp base_JRPO updates 8913/100000000000.0 steps in 86.75
total episode rewards is -30.0
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'value_loss': 0.2100100767269032, '_timestamp': 1721932625.1065834}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02983500236178164, '_timestamp': 1721932625.1079576}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8381424570083618, '_timestamp': 1721932625.108032}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.22845570743083954, '_timestamp': 1721932625.1085713}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.29430532455444336, '_timestamp': 1721932625.1089342}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'ratio': 0.924706757068634, '_timestamp': 1721932625.1090388}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721932625.1091762}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932625.1100113}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'Episode_Time': 78.24636030197144, '_timestamp': 1721932625.110075}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932625.1110115}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932625.1113932}).
wandb: WARNING (User provided step: 9682 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932625.1117826}).
Env Football Algo jrpo Exp base_JRPO updates 9682/100000000000.0 steps in 78.25
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7644/100000000000.0 steps in 86.77
total episode rewards is -40.0
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'value_loss': 0.2843213356367778, '_timestamp': 1721932711.8867543}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'policy_loss': 0.03721252525661839, '_timestamp': 1721932711.886972}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8830452307065328, '_timestamp': 1721932711.8870418}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.39597439765930176, '_timestamp': 1721932711.8871431}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3055150806903839, '_timestamp': 1721932711.8874087}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'ratio': 0.9610406756401062, '_timestamp': 1721932711.8875148}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721932711.888168}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932711.8882701}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'Episode_Time': 86.77405905723572, '_timestamp': 1721932711.88833}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932711.8894215}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932711.8899212}).
wandb: WARNING (User provided step: 7644 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932711.8903902}).
Env Football Algo jrpo Exp base_JRPO updates 4093/100000000000.0 steps in 37.98
total episode rewards is -120.0
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'value_loss': 0.7782664240027467, '_timestamp': 1721932749.8719552}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06868877492224176, '_timestamp': 1721932749.8721688}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7597573367754618, '_timestamp': 1721932749.8724117}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.5107079148292542, '_timestamp': 1721932749.8725333}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.531872272491455, '_timestamp': 1721932749.87282}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'ratio': 0.8558288812637329, '_timestamp': 1721932749.8729239}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721932749.873223}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932749.873317}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'Episode_Time': 37.980425119400024, '_timestamp': 1721932749.8733742}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932749.8737178}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932749.8739166}).
wandb: WARNING (User provided step: 4093 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932749.8741105}).
Env Football Algo jrpo Exp base_JRPO updates 8367/100000000000.0 steps in 85.83
total episode rewards is -30.0
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'value_loss': 0.20732661318344375, '_timestamp': 1721932835.7017844}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04655141344216342, '_timestamp': 1721932835.701948}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9423178370793661, '_timestamp': 1721932835.7020144}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3842868506908417, '_timestamp': 1721932835.702105}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.1406935304403305, '_timestamp': 1721932835.7023675}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'ratio': 0.49430981278419495, '_timestamp': 1721932835.7024734}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721932835.7027905}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932835.7028813}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.8269591331482, '_timestamp': 1721932835.702937}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721932835.7035224}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721932835.7039328}).
wandb: WARNING (User provided step: 8367 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721932835.7043765}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'value_loss': 0.3033617302542552, '_timestamp': 1721932923.4136827}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04176714136335553, '_timestamp': 1721932923.413924}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.88819797595342, '_timestamp': 1721932923.4139931}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.30056965351104736, '_timestamp': 1721932923.4141471}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.23781123757362366, '_timestamp': 1721932923.4144049}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'ratio': 0.47638362646102905, '_timestamp': 1721932923.4145076}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721932923.4149249}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932923.415021}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.7082736492157, '_timestamp': 1721932923.4150786}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.19772017912878273, '_timestamp': 1721932923.4158232}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'train_goal': 0.40113991043560865, '_timestamp': 1721932923.4162939}).
wandb: WARNING (User provided step: 7631 is less than current step: 14326. Dropping entry: {'train_WDL': -0.19772017912878273, '_timestamp': 1721932923.4167585}).
Env Football Algo jrpo Exp base_JRPO updates 7631/100000000000.0 steps in 87.71
total episode rewards is -20.0
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'value_loss': 0.8351107357194026, '_timestamp': 1721932968.3809013}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'policy_loss': 0.051599056873577256, '_timestamp': 1721932968.3822012}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.8699329574902852, '_timestamp': 1721932968.3822753}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.30704399943351746, '_timestamp': 1721932968.382757}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.123856782913208, '_timestamp': 1721932968.3830967}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'ratio': 0.49224138259887695, '_timestamp': 1721932968.3832002}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721932968.3839278}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721932968.3841672}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'Episode_Time': 44.95820713043213, '_timestamp': 1721932968.3842258}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.27089478859390365, '_timestamp': 1721932968.385209}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'train_goal': 0.3645526057030482, '_timestamp': 1721932968.385663}).
wandb: WARNING (User provided step: 3472 is less than current step: 14326. Dropping entry: {'train_WDL': -0.27089478859390365, '_timestamp': 1721932968.3860066}).
Env Football Algo jrpo Exp base_JRPO updates 3472/100000000000.0 steps in 44.96
total episode rewards is -80.0
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'value_loss': 0.5278697517731538, '_timestamp': 1721933032.0830424}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05881113720165255, '_timestamp': 1721933032.0832148}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.051865557829539, '_timestamp': 1721933032.083285}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3689276874065399, '_timestamp': 1721933032.0833783}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1025935411453247, '_timestamp': 1721933032.0836205}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'ratio': 0.6992048025131226, '_timestamp': 1721933032.0837295}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721933032.084103}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933032.0842004}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'Episode_Time': 63.696228981018066, '_timestamp': 1721933032.084258}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.6965365585486532, '_timestamp': 1721933032.08464}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'train_goal': 0.15173172072567345, '_timestamp': 1721933032.0849206}).
wandb: WARNING (User provided step: 7427 is less than current step: 14326. Dropping entry: {'train_WDL': -0.6965365585486532, '_timestamp': 1721933032.085191}).
Env Football Algo jrpo Exp base_JRPO updates 7427/100000000000.0 steps in 63.70
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 3892/100000000000.0 steps in 90.31
total episode rewards is 0.0
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'value_loss': 0.32216528213893375, '_timestamp': 1721933122.3959668}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'policy_loss': 0.0711593592876064, '_timestamp': 1721933122.3961952}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.0364765310287476, '_timestamp': 1721933122.3962636}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.46375998854637146, '_timestamp': 1721933122.3964162}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.29078394174575806, '_timestamp': 1721933122.3967423}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'ratio': 0.28468576073646545, '_timestamp': 1721933122.3968456}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721933122.3972049}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933122.397301}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'Episode_Time': 90.3098692893982, '_timestamp': 1721933122.3973587}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.06769895570759812, '_timestamp': 1721933122.3981943}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'train_goal': 0.5338494778537991, '_timestamp': 1721933122.3988237}).
wandb: WARNING (User provided step: 3892 is less than current step: 14326. Dropping entry: {'train_WDL': 0.06769895570759812, '_timestamp': 1721933122.3994536}).
Env Football Algo jrpo Exp base_JRPO updates 6570/100000000000.0 steps in 70.13
total episode rewards is -70.0
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'value_loss': 0.45916367003694175, '_timestamp': 1721933192.531981}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'policy_loss': 0.005611567994734893, '_timestamp': 1721933192.533364}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.285217145284017, '_timestamp': 1721933192.5334344}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.40433064103126526, '_timestamp': 1721933192.5339508}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.7656285762786865, '_timestamp': 1721933192.5343091}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'ratio': 0.5412079691886902, '_timestamp': 1721933192.5347018}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721933192.5350811}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933192.5352964}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'Episode_Time': 70.12632513046265, '_timestamp': 1721933192.535358}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933192.5362277}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933192.5365686}).
wandb: WARNING (User provided step: 6570 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933192.536909}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'value_loss': 0.21958792032014268, '_timestamp': 1721933275.220766}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02366008500898412, '_timestamp': 1721933275.2209363}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2945161485671997, '_timestamp': 1721933275.221003}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3516864478588104, '_timestamp': 1721933275.2210975}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3910825848579407, '_timestamp': 1721933275.2213812}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'ratio': 0.8470182418823242, '_timestamp': 1721933275.2214835}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721933275.222128}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933275.22223}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'Episode_Time': 82.6828339099884, '_timestamp': 1721933275.222286}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.10941017559657812, '_timestamp': 1721933275.2229216}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'train_goal': 0.44529491220171097, '_timestamp': 1721933275.2233715}).
wandb: WARNING (User provided step: 8337 is less than current step: 14326. Dropping entry: {'train_WDL': -0.10941017559657812, '_timestamp': 1721933275.2237875}).
Env Football Algo jrpo Exp base_JRPO updates 8337/100000000000.0 steps in 82.68
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 2641/100000000000.0 steps in 36.62
total episode rewards is -80.0
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'value_loss': 0.6539125480813285, '_timestamp': 1721933311.8409698}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'policy_loss': 0.08955401812369625, '_timestamp': 1721933311.8411283}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.927561226685842, '_timestamp': 1721933311.8411934}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3536270260810852, '_timestamp': 1721933311.8412807}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.9170757532119751, '_timestamp': 1721933311.8415458}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'ratio': 0.8355619311332703, '_timestamp': 1721933311.8418193}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721933311.8419561}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933311.8420477}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'Episode_Time': 36.61643028259277, '_timestamp': 1721933311.8421052}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.20623916811091855, '_timestamp': 1721933311.842394}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'train_goal': 0.6031195840554593, '_timestamp': 1721933311.8425994}).
wandb: WARNING (User provided step: 2641 is less than current step: 14326. Dropping entry: {'train_WDL': 0.20623916811091855, '_timestamp': 1721933311.8427773}).
Env Football Algo jrpo Exp base_JRPO updates 2534/100000000000.0 steps in 37.15
total episode rewards is -70.0
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'value_loss': 0.7318348358199, '_timestamp': 1721933348.9911532}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'policy_loss': 0.053567840403605564, '_timestamp': 1721933348.9913197}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2414947923024497, '_timestamp': 1721933348.9913838}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.2778221070766449, '_timestamp': 1721933348.991476}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.2104731798171997, '_timestamp': 1721933348.9916759}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'ratio': 0.9161890149116516, '_timestamp': 1721933348.9917767}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721933348.9920216}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933348.9921157}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'Episode_Time': 37.14751696586609, '_timestamp': 1721933348.9921727}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.30440587449933243, '_timestamp': 1721933348.9925046}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'train_goal': 0.3477970627503338, '_timestamp': 1721933348.9927442}).
wandb: WARNING (User provided step: 2534 is less than current step: 14326. Dropping entry: {'train_WDL': -0.30440587449933243, '_timestamp': 1721933348.99298}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'value_loss': 0.6493104047576587, '_timestamp': 1721933415.3603609}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04341280750498602, '_timestamp': 1721933415.3605235}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2456677929560342, '_timestamp': 1721933415.3605902}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.40495428442955017, '_timestamp': 1721933415.3606803}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.1558395624160767, '_timestamp': 1721933415.36136}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'ratio': 0.9512912034988403, '_timestamp': 1721933415.3614671}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721933415.361606}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933415.3616982}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'Episode_Time': 66.36644268035889, '_timestamp': 1721933415.361755}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.10339565051507059, '_timestamp': 1721933415.3622537}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'train_goal': 0.4483021747424647, '_timestamp': 1721933415.3626235}).
wandb: WARNING (User provided step: 6568 is less than current step: 14326. Dropping entry: {'train_WDL': -0.10339565051507059, '_timestamp': 1721933415.362973}).
Env Football Algo jrpo Exp base_JRPO updates 6568/100000000000.0 steps in 66.37
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 2464/100000000000.0 steps in 47.62
total episode rewards is -100.0
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'value_loss': 0.6490271326899528, '_timestamp': 1721933462.9807215}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'policy_loss': 0.028600900939200074, '_timestamp': 1721933462.9808998}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.2711575984954835, '_timestamp': 1721933462.9809704}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3837299048900604, '_timestamp': 1721933462.981069}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.8994956612586975, '_timestamp': 1721933462.981335}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'ratio': 0.7052233815193176, '_timestamp': 1721933462.981439}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721933462.9821513}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933462.9822502}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'Episode_Time': 47.61692833900452, '_timestamp': 1721933462.982308}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721933462.9827392}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721933462.9830353}).
wandb: WARNING (User provided step: 2464 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721933462.9833267}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'value_loss': 0.3323832173862805, '_timestamp': 1721933547.4259849}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'policy_loss': 0.054708856496048, '_timestamp': 1721933547.4261537}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.046202396551768, '_timestamp': 1721933547.4262223}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4453543722629547, '_timestamp': 1721933547.426315}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.35819000005722046, '_timestamp': 1721933547.4265769}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'ratio': 0.6982894539833069, '_timestamp': 1721933547.4268787}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721933547.4270165}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933547.4271085}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'Episode_Time': 84.44167375564575, '_timestamp': 1721933547.4271667}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.11226371599815584, '_timestamp': 1721933547.4282074}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'train_goal': 0.44386814200092206, '_timestamp': 1721933547.4291008}).
wandb: WARNING (User provided step: 6324 is less than current step: 14326. Dropping entry: {'train_WDL': -0.11226371599815584, '_timestamp': 1721933547.4331784}).
Env Football Algo jrpo Exp base_JRPO updates 6324/100000000000.0 steps in 84.44
total episode rewards is 0.0
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'value_loss': 0.9811858808994294, '_timestamp': 1721933589.8660805}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'policy_loss': 0.06443230927417365, '_timestamp': 1721933589.8662436}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'dist_entropy': 2.143388348420461, '_timestamp': 1721933589.8663082}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.44780686497688293, '_timestamp': 1721933589.8663962}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.41653573513031, '_timestamp': 1721933589.8666573}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'ratio': 0.6797319054603577, '_timestamp': 1721933589.8668857}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721933589.8670254}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933589.867115}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'Episode_Time': 42.43183779716492, '_timestamp': 1721933589.8671715}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.35721459658520255, '_timestamp': 1721933589.867554}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'train_goal': 0.6786072982926012, '_timestamp': 1721933589.8677897}).
wandb: WARNING (User provided step: 2158 is less than current step: 14326. Dropping entry: {'train_WDL': 0.35721459658520255, '_timestamp': 1721933589.8680654}).
Env Football Algo jrpo Exp base_JRPO updates 2158/100000000000.0 steps in 42.43
total episode rewards is -90.0
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'value_loss': 0.2919974632607773, '_timestamp': 1721933677.8441672}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05423122128937394, '_timestamp': 1721933677.8443868}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6066839321454367, '_timestamp': 1721933677.844459}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.6058048605918884, '_timestamp': 1721933677.844592}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.3122246563434601, '_timestamp': 1721933677.8448725}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'ratio': 0.44092702865600586, '_timestamp': 1721933677.8453732}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721933677.8455145}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933677.8456142}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.97512364387512, '_timestamp': 1721933677.8456757}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.3144076140466032, '_timestamp': 1721933677.8463511}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'train_goal': 0.6572038070233016, '_timestamp': 1721933677.8467774}).
wandb: WARNING (User provided step: 8906 is less than current step: 14326. Dropping entry: {'train_WDL': 0.3144076140466032, '_timestamp': 1721933677.847182}).
Env Football Algo jrpo Exp base_JRPO updates 8906/100000000000.0 steps in 87.98
total episode rewards is 0.0
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'value_loss': 0.44597221637765566, '_timestamp': 1721933753.9027882}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04429869865300134, '_timestamp': 1721933753.9038713}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9482694101333617, '_timestamp': 1721933753.9080052}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.3907009959220886, '_timestamp': 1721933753.9126422}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.5011997818946838, '_timestamp': 1721933753.9130707}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'ratio': 0.5266082286834717, '_timestamp': 1721933753.9131935}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721933753.9142377}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933753.9144475}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'Episode_Time': 76.04413866996765, '_timestamp': 1721933753.9145103}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.1475282210977034, '_timestamp': 1721933753.9156518}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'train_goal': 0.5737641105488517, '_timestamp': 1721933753.9202974}).
wandb: WARNING (User provided step: 3818 is less than current step: 14326. Dropping entry: {'train_WDL': 0.1475282210977034, '_timestamp': 1721933753.9208887}).
Env Football Algo jrpo Exp base_JRPO updates 3818/100000000000.0 steps in 76.04
total episode rewards is -20.0
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'value_loss': 0.681201890061299, '_timestamp': 1721933801.8767078}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04249653208670982, '_timestamp': 1721933801.87694}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.7972321995099385, '_timestamp': 1721933801.8770235}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4197819232940674, '_timestamp': 1721933801.877125}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.0889816284179688, '_timestamp': 1721933801.8774192}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'ratio': 0.8864684104919434, '_timestamp': 1721933801.8775468}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721933801.8783827}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933801.8784976}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'Episode_Time': 47.947060108184814, '_timestamp': 1721933801.8785565}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.36122792262405384, '_timestamp': 1721933801.8808742}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'train_goal': 0.6806139613120269, '_timestamp': 1721933801.881545}).
wandb: WARNING (User provided step: 3509 is less than current step: 14326. Dropping entry: {'train_WDL': 0.36122792262405384, '_timestamp': 1721933801.8819263}).
Env Football Algo jrpo Exp base_JRPO updates 3509/100000000000.0 steps in 47.95
total episode rewards is -40.0
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'value_loss': 0.4169673333386891, '_timestamp': 1721933888.9010572}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'policy_loss': 0.017950773776004403, '_timestamp': 1721933888.9012368}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.9275717584292094, '_timestamp': 1721933888.901304}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.41976022720336914, '_timestamp': 1721933888.9014032}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.47868451476097107, '_timestamp': 1721933888.9016726}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'ratio': 0.9589133858680725, '_timestamp': 1721933888.9017797}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721933888.9019086}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933888.9025292}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'Episode_Time': 87.01805543899536, '_timestamp': 1721933888.9025888}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.03884016466797924, '_timestamp': 1721933888.9038033}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'train_goal': 0.5194200823339896, '_timestamp': 1721933888.9045687}).
wandb: WARNING (User provided step: 3391 is less than current step: 14326. Dropping entry: {'train_WDL': 0.03884016466797924, '_timestamp': 1721933888.905219}).
Env Football Algo jrpo Exp base_JRPO updates 3391/100000000000.0 steps in 87.02
total episode rewards is -30.0
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'value_loss': 0.7897435712814331, '_timestamp': 1721933924.9297872}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'policy_loss': 0.02003264018203481, '_timestamp': 1721933924.9310987}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.817801103591919, '_timestamp': 1721933924.9311705}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.4414708614349365, '_timestamp': 1721933924.931705}).
Env Football Algo jrpo Exp base_JRPO updates 2131/100000000000.0 steps in 36.02
total episode rewards is -30.0
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 1.2636141777038574, '_timestamp': 1721933924.932147}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'ratio': 0.29644063115119934, '_timestamp': 1721933924.9329162}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721933924.933086}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721933924.9338913}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'Episode_Time': 36.018487215042114, '_timestamp': 1721933924.9339614}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.9891339085969958, '_timestamp': 1721933924.9349215}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'train_goal': 0.994566954298498, '_timestamp': 1721933924.93518}).
wandb: WARNING (User provided step: 2131 is less than current step: 14326. Dropping entry: {'train_WDL': 0.9891339085969958, '_timestamp': 1721933924.935428}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'value_loss': 0.21787644640076906, '_timestamp': 1721934010.9307394}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'policy_loss': 0.04107821728568524, '_timestamp': 1721934010.9309413}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.3750622860590618, '_timestamp': 1721934010.9310098}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.446035772562027, '_timestamp': 1721934010.9311383}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.26711151003837585, '_timestamp': 1721934010.9313924}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'ratio': 0.6182048916816711, '_timestamp': 1721934010.9314983}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721934010.9316263}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934010.9319212}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'Episode_Time': 85.99432635307312, '_timestamp': 1721934010.932006}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'train_goal_diff': -0.1821561338289963, '_timestamp': 1721934010.9326468}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'train_goal': 0.40892193308550184, '_timestamp': 1721934010.9331136}).
wandb: WARNING (User provided step: 7737 is less than current step: 14326. Dropping entry: {'train_WDL': -0.1821561338289963, '_timestamp': 1721934010.9335654}).
Env Football Algo jrpo Exp base_JRPO updates 7737/100000000000.0 steps in 85.99
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 4034/100000000000.0 steps in 88.25
total episode rewards is 0.0
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'value_loss': 0.3225182421175608, '_timestamp': 1721934099.1836143}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'policy_loss': 0.014151152283884584, '_timestamp': 1721934099.183838}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.4129812280337015, '_timestamp': 1721934099.1839101}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.43973037600517273, '_timestamp': 1721934099.1840637}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.2154868096113205, '_timestamp': 1721934099.1843438}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'ratio': 0.7545365691184998, '_timestamp': 1721934099.1844523}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721934099.1845865}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934099.1849835}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'Episode_Time': 88.24914193153381, '_timestamp': 1721934099.1850438}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_goal_diff': 0.06620463250045595, '_timestamp': 1721934099.1858423}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_goal': 0.533102316250228, '_timestamp': 1721934099.186476}).
wandb: WARNING (User provided step: 4034 is less than current step: 14326. Dropping entry: {'train_WDL': 0.06620463250045595, '_timestamp': 1721934099.1870723}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'value_loss': 0.27685271320010846, '_timestamp': 1721934180.0143228}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'policy_loss': 0.05956366518027304, '_timestamp': 1721934180.0145183}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'dist_entropy': 1.6502195421854655, '_timestamp': 1721934180.0145864}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'actor_grad_norm': 0.14155051112174988, '_timestamp': 1721934180.0146801}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'critic_grad_norm': 0.44551610946655273, '_timestamp': 1721934180.0149379}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'ratio': 0.5930137634277344, '_timestamp': 1721934180.015041}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934180.0154378}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934180.0155377}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'Episode_Time': 80.82628059387207, '_timestamp': 1721934180.0155945}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934180.0164013}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934180.0167558}).
wandb: WARNING (User provided step: 10693 is less than current step: 14326. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934180.0171804}).
Env Football Algo jrpo Exp base_JRPO updates 10693/100000000000.0 steps in 80.83
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 84.48
total episode rewards is 0.0
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'value_loss': 0.14787717538652942, '_timestamp': 1721934349.489753}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01421429174709677, '_timestamp': 1721934349.489915}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5297126921017965, '_timestamp': 1721934349.4899812}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2858242988586426, '_timestamp': 1721934349.490077}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3443504273891449, '_timestamp': 1721934349.4903357}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'ratio': 0.9999907612800598, '_timestamp': 1721934349.4904416}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721934349.4905684}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934349.4906554}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.98794746398926, '_timestamp': 1721934349.4907112}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934349.4910405}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934349.4912891}).
wandb: WARNING (User provided step: 11724 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934349.4915385}).
Env Football Algo jrpo Exp base_JRPO updates 11724/100000000000.0 steps in 84.99
total episode rewards is -20.0
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'value_loss': 0.26378520916371295, '_timestamp': 1721934431.3011765}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009705391685323169, '_timestamp': 1721934431.3013346}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4409108726183573, '_timestamp': 1721934431.3014023}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48354142904281616, '_timestamp': 1721934431.3014932}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.40129292011260986, '_timestamp': 1721934431.3017476}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'ratio': 0.995599091053009, '_timestamp': 1721934431.301852}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934431.301971}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934431.3020623}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.80894422531128, '_timestamp': 1721934431.30212}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934431.302709}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934431.3032098}).
wandb: WARNING (User provided step: 6305 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934431.3037164}).
Env Football Algo jrpo Exp base_JRPO updates 6305/100000000000.0 steps in 81.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'value_loss': 0.596945868016531, '_timestamp': 1721934460.726458}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03503598223634374, '_timestamp': 1721934460.7266128}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5015921409924824, '_timestamp': 1721934460.7266777}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5717490911483765, '_timestamp': 1721934460.7267637}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9829192161560059, '_timestamp': 1721934460.7270236}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'ratio': 0.8233078122138977, '_timestamp': 1721934460.7271261}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721934460.7272534}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934460.7273417}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'Episode_Time': 29.42174530029297, '_timestamp': 1721934460.727398}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.121894858463316, '_timestamp': 1721934460.7276657}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'train_goal': 0.439052570768342, '_timestamp': 1721934460.7278485}).
wandb: WARNING (User provided step: 2149 is less than current step: 15000. Dropping entry: {'train_WDL': -0.121894858463316, '_timestamp': 1721934460.7280362}).
Env Football Algo jrpo Exp base_JRPO updates 2149/100000000000.0 steps in 29.42
total episode rewards is -70.0
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'value_loss': 0.25526034195286534, '_timestamp': 1721934548.4859073}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0239101128159867, '_timestamp': 1721934548.486082}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4623621312777202, '_timestamp': 1721934548.4861515}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48430025577545166, '_timestamp': 1721934548.486249}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5548104643821716, '_timestamp': 1721934548.4864972}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'ratio': 1.2643542289733887, '_timestamp': 1721934548.4866025}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934548.48673}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934548.486821}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.75709795951843, '_timestamp': 1721934548.4868789}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934548.4874098}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934548.4878275}).
wandb: WARNING (User provided step: 8630 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934548.488271}).
Env Football Algo jrpo Exp base_JRPO updates 8630/100000000000.0 steps in 87.76
total episode rewards is -40.0
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'value_loss': 0.26134051495619737, '_timestamp': 1721934629.9817216}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02884428595833015, '_timestamp': 1721934629.9818826}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5131384102503458, '_timestamp': 1721934629.9819474}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2154095321893692, '_timestamp': 1721934629.982039}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3815680742263794, '_timestamp': 1721934629.9822717}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'ratio': 0.8410993814468384, '_timestamp': 1721934629.982377}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934629.9825048}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934629.9825993}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.49225163459778, '_timestamp': 1721934629.982656}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934629.9830456}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934629.9833236}).
wandb: WARNING (User provided step: 11174 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934629.9836085}).
Env Football Algo jrpo Exp base_JRPO updates 11174/100000000000.0 steps in 81.49
total episode rewards is -40.0
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'value_loss': 0.06500518307647629, '_timestamp': 1721934711.511554}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'policy_loss': 0.025258666918574212, '_timestamp': 1721934711.5117192}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1915084028244018, '_timestamp': 1721934711.5117867}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2819417417049408, '_timestamp': 1721934711.511879}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20950257778167725, '_timestamp': 1721934711.5121603}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'ratio': 0.7920745611190796, '_timestamp': 1721934711.5122697}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721934711.5124009}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934711.512495}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.52723622322083, '_timestamp': 1721934711.5125518}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934711.5128253}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934711.512926}).
wandb: WARNING (User provided step: 14892 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934711.513015}).
Env Football Algo jrpo Exp base_JRPO updates 14892/100000000000.0 steps in 81.53
total episode rewards is -10.0
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'value_loss': 0.1373669374162273, '_timestamp': 1721934795.9330318}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012893584512639791, '_timestamp': 1721934795.933211}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4461293903986614, '_timestamp': 1721934795.9332771}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10710307210683823, '_timestamp': 1721934795.9333706}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3337494730949402, '_timestamp': 1721934795.933621}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'ratio': 0.7732515931129456, '_timestamp': 1721934795.9337249}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721934795.9338539}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934795.9339445}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.41923904418945, '_timestamp': 1721934795.9340005}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934795.9343839}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934795.9346588}).
wandb: WARNING (User provided step: 11332 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934795.934977}).
Env Football Algo jrpo Exp base_JRPO updates 11332/100000000000.0 steps in 84.42
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 9848/100000000000.0 steps in 78.82
total episode rewards is -40.0
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'value_loss': 0.27258891428937204, '_timestamp': 1721934874.7595742}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009139297992999977, '_timestamp': 1721934874.7597923}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1140403175354003, '_timestamp': 1721934874.7598655}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39839449524879456, '_timestamp': 1721934874.7600176}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3066428303718567, '_timestamp': 1721934874.760297}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'ratio': 0.9644760489463806, '_timestamp': 1721934874.7604032}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934874.760537}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934874.760634}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.82366108894348, '_timestamp': 1721934874.7606938}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934874.7612753}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934874.761626}).
wandb: WARNING (User provided step: 9848 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934874.7619812}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'value_loss': 0.28486700606532395, '_timestamp': 1721934961.6562314}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0004215143372615178, '_timestamp': 1721934961.6563919}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1120167628924051, '_timestamp': 1721934961.6564603}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16854727268218994, '_timestamp': 1721934961.6565526}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3053976893424988, '_timestamp': 1721934961.6567647}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'ratio': 1.0909137725830078, '_timestamp': 1721934961.6568675}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721934961.656995}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721934961.657088}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.89327192306519, '_timestamp': 1721934961.6571448}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721934961.6576464}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721934961.6580362}).
wandb: WARNING (User provided step: 8672 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721934961.658452}).
Env Football Algo jrpo Exp base_JRPO updates 8672/100000000000.0 steps in 86.89
total episode rewards is -40.0
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'value_loss': 0.25306645369681063, '_timestamp': 1721935050.1621532}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0021542338258586824, '_timestamp': 1721935050.1623228}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9960749745368958, '_timestamp': 1721935050.1623907}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22895854711532593, '_timestamp': 1721935050.1624813}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.30572760105133057, '_timestamp': 1721935050.1627405}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'ratio': 0.9498539566993713, '_timestamp': 1721935050.162844}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935050.1629753}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935050.1630697}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.50268363952637, '_timestamp': 1721935050.1631284}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935050.1636467}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935050.1640437}).
wandb: WARNING (User provided step: 8737 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935050.1644468}).
Env Football Algo jrpo Exp base_JRPO updates 8737/100000000000.0 steps in 88.50
total episode rewards is -40.0
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'value_loss': 0.2061676865334933, '_timestamp': 1721935133.6356382}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006645117558073252, '_timestamp': 1721935133.635911}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.024448935985565, '_timestamp': 1721935133.6360157}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3139519691467285, '_timestamp': 1721935133.636179}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.28129997849464417, '_timestamp': 1721935133.6364543}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'ratio': 0.8979784250259399, '_timestamp': 1721935133.6365607}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721935133.6366978}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935133.6367931}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.47013139724731, '_timestamp': 1721935133.6368508}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935133.6375394}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935133.6378782}).
wandb: WARNING (User provided step: 10143 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935133.6383955}).
Env Football Algo jrpo Exp base_JRPO updates 10143/100000000000.0 steps in 83.47
total episode rewards is -30.0
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'value_loss': 0.12822116851942458, '_timestamp': 1721935221.765023}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02061223721616746, '_timestamp': 1721935221.766272}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2961305093765259, '_timestamp': 1721935221.7663436}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.237196147441864, '_timestamp': 1721935221.766817}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25724855065345764, '_timestamp': 1721935221.767154}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'ratio': 0.8183790445327759, '_timestamp': 1721935221.767261}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721935221.7673979}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935221.7676015}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.12077808380127, '_timestamp': 1721935221.7676609}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935221.768655}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935221.7689495}).
wandb: WARNING (User provided step: 11114 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935221.7692454}).
Env Football Algo jrpo Exp base_JRPO updates 11114/100000000000.0 steps in 88.12
total episode rewards is -20.0
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'value_loss': 0.20639747716467052, '_timestamp': 1721935301.7608986}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00036916609310234586, '_timestamp': 1721935301.7610855}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1830255325635275, '_timestamp': 1721935301.7611554}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16000334918498993, '_timestamp': 1721935301.7612565}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14057187736034393, '_timestamp': 1721935301.7615273}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'ratio': 0.9466065764427185, '_timestamp': 1721935301.761638}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721935301.761775}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935301.7618682}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.99062323570251, '_timestamp': 1721935301.7619288}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935301.762582}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935301.762966}).
wandb: WARNING (User provided step: 10221 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935301.7633011}).
Env Football Algo jrpo Exp base_JRPO updates 10221/100000000000.0 steps in 79.99
total episode rewards is -30.0
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'value_loss': 0.14258125102419095, '_timestamp': 1721935386.3304806}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0005281132480013185, '_timestamp': 1721935386.3318255}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2791901723543804, '_timestamp': 1721935386.3319004}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21570709347724915, '_timestamp': 1721935386.3324404}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24502666294574738, '_timestamp': 1721935386.3328092}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'ratio': 0.9011483192443848, '_timestamp': 1721935386.3329191}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721935386.3330524}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935386.3332632}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.56081223487854, '_timestamp': 1721935386.3333268}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935386.3342025}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935386.334616}).
wandb: WARNING (User provided step: 10128 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935386.3349643}).
Env Football Algo jrpo Exp base_JRPO updates 10128/100000000000.0 steps in 84.56
total episode rewards is -20.0
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'value_loss': 0.21184339133634542, '_timestamp': 1721935475.9464092}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0007272409494422997, '_timestamp': 1721935475.9466555}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4736026899019876, '_timestamp': 1721935475.9467244}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48701000213623047, '_timestamp': 1721935475.9468946}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3922264873981476, '_timestamp': 1721935475.9472048}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'ratio': 0.7485944628715515, '_timestamp': 1721935475.9473193}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721935475.9474483}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935475.9475396}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.60993647575378, '_timestamp': 1721935475.9475963}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.1347728965003723, '_timestamp': 1721935475.9482281}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'train_goal': 0.43261355174981386, '_timestamp': 1721935475.9486732}).
wandb: WARNING (User provided step: 8285 is less than current step: 15000. Dropping entry: {'train_WDL': -0.1347728965003723, '_timestamp': 1721935475.9491289}).
Env Football Algo jrpo Exp base_JRPO updates 8285/100000000000.0 steps in 89.61
total episode rewards is -10.0
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'value_loss': 0.29162617037732463, '_timestamp': 1721935559.3931732}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00385588251047011, '_timestamp': 1721935559.394273}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3564965176582335, '_timestamp': 1721935559.3943458}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18389445543289185, '_timestamp': 1721935559.394806}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24802999198436737, '_timestamp': 1721935559.3951433}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'ratio': 0.8715144991874695, '_timestamp': 1721935559.3952491}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935559.39539}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935559.3955753}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.43893003463745, '_timestamp': 1721935559.3956437}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935559.396603}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935559.3970282}).
wandb: WARNING (User provided step: 8557 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935559.3974717}).
Env Football Algo jrpo Exp base_JRPO updates 8557/100000000000.0 steps in 83.44
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 3908/100000000000.0 steps in 55.64
total episode rewards is -90.0
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'value_loss': 0.577929641691347, '_timestamp': 1721935615.0372434}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004588975748435284, '_timestamp': 1721935615.0374043}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3401102630297343, '_timestamp': 1721935615.0374691}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6662851572036743, '_timestamp': 1721935615.0375578}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0674036741256714, '_timestamp': 1721935615.0378125}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'ratio': 0.9430907368659973, '_timestamp': 1721935615.037914}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721935615.0380394}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935615.038129}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'Episode_Time': 55.638936042785645, '_timestamp': 1721935615.0381846}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935615.03881}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935615.0391119}).
wandb: WARNING (User provided step: 3908 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935615.0394258}).
Env Football Algo jrpo Exp base_JRPO updates 7210/100000000000.0 steps in 80.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'value_loss': 0.2974454436063146, '_timestamp': 1721935695.9407096}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013867049011557053, '_timestamp': 1721935695.9409645}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3604495350519816, '_timestamp': 1721935695.9410343}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17514760792255402, '_timestamp': 1721935695.9411712}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.33478423953056335, '_timestamp': 1721935695.9414418}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'ratio': 0.9105036854743958, '_timestamp': 1721935695.941547}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935695.9416811}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935695.9417748}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.90001010894775, '_timestamp': 1721935695.9418342}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935695.942513}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935695.9430091}).
wandb: WARNING (User provided step: 7210 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935695.9435022}).
Env Football Algo jrpo Exp base_JRPO updates 8158/100000000000.0 steps in 81.67
total episode rewards is -40.0
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'value_loss': 0.2679726008612973, '_timestamp': 1721935777.618032}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02998141541912143, '_timestamp': 1721935777.6193955}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4769617319107056, '_timestamp': 1721935777.6194685}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.192013680934906, '_timestamp': 1721935777.6200197}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22328905761241913, '_timestamp': 1721935777.620394}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'ratio': 0.9830225110054016, '_timestamp': 1721935777.620504}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721935777.6206403}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935777.620848}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.66808557510376, '_timestamp': 1721935777.6209056}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935777.6221862}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935777.6226304}).
wandb: WARNING (User provided step: 8158 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935777.6230774}).
Env Football Algo jrpo Exp base_JRPO updates 10354/100000000000.0 steps in 85.66
total episode rewards is -20.0
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'value_loss': 0.15034910816970903, '_timestamp': 1721935863.2802022}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'policy_loss': 0.017707638453017958, '_timestamp': 1721935863.2803674}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5696744894981385, '_timestamp': 1721935863.280435}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1733953207731247, '_timestamp': 1721935863.280523}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3097669184207916, '_timestamp': 1721935863.2807853}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'ratio': 0.8707756996154785, '_timestamp': 1721935863.280889}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721935863.281018}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935863.2811074}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.65628409385681, '_timestamp': 1721935863.2811666}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721935863.2815874}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721935863.2819102}).
wandb: WARNING (User provided step: 10354 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721935863.2822518}).
Env Football Algo jrpo Exp base_JRPO updates 6017/100000000000.0 steps in 82.22
total episode rewards is 0.0
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'value_loss': 0.3093716406732953, '_timestamp': 1721935945.5001884}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03296710117429029, '_timestamp': 1721935945.5003495}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6723933633168537, '_timestamp': 1721935945.5004163}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6804232597351074, '_timestamp': 1721935945.500508}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.40838131308555603, '_timestamp': 1721935945.5087934}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'ratio': 1.0520575046539307, '_timestamp': 1721935945.5089107}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721935945.5090423}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721935945.5091376}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.21674966812134, '_timestamp': 1721935945.5091941}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3138149838583992, '_timestamp': 1721935945.509956}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal': 0.6569074919291996, '_timestamp': 1721935945.5104892}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3138149838583992, '_timestamp': 1721935945.511016}).
Env Football Algo jrpo Exp base_JRPO updates 7947/100000000000.0 steps in 86.87
total episode rewards is -10.0
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'value_loss': 0.21777676866739057, '_timestamp': 1721936032.3793526}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04324964168236572, '_timestamp': 1721936032.379565}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8255360889434815, '_timestamp': 1721936032.3796325}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.529107928276062, '_timestamp': 1721936032.3797321}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24778814613819122, '_timestamp': 1721936032.3799777}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'ratio': 0.444304883480072, '_timestamp': 1721936032.3800883}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721936032.3802178}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936032.3803146}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.8674623966217, '_timestamp': 1721936032.3803756}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.16035729476818375, '_timestamp': 1721936032.3814652}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_goal': 0.41982135261590814, '_timestamp': 1721936032.381917}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_WDL': -0.16035729476818375, '_timestamp': 1721936032.3826427}).
Env Football Algo jrpo Exp base_JRPO updates 6742/100000000000.0 steps in 72.90
total episode rewards is -30.0
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'value_loss': 0.35733304884750394, '_timestamp': 1721936105.2834218}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04738161924333933, '_timestamp': 1721936105.2835913}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6531361023585, '_timestamp': 1721936105.2836566}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.37348437309265137, '_timestamp': 1721936105.2837455}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5158888101577759, '_timestamp': 1721936105.2840307}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'ratio': 0.7323445081710815, '_timestamp': 1721936105.2841346}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721936105.2842681}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936105.284357}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.8996787071228, '_timestamp': 1721936105.284416}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.13035746043037524, '_timestamp': 1721936105.2849407}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_goal': 0.4348212697848124, '_timestamp': 1721936105.2854025}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_WDL': -0.13035746043037524, '_timestamp': 1721936105.2857769}).
Env Football Algo jrpo Exp base_JRPO updates 12141/100000000000.0 steps in 84.12
total episode rewards is -20.0
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'value_loss': 0.1391652048791487, '_timestamp': 1721936189.4027777}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00032838778492684165, '_timestamp': 1721936189.4031186}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7869419233004251, '_timestamp': 1721936189.4031982}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1331496238708496, '_timestamp': 1721936189.403337}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2680239677429199, '_timestamp': 1721936189.4036684}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'ratio': 0.9451566934585571, '_timestamp': 1721936189.403781}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721936189.4040031}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936189.4041097}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.1155776977539, '_timestamp': 1721936189.4041746}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936189.4045484}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936189.4048047}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936189.4050379}).
Env Football Algo jrpo Exp base_JRPO updates 7387/100000000000.0 steps in 85.62
total episode rewards is -40.0
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'value_loss': 0.2888373037334532, '_timestamp': 1721936275.021871}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'policy_loss': 0.003617062506188328, '_timestamp': 1721936275.022071}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6925531562169394, '_timestamp': 1721936275.022139}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5625749230384827, '_timestamp': 1721936275.0222642}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5164796710014343, '_timestamp': 1721936275.0225053}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'ratio': 1.176041603088379, '_timestamp': 1721936275.0226066}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936275.0227375}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936275.0228257}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.61581921577454, '_timestamp': 1721936275.0228846}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936275.0234444}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936275.0242074}).
wandb: WARNING (User provided step: 7387 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936275.0246804}).
Env Football Algo jrpo Exp base_JRPO updates 12602/100000000000.0 steps in 78.28
total episode rewards is -10.0
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'value_loss': 0.07348653721749239, '_timestamp': 1721936353.301412}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004398328997970869, '_timestamp': 1721936353.3016584}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.610856740474701, '_timestamp': 1721936353.3017278}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1116897463798523, '_timestamp': 1721936353.3018582}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.10739842802286148, '_timestamp': 1721936353.3021145}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'ratio': 0.9602642059326172, '_timestamp': 1721936353.3022182}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721936353.30235}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936353.3024461}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.27569532394409, '_timestamp': 1721936353.3025048}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936353.3029149}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936353.3031306}).
wandb: WARNING (User provided step: 12602 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936353.3033423}).
Env Football Algo jrpo Exp base_JRPO updates 11239/100000000000.0 steps in 88.44
total episode rewards is -30.0
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'value_loss': 0.20741703798237723, '_timestamp': 1721936441.7492313}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0011357656497663507, '_timestamp': 1721936441.7494056}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.471966314315796, '_timestamp': 1721936441.749473}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5251657962799072, '_timestamp': 1721936441.7495666}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.48727214336395264, '_timestamp': 1721936441.7498364}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'ratio': 0.9442800879478455, '_timestamp': 1721936441.7499394}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721936441.7500708}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936441.7501674}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.44489574432373, '_timestamp': 1721936441.750223}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936441.7506375}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936441.7511077}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936441.7514427}).
Env Football Algo jrpo Exp base_JRPO updates 7856/100000000000.0 steps in 84.20
total episode rewards is -40.0
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'value_loss': 0.27734706704233153, '_timestamp': 1721936525.955047}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'policy_loss': -0.008621688710215191, '_timestamp': 1721936525.9552202}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4737244137128194, '_timestamp': 1721936525.9552884}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39053311944007874, '_timestamp': 1721936525.9553812}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.517416775226593, '_timestamp': 1721936525.9556332}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'ratio': 0.9326924085617065, '_timestamp': 1721936525.9557374}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936525.9558651}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936525.9559798}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.20282316207886, '_timestamp': 1721936525.9560432}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936525.9565954}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936525.9570498}).
wandb: WARNING (User provided step: 7856 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936525.9574988}).
Env Football Algo jrpo Exp base_JRPO updates 3257/100000000000.0 steps in 46.33
total episode rewards is -80.0
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'value_loss': 0.6857962027192116, '_timestamp': 1721936572.2903037}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'policy_loss': -0.006402163885165161, '_timestamp': 1721936572.2915957}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4460149216651916, '_timestamp': 1721936572.2916698}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.75589519739151, '_timestamp': 1721936572.2921984}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0624810457229614, '_timestamp': 1721936572.2925498}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'ratio': 0.9483885169029236, '_timestamp': 1721936572.2926612}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721936572.2927957}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936572.2930086}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'Episode_Time': 46.327041149139404, '_timestamp': 1721936572.2930696}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2903730759196452, '_timestamp': 1721936572.293955}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'train_goal': 0.3548134620401774, '_timestamp': 1721936572.2942524}).
wandb: WARNING (User provided step: 3257 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2903730759196452, '_timestamp': 1721936572.2945387}).
Env Football Algo jrpo Exp base_JRPO updates 7936/100000000000.0 steps in 84.42
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'value_loss': 0.26978401742720354, '_timestamp': 1721936656.7200034}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02382227182786058, '_timestamp': 1721936656.720374}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4754732871055602, '_timestamp': 1721936656.7204473}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29574352502822876, '_timestamp': 1721936656.7205908}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2478746622800827, '_timestamp': 1721936656.7209942}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'ratio': 0.5261223912239075, '_timestamp': 1721936656.7211049}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936656.7213962}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936656.721535}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.42395949363708, '_timestamp': 1721936656.721598}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936656.7234132}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936656.7239163}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936656.724423}).
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8306/100000000000.0 steps in 89.43
total episode rewards is -40.0
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'value_loss': 0.28242213658522813, '_timestamp': 1721936746.1566288}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'policy_loss': 0.050026502757294415, '_timestamp': 1721936746.1578815}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7456756329536438, '_timestamp': 1721936746.15795}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1297956109046936, '_timestamp': 1721936746.1584344}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3521958291530609, '_timestamp': 1721936746.158767}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'ratio': 0.6974522471427917, '_timestamp': 1721936746.1588683}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936746.158995}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936746.1591792}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.42650485038757, '_timestamp': 1721936746.159251}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936746.1601152}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936746.1605434}).
wandb: WARNING (User provided step: 8306 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936746.1609695}).
Env Football Algo jrpo Exp base_JRPO updates 3704/100000000000.0 steps in 40.22
total episode rewards is -60.0
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'value_loss': 0.5443861348057787, '_timestamp': 1721936786.3790848}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'policy_loss': 0.015171105574117973, '_timestamp': 1721936786.3792448}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7187988193829855, '_timestamp': 1721936786.3793116}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.41069138050079346, '_timestamp': 1721936786.379398}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0732256174087524, '_timestamp': 1721936786.3796384}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'ratio': 0.4277365207672119, '_timestamp': 1721936786.379739}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721936786.3798566}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936786.3799596}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'Episode_Time': 40.2172532081604, '_timestamp': 1721936786.3800607}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.13599458728010824, '_timestamp': 1721936786.3804047}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'train_goal': 0.43200270635994586, '_timestamp': 1721936786.380636}).
wandb: WARNING (User provided step: 3704 is less than current step: 15000. Dropping entry: {'train_WDL': -0.13599458728010824, '_timestamp': 1721936786.380865}).
Env Football Algo jrpo Exp base_JRPO updates 11390/100000000000.0 steps in 89.54
total episode rewards is -30.0
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'value_loss': 0.1956276246610408, '_timestamp': 1721936875.9268925}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00014511527804036934, '_timestamp': 1721936875.9270976}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9024005270004272, '_timestamp': 1721936875.9271703}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24178409576416016, '_timestamp': 1721936875.9272761}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2635331153869629, '_timestamp': 1721936875.9275563}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'ratio': 0.7856758832931519, '_timestamp': 1721936875.9276638}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721936875.927798}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936875.9279034}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.54496431350708, '_timestamp': 1721936875.9279845}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936875.92839}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936875.9286668}).
wandb: WARNING (User provided step: 11390 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936875.9289494}).
Env Football Algo jrpo Exp base_JRPO updates 8209/100000000000.0 steps in 78.98
total episode rewards is -40.0
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'value_loss': 0.28583631570800205, '_timestamp': 1721936954.9121377}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0025477860666190586, '_timestamp': 1721936954.9123373}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.839855392773946, '_timestamp': 1721936954.9124165}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.25724926590919495, '_timestamp': 1721936954.9125211}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.37041381001472473, '_timestamp': 1721936954.912808}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'ratio': 0.8138468861579895, '_timestamp': 1721936954.9129386}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721936954.9130752}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721936954.913182}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.98229598999023, '_timestamp': 1721936954.9132407}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721936954.9139943}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721936954.914435}).
wandb: WARNING (User provided step: 8209 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721936954.9148767}).
Env Football Algo jrpo Exp base_JRPO updates 6605/100000000000.0 steps in 89.05
total episode rewards is -40.0
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'value_loss': 0.28661081514224257, '_timestamp': 1721937043.9624126}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00463823249641185, '_timestamp': 1721937043.9626203}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7204732251167298, '_timestamp': 1721937043.9626908}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.23462997376918793, '_timestamp': 1721937043.9628024}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23489274084568024, '_timestamp': 1721937043.9630566}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'ratio': 0.8792515993118286, '_timestamp': 1721937043.9631631}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721937043.9632924}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937043.9633856}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.04663252830505, '_timestamp': 1721937043.9635346}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937043.969588}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937043.970222}).
wandb: WARNING (User provided step: 6605 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937043.970831}).
Env Football Algo jrpo Exp base_JRPO updates 6707/100000000000.0 steps in 72.27
total episode rewards is -60.0
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'value_loss': 0.4439290028158575, '_timestamp': 1721937116.2505803}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'policy_loss': 0.002154247430347217, '_timestamp': 1721937116.251908}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4877335651715597, '_timestamp': 1721937116.2520063}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3368913233280182, '_timestamp': 1721937116.2525136}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6118513345718384, '_timestamp': 1721937116.2528806}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'ratio': 0.8664069771766663, '_timestamp': 1721937116.2529926}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721937116.2531295}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937116.2533348}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.27356004714966, '_timestamp': 1721937116.2533944}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937116.2545972}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937116.255034}).
wandb: WARNING (User provided step: 6707 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937116.255489}).
Env Football Algo jrpo Exp base_JRPO updates 7314/100000000000.0 steps in 89.00
total episode rewards is -70.0
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'value_loss': 0.4709649502680016, '_timestamp': 1721937205.257931}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00353799331584014, '_timestamp': 1721937205.2581463}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7574149338404337, '_timestamp': 1721937205.258219}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29179495573043823, '_timestamp': 1721937205.2583215}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.48364898562431335, '_timestamp': 1721937205.2586792}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'ratio': 0.8728189468383789, '_timestamp': 1721937205.2588258}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721937205.259077}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937205.2592113}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.00157642364502, '_timestamp': 1721937205.2594597}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937205.2602894}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937205.2607539}).
wandb: WARNING (User provided step: 7314 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937205.261215}).
Env Football Algo jrpo Exp base_JRPO updates 10173/100000000000.0 steps in 86.02
total episode rewards is -40.0
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'value_loss': 0.2603927324533773, '_timestamp': 1721937291.2850616}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'policy_loss': 0.030541068320550646, '_timestamp': 1721937291.2852829}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8035733056068421, '_timestamp': 1721937291.2853565}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1639031618833542, '_timestamp': 1721937291.285492}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.32981249690055847, '_timestamp': 1721937291.285765}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'ratio': 0.6837559938430786, '_timestamp': 1721937291.2858691}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721937291.2860093}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937291.2862012}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.02264618873596, '_timestamp': 1721937291.2862613}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937291.286707}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937291.2870398}).
wandb: WARNING (User provided step: 10173 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937291.287369}).
Env Football Algo jrpo Exp base_JRPO updates 5907/100000000000.0 steps in 84.47
total episode rewards is -20.0
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'value_loss': 0.2848692420745889, '_timestamp': 1721937375.7582142}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012208341182558797, '_timestamp': 1721937375.7583935}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7863925011952717, '_timestamp': 1721937375.758462}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5120607018470764, '_timestamp': 1721937375.7585607}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22533027827739716, '_timestamp': 1721937375.7588406}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'ratio': 0.8180371522903442, '_timestamp': 1721937375.758946}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937375.7590764}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937375.7591705}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.47000193595886, '_timestamp': 1721937375.7594466}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3432310568569229, '_timestamp': 1721937375.7601779}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'train_goal': 0.32838447157153855, '_timestamp': 1721937375.7607305}).
wandb: WARNING (User provided step: 5907 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3432310568569229, '_timestamp': 1721937375.7612932}).
Env Football Algo jrpo Exp base_JRPO updates 4279/100000000000.0 steps in 56.07
total episode rewards is -60.0
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'value_loss': 0.5408420676055053, '_timestamp': 1721937431.8283093}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021523736555560998, '_timestamp': 1721937431.8284717}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5023186135292053, '_timestamp': 1721937431.8285353}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4954576790332794, '_timestamp': 1721937431.828624}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.756614625453949, '_timestamp': 1721937431.8288865}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'ratio': 0.6567420363426208, '_timestamp': 1721937431.828989}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721937431.8291173}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937431.8292081}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.065956592559814, '_timestamp': 1721937431.82933}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.1716760061130922, '_timestamp': 1721937431.8297322}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'train_goal': 0.4141619969434539, '_timestamp': 1721937431.8300061}).
wandb: WARNING (User provided step: 4279 is less than current step: 15000. Dropping entry: {'train_WDL': -0.1716760061130922, '_timestamp': 1721937431.8302865}).
Env Football Algo jrpo Exp base_JRPO updates 7188/100000000000.0 steps in 82.45
total episode rewards is -10.0
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'value_loss': 0.2294389585069924, '_timestamp': 1721937514.2800019}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02364245751329387, '_timestamp': 1721937514.2801862}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6687955435117086, '_timestamp': 1721937514.2802577}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.41525211930274963, '_timestamp': 1721937514.2803562}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23299965262413025, '_timestamp': 1721937514.2806306}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'ratio': 0.8272437453269958, '_timestamp': 1721937514.2807379}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721937514.2808735}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937514.2812822}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.4486951828003, '_timestamp': 1721937514.2813444}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.24628776241679468, '_timestamp': 1721937514.2820983}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'train_goal': 0.3768561187916027, '_timestamp': 1721937514.2826028}).
wandb: WARNING (User provided step: 7188 is less than current step: 15000. Dropping entry: {'train_WDL': -0.24628776241679468, '_timestamp': 1721937514.2830904}).
Env Football Algo jrpo Exp base_JRPO updates 10337/100000000000.0 steps in 90.75
total episode rewards is -20.0
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'value_loss': 0.1619133688363945, '_timestamp': 1721937605.0368402}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018502077636549076, '_timestamp': 1721937605.0370235}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.577157506942749, '_timestamp': 1721937605.0370893}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12724046409130096, '_timestamp': 1721937605.037185}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19243711233139038, '_timestamp': 1721937605.037458}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'ratio': 0.8519196510314941, '_timestamp': 1721937605.0375614}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937605.037698}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937605.03779}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.7528932094574, '_timestamp': 1721937605.0378447}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721937605.0384336}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721937605.0387456}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721937605.0390697}).
Env Football Algo jrpo Exp base_JRPO updates 6818/100000000000.0 steps in 87.89
total episode rewards is 0.0
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'value_loss': 0.2789385136698062, '_timestamp': 1721937692.9374073}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'policy_loss': 0.025631690687732772, '_timestamp': 1721937692.938266}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5576030659675597, '_timestamp': 1721937692.9383404}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.495575875043869, '_timestamp': 1721937692.9386675}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.33837175369262695, '_timestamp': 1721937692.9389913}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'ratio': 0.9323357343673706, '_timestamp': 1721937692.9390981}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721937692.939234}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937692.939394}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.89430856704712, '_timestamp': 1721937692.9396794}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2837936934734784, '_timestamp': 1721937692.940633}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'train_goal': 0.6418968467367392, '_timestamp': 1721937692.9411185}).
wandb: WARNING (User provided step: 6818 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2837936934734784, '_timestamp': 1721937692.941604}).
Env Football Algo jrpo Exp base_JRPO updates 7716/100000000000.0 steps in 80.12
total episode rewards is -20.0
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'value_loss': 0.3200941779150162, '_timestamp': 1721937773.0648327}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00887286637605333, '_timestamp': 1721937773.065005}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6032504971822104, '_timestamp': 1721937773.0650713}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.322283536195755, '_timestamp': 1721937773.0651634}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21032263338565826, '_timestamp': 1721937773.0654178}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'ratio': 0.9647963643074036, '_timestamp': 1721937773.0655184}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721937773.0656505}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937773.0657454}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.12220454216003, '_timestamp': 1721937773.0659072}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.44481054365733114, '_timestamp': 1721937773.0664554}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'train_goal': 0.2775947281713344, '_timestamp': 1721937773.0669005}).
wandb: WARNING (User provided step: 7716 is less than current step: 15000. Dropping entry: {'train_WDL': -0.44481054365733114, '_timestamp': 1721937773.0673585}).
Env Football Algo jrpo Exp base_JRPO updates 2581/100000000000.0 steps in 32.72
total episode rewards is -30.0
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'value_loss': 0.9050313115244111, '_timestamp': 1721937805.7889688}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02387299638784801, '_timestamp': 1721937805.789134}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6043967978159586, '_timestamp': 1721937805.7891977}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7956634759902954, '_timestamp': 1721937805.789285}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0842643976211548, '_timestamp': 1721937805.789513}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'ratio': 0.9513012170791626, '_timestamp': 1721937805.7896125}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721937805.789723}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937805.7898648}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'Episode_Time': 32.720669746398926, '_timestamp': 1721937805.7899203}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.15118887393449978, '_timestamp': 1721937805.7902017}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'train_goal': 0.4244055630327501, '_timestamp': 1721937805.7903938}).
wandb: WARNING (User provided step: 2581 is less than current step: 15000. Dropping entry: {'train_WDL': -0.15118887393449978, '_timestamp': 1721937805.7905836}).
Env Football Algo jrpo Exp base_JRPO updates 7260/100000000000.0 steps in 76.00
total episode rewards is -50.0
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'value_loss': 0.6099911218757431, '_timestamp': 1721937881.7883806}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'policy_loss': 0.019594020063911255, '_timestamp': 1721937881.78855}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5286886843045553, '_timestamp': 1721937881.788616}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6805272698402405, '_timestamp': 1721937881.7887065}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9567021131515503, '_timestamp': 1721937881.7889671}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'ratio': 0.9123800992965698, '_timestamp': 1721937881.7890704}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721937881.7892041}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937881.7892962}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'Episode_Time': 75.99681448936462, '_timestamp': 1721937881.7893536}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.06266416510318949, '_timestamp': 1721937881.7899258}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'train_goal': 0.46866791744840525, '_timestamp': 1721937881.7902904}).
wandb: WARNING (User provided step: 7260 is less than current step: 15000. Dropping entry: {'train_WDL': -0.06266416510318949, '_timestamp': 1721937881.7906415}).
Env Football Algo jrpo Exp base_JRPO updates 10367/100000000000.0 steps in 88.50
total episode rewards is -10.0
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'value_loss': 0.24230207032756879, '_timestamp': 1721937970.2913477}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'policy_loss': 0.002052698172046803, '_timestamp': 1721937970.2915251}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4887406476338705, '_timestamp': 1721937970.2915924}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3414389491081238, '_timestamp': 1721937970.2916946}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4760986864566803, '_timestamp': 1721937970.2948601}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'ratio': 0.9589290618896484, '_timestamp': 1721937970.2951093}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721937970.2952607}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721937970.295372}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.49985027313232, '_timestamp': 1721937970.2956154}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2682926829268293, '_timestamp': 1721937970.2962182}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'train_goal': 0.6341463414634146, '_timestamp': 1721937970.296546}).
wandb: WARNING (User provided step: 10367 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2682926829268293, '_timestamp': 1721937970.2968676}).
Env Football Algo jrpo Exp base_JRPO updates 6175/100000000000.0 steps in 80.02
total episode rewards is -40.0
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'value_loss': 0.31981317503610623, '_timestamp': 1721938050.3136024}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004603861138845484, '_timestamp': 1721938050.3138263}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.459607002735138, '_timestamp': 1721938050.313898}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.26230236887931824, '_timestamp': 1721938050.314}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.315390020608902, '_timestamp': 1721938050.3142653}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'ratio': 0.936515212059021, '_timestamp': 1721938050.3143735}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721938050.3145049}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938050.3146071}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.01525115966797, '_timestamp': 1721938050.3146691}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938050.3153846}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938050.3159215}).
wandb: WARNING (User provided step: 6175 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938050.316501}).
Env Football Algo jrpo Exp base_JRPO updates 6033/100000000000.0 steps in 90.83
total episode rewards is 0.0
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'value_loss': 0.3116266930413743, '_timestamp': 1721938141.1517048}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009521421319805086, '_timestamp': 1721938141.1529946}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4077232758204141, '_timestamp': 1721938141.1530666}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5949900150299072, '_timestamp': 1721938141.1535394}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.32673516869544983, '_timestamp': 1721938141.153842}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'ratio': 0.9318569302558899, '_timestamp': 1721938141.153945}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721938141.1540756}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938141.1542654}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.82941794395447, '_timestamp': 1721938141.1544547}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.09267313482770158, '_timestamp': 1721938141.1555064}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'train_goal': 0.5463365674138508, '_timestamp': 1721938141.1560748}).
wandb: WARNING (User provided step: 6033 is less than current step: 15000. Dropping entry: {'train_WDL': 0.09267313482770158, '_timestamp': 1721938141.1566133}).
Env Football Algo jrpo Exp base_JRPO updates 11011/100000000000.0 steps in 89.29
total episode rewards is -20.0
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'value_loss': 0.16165132886885356, '_timestamp': 1721938230.4512017}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007276676286904452, '_timestamp': 1721938230.4513714}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4969051384925842, '_timestamp': 1721938230.4514399}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32557186484336853, '_timestamp': 1721938230.4515324}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18093283474445343, '_timestamp': 1721938230.4517894}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'ratio': 0.8665680885314941, '_timestamp': 1721938230.4518924}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721938230.4520526}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938230.4521482}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.29374313354492, '_timestamp': 1721938230.4523084}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938230.4527156}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938230.4530199}).
wandb: WARNING (User provided step: 11011 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938230.4533215}).
Env Football Algo jrpo Exp base_JRPO updates 7566/100000000000.0 steps in 81.24
total episode rewards is -10.0
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'value_loss': 0.22551269574090838, '_timestamp': 1721938311.6909258}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007204521102952033, '_timestamp': 1721938311.6911783}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5644381022453309, '_timestamp': 1721938311.6912477}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.41443654894828796, '_timestamp': 1721938311.6913843}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20870685577392578, '_timestamp': 1721938311.691657}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'ratio': 0.9131198525428772, '_timestamp': 1721938311.691765}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721938311.6920326}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938311.6921344}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.23668909072876, '_timestamp': 1721938311.692194}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.19612590799031476, '_timestamp': 1721938311.6932302}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'train_goal': 0.4019370460048426, '_timestamp': 1721938311.6939409}).
wandb: WARNING (User provided step: 7566 is less than current step: 15000. Dropping entry: {'train_WDL': -0.19612590799031476, '_timestamp': 1721938311.694395}).
Env Football Algo jrpo Exp base_JRPO updates 12052/100000000000.0 steps in 91.16
total episode rewards is 10.0
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'value_loss': 0.08787664338713512, '_timestamp': 1721938402.8612876}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'policy_loss': 0.025010557212711622, '_timestamp': 1721938402.8626149}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.687883947690328, '_timestamp': 1721938402.8626864}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.8233418464660645, '_timestamp': 1721938402.8632069}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.09480280429124832, '_timestamp': 1721938402.863574}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'ratio': 0.8619951605796814, '_timestamp': 1721938402.86368}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721938402.863814}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938402.864032}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.16067099571228, '_timestamp': 1721938402.8643148}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721938402.8652096}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721938402.8654497}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721938402.86568}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'value_loss': 0.33050608469794196, '_timestamp': 1721938492.7877674}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004517492561523492, '_timestamp': 1721938492.7880414}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6784708944956461, '_timestamp': 1721938492.7881134}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3211406469345093, '_timestamp': 1721938492.7882726}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3775249719619751, '_timestamp': 1721938492.7885368}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'ratio': 0.8781275749206543, '_timestamp': 1721938492.7886407}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721938492.7887673}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938492.7888591}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.92094278335571, '_timestamp': 1721938492.788918}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938492.7898195}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938492.7902741}).
wandb: WARNING (User provided step: 7312 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938492.7907453}).
Env Football Algo jrpo Exp base_JRPO updates 7312/100000000000.0 steps in 89.92
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5104/100000000000.0 steps in 79.40
total episode rewards is 10.0
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'value_loss': 0.3849148339747141, '_timestamp': 1721938572.189109}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01842150806109809, '_timestamp': 1721938572.1892688}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6522449946403504, '_timestamp': 1721938572.1893353}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 1.0289874076843262, '_timestamp': 1721938572.189457}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22730787098407745, '_timestamp': 1721938572.1897101}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'ratio': 0.939211368560791, '_timestamp': 1721938572.1898143}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721938572.189946}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938572.1901076}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.39740347862244, '_timestamp': 1721938572.1901655}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.8656330749354005, '_timestamp': 1721938572.191228}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'train_goal': 0.9328165374677002, '_timestamp': 1721938572.1917398}).
wandb: WARNING (User provided step: 5104 is less than current step: 15000. Dropping entry: {'train_WDL': 0.8656330749354005, '_timestamp': 1721938572.1922777}).
Env Football Algo jrpo Exp base_JRPO updates 6964/100000000000.0 steps in 89.52
total episode rewards is 10.0
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'value_loss': 0.20546488053553427, '_timestamp': 1721938661.7132215}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013655924064223654, '_timestamp': 1721938661.7133994}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6969675278663636, '_timestamp': 1721938661.713468}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4914230406284332, '_timestamp': 1721938661.7135663}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.39672866463661194, '_timestamp': 1721938661.7138462}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'ratio': 0.8473386764526367, '_timestamp': 1721938661.7139552}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721938661.714092}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938661.7142327}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.51981616020203, '_timestamp': 1721938661.7145307}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.4808362369337979, '_timestamp': 1721938661.7155874}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_goal': 0.740418118466899, '_timestamp': 1721938661.7161133}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_WDL': 0.4808362369337979, '_timestamp': 1721938661.7166123}).
Env Football Algo jrpo Exp base_JRPO updates 8008/100000000000.0 steps in 89.00
total episode rewards is -10.0
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'value_loss': 0.2443577775809293, '_timestamp': 1721938750.721997}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004581458719718891, '_timestamp': 1721938750.7221656}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7104203430811564, '_timestamp': 1721938750.7222323}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3922201991081238, '_timestamp': 1721938750.7223232}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.39153599739074707, '_timestamp': 1721938750.722538}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'ratio': 0.9299899339675903, '_timestamp': 1721938750.7226403}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721938750.7227638}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938750.7228556}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.00421643257141, '_timestamp': 1721938750.722912}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.15961098398169338, '_timestamp': 1721938750.723671}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'train_goal': 0.4201945080091533, '_timestamp': 1721938750.7241242}).
wandb: WARNING (User provided step: 8008 is less than current step: 15000. Dropping entry: {'train_WDL': -0.15961098398169338, '_timestamp': 1721938750.7246122}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'value_loss': 0.20577409940383706, '_timestamp': 1721938831.1761837}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007176289896597155, '_timestamp': 1721938831.1763456}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6789222526550294, '_timestamp': 1721938831.1764119}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42818278074264526, '_timestamp': 1721938831.1765013}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24663405120372772, '_timestamp': 1721938831.1767654}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'ratio': 0.9216387867927551, '_timestamp': 1721938831.1768804}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721938831.1770191}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938831.1771138}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.45061826705933, '_timestamp': 1721938831.1773267}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.553030303030303, '_timestamp': 1721938831.1778045}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'train_goal': 0.7765151515151515, '_timestamp': 1721938831.1780765}).
wandb: WARNING (User provided step: 11304 is less than current step: 15000. Dropping entry: {'train_WDL': 0.553030303030303, '_timestamp': 1721938831.178337}).
Env Football Algo jrpo Exp base_JRPO updates 11304/100000000000.0 steps in 80.45
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 12818/100000000000.0 steps in 87.94
total episode rewards is -10.0
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'value_loss': 0.07174985093142217, '_timestamp': 1721938919.1167502}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'policy_loss': 0.017081269870201747, '_timestamp': 1721938919.1169245}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6672963404655456, '_timestamp': 1721938919.116992}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15959522128105164, '_timestamp': 1721938919.1170878}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.34515345096588135, '_timestamp': 1721938919.1173403}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'ratio': 0.8638164401054382, '_timestamp': 1721938919.1174467}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721938919.1175728}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721938919.117665}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.93763399124146, '_timestamp': 1721938919.1177232}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721938919.1182518}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721938919.1185036}).
wandb: WARNING (User provided step: 12818 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721938919.1187565}).
Env Football Algo jrpo Exp base_JRPO updates 6242/100000000000.0 steps in 87.50
total episode rewards is 0.0
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'value_loss': 0.29920402724451073, '_timestamp': 1721939006.6204526}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'policy_loss': -0.002156430790006804, '_timestamp': 1721939006.620637}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6113470896085103, '_timestamp': 1721939006.6207087}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.370545893907547, '_timestamp': 1721939006.620805}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6018363237380981, '_timestamp': 1721939006.6210868}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'ratio': 0.9214074015617371, '_timestamp': 1721939006.6211922}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721939006.6213267}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939006.621419}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.50063610076904, '_timestamp': 1721939006.6214786}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.21511760675953415, '_timestamp': 1721939006.6223254}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'train_goal': 0.6075588033797671, '_timestamp': 1721939006.6232238}).
wandb: WARNING (User provided step: 6242 is less than current step: 15000. Dropping entry: {'train_WDL': 0.21511760675953415, '_timestamp': 1721939006.6240187}).
Env Football Algo jrpo Exp base_JRPO updates 10771/100000000000.0 steps in 84.77
total episode rewards is -20.0
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'value_loss': 0.302864856615973, '_timestamp': 1721939091.3955932}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009587532913913795, '_timestamp': 1721939091.3958204}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3978097931543987, '_timestamp': 1721939091.3958948}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39325150847435, '_timestamp': 1721939091.3960185}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5098000764846802, '_timestamp': 1721939091.3962982}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'ratio': 0.9344486594200134, '_timestamp': 1721939091.3964057}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721939091.396534}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939091.3970609}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.77051210403442, '_timestamp': 1721939091.3971224}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.01678883896902341, '_timestamp': 1721939091.3977265}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'train_goal': 0.5083944194845117, '_timestamp': 1721939091.398033}).
wandb: WARNING (User provided step: 10771 is less than current step: 15000. Dropping entry: {'train_WDL': 0.01678883896902341, '_timestamp': 1721939091.3983335}).
Env Football Algo jrpo Exp base_JRPO updates 9665/100000000000.0 steps in 90.11
total episode rewards is -20.0
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'value_loss': 0.2959260363529514, '_timestamp': 1721939181.5148897}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007810767593279404, '_timestamp': 1721939181.5162685}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.336536636352539, '_timestamp': 1721939181.5163467}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5949807167053223, '_timestamp': 1721939181.5168443}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3325388729572296, '_timestamp': 1721939181.5172188}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'ratio': 0.989125669002533, '_timestamp': 1721939181.517329}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721939181.5174687}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939181.5176802}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.11065673828125, '_timestamp': 1721939181.5183325}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.11677600749765699, '_timestamp': 1721939181.5193183}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'train_goal': 0.5583880037488285, '_timestamp': 1721939181.5197072}).
wandb: WARNING (User provided step: 9665 is less than current step: 15000. Dropping entry: {'train_WDL': 0.11677600749765699, '_timestamp': 1721939181.5201151}).
Env Football Algo jrpo Exp base_JRPO updates 8608/100000000000.0 steps in 91.33
total episode rewards is -40.0
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'value_loss': 0.2976867588522146, '_timestamp': 1721939272.852152}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010590581252860526, '_timestamp': 1721939272.8523226}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3169798803329469, '_timestamp': 1721939272.8523922}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.9935835003852844, '_timestamp': 1721939272.8524864}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.41379934549331665, '_timestamp': 1721939272.8527453}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'ratio': 1.0003365278244019, '_timestamp': 1721939272.8528469}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721939272.8531857}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939272.8532858}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.33104705810547, '_timestamp': 1721939272.8533444}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939272.853919}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939272.8543236}).
wandb: WARNING (User provided step: 8608 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939272.854737}).
Env Football Algo jrpo Exp base_JRPO updates 5379/100000000000.0 steps in 85.19
total episode rewards is -30.0
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'value_loss': 0.381819296022101, '_timestamp': 1721939358.0482535}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008671093717372666, '_timestamp': 1721939358.0484383}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3276001946131388, '_timestamp': 1721939358.0485048}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7298880815505981, '_timestamp': 1721939358.0485926}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.30270835757255554, '_timestamp': 1721939358.048839}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'ratio': 0.9951508045196533, '_timestamp': 1721939358.048942}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721939358.0490665}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939358.0492394}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.19274497032166, '_timestamp': 1721939358.0492983}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3685592385953397, '_timestamp': 1721939358.0500288}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'train_goal': 0.31572038070233016, '_timestamp': 1721939358.0509024}).
wandb: WARNING (User provided step: 5379 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3685592385953397, '_timestamp': 1721939358.051444}).
Env Football Algo jrpo Exp base_JRPO updates 7440/100000000000.0 steps in 82.41
total episode rewards is 10.0
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'value_loss': 0.2581930591794662, '_timestamp': 1721939440.4592183}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008653660011962832, '_timestamp': 1721939440.4593897}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.453411677678426, '_timestamp': 1721939440.45946}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7025360465049744, '_timestamp': 1721939440.4595563}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4704195261001587, '_timestamp': 1721939440.4598215}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'ratio': 0.9869004487991333, '_timestamp': 1721939440.4599264}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721939440.460097}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939440.460407}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.40692329406738, '_timestamp': 1721939440.4604673}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5087301587301587, '_timestamp': 1721939440.4611633}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'train_goal': 0.7543650793650793, '_timestamp': 1721939440.4616337}).
wandb: WARNING (User provided step: 7440 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5087301587301587, '_timestamp': 1721939440.4620845}).
Env Football Algo jrpo Exp base_JRPO updates 13246/100000000000.0 steps in 91.09
total episode rewards is 10.0
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'value_loss': 0.07975550072422873, '_timestamp': 1721939531.5519238}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012841344284048924, '_timestamp': 1721939531.5521905}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.483928480943044, '_timestamp': 1721939531.5522578}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6585766077041626, '_timestamp': 1721939531.5524342}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5016158223152161, '_timestamp': 1721939531.552686}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'ratio': 0.9941090941429138, '_timestamp': 1721939531.5527897}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721939531.5529227}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939531.5531669}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.08863019943237, '_timestamp': 1721939531.553227}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721939531.5536485}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721939531.553826}).
wandb: WARNING (User provided step: 13246 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721939531.5539958}).
Env Football Algo jrpo Exp base_JRPO updates 10471/100000000000.0 steps in 82.60
total episode rewards is -30.0
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'value_loss': 0.2207386050443165, '_timestamp': 1721939614.1625006}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018305019201240308, '_timestamp': 1721939614.1634548}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4808485539754233, '_timestamp': 1721939614.1635249}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 1.0900555849075317, '_timestamp': 1721939614.1639009}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5336995124816895, '_timestamp': 1721939614.1642442}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'ratio': 0.9971893429756165, '_timestamp': 1721939614.1643534}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721939614.1644928}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939614.1646707}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.60364413261414, '_timestamp': 1721939614.1651218}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939614.1658864}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939614.1662042}).
wandb: WARNING (User provided step: 10471 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939614.1665177}).
Env Football Algo jrpo Exp base_JRPO updates 8072/100000000000.0 steps in 84.15
total episode rewards is -10.0
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'value_loss': 0.2284349419424931, '_timestamp': 1721939698.3210154}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0036832311865873635, '_timestamp': 1721939698.3212328}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5344172565142313, '_timestamp': 1721939698.3213034}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.615382730960846, '_timestamp': 1721939698.321399}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21465592086315155, '_timestamp': 1721939698.321661}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'ratio': 0.9881715178489685, '_timestamp': 1721939698.3217657}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721939698.3218918}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939698.32217}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.1534652709961, '_timestamp': 1721939698.3222291}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.14751732101616627, '_timestamp': 1721939698.3228633}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_goal': 0.42624133949191684, '_timestamp': 1721939698.323289}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_WDL': -0.14751732101616627, '_timestamp': 1721939698.3237274}).
Env Football Algo jrpo Exp base_JRPO updates 5187/100000000000.0 steps in 76.22
total episode rewards is -60.0
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'value_loss': 0.45197222045933205, '_timestamp': 1721939774.5472357}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014191147829405963, '_timestamp': 1721939774.547658}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5858823426564534, '_timestamp': 1721939774.5477276}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.9810909032821655, '_timestamp': 1721939774.5478978}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5004833936691284, '_timestamp': 1721939774.548192}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'ratio': 0.982825756072998, '_timestamp': 1721939774.548298}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721939774.548428}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939774.5488443}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'Episode_Time': 76.22148752212524, '_timestamp': 1721939774.5489037}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939774.549538}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939774.549976}).
wandb: WARNING (User provided step: 5187 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939774.5504265}).
Env Football Algo jrpo Exp base_JRPO updates 7948/100000000000.0 steps in 82.69
total episode rewards is -30.0
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'value_loss': 0.24432127708646778, '_timestamp': 1721939857.239518}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01893454024529395, '_timestamp': 1721939857.239673}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.579010350704193, '_timestamp': 1721939857.2397394}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6194912195205688, '_timestamp': 1721939857.2398303}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16098785400390625, '_timestamp': 1721939857.2401035}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'ratio': 1.01808762550354, '_timestamp': 1721939857.2402112}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721939857.2403378}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939857.2404284}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.68829488754272, '_timestamp': 1721939857.240623}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939857.2411444}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939857.241582}).
wandb: WARNING (User provided step: 7948 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939857.242026}).
Env Football Algo jrpo Exp base_JRPO updates 7449/100000000000.0 steps in 86.54
total episode rewards is -40.0
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'value_loss': 0.3270821659608434, '_timestamp': 1721939943.7791128}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007361687036852042, '_timestamp': 1721939943.7792988}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5860000435511272, '_timestamp': 1721939943.7793725}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6537206768989563, '_timestamp': 1721939943.7794745}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3058461546897888, '_timestamp': 1721939943.7797585}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'ratio': 0.9727680683135986, '_timestamp': 1721939943.7798653}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721939943.780025}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721939943.7801218}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.53602766990662, '_timestamp': 1721939943.7806869}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721939943.7813213}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721939943.7817826}).
wandb: WARNING (User provided step: 7449 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721939943.7822664}).
Env Football Algo jrpo Exp base_JRPO updates 3226/100000000000.0 steps in 90.35
total episode rewards is 20.0
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'value_loss': 0.32997631810818956, '_timestamp': 1721940034.1294723}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0008255604557537784, '_timestamp': 1721940034.129629}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5785408306121826, '_timestamp': 1721940034.1296947}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6280776262283325, '_timestamp': 1721940034.1297846}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16368529200553894, '_timestamp': 1721940034.130022}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'ratio': 0.9894270896911621, '_timestamp': 1721940034.1301365}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721940034.1302676}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940034.1305068}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.34645795822144, '_timestamp': 1721940034.1305652}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5202989638185833, '_timestamp': 1721940034.1313202}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'train_goal': 0.7601494819092917, '_timestamp': 1721940034.1319969}).
wandb: WARNING (User provided step: 3226 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5202989638185833, '_timestamp': 1721940034.1326623}).
Env Football Algo jrpo Exp base_JRPO updates 4187/100000000000.0 steps in 85.01
total episode rewards is 0.0
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'value_loss': 0.30508312432211826, '_timestamp': 1721940119.1429002}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007657449742158254, '_timestamp': 1721940119.1430907}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6244277397791544, '_timestamp': 1721940119.1431584}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5556886792182922, '_timestamp': 1721940119.1432605}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.34089621901512146, '_timestamp': 1721940119.143532}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'ratio': 0.9944014549255371, '_timestamp': 1721940119.1436381}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721940119.1437716}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940119.1438653}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.00849676132202, '_timestamp': 1721940119.1439245}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.10422639415518357, '_timestamp': 1721940119.144907}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_goal': 0.5521131970775918, '_timestamp': 1721940119.1455426}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_WDL': 0.10422639415518357, '_timestamp': 1721940119.1461864}).
Env Football Algo jrpo Exp base_JRPO updates 6694/100000000000.0 steps in 86.50
total episode rewards is -20.0
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'value_loss': 0.2970756987441564, '_timestamp': 1721940205.6569912}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0006629578641150147, '_timestamp': 1721940205.6583698}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6295934303601582, '_timestamp': 1721940205.658449}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.49431610107421875, '_timestamp': 1721940205.6589432}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3186776340007782, '_timestamp': 1721940205.6593235}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'ratio': 0.9865456223487854, '_timestamp': 1721940205.6594312}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721940205.6597056}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940205.6599655}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.50412726402283, '_timestamp': 1721940205.6606033}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2807608957380207, '_timestamp': 1721940205.6624665}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'train_goal': 0.3596195521309897, '_timestamp': 1721940205.6633568}).
wandb: WARNING (User provided step: 6694 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2807608957380207, '_timestamp': 1721940205.663916}).
Env Football Algo jrpo Exp base_JRPO updates 4892/100000000000.0 steps in 88.99
total episode rewards is -10.0
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'value_loss': 0.40086216780434675, '_timestamp': 1721940294.6575263}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008706087559694424, '_timestamp': 1721940294.65771}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.60623433192571, '_timestamp': 1721940294.6577785}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6585697531700134, '_timestamp': 1721940294.6578786}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4104137122631073, '_timestamp': 1721940294.6581395}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'ratio': 0.9981539249420166, '_timestamp': 1721940294.6582525}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721940294.658383}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940294.6584785}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.99261665344238, '_timestamp': 1721940294.658745}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.018050541516245487, '_timestamp': 1721940294.6598048}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'train_goal': 0.5090252707581228, '_timestamp': 1721940294.66071}).
wandb: WARNING (User provided step: 4892 is less than current step: 15000. Dropping entry: {'train_WDL': 0.018050541516245487, '_timestamp': 1721940294.6616108}).
Env Football Algo jrpo Exp base_JRPO updates 5125/100000000000.0 steps in 62.84
total episode rewards is -40.0
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'value_loss': 0.3633967156576303, '_timestamp': 1721940357.500805}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007818776467853847, '_timestamp': 1721940357.5009875}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6542142097155252, '_timestamp': 1721940357.501054}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6336458921432495, '_timestamp': 1721940357.501152}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.34564390778541565, '_timestamp': 1721940357.5014486}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'ratio': 0.9867969751358032, '_timestamp': 1721940357.5015528}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721940357.501692}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940357.5017874}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'Episode_Time': 62.838157415390015, '_timestamp': 1721940357.501883}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.21843838193791157, '_timestamp': 1721940357.5024033}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'train_goal': 0.39078080903104423, '_timestamp': 1721940357.5027854}).
wandb: WARNING (User provided step: 5125 is less than current step: 15000. Dropping entry: {'train_WDL': -0.21843838193791157, '_timestamp': 1721940357.5031416}).
Env Football Algo jrpo Exp base_JRPO updates 9155/100000000000.0 steps in 88.66
total episode rewards is -10.0
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'value_loss': 0.2272731559354967, '_timestamp': 1721940446.1665065}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0005849923273005212, '_timestamp': 1721940446.1667295}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7012780356407164, '_timestamp': 1721940446.166798}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2817932069301605, '_timestamp': 1721940446.1668942}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17093710601329803, '_timestamp': 1721940446.167153}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'ratio': 0.6392378211021423, '_timestamp': 1721940446.167257}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721940446.1674528}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940446.1676326}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.66227531433105, '_timestamp': 1721940446.1677003}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.02172797262617622, '_timestamp': 1721940446.1686783}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'train_goal': 0.5108639863130882, '_timestamp': 1721940446.169144}).
wandb: WARNING (User provided step: 9155 is less than current step: 15000. Dropping entry: {'train_WDL': 0.02172797262617622, '_timestamp': 1721940446.1695926}).
Env Football Algo jrpo Exp base_JRPO updates 11412/100000000000.0 steps in 78.98
total episode rewards is -20.0
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'value_loss': 0.16297138799719202, '_timestamp': 1721940525.1454022}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02834282697159021, '_timestamp': 1721940525.1455636}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7054294768969218, '_timestamp': 1721940525.1456294}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07820001989603043, '_timestamp': 1721940525.145719}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4609038829803467, '_timestamp': 1721940525.145983}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'ratio': 0.5773747563362122, '_timestamp': 1721940525.1460893}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721940525.1462102}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940525.1463017}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.9750771522522, '_timestamp': 1721940525.1464977}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940525.1468375}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940525.147101}).
wandb: WARNING (User provided step: 11412 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940525.1473687}).
Env Football Algo jrpo Exp base_JRPO updates 4571/100000000000.0 steps in 87.03
total episode rewards is 0.0
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'value_loss': 0.28843007964955175, '_timestamp': 1721940612.1784673}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004428002381367454, '_timestamp': 1721940612.178627}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6145356289545696, '_timestamp': 1721940612.178693}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.36880210041999817, '_timestamp': 1721940612.178784}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.33320021629333496, '_timestamp': 1721940612.1790366}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'ratio': 0.7765502333641052, '_timestamp': 1721940612.1791427}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721940612.1793795}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940612.179474}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.0304045677185, '_timestamp': 1721940612.179532}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.14526800268482118, '_timestamp': 1721940612.1896188}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'train_goal': 0.5726340013424106, '_timestamp': 1721940612.1903522}).
wandb: WARNING (User provided step: 4571 is less than current step: 15000. Dropping entry: {'train_WDL': 0.14526800268482118, '_timestamp': 1721940612.1909814}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'value_loss': 0.3095161051325461, '_timestamp': 1721940699.3884122}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004714269379231458, '_timestamp': 1721940699.3885813}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5749928267796833, '_timestamp': 1721940699.3886468}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4807961583137512, '_timestamp': 1721940699.388739}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2764350473880768, '_timestamp': 1721940699.3890035}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'ratio': 0.6772450804710388, '_timestamp': 1721940699.3891072}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721940699.3892388}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940699.3895445}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.19630336761475, '_timestamp': 1721940699.3896027}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.35217341958914994, '_timestamp': 1721940699.3903317}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'train_goal': 0.676086709794575, '_timestamp': 1721940699.3908532}).
wandb: WARNING (User provided step: 6189 is less than current step: 15000. Dropping entry: {'train_WDL': 0.35217341958914994, '_timestamp': 1721940699.3913686}).
Env Football Algo jrpo Exp base_JRPO updates 6189/100000000000.0 steps in 87.20
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 5984/100000000000.0 steps in 85.05
total episode rewards is 10.0
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'value_loss': 0.35780544154229577, '_timestamp': 1721940784.4419298}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009653004585998133, '_timestamp': 1721940784.4421127}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5307797265052796, '_timestamp': 1721940784.4421818}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5132046937942505, '_timestamp': 1721940784.4422817}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.36862674355506897, '_timestamp': 1721940784.442552}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'ratio': 0.6447423696517944, '_timestamp': 1721940784.442658}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721940784.4428012}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940784.443059}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.04969954490662, '_timestamp': 1721940784.44313}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.31233362910381546, '_timestamp': 1721940784.4439886}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'train_goal': 0.6561668145519077, '_timestamp': 1721940784.4445288}).
wandb: WARNING (User provided step: 5984 is less than current step: 15000. Dropping entry: {'train_WDL': 0.31233362910381546, '_timestamp': 1721940784.4450762}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'value_loss': 0.307140306631336, '_timestamp': 1721940875.4339087}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0023959677759557963, '_timestamp': 1721940875.435218}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3037201356887818, '_timestamp': 1721940875.4352913}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30475038290023804, '_timestamp': 1721940875.4358084}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22675929963588715, '_timestamp': 1721940875.4361737}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'ratio': 0.734004557132721, '_timestamp': 1721940875.4362957}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721940875.4369438}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940875.4371595}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.98297882080078, '_timestamp': 1721940875.437219}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.42780130920292647, '_timestamp': 1721940875.4385042}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'train_goal': 0.28609934539853676, '_timestamp': 1721940875.4391546}).
wandb: WARNING (User provided step: 4612 is less than current step: 15000. Dropping entry: {'train_WDL': -0.42780130920292647, '_timestamp': 1721940875.4397779}).
Env Football Algo jrpo Exp base_JRPO updates 4612/100000000000.0 steps in 90.98
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 12141/100000000000.0 steps in 81.17
total episode rewards is -30.0
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'value_loss': 0.22282504069657685, '_timestamp': 1721940956.612366}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02499372007509616, '_timestamp': 1721940956.6125844}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4578555750846862, '_timestamp': 1721940956.612654}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2662765383720398, '_timestamp': 1721940956.6127858}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24086883664131165, '_timestamp': 1721940956.6130447}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'ratio': 0.9693769812583923, '_timestamp': 1721940956.6131546}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721940956.6132894}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721940956.6133826}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.17113995552063, '_timestamp': 1721940956.6136448}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721940956.614026}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721940956.6142545}).
wandb: WARNING (User provided step: 12141 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721940956.614485}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'value_loss': 0.36494753245729955, '_timestamp': 1721941044.0230556}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0069529167439516945, '_timestamp': 1721941044.0232174}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.278420238494873, '_timestamp': 1721941044.0232847}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5758477449417114, '_timestamp': 1721941044.0233753}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16091206669807434, '_timestamp': 1721941044.0236218}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'ratio': 0.9400855898857117, '_timestamp': 1721941044.023725}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721941044.0238569}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941044.024099}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.40777850151062, '_timestamp': 1721941044.0241585}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.09218734528171106, '_timestamp': 1721941044.0248592}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'train_goal': 0.5460936726408555, '_timestamp': 1721941044.0254402}).
wandb: WARNING (User provided step: 4901 is less than current step: 15000. Dropping entry: {'train_WDL': 0.09218734528171106, '_timestamp': 1721941044.0260277}).
Env Football Algo jrpo Exp base_JRPO updates 4901/100000000000.0 steps in 87.41
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 10812/100000000000.0 steps in 89.40
total episode rewards is -10.0
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'value_loss': 0.227481974180749, '_timestamp': 1721941133.4314678}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0007530986478862663, '_timestamp': 1721941133.4316401}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.300789270401001, '_timestamp': 1721941133.4317093}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6088021993637085, '_timestamp': 1721941133.431803}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4607493281364441, '_timestamp': 1721941133.432076}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'ratio': 0.9046653509140015, '_timestamp': 1721941133.432181}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721941133.432316}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941133.4324088}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.40448474884033, '_timestamp': 1721941133.4326258}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.40830945558739257, '_timestamp': 1721941133.4331648}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'train_goal': 0.7041547277936963, '_timestamp': 1721941133.4334526}).
wandb: WARNING (User provided step: 10812 is less than current step: 15000. Dropping entry: {'train_WDL': 0.40830945558739257, '_timestamp': 1721941133.4337406}).
Env Football Algo jrpo Exp base_JRPO updates 8404/100000000000.0 steps in 79.18
total episode rewards is 10.0
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'value_loss': 0.23041568215354347, '_timestamp': 1721941212.6171353}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0005980334572086576, '_timestamp': 1721941212.6182396}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2669767951965332, '_timestamp': 1721941212.6183112}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.609393298625946, '_timestamp': 1721941212.618741}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.46101248264312744, '_timestamp': 1721941212.6190755}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'ratio': 0.8851481080055237, '_timestamp': 1721941212.619182}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721941212.6193144}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941212.6194904}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.17798233032227, '_timestamp': 1721941212.619654}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.7468162522741055, '_timestamp': 1721941212.6207798}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'train_goal': 0.8734081261370528, '_timestamp': 1721941212.6211991}).
wandb: WARNING (User provided step: 8404 is less than current step: 15000. Dropping entry: {'train_WDL': 0.7468162522741055, '_timestamp': 1721941212.6216018}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'value_loss': 0.3264535815354126, '_timestamp': 1721941304.2645118}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'policy_loss': 0.011915572215026865, '_timestamp': 1721941304.2647514}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2299745472272237, '_timestamp': 1721941304.2648234}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.8394989967346191, '_timestamp': 1721941304.264962}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20725741982460022, '_timestamp': 1721941304.2652104}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'ratio': 0.9271230101585388, '_timestamp': 1721941304.2653196}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721941304.2654502}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941304.2661548}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.64186406135559, '_timestamp': 1721941304.2662184}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941304.2668374}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941304.267297}).
wandb: WARNING (User provided step: 7957 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941304.267749}).
Env Football Algo jrpo Exp base_JRPO updates 7957/100000000000.0 steps in 91.64
total episode rewards is -40.0
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'value_loss': 0.2524000875838101, '_timestamp': 1721941394.3106468}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004704118158163813, '_timestamp': 1721941394.310854}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.217007106145223, '_timestamp': 1721941394.310921}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6766900420188904, '_timestamp': 1721941394.3110478}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16287711262702942, '_timestamp': 1721941394.311303}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'ratio': 0.968450665473938, '_timestamp': 1721941394.3114054}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941394.3115396}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941394.3116317}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.04179787635803, '_timestamp': 1721941394.3118458}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941394.3123844}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941394.3127832}).
wandb: WARNING (User provided step: 8731 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941394.313196}).
Env Football Algo jrpo Exp base_JRPO updates 8731/100000000000.0 steps in 90.04
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 9637/100000000000.0 steps in 83.87
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'value_loss': 0.24846436601132155, '_timestamp': 1721941478.1836493}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005806505522535493, '_timestamp': 1721941478.1838682}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2680701359113058, '_timestamp': 1721941478.1839447}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.372080534696579, '_timestamp': 1721941478.1840909}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6481226086616516, '_timestamp': 1721941478.1843483}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'ratio': 0.8917310833930969, '_timestamp': 1721941478.184454}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941478.1845844}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941478.1849794}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.86925029754639, '_timestamp': 1721941478.1850383}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941478.1855578}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941478.1859853}).
wandb: WARNING (User provided step: 9637 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941478.1863828}).
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 8620/100000000000.0 steps in 85.39
total episode rewards is -20.0
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'value_loss': 0.28628650509752335, '_timestamp': 1721941563.5858023}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'policy_loss': -0.006710479123479066, '_timestamp': 1721941563.5870242}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2313167270024616, '_timestamp': 1721941563.5870938}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4081827998161316, '_timestamp': 1721941563.5875494}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16747726500034332, '_timestamp': 1721941563.5878727}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'ratio': 0.8558991551399231, '_timestamp': 1721941563.5879965}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721941563.5881252}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941563.5883067}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.39390254020691, '_timestamp': 1721941563.5887208}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.06300940438871473, '_timestamp': 1721941563.5896404}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'train_goal': 0.46849529780564264, '_timestamp': 1721941563.590054}).
wandb: WARNING (User provided step: 8620 is less than current step: 15000. Dropping entry: {'train_WDL': -0.06300940438871473, '_timestamp': 1721941563.5904539}).
Env Football Algo jrpo Exp base_JRPO updates 13077/100000000000.0 steps in 89.89
total episode rewards is -40.0
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'value_loss': 0.2827556522431163, '_timestamp': 1721941653.4846494}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008079230408184231, '_timestamp': 1721941653.4848154}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.177598094145457, '_timestamp': 1721941653.4848857}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3852432072162628, '_timestamp': 1721941653.4849856}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.198574036359787, '_timestamp': 1721941653.4852488}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'ratio': 0.929241955280304, '_timestamp': 1721941653.4853632}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721941653.4859428}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941653.4860477}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.89341402053833, '_timestamp': 1721941653.4861064}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941653.4864018}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941653.4866402}).
wandb: WARNING (User provided step: 13077 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941653.486829}).
Env Football Algo jrpo Exp base_JRPO updates 3850/100000000000.0 steps in 70.32
total episode rewards is -30.0
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'value_loss': 0.6943620215977232, '_timestamp': 1721941723.807963}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0003118784469552338, '_timestamp': 1721941723.8081362}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1651811512311299, '_timestamp': 1721941723.8082056}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7205570936203003, '_timestamp': 1721941723.8083012}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9473751783370972, '_timestamp': 1721941723.808565}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'ratio': 0.9735879898071289, '_timestamp': 1721941723.8086698}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941723.8087995}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941723.8088906}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'Episode_Time': 70.31983923912048, '_timestamp': 1721941723.8089488}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.1750943396226415, '_timestamp': 1721941723.8095648}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'train_goal': 0.5875471698113207, '_timestamp': 1721941723.8100438}).
wandb: WARNING (User provided step: 3850 is less than current step: 15000. Dropping entry: {'train_WDL': 0.1750943396226415, '_timestamp': 1721941723.8105326}).
Env Football Algo jrpo Exp base_JRPO updates 10041/100000000000.0 steps in 85.55
total episode rewards is -30.0
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'value_loss': 0.2307531699212268, '_timestamp': 1721941809.365338}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0026082250574836507, '_timestamp': 1721941809.3667097}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2613864994049073, '_timestamp': 1721941809.3667839}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3466130793094635, '_timestamp': 1721941809.3672996}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3010241389274597, '_timestamp': 1721941809.367676}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'ratio': 0.8713603019714355, '_timestamp': 1721941809.367781}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721941809.3684642}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941809.3686817}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.54856467247009, '_timestamp': 1721941809.3687427}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721941809.369658}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721941809.3700778}).
wandb: WARNING (User provided step: 10041 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721941809.3704872}).
Env Football Algo jrpo Exp base_JRPO updates 5978/100000000000.0 steps in 58.92
total episode rewards is -50.0
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'value_loss': 0.6552235746197402, '_timestamp': 1721941868.2894418}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00202975481050089, '_timestamp': 1721941868.289703}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2871973594029744, '_timestamp': 1721941868.2897754}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7475305199623108, '_timestamp': 1721941868.2899082}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8561802506446838, '_timestamp': 1721941868.290185}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'ratio': 0.9127464890480042, '_timestamp': 1721941868.2902923}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721941868.2904205}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941868.290958}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'Episode_Time': 58.917845487594604, '_timestamp': 1721941868.2910175}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.05114969497888315, '_timestamp': 1721941868.2916079}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'train_goal': 0.47442515251055845, '_timestamp': 1721941868.2919292}).
wandb: WARNING (User provided step: 5978 is less than current step: 15000. Dropping entry: {'train_WDL': -0.05114969497888315, '_timestamp': 1721941868.2923758}).
Env Football Algo jrpo Exp base_JRPO updates 11803/100000000000.0 steps in 88.11
total episode rewards is 0.0
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'value_loss': 0.16856301054280873, '_timestamp': 1721941956.4063969}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'policy_loss': 0.019493092523577314, '_timestamp': 1721941956.406659}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3023486566543578, '_timestamp': 1721941956.4067297}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.405651330947876, '_timestamp': 1721941956.4068615}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.39295098185539246, '_timestamp': 1721941956.407122}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'ratio': 0.841762125492096, '_timestamp': 1721941956.40723}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721941956.4074013}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721941956.4079137}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.1128191947937, '_timestamp': 1721941956.4079893}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.19174225836721928, '_timestamp': 1721941956.4085512}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'train_goal': 0.4041288708163904, '_timestamp': 1721941956.4088078}).
wandb: WARNING (User provided step: 11803 is less than current step: 15000. Dropping entry: {'train_WDL': -0.19174225836721928, '_timestamp': 1721941956.409158}).
Env Football Algo jrpo Exp base_JRPO updates 7446/100000000000.0 steps in 85.73
total episode rewards is 0.0
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'value_loss': 0.30240333295504873, '_timestamp': 1721942042.1406887}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014301832821802236, '_timestamp': 1721942042.140916}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2146875580151877, '_timestamp': 1721942042.1409874}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5049542188644409, '_timestamp': 1721942042.1411214}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22770056128501892, '_timestamp': 1721942042.1413894}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'ratio': 0.7548972964286804, '_timestamp': 1721942042.1414983}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721942042.1421309}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942042.1422296}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.73028802871704, '_timestamp': 1721942042.1422887}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.4633306857294149, '_timestamp': 1721942042.143028}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'train_goal': 0.7316653428647074, '_timestamp': 1721942042.1435301}).
wandb: WARNING (User provided step: 7446 is less than current step: 15000. Dropping entry: {'train_WDL': 0.4633306857294149, '_timestamp': 1721942042.1440132}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'value_loss': 0.617599306392173, '_timestamp': 1721942105.239785}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04081250791903585, '_timestamp': 1721942105.2409058}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1270692845185597, '_timestamp': 1721942105.2409854}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.582149088382721, '_timestamp': 1721942105.2414331}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7448777556419373, '_timestamp': 1721942105.241776}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'ratio': 0.8237186670303345, '_timestamp': 1721942105.241882}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721942105.2427351}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942105.242937}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'Episode_Time': 63.09066891670227, '_timestamp': 1721942105.243002}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2429614181438999, '_timestamp': 1721942105.243821}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'train_goal': 0.37851929092805003, '_timestamp': 1721942105.2442071}).
wandb: WARNING (User provided step: 4425 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2429614181438999, '_timestamp': 1721942105.2445846}).
Env Football Algo jrpo Exp base_JRPO updates 4425/100000000000.0 steps in 63.09
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 9527/100000000000.0 steps in 87.27
total episode rewards is -30.0
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'value_loss': 0.32197117631090805, '_timestamp': 1721942192.512502}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'policy_loss': -0.006997502587619237, '_timestamp': 1721942192.5126665}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.240481023788452, '_timestamp': 1721942192.5127337}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29904767870903015, '_timestamp': 1721942192.5128305}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3611633777618408, '_timestamp': 1721942192.5130746}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'ratio': 0.6824683547019958, '_timestamp': 1721942192.5131795}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721942192.5133102}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942192.5135982}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.2670648097992, '_timestamp': 1721942192.5136673}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721942192.5141308}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721942192.514486}).
wandb: WARNING (User provided step: 9527 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721942192.514857}).
Env Football Algo jrpo Exp base_JRPO updates 3366/100000000000.0 steps in 52.57
total episode rewards is 0.0
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'value_loss': 1.14548558562994, '_timestamp': 1721942245.0905206}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006450394575270669, '_timestamp': 1721942245.0907056}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0813383746147156, '_timestamp': 1721942245.0907736}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 1.015372395515442, '_timestamp': 1721942245.0908768}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.263530969619751, '_timestamp': 1721942245.0911162}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'ratio': 0.8761517405509949, '_timestamp': 1721942245.0912204}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721942245.0913484}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942245.0914445}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'Episode_Time': 52.57460069656372, '_timestamp': 1721942245.0916593}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3338866984851629, '_timestamp': 1721942245.0922039}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'train_goal': 0.6669433492425815, '_timestamp': 1721942245.0925224}).
wandb: WARNING (User provided step: 3366 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3338866984851629, '_timestamp': 1721942245.0928612}).
Env Football Algo jrpo Exp base_JRPO updates 7808/100000000000.0 steps in 79.49
total episode rewards is -40.0
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'value_loss': 0.5427671455871313, '_timestamp': 1721942324.5846086}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'policy_loss': 0.046819125032246424, '_timestamp': 1721942324.5847614}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1914153854052225, '_timestamp': 1721942324.5848281}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6205487847328186, '_timestamp': 1721942324.5849159}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5613188147544861, '_timestamp': 1721942324.5851588}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'ratio': 0.8571140766143799, '_timestamp': 1721942324.5852625}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721942324.5853875}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942324.585644}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.49102592468262, '_timestamp': 1721942324.5857038}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.5373046299026836, '_timestamp': 1721942324.5862544}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'train_goal': 0.2313476850486582, '_timestamp': 1721942324.5866733}).
wandb: WARNING (User provided step: 7808 is less than current step: 15000. Dropping entry: {'train_WDL': -0.5373046299026836, '_timestamp': 1721942324.5870976}).
Env Football Algo jrpo Exp base_JRPO updates 5577/100000000000.0 steps in 79.66
total episode rewards is 10.0
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'value_loss': 0.7116724759278198, '_timestamp': 1721942404.2465484}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'policy_loss': 0.022849624074103, '_timestamp': 1721942404.246782}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.16875936905543, '_timestamp': 1721942404.246853}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.686945378780365, '_timestamp': 1721942404.2469943}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6711220741271973, '_timestamp': 1721942404.247269}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'ratio': 0.8154723048210144, '_timestamp': 1721942404.2473776}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721942404.247515}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942404.2476113}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.6582453250885, '_timestamp': 1721942404.2479036}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.18355934572906474, '_timestamp': 1721942404.248583}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'train_goal': 0.5917796728645324, '_timestamp': 1721942404.249033}).
wandb: WARNING (User provided step: 5577 is less than current step: 15000. Dropping entry: {'train_WDL': 0.18355934572906474, '_timestamp': 1721942404.2494764}).
Env Football Algo jrpo Exp base_JRPO updates 7200/100000000000.0 steps in 79.69
total episode rewards is -40.0
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'value_loss': 0.44382089253204565, '_timestamp': 1721942483.9432013}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'policy_loss': 0.028634663918055595, '_timestamp': 1721942483.943416}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2421422131856283, '_timestamp': 1721942483.9434857}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42320773005485535, '_timestamp': 1721942483.9435885}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6060083508491516, '_timestamp': 1721942483.9438617}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'ratio': 0.8772048354148865, '_timestamp': 1721942483.9440043}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721942483.94484}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942483.9449592}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.69263958930969, '_timestamp': 1721942483.94502}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.18273809523809523, '_timestamp': 1721942483.9458218}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'train_goal': 0.4086309523809524, '_timestamp': 1721942483.9462798}).
wandb: WARNING (User provided step: 7200 is less than current step: 15000. Dropping entry: {'train_WDL': -0.18273809523809523, '_timestamp': 1721942483.9467924}).
Env Football Algo jrpo Exp base_JRPO updates 5293/100000000000.0 steps in 76.51
total episode rewards is -30.0
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'value_loss': 0.52959195120881, '_timestamp': 1721942560.4564276}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01789493184061333, '_timestamp': 1721942560.456646}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.201448189417521, '_timestamp': 1721942560.4567153}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42635104060173035, '_timestamp': 1721942560.456813}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6929708123207092, '_timestamp': 1721942560.4570746}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'ratio': 0.8549358248710632, '_timestamp': 1721942560.4573555}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721942560.4574914}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942560.4575846}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'Episode_Time': 76.50830292701721, '_timestamp': 1721942560.4576423}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.31222562192363973, '_timestamp': 1721942560.4583778}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'train_goal': 0.6561128109618198, '_timestamp': 1721942560.4588373}).
wandb: WARNING (User provided step: 5293 is less than current step: 15000. Dropping entry: {'train_WDL': 0.31222562192363973, '_timestamp': 1721942560.45929}).
Env Football Algo jrpo Exp base_JRPO updates 7708/100000000000.0 steps in 91.18
total episode rewards is -20.0
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'value_loss': 0.35572458303223053, '_timestamp': 1721942651.641701}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009736110358693015, '_timestamp': 1721942651.6430647}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1600206383069356, '_timestamp': 1721942651.6431372}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6826822757720947, '_timestamp': 1721942651.6436534}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3099265992641449, '_timestamp': 1721942651.6440485}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'ratio': 0.8444372415542603, '_timestamp': 1721942651.6441576}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721942651.6447725}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942651.6449866}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.17603325843811, '_timestamp': 1721942651.6450443}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.7347778387273725, '_timestamp': 1721942651.6460652}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'train_goal': 0.13261108063631377, '_timestamp': 1721942651.6465259}).
wandb: WARNING (User provided step: 7708 is less than current step: 15000. Dropping entry: {'train_WDL': -0.7347778387273725, '_timestamp': 1721942651.6470244}).
Env Football Algo jrpo Exp base_JRPO updates 7348/100000000000.0 steps in 88.45
total episode rewards is -20.0
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'value_loss': 0.28433835494642457, '_timestamp': 1721942740.0970035}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'policy_loss': -0.020484438689406186, '_timestamp': 1721942740.0971854}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1175033926963807, '_timestamp': 1721942740.0972524}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7076320052146912, '_timestamp': 1721942740.0973613}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.28432920575141907, '_timestamp': 1721942740.0976176}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'ratio': 0.5426110029220581, '_timestamp': 1721942740.0979645}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721942740.0981023}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942740.0981953}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.44907259941101, '_timestamp': 1721942740.0982518}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2211186617877679, '_timestamp': 1721942740.0989087}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_goal': 0.389440669106116, '_timestamp': 1721942740.099379}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2211186617877679, '_timestamp': 1721942740.099851}).
Env Football Algo jrpo Exp base_JRPO updates 4216/100000000000.0 steps in 73.91
total episode rewards is 10.0
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'value_loss': 0.444793717029194, '_timestamp': 1721942814.0086648}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00033442066749557854, '_timestamp': 1721942814.008905}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.131394890944163, '_timestamp': 1721942814.0089731}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4666636884212494, '_timestamp': 1721942814.009068}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3654117286205292, '_timestamp': 1721942814.0093257}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'ratio': 0.7391439080238342, '_timestamp': 1721942814.0096009}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721942814.0097342}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942814.0098255}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'Episode_Time': 73.90781092643738, '_timestamp': 1721942814.0098815}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.1659741458910434, '_timestamp': 1721942814.0106745}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'train_goal': 0.5829870729455217, '_timestamp': 1721942814.0111938}).
wandb: WARNING (User provided step: 4216 is less than current step: 15000. Dropping entry: {'train_WDL': 0.1659741458910434, '_timestamp': 1721942814.0117004}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'value_loss': 0.3420304448219637, '_timestamp': 1721942906.336011}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004372918524701769, '_timestamp': 1721942906.3362226}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.118782233397166, '_timestamp': 1721942906.3363214}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6062211394309998, '_timestamp': 1721942906.3364298}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15498106181621552, '_timestamp': 1721942906.3367167}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'ratio': 0.6897439956665039, '_timestamp': 1721942906.3368218}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721942906.3369644}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942906.3370595}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.32276320457458, '_timestamp': 1721942906.3371158}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2245784628116272, '_timestamp': 1721942906.3379068}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'train_goal': 0.6122892314058136, '_timestamp': 1721942906.33882}).
wandb: WARNING (User provided step: 5333 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2245784628116272, '_timestamp': 1721942906.3397276}).
Env Football Algo jrpo Exp base_JRPO updates 5333/100000000000.0 steps in 92.32
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 6689/100000000000.0 steps in 82.80
total episode rewards is -20.0
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'value_loss': 0.47210290836946417, '_timestamp': 1721942989.1379142}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03384174547429818, '_timestamp': 1721942989.1380825}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4480125713348388, '_timestamp': 1721942989.1381497}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1307230144739151, '_timestamp': 1721942989.1382422}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5574803948402405, '_timestamp': 1721942989.1385052}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'ratio': 0.4666258990764618, '_timestamp': 1721942989.138607}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721942989.1387417}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721942989.139083}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.79672312736511, '_timestamp': 1721942989.1391408}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.023346303501945526, '_timestamp': 1721942989.1396816}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'train_goal': 0.4883268482490272, '_timestamp': 1721942989.1401415}).
wandb: WARNING (User provided step: 6689 is less than current step: 15000. Dropping entry: {'train_WDL': -0.023346303501945526, '_timestamp': 1721942989.1405845}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'value_loss': 0.8367709553645303, '_timestamp': 1721943031.9378104}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03282931374385953, '_timestamp': 1721943031.9379797}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6453780841827392, '_timestamp': 1721943031.9380457}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40072229504585266, '_timestamp': 1721943031.9381387}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0437318086624146, '_timestamp': 1721943031.9383984}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'ratio': 0.7290480136871338, '_timestamp': 1721943031.9385085}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721943031.9387872}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943031.938885}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'Episode_Time': 42.79627227783203, '_timestamp': 1721943031.9389412}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.020731247644176404, '_timestamp': 1721943031.9392867}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'train_goal': 0.4896343761779118, '_timestamp': 1721943031.9395068}).
wandb: WARNING (User provided step: 3952 is less than current step: 15000. Dropping entry: {'train_WDL': -0.020731247644176404, '_timestamp': 1721943031.9397223}).
Env Football Algo jrpo Exp base_JRPO updates 3952/100000000000.0 steps in 42.80
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 8940/100000000000.0 steps in 87.92
total episode rewards is 0.0
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'value_loss': 0.31317329745700895, '_timestamp': 1721943119.8637197}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04175838373620839, '_timestamp': 1721943119.8639753}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8831401975949604, '_timestamp': 1721943119.8640482}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3932268023490906, '_timestamp': 1721943119.8642006}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17854467034339905, '_timestamp': 1721943119.8644502}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'ratio': 0.8936054706573486, '_timestamp': 1721943119.864553}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721943119.864682}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943119.8649702}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.92299222946167, '_timestamp': 1721943119.8650296}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.12475247524752475, '_timestamp': 1721943119.865692}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'train_goal': 0.5623762376237624, '_timestamp': 1721943119.8661642}).
wandb: WARNING (User provided step: 8940 is less than current step: 15000. Dropping entry: {'train_WDL': 0.12475247524752475, '_timestamp': 1721943119.8665602}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'value_loss': 0.4453606636806702, '_timestamp': 1721943196.048356}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010365574922373829, '_timestamp': 1721943196.0497532}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4533157682418822, '_timestamp': 1721943196.0498264}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39831167459487915, '_timestamp': 1721943196.0503497}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5064594149589539, '_timestamp': 1721943196.0507224}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'ratio': 0.9378290772438049, '_timestamp': 1721943196.0508354}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721943196.0515428}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943196.0517933}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'Episode_Time': 76.17419028282166, '_timestamp': 1721943196.0518553}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.06002377179080824, '_timestamp': 1721943196.053083}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'train_goal': 0.5300118858954042, '_timestamp': 1721943196.053689}).
wandb: WARNING (User provided step: 3469 is less than current step: 15000. Dropping entry: {'train_WDL': 0.06002377179080824, '_timestamp': 1721943196.0542765}).
Env Football Algo jrpo Exp base_JRPO updates 3469/100000000000.0 steps in 76.17
total episode rewards is -20.0
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'value_loss': 0.26163604596823764, '_timestamp': 1721943286.340134}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0609830712176093, '_timestamp': 1721943286.3402998}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6850058285395304, '_timestamp': 1721943286.3403668}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.38924670219421387, '_timestamp': 1721943286.3404615}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13074517250061035, '_timestamp': 1721943286.3407214}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'ratio': 0.6769721508026123, '_timestamp': 1721943286.3408244}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721943286.3409564}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943286.3410513}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.28153467178345, '_timestamp': 1721943286.3412504}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943286.3417299}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943286.3420768}).
wandb: WARNING (User provided step: 9821 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943286.3424232}).
Env Football Algo jrpo Exp base_JRPO updates 9821/100000000000.0 steps in 90.28
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 8643/100000000000.0 steps in 81.44
total episode rewards is -30.0
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'value_loss': 0.2109210799463714, '_timestamp': 1721943367.7852206}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03147604265162954, '_timestamp': 1721943367.7853858}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7821244096755982, '_timestamp': 1721943367.7854562}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2691842317581177, '_timestamp': 1721943367.7855537}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.40333306789398193, '_timestamp': 1721943367.7858064}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'ratio': 0.8690336346626282, '_timestamp': 1721943367.7859092}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721943367.7861733}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943367.7862692}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.44203209877014, '_timestamp': 1721943367.7863302}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943367.786828}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943367.7872195}).
wandb: WARNING (User provided step: 8643 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943367.7876256}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'value_loss': 0.22539025308835942, '_timestamp': 1721943452.446625}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'policy_loss': 0.032429588246983866, '_timestamp': 1721943452.4467876}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8144054539998373, '_timestamp': 1721943452.4468539}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2131328582763672, '_timestamp': 1721943452.446943}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18648242950439453, '_timestamp': 1721943452.4471793}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'ratio': 0.8285685777664185, '_timestamp': 1721943452.4472835}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721943452.4474115}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943452.4476032}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.658287525177, '_timestamp': 1721943452.4476633}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721943452.4481516}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721943452.4485052}).
wandb: WARNING (User provided step: 9493 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721943452.4488714}).
Env Football Algo jrpo Exp base_JRPO updates 9493/100000000000.0 steps in 84.66
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 10314/100000000000.0 steps in 89.37
total episode rewards is -20.0
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'value_loss': 0.30527807312939936, '_timestamp': 1721943541.8207605}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012067715496135254, '_timestamp': 1721943541.820912}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.607365460395813, '_timestamp': 1721943541.8209772}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2941147983074188, '_timestamp': 1721943541.8210635}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.33484846353530884, '_timestamp': 1721943541.8212988}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'ratio': 0.8756611347198486, '_timestamp': 1721943541.8213968}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721943541.8216317}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943541.8217196}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.37118625640869, '_timestamp': 1721943541.8217764}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.8040973111395646, '_timestamp': 1721943541.822204}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'train_goal': 0.09795134443021766, '_timestamp': 1721943541.8225257}).
wandb: WARNING (User provided step: 10314 is less than current step: 15000. Dropping entry: {'train_WDL': -0.8040973111395646, '_timestamp': 1721943541.8228457}).
Env Football Algo jrpo Exp base_JRPO updates 7615/100000000000.0 steps in 90.47
total episode rewards is -10.0
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'value_loss': 0.2713192535317891, '_timestamp': 1721943632.2978194}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0058156632164415595, '_timestamp': 1721943632.2980354}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5330350478490193, '_timestamp': 1721943632.2981057}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2638022303581238, '_timestamp': 1721943632.2982032}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1480349600315094, '_timestamp': 1721943632.2984316}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'ratio': 0.929151713848114, '_timestamp': 1721943632.2985382}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721943632.2987905}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943632.2988887}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.47367596626282, '_timestamp': 1721943632.298948}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.190521327014218, '_timestamp': 1721943632.2998178}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'train_goal': 0.404739336492891, '_timestamp': 1721943632.3006167}).
wandb: WARNING (User provided step: 7615 is less than current step: 15000. Dropping entry: {'train_WDL': -0.190521327014218, '_timestamp': 1721943632.301395}).
Env Football Algo jrpo Exp base_JRPO updates 5214/100000000000.0 steps in 84.03
total episode rewards is 0.0
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'value_loss': 0.3322048661504717, '_timestamp': 1721943716.336658}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0066997903701849285, '_timestamp': 1721943716.3368769}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4877727460861205, '_timestamp': 1721943716.3369446}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40964871644973755, '_timestamp': 1721943716.3370328}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.37918713688850403, '_timestamp': 1721943716.337262}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'ratio': 0.8956338763237, '_timestamp': 1721943716.3373637}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721943716.337571}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943716.3377757}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.03446316719055, '_timestamp': 1721943716.3378365}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2035561005518087, '_timestamp': 1721943716.3390198}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'train_goal': 0.6017780502759044, '_timestamp': 1721943716.3395853}).
wandb: WARNING (User provided step: 5214 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2035561005518087, '_timestamp': 1721943716.3401797}).
Env Football Algo jrpo Exp base_JRPO updates 6722/100000000000.0 steps in 82.57
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'value_loss': 0.40613254099929086, '_timestamp': 1721943798.910636}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'policy_loss': 0.023150755122866636, '_timestamp': 1721943798.9107919}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4411169894536335, '_timestamp': 1721943798.9108593}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4478909969329834, '_timestamp': 1721943798.9109488}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.262985497713089, '_timestamp': 1721943798.9111862}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'ratio': 0.8447853922843933, '_timestamp': 1721943798.9112883}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721943798.9115138}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943798.9116032}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.56963229179382, '_timestamp': 1721943798.9116602}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5631110462571137, '_timestamp': 1721943798.9123776}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'train_goal': 0.7815555231285568, '_timestamp': 1721943798.9128017}).
wandb: WARNING (User provided step: 6722 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5631110462571137, '_timestamp': 1721943798.9132202}).
total episode rewards is 10.0
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'value_loss': 0.33581937617622315, '_timestamp': 1721943889.8443766}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004151682179296282, '_timestamp': 1721943889.844539}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5952856095631918, '_timestamp': 1721943889.844606}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.26797929406166077, '_timestamp': 1721943889.8446972}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2652287483215332, '_timestamp': 1721943889.8449423}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'ratio': 0.9535993933677673, '_timestamp': 1721943889.8451169}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721943889.8454282}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943889.8455205}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.93037438392639, '_timestamp': 1721943889.8455775}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.10311661888467585, '_timestamp': 1721943889.8463485}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_goal': 0.551558309442338, '_timestamp': 1721943889.84696}).
wandb: WARNING (User provided step: 4187 is less than current step: 15000. Dropping entry: {'train_WDL': 0.10311661888467585, '_timestamp': 1721943889.8475764}).
Env Football Algo jrpo Exp base_JRPO updates 4187/100000000000.0 steps in 90.93
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 7089/100000000000.0 steps in 89.05
total episode rewards is 10.0
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'value_loss': 0.25679834074379565, '_timestamp': 1721943978.8948083}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0065091719408519565, '_timestamp': 1721943978.8949609}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7733802477518716, '_timestamp': 1721943978.8950262}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4184262454509735, '_timestamp': 1721943978.8951108}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4027611017227173, '_timestamp': 1721943978.8953397}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'ratio': 0.9783480167388916, '_timestamp': 1721943978.89544}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721943978.8956573}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721943978.8957453}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.04646301269531, '_timestamp': 1721943978.895802}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5052458601946657, '_timestamp': 1721943978.8964927}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'train_goal': 0.7526229300973328, '_timestamp': 1721943978.896958}).
wandb: WARNING (User provided step: 7089 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5052458601946657, '_timestamp': 1721943978.897423}).
Env Football Algo jrpo Exp base_JRPO updates 4303/100000000000.0 steps in 81.02
total episode rewards is 20.0
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'value_loss': 0.2970105636796992, '_timestamp': 1721944059.919904}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010718123357413182, '_timestamp': 1721944059.9201922}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9287446316083272, '_timestamp': 1721944059.9202635}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5297743082046509, '_timestamp': 1721944059.9204404}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.28203529119491577, '_timestamp': 1721944059.9216328}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'ratio': 0.8161912560462952, '_timestamp': 1721944059.9217494}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721944059.9220598}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944059.922166}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.02131032943726, '_timestamp': 1721944059.9224644}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5368794989249323, '_timestamp': 1721944059.9238963}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'train_goal': 0.7684397494624661, '_timestamp': 1721944059.9246407}).
wandb: WARNING (User provided step: 4303 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5368794989249323, '_timestamp': 1721944059.9256618}).
Env Football Algo jrpo Exp base_JRPO updates 6017/100000000000.0 steps in 90.20
total episode rewards is 0.0
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'value_loss': 0.341767277145215, '_timestamp': 1721944150.127378}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'policy_loss': 0.023584461540255387, '_timestamp': 1721944150.1275558}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9284547344843546, '_timestamp': 1721944150.127626}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6930208206176758, '_timestamp': 1721944150.1277237}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20473748445510864, '_timestamp': 1721944150.1280165}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'ratio': 0.6592134833335876, '_timestamp': 1721944150.1281278}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721944150.1282582}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944150.1283529}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.20021629333496, '_timestamp': 1721944150.128413}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.32828676388734274, '_timestamp': 1721944150.1291225}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal': 0.6641433819436714, '_timestamp': 1721944150.1296535}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_WDL': 0.32828676388734274, '_timestamp': 1721944150.130189}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'value_loss': 0.2130767059599748, '_timestamp': 1721944237.815706}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013848527205021431, '_timestamp': 1721944237.8158753}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.195761300722758, '_timestamp': 1721944237.81594}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.257941871881485, '_timestamp': 1721944237.816049}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2516304850578308, '_timestamp': 1721944237.8163052}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'ratio': 0.7212992310523987, '_timestamp': 1721944237.8164105}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721944237.8165448}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944237.816868}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.68422317504883, '_timestamp': 1721944237.8169272}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.8225339228540937, '_timestamp': 1721944237.8177047}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'train_goal': 0.9112669614270468, '_timestamp': 1721944237.8181033}).
wandb: WARNING (User provided step: 8441 is less than current step: 15000. Dropping entry: {'train_WDL': 0.8225339228540937, '_timestamp': 1721944237.8184981}).
Env Football Algo jrpo Exp base_JRPO updates 8441/100000000000.0 steps in 87.68
total episode rewards is 10.0
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'value_loss': 0.3103201097616693, '_timestamp': 1721944321.8349957}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006996065497902843, '_timestamp': 1721944321.8351746}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.242443874677022, '_timestamp': 1721944321.8352482}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42661231756210327, '_timestamp': 1721944321.8353455}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19501367211341858, '_timestamp': 1721944321.835614}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'ratio': 0.8313168287277222, '_timestamp': 1721944321.8357227}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721944321.8358564}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944321.8362365}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.01567578315735, '_timestamp': 1721944321.8362982}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.8189786973804913, '_timestamp': 1721944321.8373578}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'train_goal': 0.9094893486902457, '_timestamp': 1721944321.8379443}).
wandb: WARNING (User provided step: 5189 is less than current step: 15000. Dropping entry: {'train_WDL': 0.8189786973804913, '_timestamp': 1721944321.8385332}).
Env Football Algo jrpo Exp base_JRPO updates 5189/100000000000.0 steps in 84.02
total episode rewards is 20.0
Env Football Algo jrpo Exp base_JRPO updates 12030/100000000000.0 steps in 90.98
total episode rewards is 10.0
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'value_loss': 0.06778425948936881, '_timestamp': 1721944412.8234026}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021961252382025124, '_timestamp': 1721944412.8235688}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9950471194585164, '_timestamp': 1721944412.8236382}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3900987207889557, '_timestamp': 1721944412.8237312}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.09608475863933563, '_timestamp': 1721944412.8240137}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'ratio': 0.29339197278022766, '_timestamp': 1721944412.8241234}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721944412.8242557}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944412.8243477}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.98407244682312, '_timestamp': 1721944412.8247235}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721944412.82529}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721944412.8255854}).
wandb: WARNING (User provided step: 12030 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721944412.8258228}).
Env Football Algo jrpo Exp base_JRPO updates 9123/100000000000.0 steps in 84.07
total episode rewards is -10.0
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'value_loss': 0.22666241132227394, '_timestamp': 1721944496.8963354}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03593236764951144, '_timestamp': 1721944496.8965163}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.116129775842031, '_timestamp': 1721944496.8965862}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2765735387802124, '_timestamp': 1721944496.8966823}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5701872110366821, '_timestamp': 1721944496.8969524}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'ratio': 0.5065474510192871, '_timestamp': 1721944496.8970635}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721944496.8971977}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944496.897899}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.06960201263428, '_timestamp': 1721944496.8979604}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.014803471158754467, '_timestamp': 1721944496.898612}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'train_goal': 0.5074017355793773, '_timestamp': 1721944496.8991477}).
wandb: WARNING (User provided step: 9123 is less than current step: 15000. Dropping entry: {'train_WDL': 0.014803471158754467, '_timestamp': 1721944496.8995547}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'value_loss': 0.2573364684531892, '_timestamp': 1721944583.8417923}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0058747729395933375, '_timestamp': 1721944583.8419588}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.367763064702352, '_timestamp': 1721944583.8420246}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3785633146762848, '_timestamp': 1721944583.8421202}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16125035285949707, '_timestamp': 1721944583.8423567}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'ratio': 0.8776882290840149, '_timestamp': 1721944583.8424594}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721944583.8425913}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944583.8429086}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.94140148162842, '_timestamp': 1721944583.8429694}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.6628491620111732, '_timestamp': 1721944583.843721}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'train_goal': 0.8314245810055866, '_timestamp': 1721944583.8441813}).
wandb: WARNING (User provided step: 7840 is less than current step: 15000. Dropping entry: {'train_WDL': 0.6628491620111732, '_timestamp': 1721944583.8446145}).
Env Football Algo jrpo Exp base_JRPO updates 7840/100000000000.0 steps in 86.94
total episode rewards is 10.0
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'value_loss': 0.5529136130042995, '_timestamp': 1721944648.0099168}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'policy_loss': 0.030134315319592132, '_timestamp': 1721944648.0100708}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.308936842282613, '_timestamp': 1721944648.0101364}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3226374387741089, '_timestamp': 1721944648.0102227}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5764454007148743, '_timestamp': 1721944648.0104563}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'ratio': 0.7681121230125427, '_timestamp': 1721944648.0105584}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721944648.010683}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944648.010772}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'Episode_Time': 64.16451621055603, '_timestamp': 1721944648.010927}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3786122927974182, '_timestamp': 1721944648.0114567}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'train_goal': 0.31069385360129087, '_timestamp': 1721944648.0118802}).
wandb: WARNING (User provided step: 4023 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3786122927974182, '_timestamp': 1721944648.0123284}).
Env Football Algo jrpo Exp base_JRPO updates 4023/100000000000.0 steps in 64.16
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 6986/100000000000.0 steps in 91.54
total episode rewards is 0.0
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'value_loss': 0.32804976458661256, '_timestamp': 1721944739.5522892}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'policy_loss': 0.019607509725271182, '_timestamp': 1721944739.5525608}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.169125671386719, '_timestamp': 1721944739.552633}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4499838352203369, '_timestamp': 1721944739.5527725}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3932710886001587, '_timestamp': 1721944739.553066}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'ratio': 0.5420140027999878, '_timestamp': 1721944739.5531695}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721944739.5533104}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944739.5538392}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.5386860370636, '_timestamp': 1721944739.5538998}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.013725979535812328, '_timestamp': 1721944739.554991}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'train_goal': 0.49313701023209383, '_timestamp': 1721944739.5558665}).
wandb: WARNING (User provided step: 6986 is less than current step: 15000. Dropping entry: {'train_WDL': -0.013725979535812328, '_timestamp': 1721944739.5567384}).
Env Football Algo jrpo Exp base_JRPO updates 6387/100000000000.0 steps in 85.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'value_loss': 0.3478570767736528, '_timestamp': 1721944824.8063378}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'policy_loss': 0.017843527893031327, '_timestamp': 1721944824.8074057}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.280420161883036, '_timestamp': 1721944824.8074749}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18048326671123505, '_timestamp': 1721944824.8078804}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.203650563955307, '_timestamp': 1721944824.8082376}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'ratio': 1.0144950151443481, '_timestamp': 1721944824.8083413}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721944824.8084733}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944824.80866}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.24455523490906, '_timestamp': 1721944824.8089821}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944824.809957}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944824.8104591}).
wandb: WARNING (User provided step: 6387 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944824.8109848}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'value_loss': 0.16616243656899315, '_timestamp': 1721944912.3315122}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0017310840035012613, '_timestamp': 1721944912.3316884}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2907449420293173, '_timestamp': 1721944912.3317592}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1570490449666977, '_timestamp': 1721944912.331859}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16764691472053528, '_timestamp': 1721944912.332125}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'ratio': 0.987679660320282, '_timestamp': 1721944912.3322313}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721944912.332367}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944912.3324587}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.51966047286987, '_timestamp': 1721944912.3326573}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944912.3330452}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944912.3333194}).
wandb: WARNING (User provided step: 11266 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944912.3336012}).
Env Football Algo jrpo Exp base_JRPO updates 11266/100000000000.0 steps in 87.52
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 3537/100000000000.0 steps in 41.24
total episode rewards is -50.0
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'value_loss': 0.6174625267422137, '_timestamp': 1721944953.574181}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01007679543729561, '_timestamp': 1721944953.5752325}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2772606166203815, '_timestamp': 1721944953.575301}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.563423216342926, '_timestamp': 1721944953.5757027}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7846686244010925, '_timestamp': 1721944953.5760412}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'ratio': 0.964530885219574, '_timestamp': 1721944953.5761468}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721944953.5762744}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721944953.576446}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'Episode_Time': 41.23591184616089, '_timestamp': 1721944953.5767276}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721944953.5773225}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721944953.5775414}).
wandb: WARNING (User provided step: 3537 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721944953.577759}).
Env Football Algo jrpo Exp base_JRPO updates 10018/100000000000.0 steps in 88.24
total episode rewards is -20.0
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'value_loss': 0.319396465064104, '_timestamp': 1721945041.81607}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'policy_loss': 0.022366452939847174, '_timestamp': 1721945041.8162253}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1739721767107647, '_timestamp': 1721945041.8162909}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2703079879283905, '_timestamp': 1721945041.8163788}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2537549138069153, '_timestamp': 1721945041.8166173}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'ratio': 0.8566689491271973, '_timestamp': 1721945041.8167193}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721945041.816972}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945041.8170614}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.23758625984192, '_timestamp': 1721945041.8171175}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.19309514251304696, '_timestamp': 1721945041.8178735}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'train_goal': 0.5965475712565235, '_timestamp': 1721945041.8182034}).
wandb: WARNING (User provided step: 10018 is less than current step: 15000. Dropping entry: {'train_WDL': 0.19309514251304696, '_timestamp': 1721945041.818532}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'value_loss': 0.2961324126684728, '_timestamp': 1721945124.8751636}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'policy_loss': 0.029517901669605634, '_timestamp': 1721945124.8753223}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0699045181274416, '_timestamp': 1721945124.875387}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.38240018486976624, '_timestamp': 1721945124.8754752}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.28725919127464294, '_timestamp': 1721945124.8757122}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'ratio': 0.8441193103790283, '_timestamp': 1721945124.8758125}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721945124.8759363}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945124.8762002}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.05568099021912, '_timestamp': 1721945124.876257}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.030071267164957415, '_timestamp': 1721945124.876792}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'train_goal': 0.5150356335824787, '_timestamp': 1721945124.8771598}).
wandb: WARNING (User provided step: 9247 is less than current step: 15000. Dropping entry: {'train_WDL': 0.030071267164957415, '_timestamp': 1721945124.877531}).
Env Football Algo jrpo Exp base_JRPO updates 9247/100000000000.0 steps in 83.06
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8860/100000000000.0 steps in 84.79
total episode rewards is -40.0
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'value_loss': 0.3034618369555877, '_timestamp': 1721945209.6703925}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03869325874518836, '_timestamp': 1721945209.6705737}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1721412150065103, '_timestamp': 1721945209.6706417}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48273956775665283, '_timestamp': 1721945209.6707385}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2713140547275543, '_timestamp': 1721945209.6710122}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'ratio': 0.8257626295089722, '_timestamp': 1721945209.6711235}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945209.6716175}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945209.6717124}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.79187560081482, '_timestamp': 1721945209.6717696}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945209.6726437}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945209.6730392}).
wandb: WARNING (User provided step: 8860 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945209.6737316}).
Env Football Algo jrpo Exp base_JRPO updates 4168/100000000000.0 steps in 70.34
total episode rewards is -40.0
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'value_loss': 0.48446220996479195, '_timestamp': 1721945280.0238194}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00858046919752572, '_timestamp': 1721945280.0251086}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.258542373975118, '_timestamp': 1721945280.0251787}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40716102719306946, '_timestamp': 1721945280.0256634}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8129865527153015, '_timestamp': 1721945280.026043}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'ratio': 0.9061806201934814, '_timestamp': 1721945280.0261476}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945280.026283}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945280.026853}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'Episode_Time': 70.34395813941956, '_timestamp': 1721945280.0269122}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3574417214584579, '_timestamp': 1721945280.027878}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'train_goal': 0.32127913927077106, '_timestamp': 1721945280.0283616}).
wandb: WARNING (User provided step: 4168 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3574417214584579, '_timestamp': 1721945280.0288084}).
Env Football Algo jrpo Exp base_JRPO updates 6199/100000000000.0 steps in 78.00
total episode rewards is -40.0
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'value_loss': 0.3475558574538445, '_timestamp': 1721945358.0295782}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005967338555734993, '_timestamp': 1721945358.0297484}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2513055356343585, '_timestamp': 1721945358.0298185}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19885176420211792, '_timestamp': 1721945358.029912}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.147525355219841, '_timestamp': 1721945358.030168}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'ratio': 0.9333093762397766, '_timestamp': 1721945358.030272}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945358.0307195}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945358.0308135}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.99995374679565, '_timestamp': 1721945358.0308716}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945358.0315971}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945358.032512}).
wandb: WARNING (User provided step: 6199 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945358.0330403}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'value_loss': 0.3549083950565546, '_timestamp': 1721945450.7594087}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0015369107838099202, '_timestamp': 1721945450.7595847}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2067956829071047, '_timestamp': 1721945450.7596548}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24341031908988953, '_timestamp': 1721945450.759751}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17802086472511292, '_timestamp': 1721945450.7600772}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'ratio': 0.9071283340454102, '_timestamp': 1721945450.7601852}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945450.7603178}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945450.7605684}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.72551918029785, '_timestamp': 1721945450.760628}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945450.7614505}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945450.76196}).
wandb: WARNING (User provided step: 6330 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945450.7624993}).
Env Football Algo jrpo Exp base_JRPO updates 6330/100000000000.0 steps in 92.73
total episode rewards is -40.0
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'value_loss': 0.343760781615468, '_timestamp': 1721945541.6295977}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'policy_loss': -0.008840931851688463, '_timestamp': 1721945541.6298578}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2168787129720053, '_timestamp': 1721945541.6299276}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.329253613948822, '_timestamp': 1721945541.6300328}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.48085495829582214, '_timestamp': 1721945541.6302972}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'ratio': 0.8459175229072571, '_timestamp': 1721945541.6304035}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721945541.6311748}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945541.631326}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.86577606201172, '_timestamp': 1721945541.631388}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.39841393946163295, '_timestamp': 1721945541.6327848}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'train_goal': 0.3007930302691835, '_timestamp': 1721945541.6334639}).
wandb: WARNING (User provided step: 6047 is less than current step: 15000. Dropping entry: {'train_WDL': -0.39841393946163295, '_timestamp': 1721945541.6341052}).
Env Football Algo jrpo Exp base_JRPO updates 6047/100000000000.0 steps in 90.87
total episode rewards is -20.0
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'value_loss': 0.5227837707785269, '_timestamp': 1721945605.22905}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004194287989133348, '_timestamp': 1721945605.2292717}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1891943407058716, '_timestamp': 1721945605.22934}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5379565954208374, '_timestamp': 1721945605.229474}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6421679854393005, '_timestamp': 1721945605.229743}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'ratio': 0.9354424476623535, '_timestamp': 1721945605.2298467}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721945605.229981}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945605.2300715}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'Episode_Time': 63.59351205825806, '_timestamp': 1721945605.2303324}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3610174685871897, '_timestamp': 1721945605.2309575}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'train_goal': 0.6805087342935948, '_timestamp': 1721945605.2313654}).
wandb: WARNING (User provided step: 4904 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3610174685871897, '_timestamp': 1721945605.2318985}).
Env Football Algo jrpo Exp base_JRPO updates 4904/100000000000.0 steps in 63.59
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 8162/100000000000.0 steps in 92.59
total episode rewards is -40.0
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'value_loss': 0.3161115790880285, '_timestamp': 1721945697.8231492}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014203268853404248, '_timestamp': 1721945697.823366}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1728244495391844, '_timestamp': 1721945697.8234386}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18983414769172668, '_timestamp': 1721945697.823574}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4184373915195465, '_timestamp': 1721945697.8238416}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'ratio': 0.9670683741569519, '_timestamp': 1721945697.8239655}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721945697.8244905}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945697.8245885}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.59028911590576, '_timestamp': 1721945697.8246467}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945697.825517}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945697.8259664}).
wandb: WARNING (User provided step: 8162 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945697.8266788}).
Env Football Algo jrpo Exp base_JRPO updates 4493/100000000000.0 steps in 62.90
total episode rewards is -70.0
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'value_loss': 0.5369516122589508, '_timestamp': 1721945760.7283762}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'policy_loss': -0.001134751053371777, '_timestamp': 1721945760.728586}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.097072269121806, '_timestamp': 1721945760.7286541}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3857910931110382, '_timestamp': 1721945760.7287807}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5272058844566345, '_timestamp': 1721945760.7290397}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'ratio': 0.8394109010696411, '_timestamp': 1721945760.729141}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721945760.7292743}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945760.7293632}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'Episode_Time': 62.90062069892883, '_timestamp': 1721945760.729593}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721945760.7301178}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721945760.7305346}).
wandb: WARNING (User provided step: 4493 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721945760.7309546}).
Env Football Algo jrpo Exp base_JRPO updates 5486/100000000000.0 steps in 87.70
total episode rewards is 0.0
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'value_loss': 0.33997241150490787, '_timestamp': 1721945848.4292176}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01364880688682509, '_timestamp': 1721945848.4294636}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1391775687535604, '_timestamp': 1721945848.4295459}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5360442996025085, '_timestamp': 1721945848.4296556}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21125376224517822, '_timestamp': 1721945848.4299545}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'ratio': 0.8580723404884338, '_timestamp': 1721945848.430622}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721945848.430803}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945848.4309077}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.69723963737488, '_timestamp': 1721945848.430966}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2493167963001892, '_timestamp': 1721945848.431835}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'train_goal': 0.6246583981500946, '_timestamp': 1721945848.432446}).
wandb: WARNING (User provided step: 5486 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2493167963001892, '_timestamp': 1721945848.4330113}).
Env Football Algo jrpo Exp base_JRPO updates 8468/100000000000.0 steps in 88.67
total episode rewards is -20.0
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'value_loss': 0.30852343783752684, '_timestamp': 1721945937.1129093}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018274127667148907, '_timestamp': 1721945937.1139693}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8590105533599854, '_timestamp': 1721945937.1213698}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3893042802810669, '_timestamp': 1721945937.1219873}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2322997897863388, '_timestamp': 1721945937.1223288}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'ratio': 0.8205432295799255, '_timestamp': 1721945937.122438}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721945937.1225736}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721945937.1227696}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.67063045501709, '_timestamp': 1721945937.1233199}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.09001837109614207, '_timestamp': 1721945937.1251433}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'train_goal': 0.45499081445192896, '_timestamp': 1721945937.1257052}).
wandb: WARNING (User provided step: 8468 is less than current step: 15000. Dropping entry: {'train_WDL': -0.09001837109614207, '_timestamp': 1721945937.1261256}).
Env Football Algo jrpo Exp base_JRPO updates 10521/100000000000.0 steps in 83.28
total episode rewards is -30.0
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'value_loss': 0.39978547213948334, '_timestamp': 1721946020.4111214}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009010164856056994, '_timestamp': 1721946020.4113393}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0085181069374083, '_timestamp': 1721946020.4114082}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30521106719970703, '_timestamp': 1721946020.4115086}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5296038389205933, '_timestamp': 1721946020.4122965}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'ratio': 0.8985157608985901, '_timestamp': 1721946020.412407}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721946020.4125419}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946020.4126372}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.28390550613403, '_timestamp': 1721946020.4126942}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.8769318832283916, '_timestamp': 1721946020.413139}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'train_goal': 0.06153405838580424, '_timestamp': 1721946020.4134343}).
wandb: WARNING (User provided step: 10521 is less than current step: 15000. Dropping entry: {'train_WDL': -0.8769318832283916, '_timestamp': 1721946020.413706}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'value_loss': 0.2271376560558565, '_timestamp': 1721946107.7476816}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004932937303092331, '_timestamp': 1721946107.7490604}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1618124357859294, '_timestamp': 1721946107.7491376}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.37410596013069153, '_timestamp': 1721946107.7496467}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5502193570137024, '_timestamp': 1721946107.7500253}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'ratio': 1.9562009572982788, '_timestamp': 1721946107.750133}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721946107.750277}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946107.7504828}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.32800555229187, '_timestamp': 1721946107.751265}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.34337899543378997, '_timestamp': 1721946107.7521217}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'train_goal': 0.32831050228310504, '_timestamp': 1721946107.7524595}).
wandb: WARNING (User provided step: 10620 is less than current step: 15000. Dropping entry: {'train_WDL': -0.34337899543378997, '_timestamp': 1721946107.7527854}).
Env Football Algo jrpo Exp base_JRPO updates 10620/100000000000.0 steps in 87.33
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 6917/100000000000.0 steps in 84.46
total episode rewards is -10.0
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'value_loss': 0.26476560278834466, '_timestamp': 1721946192.2119775}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004092084970907308, '_timestamp': 1721946192.2121558}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2439562543233236, '_timestamp': 1721946192.212224}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.27900171279907227, '_timestamp': 1721946192.2123218}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.40259742736816406, '_timestamp': 1721946192.212591}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'ratio': 0.9028214812278748, '_timestamp': 1721946192.2130632}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721946192.2132025}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946192.2132962}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.4581344127655, '_timestamp': 1721946192.213355}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2675986638624273, '_timestamp': 1721946192.213995}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'train_goal': 0.3662006680687863, '_timestamp': 1721946192.2144825}).
wandb: WARNING (User provided step: 6917 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2675986638624273, '_timestamp': 1721946192.21497}).
Env Football Algo jrpo Exp base_JRPO updates 6489/100000000000.0 steps in 90.13
total episode rewards is -40.0
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'value_loss': 0.30031447553968366, '_timestamp': 1721946282.3499856}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008742974789056461, '_timestamp': 1721946282.3502023}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.302372285525004, '_timestamp': 1721946282.3502715}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18822264671325684, '_timestamp': 1721946282.3503668}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20175397396087646, '_timestamp': 1721946282.350649}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'ratio': 0.9386124014854431, '_timestamp': 1721946282.3507538}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721946282.3509402}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946282.3510814}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.1339123249054, '_timestamp': 1721946282.3516428}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946282.3523471}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946282.3528562}).
wandb: WARNING (User provided step: 6489 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946282.353621}).
Env Football Algo jrpo Exp base_JRPO updates 3940/100000000000.0 steps in 55.89
total episode rewards is -10.0
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'value_loss': 0.3809341019578278, '_timestamp': 1721946338.2404656}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006339416665335496, '_timestamp': 1721946338.240634}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1517402855555217, '_timestamp': 1721946338.2407017}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3937700092792511, '_timestamp': 1721946338.2407951}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.460857093334198, '_timestamp': 1721946338.241051}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'ratio': 0.8588743209838867, '_timestamp': 1721946338.241304}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721946338.2414372}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946338.2415276}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'Episode_Time': 55.88586187362671, '_timestamp': 1721946338.2415862}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.31269035532994927, '_timestamp': 1721946338.2421536}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'train_goal': 0.6563451776649746, '_timestamp': 1721946338.242533}).
wandb: WARNING (User provided step: 3940 is less than current step: 15000. Dropping entry: {'train_WDL': 0.31269035532994927, '_timestamp': 1721946338.242908}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'value_loss': 0.3114574018510757, '_timestamp': 1721946430.6552277}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004911881093673098, '_timestamp': 1721946430.6554015}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.2098221921920778, '_timestamp': 1721946430.65547}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22888603806495667, '_timestamp': 1721946430.6555622}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24419142305850983, '_timestamp': 1721946430.6558437}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'ratio': 0.9231686592102051, '_timestamp': 1721946430.655959}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721946430.6560988}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946430.656539}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.41138768196106, '_timestamp': 1721946430.6565986}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946430.6573176}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946430.657671}).
wandb: WARNING (User provided step: 9670 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946430.658102}).
Env Football Algo jrpo Exp base_JRPO updates 9670/100000000000.0 steps in 92.41
total episode rewards is -40.0
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'value_loss': 0.5506505161399643, '_timestamp': 1721946504.3811827}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0019267387870543946, '_timestamp': 1721946504.381345}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.278617893854777, '_timestamp': 1721946504.3814101}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6125844717025757, '_timestamp': 1721946504.3814976}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7295798063278198, '_timestamp': 1721946504.3817492}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'ratio': 0.9588786959648132, '_timestamp': 1721946504.3818521}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721946504.3821065}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946504.3821986}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'Episode_Time': 73.72219181060791, '_timestamp': 1721946504.382255}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3127599624312357, '_timestamp': 1721946504.382807}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'train_goal': 0.6563799812156179, '_timestamp': 1721946504.3835864}).
wandb: WARNING (User provided step: 5027 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3127599624312357, '_timestamp': 1721946504.3840466}).
Env Football Algo jrpo Exp base_JRPO updates 5027/100000000000.0 steps in 73.72
total episode rewards is -30.0
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'value_loss': 0.4451034822842727, '_timestamp': 1721946586.1525698}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004026500497323771, '_timestamp': 1721946586.1527333}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.218584574063619, '_timestamp': 1721946586.1528034}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2969416081905365, '_timestamp': 1721946586.1528957}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5542033910751343, '_timestamp': 1721946586.1531417}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'ratio': 0.8758897185325623, '_timestamp': 1721946586.1532454}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721946586.1533747}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946586.153472}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.76760792732239, '_timestamp': 1721946586.1536293}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946586.1541479}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946586.1545312}).
wandb: WARNING (User provided step: 7953 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946586.1549299}).
Env Football Algo jrpo Exp base_JRPO updates 7953/100000000000.0 steps in 81.77
total episode rewards is -60.0
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'value_loss': 0.2521830520452932, '_timestamp': 1721946674.0629354}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0009644543859758415, '_timestamp': 1721946674.063105}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.230196264584859, '_timestamp': 1721946674.0631714}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5308386087417603, '_timestamp': 1721946674.0632594}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.36345821619033813, '_timestamp': 1721946674.0635023}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'ratio': 0.8296859264373779, '_timestamp': 1721946674.0636036}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721946674.0638351}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946674.0639648}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.90671944618225, '_timestamp': 1721946674.06403}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3629493931760934, '_timestamp': 1721946674.064753}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'train_goal': 0.6814746965880467, '_timestamp': 1721946674.065255}).
wandb: WARNING (User provided step: 6266 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3629493931760934, '_timestamp': 1721946674.0657613}).
Env Football Algo jrpo Exp base_JRPO updates 6266/100000000000.0 steps in 87.91
total episode rewards is 10.0
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'value_loss': 0.28039065851053846, '_timestamp': 1721946752.655291}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0018045279055756206, '_timestamp': 1721946752.65546}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.178957087198893, '_timestamp': 1721946752.655527}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2527350187301636, '_timestamp': 1721946752.6556182}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15025825798511505, '_timestamp': 1721946752.6558557}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'ratio': 1.5377405881881714, '_timestamp': 1721946752.6559813}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721946752.6561236}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946752.6563177}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.58877968788147, '_timestamp': 1721946752.6563776}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946752.6569016}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946752.6573007}).
wandb: WARNING (User provided step: 8445 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946752.657719}).
Env Football Algo jrpo Exp base_JRPO updates 8445/100000000000.0 steps in 78.59
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7230/100000000000.0 steps in 84.64
total episode rewards is -30.0
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'value_loss': 0.22796669417992235, '_timestamp': 1721946837.3028274}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'policy_loss': -0.006916809626854956, '_timestamp': 1721946837.3029995}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0734247748057046, '_timestamp': 1721946837.303067}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.25735145807266235, '_timestamp': 1721946837.3031676}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21218694746494293, '_timestamp': 1721946837.3034458}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'ratio': 0.7694568037986755, '_timestamp': 1721946837.3035693}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721946837.303707}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946837.3042915}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.64433002471924, '_timestamp': 1721946837.3043547}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946837.3049586}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946837.3054345}).
wandb: WARNING (User provided step: 7230 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946837.3059223}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'value_loss': 0.32948978851083666, '_timestamp': 1721946922.0792034}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'policy_loss': -0.003949000004989406, '_timestamp': 1721946922.0793982}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9843592953681946, '_timestamp': 1721946922.0794678}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24883463978767395, '_timestamp': 1721946922.0795743}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3185267746448517, '_timestamp': 1721946922.079854}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'ratio': 0.9357113838195801, '_timestamp': 1721946922.0799887}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721946922.0801294}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946922.0802271}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.77230787277222, '_timestamp': 1721946922.0810058}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946922.0815897}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946922.0819535}).
wandb: WARNING (User provided step: 9863 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946922.0823252}).
Env Football Algo jrpo Exp base_JRPO updates 9863/100000000000.0 steps in 84.77
total episode rewards is -40.0
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'value_loss': 0.4527277281538894, '_timestamp': 1721946996.8334453}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0028546750250582893, '_timestamp': 1721946996.8336048}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9537224396069846, '_timestamp': 1721946996.8336704}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.31951361894607544, '_timestamp': 1721946996.8337605}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5106557607650757, '_timestamp': 1721946996.8340125}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'ratio': 0.9772962927818298, '_timestamp': 1721946996.834213}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721946996.8343468}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721946996.834436}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.74687051773071, '_timestamp': 1721946996.834494}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721946996.8349943}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721946996.8353858}).
wandb: WARNING (User provided step: 7390 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721946996.8357904}).
Env Football Algo jrpo Exp base_JRPO updates 7390/100000000000.0 steps in 74.75
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 4980/100000000000.0 steps in 72.89
total episode rewards is -40.0
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'value_loss': 0.6368856282532215, '_timestamp': 1721947069.722711}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0014607348595745862, '_timestamp': 1721947069.7229452}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8874906118710835, '_timestamp': 1721947069.7230191}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6195230484008789, '_timestamp': 1721947069.7231634}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.767819344997406, '_timestamp': 1721947069.7235525}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'ratio': 0.9553065299987793, '_timestamp': 1721947069.7236638}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721947069.7244537}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947069.724559}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.88591384887695, '_timestamp': 1721947069.7246213}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2809756097560976, '_timestamp': 1721947069.7252107}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'train_goal': 0.3595121951219512, '_timestamp': 1721947069.725645}).
wandb: WARNING (User provided step: 4980 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2809756097560976, '_timestamp': 1721947069.7260797}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'value_loss': 0.15069092872552572, '_timestamp': 1721947152.4916258}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01553102259330141, '_timestamp': 1721947152.4918532}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9285487802823384, '_timestamp': 1721947152.4919217}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.46441784501075745, '_timestamp': 1721947152.492028}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4122840166091919, '_timestamp': 1721947152.4924285}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'ratio': 0.8357669711112976, '_timestamp': 1721947152.4925394}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721947152.4929626}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947152.4930615}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.7643494606018, '_timestamp': 1721947152.493122}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2602291325695581, '_timestamp': 1721947152.4935148}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'train_goal': 0.3698854337152209, '_timestamp': 1721947152.4937925}).
wandb: WARNING (User provided step: 11334 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2602291325695581, '_timestamp': 1721947152.4940603}).
Env Football Algo jrpo Exp base_JRPO updates 11334/100000000000.0 steps in 82.76
total episode rewards is 0.0
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'value_loss': 0.29881064053547257, '_timestamp': 1721947237.4342005}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0030268860945943743, '_timestamp': 1721947237.4343631}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.890493355592092, '_timestamp': 1721947237.434429}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32731571793556213, '_timestamp': 1721947237.4345186}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5478237867355347, '_timestamp': 1721947237.434783}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'ratio': 1.0043978691101074, '_timestamp': 1721947237.434885}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721947237.435218}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947237.4353113}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.93921637535095, '_timestamp': 1721947237.435369}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.6675603217158177, '_timestamp': 1721947237.4356692}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'train_goal': 0.16621983914209115, '_timestamp': 1721947237.435895}).
wandb: WARNING (User provided step: 12016 is less than current step: 15000. Dropping entry: {'train_WDL': -0.6675603217158177, '_timestamp': 1721947237.4361475}).
Env Football Algo jrpo Exp base_JRPO updates 12016/100000000000.0 steps in 84.94
total episode rewards is -20.0
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'value_loss': 0.23273917595623062, '_timestamp': 1721947327.1932144}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010600492239464075, '_timestamp': 1721947327.1934297}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9136456036567688, '_timestamp': 1721947327.1935015}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1620960384607315, '_timestamp': 1721947327.1936448}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5589146018028259, '_timestamp': 1721947327.193904}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'ratio': 0.861956000328064, '_timestamp': 1721947327.1940088}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721947327.1944678}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947327.1945689}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.75610399246216, '_timestamp': 1721947327.19463}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947327.1950278}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947327.195235}).
wandb: WARNING (User provided step: 12758 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947327.1954393}).
Env Football Algo jrpo Exp base_JRPO updates 12758/100000000000.0 steps in 89.76
total episode rewards is -30.0
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'value_loss': 0.1670541119610425, '_timestamp': 1721947410.8536227}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013648208937083836, '_timestamp': 1721947410.8537905}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8974517011642456, '_timestamp': 1721947410.853857}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2299892008304596, '_timestamp': 1721947410.8540206}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26594382524490356, '_timestamp': 1721947410.8542824}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'ratio': 0.9202318787574768, '_timestamp': 1721947410.8543894}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721947410.8547788}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947410.8548746}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.65728306770325, '_timestamp': 1721947410.854932}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947410.8553061}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947410.855569}).
wandb: WARNING (User provided step: 11381 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947410.8558333}).
Env Football Algo jrpo Exp base_JRPO updates 11381/100000000000.0 steps in 83.66
total episode rewards is -20.0
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'value_loss': 0.1567579820441703, '_timestamp': 1721947497.6532626}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'policy_loss': 0.005617173986975104, '_timestamp': 1721947497.6534333}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8720636741320291, '_timestamp': 1721947497.6535}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21855421364307404, '_timestamp': 1721947497.653592}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1326483190059662, '_timestamp': 1721947497.6538403}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'ratio': 0.8129652738571167, '_timestamp': 1721947497.6539435}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721947497.654076}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947497.654344}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.7966799736023, '_timestamp': 1721947497.6544056}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947497.654862}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947497.6551638}).
wandb: WARNING (User provided step: 10705 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947497.6554694}).
Env Football Algo jrpo Exp base_JRPO updates 10705/100000000000.0 steps in 86.80
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8412/100000000000.0 steps in 89.25
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'value_loss': 0.2355673687066883, '_timestamp': 1721947586.9017787}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004659218171533818, '_timestamp': 1721947586.9019477}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.786336415608724, '_timestamp': 1721947586.9020135}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4394237995147705, '_timestamp': 1721947586.9021049}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2648216485977173, '_timestamp': 1721947586.9023561}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'ratio': 0.9267621040344238, '_timestamp': 1721947586.9024587}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721947586.9025848}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947586.9030077}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.24537396430969, '_timestamp': 1721947586.9030654}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.09775349119611415, '_timestamp': 1721947586.903642}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'train_goal': 0.45112325440194295, '_timestamp': 1721947586.9040813}).
wandb: WARNING (User provided step: 8412 is less than current step: 15000. Dropping entry: {'train_WDL': -0.09775349119611415, '_timestamp': 1721947586.9044888}).
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 6648/100000000000.0 steps in 63.73
total episode rewards is -60.0
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'value_loss': 0.43957749449958405, '_timestamp': 1721947650.6397898}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007632000708496586, '_timestamp': 1721947650.6399932}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.754139171441396, '_timestamp': 1721947650.640062}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2643834352493286, '_timestamp': 1721947650.6401596}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.39963942766189575, '_timestamp': 1721947650.6404324}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'ratio': 1.0399237871170044, '_timestamp': 1721947650.6405394}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721947650.6406682}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947650.6407595}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'Episode_Time': 63.734192848205566, '_timestamp': 1721947650.6408162}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947650.6413765}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947650.64174}).
wandb: WARNING (User provided step: 6648 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947650.6421008}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'value_loss': 0.3141451470577158, '_timestamp': 1721947737.611826}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0055515487589097275, '_timestamp': 1721947737.612013}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7995256781578064, '_timestamp': 1721947737.6120784}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4414745569229126, '_timestamp': 1721947737.612171}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21673882007598877, '_timestamp': 1721947737.612444}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'ratio': 0.95166015625, '_timestamp': 1721947737.6125457}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721947737.6132073}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947737.6133075}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.96874284744263, '_timestamp': 1721947737.6133642}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.09593374895319624, '_timestamp': 1721947737.6141422}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'train_goal': 0.5479668744765981, '_timestamp': 1721947737.6147459}).
wandb: WARNING (User provided step: 4253 is less than current step: 15000. Dropping entry: {'train_WDL': 0.09593374895319624, '_timestamp': 1721947737.6153593}).
Env Football Algo jrpo Exp base_JRPO updates 4253/100000000000.0 steps in 86.97
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 7919/100000000000.0 steps in 88.86
total episode rewards is -30.0
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'value_loss': 0.22425152268338328, '_timestamp': 1721947826.4752967}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02829930828185752, '_timestamp': 1721947826.4755187}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7443764567375184, '_timestamp': 1721947826.475588}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11034955829381943, '_timestamp': 1721947826.475691}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23321190476417542, '_timestamp': 1721947826.4760017}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'ratio': 0.8980768322944641, '_timestamp': 1721947826.4761136}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721947826.4765751}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947826.4766738}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.85885906219482, '_timestamp': 1721947826.4767315}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947826.477731}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947826.4782448}).
wandb: WARNING (User provided step: 7919 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947826.478778}).
Env Football Algo jrpo Exp base_JRPO updates 9711/100000000000.0 steps in 78.39
total episode rewards is 0.0
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'value_loss': 0.16299769166352537, '_timestamp': 1721947904.8773596}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010011991935122448, '_timestamp': 1721947904.8787131}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7456883851687113, '_timestamp': 1721947904.8787942}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2934179902076721, '_timestamp': 1721947904.8792953}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.10608115792274475, '_timestamp': 1721947904.8797}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'ratio': 0.8948222994804382, '_timestamp': 1721947904.8798087}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721947904.880707}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947904.881023}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.39280486106873, '_timestamp': 1721947904.8810847}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.11098506333900549, '_timestamp': 1721947904.8822856}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'train_goal': 0.5554925316695027, '_timestamp': 1721947904.8826945}).
wandb: WARNING (User provided step: 9711 is less than current step: 15000. Dropping entry: {'train_WDL': 0.11098506333900549, '_timestamp': 1721947904.8830855}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'value_loss': 0.1697756748231283, '_timestamp': 1721947995.7924912}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010994696281074235, '_timestamp': 1721947995.7926924}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7430808107058207, '_timestamp': 1721947995.792759}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1400924026966095, '_timestamp': 1721947995.7928507}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25649431347846985, '_timestamp': 1721947995.7931051}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'ratio': 0.9073254466056824, '_timestamp': 1721947995.7932086}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721947995.7933373}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721947995.793586}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.90812635421753, '_timestamp': 1721947995.7936432}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721947995.7941887}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721947995.7945025}).
wandb: WARNING (User provided step: 10452 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721947995.7948177}).
Env Football Algo jrpo Exp base_JRPO updates 10452/100000000000.0 steps in 90.91
total episode rewards is -20.0
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'value_loss': 0.14817064921488055, '_timestamp': 1721948084.2950554}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00877100642110842, '_timestamp': 1721948084.2952635}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7766659967104594, '_timestamp': 1721948084.295331}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09989818185567856, '_timestamp': 1721948084.295457}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.45635515451431274, '_timestamp': 1721948084.2957153}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'ratio': 0.9568989276885986, '_timestamp': 1721948084.2958226}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948084.295975}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948084.2965791}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.49917984008789, '_timestamp': 1721948084.2966402}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948084.2970667}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948084.2972934}).
wandb: WARNING (User provided step: 12380 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948084.2975926}).
Env Football Algo jrpo Exp base_JRPO updates 12380/100000000000.0 steps in 88.50
total episode rewards is -20.0
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'value_loss': 0.25442113632995944, '_timestamp': 1721948164.257344}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0028369649707262095, '_timestamp': 1721948164.2576728}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.687242829799652, '_timestamp': 1721948164.2577431}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.34635356068611145, '_timestamp': 1721948164.2579017}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.44885340332984924, '_timestamp': 1721948164.2581692}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'ratio': 0.9174618721008301, '_timestamp': 1721948164.2582715}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721948164.2590837}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948164.2592123}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.9582633972168, '_timestamp': 1721948164.2592711}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.14964539007092198, '_timestamp': 1721948164.2602928}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'train_goal': 0.425177304964539, '_timestamp': 1721948164.2607055}).
wandb: WARNING (User provided step: 9360 is less than current step: 15000. Dropping entry: {'train_WDL': -0.14964539007092198, '_timestamp': 1721948164.2611063}).
Env Football Algo jrpo Exp base_JRPO updates 9360/100000000000.0 steps in 79.96
total episode rewards is -10.0
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'value_loss': 0.3273416588115894, '_timestamp': 1721948254.2601562}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02903576220890197, '_timestamp': 1721948254.2604022}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6817321006457011, '_timestamp': 1721948254.2604725}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2423061728477478, '_timestamp': 1721948254.2605994}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.11537179350852966, '_timestamp': 1721948254.2608757}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'ratio': 0.8635470867156982, '_timestamp': 1721948254.260982}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721948254.2611182}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948254.2618349}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.99759244918823, '_timestamp': 1721948254.2618928}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.16401468788249693, '_timestamp': 1721948254.2630498}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'train_goal': 0.5820073439412484, '_timestamp': 1721948254.2639267}).
wandb: WARNING (User provided step: 6830 is less than current step: 15000. Dropping entry: {'train_WDL': 0.16401468788249693, '_timestamp': 1721948254.264801}).
Env Football Algo jrpo Exp base_JRPO updates 6830/100000000000.0 steps in 90.00
total episode rewards is 0.0
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'value_loss': 0.22857483428592484, '_timestamp': 1721948343.6075776}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'policy_loss': 0.020362314018857432, '_timestamp': 1721948343.6078582}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7259073980649313, '_timestamp': 1721948343.6079288}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10331457853317261, '_timestamp': 1721948343.6080942}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.35640326142311096, '_timestamp': 1721948343.6083682}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'ratio': 0.8375106453895569, '_timestamp': 1721948343.6092212}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721948343.6093657}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948343.6095078}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.34136748313904, '_timestamp': 1721948343.609564}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948343.6104605}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948343.6107607}).
wandb: WARNING (User provided step: 10844 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948343.6110618}).
Env Football Algo jrpo Exp base_JRPO updates 10844/100000000000.0 steps in 89.34
total episode rewards is -30.0
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'value_loss': 0.300659795551328, '_timestamp': 1721948425.6485436}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0035070381878176704, '_timestamp': 1721948425.6498287}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6240982556343078, '_timestamp': 1721948425.6498995}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22345593571662903, '_timestamp': 1721948425.6503801}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23554019629955292, '_timestamp': 1721948425.6507378}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'ratio': 0.8796349167823792, '_timestamp': 1721948425.6508584}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948425.65143}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948425.6516275}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.03126430511475, '_timestamp': 1721948425.651697}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2627664848785325, '_timestamp': 1721948425.6527696}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'train_goal': 0.36861675756073375, '_timestamp': 1721948425.6532714}).
wandb: WARNING (User provided step: 6932 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2627664848785325, '_timestamp': 1721948425.653776}).
Env Football Algo jrpo Exp base_JRPO updates 6932/100000000000.0 steps in 82.03
total episode rewards is -20.0
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'value_loss': 0.15575891328296468, '_timestamp': 1721948510.6637907}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007190093795070424, '_timestamp': 1721948510.6639757}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6444550450642903, '_timestamp': 1721948510.664047}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09990260750055313, '_timestamp': 1721948510.6641371}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29289162158966064, '_timestamp': 1721948510.6643867}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'ratio': 0.8491774797439575, '_timestamp': 1721948510.6646457}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948510.6647854}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948510.6648784}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.00918912887573, '_timestamp': 1721948510.664937}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948510.6652386}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948510.665445}).
wandb: WARNING (User provided step: 12509 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948510.6656559}).
Env Football Algo jrpo Exp base_JRPO updates 12509/100000000000.0 steps in 85.01
total episode rewards is -20.0
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'value_loss': 0.3117168288130779, '_timestamp': 1721948601.2107902}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0009557513718997749, '_timestamp': 1721948601.2109745}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6340659515062967, '_timestamp': 1721948601.2110412}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3135926425457001, '_timestamp': 1721948601.2111404}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22446534037590027, '_timestamp': 1721948601.211368}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'ratio': 0.9541756510734558, '_timestamp': 1721948601.2115192}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948601.2117712}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948601.2118661}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.54414248466492, '_timestamp': 1721948601.2119243}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.330751708428246, '_timestamp': 1721948601.212588}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'train_goal': 0.334624145785877, '_timestamp': 1721948601.2131045}).
wandb: WARNING (User provided step: 6220 is less than current step: 15000. Dropping entry: {'train_WDL': -0.330751708428246, '_timestamp': 1721948601.2136354}).
Env Football Algo jrpo Exp base_JRPO updates 6220/100000000000.0 steps in 90.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'value_loss': 0.46592567371204496, '_timestamp': 1721948646.7032535}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016671734228148126, '_timestamp': 1721948646.7034097}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5663147298494975, '_timestamp': 1721948646.7034733}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.27602291107177734, '_timestamp': 1721948646.70356}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5881625413894653, '_timestamp': 1721948646.7038054}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'ratio': 0.9347178339958191, '_timestamp': 1721948646.7040489}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721948646.7041712}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948646.7042599}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'Episode_Time': 45.48866629600525, '_timestamp': 1721948646.7043154}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948646.7046182}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948646.7048404}).
wandb: WARNING (User provided step: 4847 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948646.7050574}).
Env Football Algo jrpo Exp base_JRPO updates 4847/100000000000.0 steps in 45.49
total episode rewards is -60.0
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'value_loss': 1.0020881911739707, '_timestamp': 1721948702.4530168}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010980032337053369, '_timestamp': 1721948702.4531906}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5356393305460612, '_timestamp': 1721948702.4532573}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.8116382360458374, '_timestamp': 1721948702.4533515}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.4074069261550903, '_timestamp': 1721948702.4536045}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'ratio': 1.0456210374832153, '_timestamp': 1721948702.453711}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721948702.4540358}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948702.454129}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'Episode_Time': 55.74702787399292, '_timestamp': 1721948702.4541852}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.36045002163565554, '_timestamp': 1721948702.454624}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'train_goal': 0.31977498918217223, '_timestamp': 1721948702.4549353}).
wandb: WARNING (User provided step: 2843 is less than current step: 15000. Dropping entry: {'train_WDL': -0.36045002163565554, '_timestamp': 1721948702.4552507}).
Env Football Algo jrpo Exp base_JRPO updates 2843/100000000000.0 steps in 55.75
total episode rewards is -90.0
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'value_loss': 0.24650554640141006, '_timestamp': 1721948781.5287685}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018584324156399816, '_timestamp': 1721948781.5289574}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6973133619626364, '_timestamp': 1721948781.5290263}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13057999312877655, '_timestamp': 1721948781.529125}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17557469010353088, '_timestamp': 1721948781.5293918}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'ratio': 0.9126591086387634, '_timestamp': 1721948781.5301063}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721948781.5302422}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948781.5303388}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.07239723205566, '_timestamp': 1721948781.5303962}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948781.5308213}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948781.5311482}).
wandb: WARNING (User provided step: 11092 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948781.531473}).
Env Football Algo jrpo Exp base_JRPO updates 11092/100000000000.0 steps in 79.07
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 10567/100000000000.0 steps in 89.93
total episode rewards is -20.0
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'value_loss': 0.16210410522685076, '_timestamp': 1721948871.4618988}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02813541660735306, '_timestamp': 1721948871.463203}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.649428423245748, '_timestamp': 1721948871.4632764}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2967235743999481, '_timestamp': 1721948871.4637556}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.205684632062912, '_timestamp': 1721948871.4641414}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'ratio': 0.8869653344154358, '_timestamp': 1721948871.4642532}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948871.4643881}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948871.4653895}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.92506194114685, '_timestamp': 1721948871.4654512}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721948871.4662578}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721948871.466615}).
wandb: WARNING (User provided step: 10567 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721948871.4669738}).
Env Football Algo jrpo Exp base_JRPO updates 5975/100000000000.0 steps in 87.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'value_loss': 0.3259099785067762, '_timestamp': 1721948959.00952}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016898177609158058, '_timestamp': 1721948959.009693}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6380534354845684, '_timestamp': 1721948959.0097606}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15293778479099274, '_timestamp': 1721948959.0098605}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29185017943382263, '_timestamp': 1721948959.010135}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'ratio': 0.7800269722938538, '_timestamp': 1721948959.010902}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721948959.0110507}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721948959.0111475}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.54126596450806, '_timestamp': 1721948959.0112064}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3378393351800554, '_timestamp': 1721948959.0119007}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'train_goal': 0.3310803324099723, '_timestamp': 1721948959.0124764}).
wandb: WARNING (User provided step: 5975 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3378393351800554, '_timestamp': 1721948959.0130284}).
Env Football Algo jrpo Exp base_JRPO updates 6455/100000000000.0 steps in 83.49
total episode rewards is -20.0
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'value_loss': 0.3349098496643516, '_timestamp': 1721949042.5055344}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006663044393838693, '_timestamp': 1721949042.5057054}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6625376383463542, '_timestamp': 1721949042.5057747}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.26296529173851013, '_timestamp': 1721949042.50587}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4098418056964874, '_timestamp': 1721949042.5061347}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'ratio': 0.8046113848686218, '_timestamp': 1721949042.506245}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721949042.506596}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949042.5066955}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.49159717559814, '_timestamp': 1721949042.5067532}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.4485664131070802, '_timestamp': 1721949042.507375}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'train_goal': 0.27571679344645994, '_timestamp': 1721949042.5078974}).
wandb: WARNING (User provided step: 6455 is less than current step: 15000. Dropping entry: {'train_WDL': -0.4485664131070802, '_timestamp': 1721949042.5084496}).
Env Football Algo jrpo Exp base_JRPO updates 10279/100000000000.0 steps in 86.57
total episode rewards is -40.0
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'value_loss': 0.35412679956449816, '_timestamp': 1721949129.0753593}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'policy_loss': 0.028734691723560295, '_timestamp': 1721949129.0755308}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5166077144940695, '_timestamp': 1721949129.0756004}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14869359135627747, '_timestamp': 1721949129.0756912}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4882982075214386, '_timestamp': 1721949129.0759783}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'ratio': 0.9087547063827515, '_timestamp': 1721949129.0760858}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949129.0767655}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949129.0769064}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.5659852027893, '_timestamp': 1721949129.0769656}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949129.0776875}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949129.0780215}).
wandb: WARNING (User provided step: 10279 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949129.0783818}).
Env Football Algo jrpo Exp base_JRPO updates 6481/100000000000.0 steps in 82.48
total episode rewards is -40.0
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'value_loss': 0.3201505340325336, '_timestamp': 1721949211.5618768}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009919451674989735, '_timestamp': 1721949211.5621958}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.518438111146291, '_timestamp': 1721949211.5622838}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1303281933069229, '_timestamp': 1721949211.5624228}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3344762623310089, '_timestamp': 1721949211.5626905}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'ratio': 0.87103670835495, '_timestamp': 1721949211.5627964}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949211.5634665}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949211.5635672}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.47947859764099, '_timestamp': 1721949211.5636263}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949211.5643632}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949211.5648744}).
wandb: WARNING (User provided step: 6481 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949211.56574}).
Env Football Algo jrpo Exp base_JRPO updates 9506/100000000000.0 steps in 87.22
total episode rewards is -40.0
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'value_loss': 0.3196599650507172, '_timestamp': 1721949298.7926908}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03437406396789205, '_timestamp': 1721949298.793683}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5404987303415933, '_timestamp': 1721949298.793756}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2797669768333435, '_timestamp': 1721949298.794137}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18759258091449738, '_timestamp': 1721949298.79446}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'ratio': 0.9320487976074219, '_timestamp': 1721949298.7945726}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949298.79471}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949298.7954535}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.22188019752502, '_timestamp': 1721949298.7955172}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949298.7962828}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949298.7966611}).
wandb: WARNING (User provided step: 9506 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949298.7970424}).
Env Football Algo jrpo Exp base_JRPO updates 3050/100000000000.0 steps in 46.54
total episode rewards is -20.0
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'value_loss': 0.7492440210903685, '_timestamp': 1721949345.3423839}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01739986330649117, '_timestamp': 1721949345.3426166}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5672812700271606, '_timestamp': 1721949345.3427114}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.35051649808883667, '_timestamp': 1721949345.3428237}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8937978148460388, '_timestamp': 1721949345.343116}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'ratio': 0.9120439887046814, '_timestamp': 1721949345.343257}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721949345.3442786}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949345.344397}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'Episode_Time': 46.54436922073364, '_timestamp': 1721949345.3444598}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.4902654867256637, '_timestamp': 1721949345.344927}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'train_goal': 0.7451327433628319, '_timestamp': 1721949345.3451965}).
wandb: WARNING (User provided step: 3050 is less than current step: 15000. Dropping entry: {'train_WDL': 0.4902654867256637, '_timestamp': 1721949345.3454576}).
Env Football Algo jrpo Exp base_JRPO updates 2960/100000000000.0 steps in 29.91
total episode rewards is -90.0
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'value_loss': 1.1534700239201388, '_timestamp': 1721949375.2546082}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'policy_loss': 0.11124040188888709, '_timestamp': 1721949375.2547681}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.072663594086965, '_timestamp': 1721949375.254834}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32055556774139404, '_timestamp': 1721949375.254923}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.2144323587417603, '_timestamp': 1721949375.2551754}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'ratio': 0.40473318099975586, '_timestamp': 1721949375.2552762}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721949375.2555125}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949375.255605}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'Episode_Time': 29.908421754837036, '_timestamp': 1721949375.2556639}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949375.255888}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949375.2560625}).
wandb: WARNING (User provided step: 2960 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949375.2562227}).
Env Football Algo jrpo Exp base_JRPO updates 6259/100000000000.0 steps in 81.77
total episode rewards is -40.0
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'value_loss': 0.3218362814343224, '_timestamp': 1721949457.0315356}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004948366302220772, '_timestamp': 1721949457.0317066}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0007075762748716, '_timestamp': 1721949457.0317729}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.44966089725494385, '_timestamp': 1721949457.0318654}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3130798637866974, '_timestamp': 1721949457.0322845}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'ratio': 0.9049603343009949, '_timestamp': 1721949457.0323923}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721949457.0325255}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949457.0335913}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.77433466911316, '_timestamp': 1721949457.0336525}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949457.0343883}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949457.0349092}).
wandb: WARNING (User provided step: 6259 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949457.0354366}).
Env Football Algo jrpo Exp base_JRPO updates 6618/100000000000.0 steps in 74.51
total episode rewards is -50.0
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'value_loss': 0.37691386775230057, '_timestamp': 1721949531.547336}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008132893014602209, '_timestamp': 1721949531.5475507}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8403027709325155, '_timestamp': 1721949531.5476177}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.263212114572525, '_timestamp': 1721949531.5477138}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.204838365316391, '_timestamp': 1721949531.5479908}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'ratio': 0.5734464526176453, '_timestamp': 1721949531.5480971}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721949531.5482676}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949531.5483978}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.51049733161926, '_timestamp': 1721949531.5484538}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949531.549029}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949531.5494106}).
wandb: WARNING (User provided step: 6618 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949531.5497918}).
Env Football Algo jrpo Exp base_JRPO updates 5893/100000000000.0 steps in 62.14
total episode rewards is -90.0
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'value_loss': 0.7061870147536198, '_timestamp': 1721949593.6877217}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07245705190114676, '_timestamp': 1721949593.6878903}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1309471265474955, '_timestamp': 1721949593.6879663}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 1.0162265300750732, '_timestamp': 1721949593.6880565}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7832576036453247, '_timestamp': 1721949593.6883104}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'ratio': 0.8172079920768738, '_timestamp': 1721949593.6884134}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721949593.6886864}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949593.6887794}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'Episode_Time': 62.13697052001953, '_timestamp': 1721949593.6888373}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949593.6892247}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949593.6895092}).
wandb: WARNING (User provided step: 5893 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949593.689804}).
Env Football Algo jrpo Exp base_JRPO updates 6933/100000000000.0 steps in 81.60
total episode rewards is -10.0
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'value_loss': 0.251804414310803, '_timestamp': 1721949675.2942789}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05495760674083916, '_timestamp': 1721949675.2944582}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0828390304247537, '_timestamp': 1721949675.294524}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3968850374221802, '_timestamp': 1721949675.2946174}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2604998052120209, '_timestamp': 1721949675.2948742}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'ratio': 0.8075546622276306, '_timestamp': 1721949675.2949748}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721949675.2952204}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949675.295314}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.60366344451904, '_timestamp': 1721949675.2953715}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.259947936035701, '_timestamp': 1721949675.2960284}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'train_goal': 0.3700260319821495, '_timestamp': 1721949675.2965233}).
wandb: WARNING (User provided step: 6933 is less than current step: 15000. Dropping entry: {'train_WDL': -0.259947936035701, '_timestamp': 1721949675.2970164}).
Env Football Algo jrpo Exp base_JRPO updates 2917/100000000000.0 steps in 48.14
total episode rewards is -30.0
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'value_loss': 0.5564386251630883, '_timestamp': 1721949723.438419}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02198517673823517, '_timestamp': 1721949723.438576}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1066856439908346, '_timestamp': 1721949723.4386396}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4385112524032593, '_timestamp': 1721949723.4387279}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7690603137016296, '_timestamp': 1721949723.4389527}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'ratio': 0.4808588922023773, '_timestamp': 1721949723.439054}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721949723.4392922}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949723.4393806}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'Episode_Time': 48.140681743621826, '_timestamp': 1721949723.4394376}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3367003367003367, '_timestamp': 1721949723.439848}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'train_goal': 0.6683501683501684, '_timestamp': 1721949723.449389}).
wandb: WARNING (User provided step: 2917 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3367003367003367, '_timestamp': 1721949723.4497297}).
Env Football Algo jrpo Exp base_JRPO updates 8602/100000000000.0 steps in 82.79
total episode rewards is -30.0
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'value_loss': 0.2754758916608989, '_timestamp': 1721949806.2383654}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'policy_loss': 0.036960860917073055, '_timestamp': 1721949806.2385435}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.126862063407898, '_timestamp': 1721949806.2386117}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15711374580860138, '_timestamp': 1721949806.2387059}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.249854177236557, '_timestamp': 1721949806.2389352}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'ratio': 0.5521922707557678, '_timestamp': 1721949806.239287}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721949806.2394176}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949806.239513}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.7873306274414, '_timestamp': 1721949806.23957}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949806.2400935}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949806.2404919}).
wandb: WARNING (User provided step: 8602 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949806.2409058}).
Env Football Algo jrpo Exp base_JRPO updates 5480/100000000000.0 steps in 88.82
total episode rewards is -20.0
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'value_loss': 0.3369038409468097, '_timestamp': 1721949895.0603175}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'policy_loss': 0.020148841724658268, '_timestamp': 1721949895.060488}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9768326918284098, '_timestamp': 1721949895.060554}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24713097512722015, '_timestamp': 1721949895.0606494}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20807252824306488, '_timestamp': 1721949895.0608964}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'ratio': 0.8530305027961731, '_timestamp': 1721949895.0609984}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721949895.0611272}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949895.0613256}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.81855511665344, '_timestamp': 1721949895.061385}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3798319327731092, '_timestamp': 1721949895.0621006}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'train_goal': 0.3100840336134454, '_timestamp': 1721949895.0626543}).
wandb: WARNING (User provided step: 5480 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3798319327731092, '_timestamp': 1721949895.0632238}).
Env Football Algo jrpo Exp base_JRPO updates 3275/100000000000.0 steps in 42.13
total episode rewards is -80.0
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'value_loss': 0.7740060472271094, '_timestamp': 1721949937.1961637}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'policy_loss': 0.053285536384015966, '_timestamp': 1721949937.1975124}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3763988757133483, '_timestamp': 1721949937.1975923}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32975924015045166, '_timestamp': 1721949937.1981285}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8263648748397827, '_timestamp': 1721949937.1985078}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'ratio': 0.7654357552528381, '_timestamp': 1721949937.1986196}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721949937.1987715}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949937.1989808}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'Episode_Time': 42.126320600509644, '_timestamp': 1721949937.1990395}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.17061769616026712, '_timestamp': 1721949937.199838}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'train_goal': 0.41469115191986644, '_timestamp': 1721949937.2001047}).
wandb: WARNING (User provided step: 3275 is less than current step: 15000. Dropping entry: {'train_WDL': -0.17061769616026712, '_timestamp': 1721949937.200445}).
Env Football Algo jrpo Exp base_JRPO updates 5271/100000000000.0 steps in 54.08
total episode rewards is -120.0
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'value_loss': 0.9208126546690861, '_timestamp': 1721949991.2809255}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04857835922991702, '_timestamp': 1721949991.281149}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4704744164148966, '_timestamp': 1721949991.2812204}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.892117440700531, '_timestamp': 1721949991.2813218}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.2193320989608765, '_timestamp': 1721949991.281594}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'ratio': 0.9448099136352539, '_timestamp': 1721949991.2817025}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721949991.281876}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721949991.2827044}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'Episode_Time': 54.07932162284851, '_timestamp': 1721949991.2827663}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721949991.283375}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721949991.2836685}).
wandb: WARNING (User provided step: 5271 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721949991.2840004}).
Env Football Algo jrpo Exp base_JRPO updates 10791/100000000000.0 steps in 87.54
total episode rewards is -30.0
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'value_loss': 0.24238629046148466, '_timestamp': 1721950078.828634}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'policy_loss': 0.031142670077970253, '_timestamp': 1721950078.8301694}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1318713688850404, '_timestamp': 1721950078.8302855}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.594083845615387, '_timestamp': 1721950078.8308468}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.41083407402038574, '_timestamp': 1721950078.8312776}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'ratio': 0.8888837099075317, '_timestamp': 1721950078.8322601}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721950078.8324127}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950078.8326588}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.53673338890076, '_timestamp': 1721950078.8327186}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950078.8341186}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950078.8344624}).
wandb: WARNING (User provided step: 10791 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950078.83501}).
Env Football Algo jrpo Exp base_JRPO updates 6149/100000000000.0 steps in 59.41
total episode rewards is -90.0
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'value_loss': 0.6708606440573931, '_timestamp': 1721950138.2461565}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0254712473708787, '_timestamp': 1721950138.246353}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2725663900375366, '_timestamp': 1721950138.2464197}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7035841941833496, '_timestamp': 1721950138.2465515}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7571225762367249, '_timestamp': 1721950138.2468157}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'ratio': 0.9828217625617981, '_timestamp': 1721950138.2469256}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721950138.247396}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950138.2474995}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'Episode_Time': 59.41003441810608, '_timestamp': 1721950138.2475567}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950138.2480924}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950138.2483916}).
wandb: WARNING (User provided step: 6149 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950138.2486477}).
Env Football Algo jrpo Exp base_JRPO updates 5565/100000000000.0 steps in 65.12
total episode rewards is -90.0
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'value_loss': 0.6828381067762772, '_timestamp': 1721950203.3740573}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03794190203722489, '_timestamp': 1721950203.3742998}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4183689069747925, '_timestamp': 1721950203.3743675}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42519935965538025, '_timestamp': 1721950203.3744607}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8851155638694763, '_timestamp': 1721950203.3747125}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'ratio': 0.7060921788215637, '_timestamp': 1721950203.3749416}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721950203.3752155}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950203.375314}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'Episode_Time': 65.12431168556213, '_timestamp': 1721950203.3753734}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950203.3762112}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950203.376631}).
wandb: WARNING (User provided step: 5565 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950203.3770022}).
Env Football Algo jrpo Exp base_JRPO updates 4771/100000000000.0 steps in 65.22
total episode rewards is -100.0
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'value_loss': 0.7696538218483329, '_timestamp': 1721950268.5994933}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05271216796162965, '_timestamp': 1721950268.5996614}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4451508982976278, '_timestamp': 1721950268.599727}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2731919586658478, '_timestamp': 1721950268.5998166}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7802576422691345, '_timestamp': 1721950268.6000807}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'ratio': 0.7497286200523376, '_timestamp': 1721950268.6001856}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721950268.6004457}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950268.6005423}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'Episode_Time': 65.22144913673401, '_timestamp': 1721950268.6005995}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950268.601193}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950268.6015916}).
wandb: WARNING (User provided step: 4771 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950268.60199}).
Env Football Algo jrpo Exp base_JRPO updates 4835/100000000000.0 steps in 84.72
total episode rewards is -70.0
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'value_loss': 0.5645107254882653, '_timestamp': 1721950353.3198404}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0005415380637471875, '_timestamp': 1721950353.3201058}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3098206090927125, '_timestamp': 1721950353.3201768}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4784282147884369, '_timestamp': 1721950353.3203058}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4468470811843872, '_timestamp': 1721950353.3205955}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'ratio': 0.886222779750824, '_timestamp': 1721950353.3207145}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950353.3215983}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950353.3217466}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.71663665771484, '_timestamp': 1721950353.3218088}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950353.3228276}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950353.3234458}).
wandb: WARNING (User provided step: 4835 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950353.324097}).
Env Football Algo jrpo Exp base_JRPO updates 9607/100000000000.0 steps in 89.61
total episode rewards is -30.0
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'value_loss': 0.25414904850224657, '_timestamp': 1721950442.9355948}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005227263564787184, '_timestamp': 1721950442.9358115}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0456087176005047, '_timestamp': 1721950442.9358795}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6070666909217834, '_timestamp': 1721950442.9359915}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3984885513782501, '_timestamp': 1721950442.9362762}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'ratio': 0.6915221810340881, '_timestamp': 1721950442.9363778}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721950442.9365127}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950442.9368684}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.60965061187744, '_timestamp': 1721950442.9369285}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950442.9374638}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950442.9378266}).
wandb: WARNING (User provided step: 9607 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950442.9381971}).
Env Football Algo jrpo Exp base_JRPO updates 11089/100000000000.0 steps in 81.55
total episode rewards is -30.0
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'value_loss': 0.2541405383249124, '_timestamp': 1721950524.4909713}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013775537713330172, '_timestamp': 1721950524.4911427}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.918409556945165, '_timestamp': 1721950524.49121}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28831127285957336, '_timestamp': 1721950524.4913}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3443085253238678, '_timestamp': 1721950524.4915779}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'ratio': 0.6684521436691284, '_timestamp': 1721950524.4916797}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721950524.4921224}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950524.4922197}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.55196475982666, '_timestamp': 1721950524.4922776}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950524.4928567}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950524.493149}).
wandb: WARNING (User provided step: 11089 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950524.4934478}).
Env Football Algo jrpo Exp base_JRPO updates 3675/100000000000.0 steps in 67.31
total episode rewards is -70.0
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'value_loss': 0.621730634868145, '_timestamp': 1721950591.8053882}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00565201274274538, '_timestamp': 1721950591.8055525}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.4627156303326289, '_timestamp': 1721950591.805621}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29389187693595886, '_timestamp': 1721950591.805718}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6049373149871826, '_timestamp': 1721950591.805984}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'ratio': 0.9230408668518066, '_timestamp': 1721950591.8060946}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950591.8062296}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950591.8066294}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'Episode_Time': 67.31099891662598, '_timestamp': 1721950591.8067005}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950591.8072689}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950591.8077242}).
wandb: WARNING (User provided step: 3675 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950591.8084009}).
Env Football Algo jrpo Exp base_JRPO updates 4129/100000000000.0 steps in 62.06
total episode rewards is -80.0
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'value_loss': 0.6332604578882456, '_timestamp': 1721950653.874315}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015280754460133418, '_timestamp': 1721950653.8744783}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6208746830622355, '_timestamp': 1721950653.8745468}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3456267714500427, '_timestamp': 1721950653.874636}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7132822871208191, '_timestamp': 1721950653.874884}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'ratio': 0.8886553049087524, '_timestamp': 1721950653.87515}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721950653.875285}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950653.8753772}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'Episode_Time': 62.06498050689697, '_timestamp': 1721950653.8754525}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950653.8761322}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950653.8765247}).
wandb: WARNING (User provided step: 4129 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950653.8769214}).
Env Football Algo jrpo Exp base_JRPO updates 5843/100000000000.0 steps in 66.03
total episode rewards is -70.0
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'value_loss': 0.5369212763259809, '_timestamp': 1721950719.9110675}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'policy_loss': 0.029082052315740535, '_timestamp': 1721950719.9112875}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7942343056201935, '_timestamp': 1721950719.911359}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2850823998451233, '_timestamp': 1721950719.9114578}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6205779314041138, '_timestamp': 1721950719.9117184}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'ratio': 0.7881874442100525, '_timestamp': 1721950719.9118233}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721950719.9125953}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950719.9126916}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'Episode_Time': 66.03308582305908, '_timestamp': 1721950719.91275}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950719.9134097}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950719.9139152}).
wandb: WARNING (User provided step: 5843 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950719.9144583}).
Env Football Algo jrpo Exp base_JRPO updates 9330/100000000000.0 steps in 82.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'value_loss': 0.3001040311933805, '_timestamp': 1721950802.3737867}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05843317563247789, '_timestamp': 1721950802.3740282}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9984528581301372, '_timestamp': 1721950802.3740997}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16817401349544525, '_timestamp': 1721950802.3741977}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29962295293807983, '_timestamp': 1721950802.375259}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'ratio': 0.7754138708114624, '_timestamp': 1721950802.3753855}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721950802.3755271}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950802.3756282}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.45807600021362, '_timestamp': 1721950802.3756864}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950802.3764248}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950802.3767936}).
wandb: WARNING (User provided step: 9330 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950802.3773282}).
Env Football Algo jrpo Exp base_JRPO updates 8696/100000000000.0 steps in 89.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'value_loss': 0.29155908551299947, '_timestamp': 1721950892.0249026}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02002188815269619, '_timestamp': 1721950892.0250797}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0597802090644837, '_timestamp': 1721950892.0251458}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.0969284176826477, '_timestamp': 1721950892.025239}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17637398838996887, '_timestamp': 1721950892.025504}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'ratio': 0.8532676100730896, '_timestamp': 1721950892.025607}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721950892.026141}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950892.026238}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.64614081382751, '_timestamp': 1721950892.0262942}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950892.0268202}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950892.0272305}).
wandb: WARNING (User provided step: 8696 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950892.02765}).
Env Football Algo jrpo Exp base_JRPO updates 3628/100000000000.0 steps in 44.11
total episode rewards is -80.0
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'value_loss': 0.6165150545537472, '_timestamp': 1721950936.142581}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07413226089362676, '_timestamp': 1721950936.1427412}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7436617354551951, '_timestamp': 1721950936.142808}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3883958160877228, '_timestamp': 1721950936.1428983}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6698446273803711, '_timestamp': 1721950936.143147}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'ratio': 0.7494077086448669, '_timestamp': 1721950936.1433976}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721950936.1435335}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950936.143625}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'Episode_Time': 44.11417818069458, '_timestamp': 1721950936.1436808}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950936.1440597}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950936.1443162}).
wandb: WARNING (User provided step: 3628 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950936.1445758}).
Env Football Algo jrpo Exp base_JRPO updates 4435/100000000000.0 steps in 47.17
total episode rewards is -130.0
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'value_loss': 0.9916681663691997, '_timestamp': 1721950983.3170571}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'policy_loss': 0.043113464064857304, '_timestamp': 1721950983.3172271}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6099548375606537, '_timestamp': 1721950983.3172956}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4833777844905853, '_timestamp': 1721950983.3173862}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9463698267936707, '_timestamp': 1721950983.3176444}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'ratio': 0.9857364296913147, '_timestamp': 1721950983.317747}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721950983.3181934}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721950983.3182862}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'Episode_Time': 47.17155194282532, '_timestamp': 1721950983.3183439}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721950983.3186517}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721950983.3188305}).
wandb: WARNING (User provided step: 4435 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721950983.319008}).
Env Football Algo jrpo Exp base_JRPO updates 7622/100000000000.0 steps in 89.96
total episode rewards is -40.0
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'value_loss': 0.3249842684715986, '_timestamp': 1721951073.2780995}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'policy_loss': -0.020633402933502413, '_timestamp': 1721951073.278275}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8285527233282725, '_timestamp': 1721951073.2783415}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2159937024116516, '_timestamp': 1721951073.2784927}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29226547479629517, '_timestamp': 1721951073.2787414}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'ratio': 0.7339392304420471, '_timestamp': 1721951073.2788439}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951073.2793865}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951073.27948}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.9583170413971, '_timestamp': 1721951073.2795365}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951073.280436}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951073.2812042}).
wandb: WARNING (User provided step: 7622 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951073.281821}).
Env Football Algo jrpo Exp base_JRPO updates 6210/100000000000.0 steps in 55.79
total episode rewards is -70.0
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'value_loss': 0.532911608076344, '_timestamp': 1721951129.0733788}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'policy_loss': -0.007442710800290418, '_timestamp': 1721951129.0744863}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.723835373322169, '_timestamp': 1721951129.0745568}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2216973900794983, '_timestamp': 1721951129.0868144}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6334298849105835, '_timestamp': 1721951129.09186}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'ratio': 0.8314664959907532, '_timestamp': 1721951129.0921526}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951129.0928597}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951129.09309}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'Episode_Time': 55.78648567199707, '_timestamp': 1721951129.093151}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951129.0938575}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951129.0941184}).
wandb: WARNING (User provided step: 6210 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951129.0943751}).
Env Football Algo jrpo Exp base_JRPO updates 5592/100000000000.0 steps in 60.22
total episode rewards is -110.0
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'value_loss': 0.8250766550873717, '_timestamp': 1721951189.3174658}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0013015530568857988, '_timestamp': 1721951189.3176339}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6841056744257609, '_timestamp': 1721951189.3177001}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3104512095451355, '_timestamp': 1721951189.317795}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0078033208847046, '_timestamp': 1721951189.3180397}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'ratio': 0.9865358471870422, '_timestamp': 1721951189.3181424}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721951189.3184419}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951189.3185332}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'Episode_Time': 60.22230648994446, '_timestamp': 1721951189.3185885}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951189.3190205}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951189.3192875}).
wandb: WARNING (User provided step: 5592 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951189.3196054}).
Env Football Algo jrpo Exp base_JRPO updates 3555/100000000000.0 steps in 61.12
total episode rewards is -110.0
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'value_loss': 0.8058768579487999, '_timestamp': 1721951250.435832}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018827136893911908, '_timestamp': 1721951250.4361024}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6740807712078094, '_timestamp': 1721951250.4361718}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.37610432505607605, '_timestamp': 1721951250.4363108}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7903926968574524, '_timestamp': 1721951250.4365895}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'ratio': 0.9238210320472717, '_timestamp': 1721951250.4366953}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721951250.4368289}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951250.4370513}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'Episode_Time': 61.11516618728638, '_timestamp': 1721951250.437109}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951250.43772}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951250.4381514}).
wandb: WARNING (User provided step: 3555 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951250.438591}).
Env Football Algo jrpo Exp base_JRPO updates 3325/100000000000.0 steps in 35.29
total episode rewards is -130.0
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'value_loss': 0.9791533766190211, '_timestamp': 1721951285.725335}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007534041013326108, '_timestamp': 1721951285.7255468}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6318659702936809, '_timestamp': 1721951285.725618}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3626287281513214, '_timestamp': 1721951285.7257276}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.081795573234558, '_timestamp': 1721951285.7259967}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'ratio': 0.9127243161201477, '_timestamp': 1721951285.7267878}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721951285.726929}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951285.727049}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'Episode_Time': 35.285752058029175, '_timestamp': 1721951285.727107}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951285.72745}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951285.7276196}).
wandb: WARNING (User provided step: 3325 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951285.7277818}).
Env Football Algo jrpo Exp base_JRPO updates 7376/100000000000.0 steps in 84.75
total episode rewards is -80.0
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'value_loss': 0.5837278404893974, '_timestamp': 1721951370.481762}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'policy_loss': 0.024649357432087224, '_timestamp': 1721951370.4819372}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7767665529251099, '_timestamp': 1721951370.4820144}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24964983761310577, '_timestamp': 1721951370.4821107}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4099710285663605, '_timestamp': 1721951370.4824166}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'ratio': 0.8731680512428284, '_timestamp': 1721951370.4825232}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721951370.4830227}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951370.4831204}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.75318455696106, '_timestamp': 1721951370.483179}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951370.4837391}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951370.4842043}).
wandb: WARNING (User provided step: 7376 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951370.48467}).
Env Football Algo jrpo Exp base_JRPO updates 3771/100000000000.0 steps in 42.83
total episode rewards is -70.0
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'value_loss': 0.5303470580652356, '_timestamp': 1721951413.3192847}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03182929859360835, '_timestamp': 1721951413.319495}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.732490036090215, '_timestamp': 1721951413.319565}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3799164295196533, '_timestamp': 1721951413.3196614}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6813170313835144, '_timestamp': 1721951413.3199337}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'ratio': 0.9591096043586731, '_timestamp': 1721951413.3245883}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951413.3247342}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951413.3248327}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'Episode_Time': 42.83356547355652, '_timestamp': 1721951413.324891}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951413.3252528}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951413.3254905}).
wandb: WARNING (User provided step: 3771 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951413.3257077}).
Env Football Algo jrpo Exp base_JRPO updates 6988/100000000000.0 steps in 91.46
total episode rewards is -40.0
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'value_loss': 0.33216797924290103, '_timestamp': 1721951504.7839708}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'policy_loss': 0.022575662217665618, '_timestamp': 1721951504.7842116}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8158126592636108, '_timestamp': 1721951504.7842822}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21307380497455597, '_timestamp': 1721951504.7844334}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3095916509628296, '_timestamp': 1721951504.784713}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'ratio': 0.8518579602241516, '_timestamp': 1721951504.7848217}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951504.7854695}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951504.7855713}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.456791639328, '_timestamp': 1721951504.7856324}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951504.7862535}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951504.7867513}).
wandb: WARNING (User provided step: 6988 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951504.787243}).
Env Football Algo jrpo Exp base_JRPO updates 9145/100000000000.0 steps in 86.60
total episode rewards is -40.0
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'value_loss': 0.33599022597074507, '_timestamp': 1721951591.3970256}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03376333547969504, '_timestamp': 1721951591.3984053}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1325082834561666, '_timestamp': 1721951591.398478}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15046429634094238, '_timestamp': 1721951591.3989763}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.31431254744529724, '_timestamp': 1721951591.3993516}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'ratio': 0.7910423278808594, '_timestamp': 1721951591.4002328}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721951591.4005296}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951591.400728}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.60349535942078, '_timestamp': 1721951591.4007883}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951591.4021614}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951591.4027393}).
wandb: WARNING (User provided step: 9145 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951591.4031417}).
Env Football Algo jrpo Exp base_JRPO updates 6513/100000000000.0 steps in 74.34
total episode rewards is -70.0
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'value_loss': 0.5225375963250796, '_timestamp': 1721951665.7427578}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018240862981571505, '_timestamp': 1721951665.7429779}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1026227140426637, '_timestamp': 1721951665.743048}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3443348705768585, '_timestamp': 1721951665.7431855}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6113225817680359, '_timestamp': 1721951665.7434685}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'ratio': 0.8308684229850769, '_timestamp': 1721951665.7435763}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951665.7445223}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951665.7446713}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.33834743499756, '_timestamp': 1721951665.7447288}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951665.7454197}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951665.745815}).
wandb: WARNING (User provided step: 6513 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951665.7462456}).
Env Football Algo jrpo Exp base_JRPO updates 4496/100000000000.0 steps in 47.53
total episode rewards is -90.0
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'value_loss': 0.6601887386292219, '_timestamp': 1721951713.2755783}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'policy_loss': 0.022640717991356116, '_timestamp': 1721951713.2759168}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9627030758062999, '_timestamp': 1721951713.2760246}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.49809128046035767, '_timestamp': 1721951713.2761805}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6560099124908447, '_timestamp': 1721951713.2764862}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'ratio': 0.8771838545799255, '_timestamp': 1721951713.2774947}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721951713.2776477}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951713.2777503}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'Episode_Time': 47.52770376205444, '_timestamp': 1721951713.277807}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951713.2783365}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951713.2786124}).
wandb: WARNING (User provided step: 4496 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951713.2788856}).
Env Football Algo jrpo Exp base_JRPO updates 8753/100000000000.0 steps in 79.63
total episode rewards is -80.0
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'value_loss': 0.5816996051246921, '_timestamp': 1721951792.9142063}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00170271092550441, '_timestamp': 1721951792.9143803}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0912705254554749, '_timestamp': 1721951792.9144452}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3015621304512024, '_timestamp': 1721951792.9145396}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7029491066932678, '_timestamp': 1721951792.9147837}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'ratio': 0.8190243244171143, '_timestamp': 1721951792.9148872}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721951792.9150193}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951792.9151082}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.63407373428345, '_timestamp': 1721951792.9151647}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951792.9157424}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951792.916081}).
wandb: WARNING (User provided step: 8753 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951792.916409}).
Env Football Algo jrpo Exp base_JRPO updates 5440/100000000000.0 steps in 60.24
total episode rewards is -80.0
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'value_loss': 0.6088808033242822, '_timestamp': 1721951853.159481}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0004717196832643822, '_timestamp': 1721951853.1596408}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3272678065299988, '_timestamp': 1721951853.1597075}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3582767844200134, '_timestamp': 1721951853.1599987}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7193207740783691, '_timestamp': 1721951853.1602447}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'ratio': 0.7730452418327332, '_timestamp': 1721951853.160345}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721951853.1604714}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951853.1605597}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'Episode_Time': 60.242353439331055, '_timestamp': 1721951853.1606152}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951853.1610205}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951853.1613472}).
wandb: WARNING (User provided step: 5440 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951853.1616778}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'value_loss': 0.5257811678635578, '_timestamp': 1721951927.7391093}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04135498745871397, '_timestamp': 1721951927.7393575}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.421472225189209, '_timestamp': 1721951927.7394295}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17284929752349854, '_timestamp': 1721951927.7395647}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.596032440662384, '_timestamp': 1721951927.7398274}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'ratio': 0.6866655945777893, '_timestamp': 1721951927.7399313}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721951927.7426596}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721951927.742821}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.57634568214417, '_timestamp': 1721951927.7428997}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721951927.743489}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721951927.7438023}).
wandb: WARNING (User provided step: 8135 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721951927.7441359}).
Env Football Algo jrpo Exp base_JRPO updates 8135/100000000000.0 steps in 74.58
total episode rewards is -70.0
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'value_loss': 0.30637590151745825, '_timestamp': 1721952009.704021}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0486537074597436, '_timestamp': 1721952009.704239}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6006312243143717, '_timestamp': 1721952009.7043097}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15600553154945374, '_timestamp': 1721952009.7044454}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2895923852920532, '_timestamp': 1721952009.704936}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'ratio': 0.7342973351478577, '_timestamp': 1721952009.7050426}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952009.7051764}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952009.705269}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.95892524719238, '_timestamp': 1721952009.705326}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952009.7058716}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952009.7062945}).
wandb: WARNING (User provided step: 7940 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952009.7067356}).
Env Football Algo jrpo Exp base_JRPO updates 7940/100000000000.0 steps in 81.96
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 3978/100000000000.0 steps in 47.00
total episode rewards is -100.0
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'value_loss': 0.7373669022818407, '_timestamp': 1721952056.7032497}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0719248244278909, '_timestamp': 1721952056.7034326}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0996572228272756, '_timestamp': 1721952056.703499}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2676781713962555, '_timestamp': 1721952056.7035952}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.720769464969635, '_timestamp': 1721952056.703859}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'ratio': 0.608504056930542, '_timestamp': 1721952056.7039819}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721952056.7041156}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952056.7045033}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'Episode_Time': 46.99567627906799, '_timestamp': 1721952056.7045648}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952056.7048514}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952056.7050354}).
wandb: WARNING (User provided step: 3978 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952056.70522}).
Env Football Algo jrpo Exp base_JRPO updates 10801/100000000000.0 steps in 80.30
total episode rewards is -30.0
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'value_loss': 0.23573073264366637, '_timestamp': 1721952137.004561}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02677966520587991, '_timestamp': 1721952137.0047276}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2194345164299012, '_timestamp': 1721952137.004793}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.26348409056663513, '_timestamp': 1721952137.004884}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24785396456718445, '_timestamp': 1721952137.0052965}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'ratio': 0.7566549777984619, '_timestamp': 1721952137.0054018}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721952137.0055332}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952137.005624}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.29842519760132, '_timestamp': 1721952137.0056787}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952137.0060833}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952137.006383}).
wandb: WARNING (User provided step: 10801 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952137.0066764}).
Env Football Algo jrpo Exp base_JRPO updates 7283/100000000000.0 steps in 86.20
total episode rewards is -30.0
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'value_loss': 0.25205452881433305, '_timestamp': 1721952223.2101583}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013093814085004851, '_timestamp': 1721952223.2103317}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0165242342154186, '_timestamp': 1721952223.2103982}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1038777157664299, '_timestamp': 1721952223.210492}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.0849362462759018, '_timestamp': 1721952223.2107437}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'ratio': 1.0870612859725952, '_timestamp': 1721952223.21085}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721952223.2113626}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952223.2114615}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.20251822471619, '_timestamp': 1721952223.2115202}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952223.2121212}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952223.212584}).
wandb: WARNING (User provided step: 7283 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952223.2130673}).
Env Football Algo jrpo Exp base_JRPO updates 6040/100000000000.0 steps in 75.77
total episode rewards is -50.0
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'value_loss': 0.37589126523816957, '_timestamp': 1721952298.9829955}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006806141627991261, '_timestamp': 1721952298.983168}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.602868328889211, '_timestamp': 1721952298.9832337}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.08277034759521484, '_timestamp': 1721952298.983323}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3427306115627289, '_timestamp': 1721952298.983764}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'ratio': 0.8378371596336365, '_timestamp': 1721952298.9838688}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721952298.9840252}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952298.98412}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'Episode_Time': 75.76888370513916, '_timestamp': 1721952298.984175}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952298.9847612}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952298.98522}).
wandb: WARNING (User provided step: 6040 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952298.9856935}).
Env Football Algo jrpo Exp base_JRPO updates 5964/100000000000.0 steps in 53.83
total episode rewards is -80.0
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'value_loss': 0.5938390844734386, '_timestamp': 1721952352.8160338}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016010543788628033, '_timestamp': 1721952352.8162875}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5672183988491694, '_timestamp': 1721952352.8163846}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21686384081840515, '_timestamp': 1721952352.8165095}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6899774074554443, '_timestamp': 1721952352.8168342}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'ratio': 0.8223690986633301, '_timestamp': 1721952352.8169816}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721952352.8181016}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952352.8182278}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'Episode_Time': 53.82927966117859, '_timestamp': 1721952352.8182986}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952352.8187332}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952352.819021}).
wandb: WARNING (User provided step: 5964 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952352.8193104}).
Env Football Algo jrpo Exp base_JRPO updates 4868/100000000000.0 steps in 60.87
total episode rewards is -100.0
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'value_loss': 0.748625410789003, '_timestamp': 1721952413.6874297}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008456963625115653, '_timestamp': 1721952413.6875913}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.42617857376734414, '_timestamp': 1721952413.6876547}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2410704642534256, '_timestamp': 1721952413.687742}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8722414374351501, '_timestamp': 1721952413.6881151}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'ratio': 0.9660255908966064, '_timestamp': 1721952413.6882203}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721952413.688341}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952413.6884341}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'Episode_Time': 60.866690158843994, '_timestamp': 1721952413.6884913}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952413.6889186}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952413.6892784}).
wandb: WARNING (User provided step: 4868 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952413.6896548}).
Env Football Algo jrpo Exp base_JRPO updates 5942/100000000000.0 steps in 84.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'value_loss': 0.3132854781241622, '_timestamp': 1721952498.3375325}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005605248924111948, '_timestamp': 1721952498.3377419}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.49476601541042325, '_timestamp': 1721952498.3378105}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10454589128494263, '_timestamp': 1721952498.3379025}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.34025436639785767, '_timestamp': 1721952498.3381677}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'ratio': 0.8555430173873901, '_timestamp': 1721952498.3382673}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952498.3383985}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952498.3384922}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.64661645889282, '_timestamp': 1721952498.338549}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952498.3392115}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952498.3397357}).
wandb: WARNING (User provided step: 5942 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952498.3402903}).
Env Football Algo jrpo Exp base_JRPO updates 4651/100000000000.0 steps in 69.90
total episode rewards is -60.0
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'value_loss': 0.4438209281892826, '_timestamp': 1721952568.2448838}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015865376470125436, '_timestamp': 1721952568.2450721}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.525172447959582, '_timestamp': 1721952568.2451417}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11319359391927719, '_timestamp': 1721952568.2452488}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.47919347882270813, '_timestamp': 1721952568.2455313}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'ratio': 0.8519899845123291, '_timestamp': 1721952568.2465641}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721952568.2467303}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952568.2468383}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'Episode_Time': 69.90364575386047, '_timestamp': 1721952568.2468991}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952568.2475603}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952568.2480366}).
wandb: WARNING (User provided step: 4651 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952568.2484827}).
Env Football Algo jrpo Exp base_JRPO updates 6731/100000000000.0 steps in 55.89
total episode rewards is -80.0
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'value_loss': 0.5872395056051513, '_timestamp': 1721952624.1416063}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00655152270415177, '_timestamp': 1721952624.1417923}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5538060373067856, '_timestamp': 1721952624.1418598}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.234937846660614, '_timestamp': 1721952624.1419523}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5547749400138855, '_timestamp': 1721952624.1422431}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'ratio': 0.9095131754875183, '_timestamp': 1721952624.1423473}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721952624.1424844}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952624.143106}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'Episode_Time': 55.891948223114014, '_timestamp': 1721952624.1431665}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952624.1435862}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952624.1438425}).
wandb: WARNING (User provided step: 6731 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952624.1441193}).
Env Football Algo jrpo Exp base_JRPO updates 7326/100000000000.0 steps in 87.17
total episode rewards is -40.0
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'value_loss': 0.3631173580698669, '_timestamp': 1721952711.316759}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'policy_loss': 0.022151564275991405, '_timestamp': 1721952711.3169222}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5691160390774409, '_timestamp': 1721952711.3169878}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10449478775262833, '_timestamp': 1721952711.3170774}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.37070974707603455, '_timestamp': 1721952711.3173244}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'ratio': 0.8483545780181885, '_timestamp': 1721952711.3175905}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952711.3177257}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952711.3178182}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.17191767692566, '_timestamp': 1721952711.317877}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952711.3184345}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952711.3188927}).
wandb: WARNING (User provided step: 7326 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952711.3193657}).
Env Football Algo jrpo Exp base_JRPO updates 7803/100000000000.0 steps in 75.38
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'value_loss': 0.5299964859553923, '_timestamp': 1721952786.6978576}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01948804674243244, '_timestamp': 1721952786.6980326}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5414959446589152, '_timestamp': 1721952786.6980982}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13862499594688416, '_timestamp': 1721952786.69819}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3807598352432251, '_timestamp': 1721952786.6984594}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'ratio': 4.163916110992432, '_timestamp': 1721952786.698562}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721952786.6986923}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952786.698784}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'Episode_Time': 75.37586283683777, '_timestamp': 1721952786.699252}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952786.6998112}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952786.70025}).
wandb: WARNING (User provided step: 7803 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952786.7006848}).
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 4412/100000000000.0 steps in 85.57
total episode rewards is -40.0
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'value_loss': 0.3505175115113767, '_timestamp': 1721952872.2697558}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010573663714312715, '_timestamp': 1721952872.269993}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.45943132241566975, '_timestamp': 1721952872.2700632}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07592758536338806, '_timestamp': 1721952872.2701635}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.11408025026321411, '_timestamp': 1721952872.2704577}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'ratio': 0.8948630094528198, '_timestamp': 1721952872.2705617}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952872.2714937}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952872.2716322}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.56807947158813, '_timestamp': 1721952872.27169}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952872.272719}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952872.273571}).
wandb: WARNING (User provided step: 4412 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952872.2743354}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'value_loss': 0.3513566313055344, '_timestamp': 1721952956.917692}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00993338501304, '_timestamp': 1721952956.9180799}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6373305336634318, '_timestamp': 1721952956.91815}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.08021082729101181, '_timestamp': 1721952956.9183316}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17384855449199677, '_timestamp': 1721952956.918622}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'ratio': 0.9255813956260681, '_timestamp': 1721952956.9187272}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721952956.9189029}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721952956.919028}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.64130234718323, '_timestamp': 1721952956.919422}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721952956.920265}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721952956.9208484}).
wandb: WARNING (User provided step: 5141 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721952956.9214623}).
Env Football Algo jrpo Exp base_JRPO updates 5141/100000000000.0 steps in 84.64
total episode rewards is -40.0
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'value_loss': 0.737400070404013, '_timestamp': 1721953002.9276989}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'policy_loss': 0.030598331604463357, '_timestamp': 1721953002.927855}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.43464913447697956, '_timestamp': 1721953002.9279203}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.33170560002326965, '_timestamp': 1721953002.928022}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8424387574195862, '_timestamp': 1721953002.9282641}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'ratio': 0.801275372505188, '_timestamp': 1721953002.9286036}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721953002.9287324}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953002.9288225}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'Episode_Time': 46.00542187690735, '_timestamp': 1721953002.9288776}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953002.9291856}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953002.9294064}).
wandb: WARNING (User provided step: 3625 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953002.9296248}).
Env Football Algo jrpo Exp base_JRPO updates 3625/100000000000.0 steps in 46.01
total episode rewards is -100.0
Env Football Algo jrpo Exp base_JRPO updates 6447/100000000000.0 steps in 79.09
total episode rewards is -40.0
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'value_loss': 0.3081905517890118, '_timestamp': 1721953082.0167499}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007636221571556234, '_timestamp': 1721953082.017027}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5022066714366277, '_timestamp': 1721953082.017095}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10421261191368103, '_timestamp': 1721953082.0172482}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23856741189956665, '_timestamp': 1721953082.0175219}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'ratio': 0.8253926634788513, '_timestamp': 1721953082.0176241}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953082.0177562}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953082.0178492}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.08583498001099, '_timestamp': 1721953082.0181224}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953082.0189512}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953082.0194795}).
wandb: WARNING (User provided step: 6447 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953082.0200317}).
Env Football Algo jrpo Exp base_JRPO updates 8526/100000000000.0 steps in 90.39
total episode rewards is -40.0
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'value_loss': 0.3417484034318477, '_timestamp': 1721953172.4130843}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010711235839407892, '_timestamp': 1721953172.4133015}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6513049924373626, '_timestamp': 1721953172.4133832}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11138688772916794, '_timestamp': 1721953172.4134822}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20110245048999786, '_timestamp': 1721953172.4137473}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'ratio': 0.7479593753814697, '_timestamp': 1721953172.413854}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953172.4145532}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953172.4146495}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.39195132255554, '_timestamp': 1721953172.4147081}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953172.4153047}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953172.4157317}).
wandb: WARNING (User provided step: 8526 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953172.4161763}).
Env Football Algo jrpo Exp base_JRPO updates 3637/100000000000.0 steps in 58.44
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'value_loss': 0.7687855754047632, '_timestamp': 1721953230.8549864}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'policy_loss': 0.005882954963405306, '_timestamp': 1721953230.85521}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.4565037270387014, '_timestamp': 1721953230.8552775}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4762049615383148, '_timestamp': 1721953230.8553782}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9833673238754272, '_timestamp': 1721953230.8556423}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'ratio': 0.8586949110031128, '_timestamp': 1721953230.8557463}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721953230.855881}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953230.855984}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'Episode_Time': 58.4378228187561, '_timestamp': 1721953230.856151}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.18808134951915498, '_timestamp': 1721953230.856676}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'train_goal': 0.5940406747595774, '_timestamp': 1721953230.8570628}).
wandb: WARNING (User provided step: 3637 is less than current step: 15000. Dropping entry: {'train_WDL': 0.18808134951915498, '_timestamp': 1721953230.857727}).
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 5954/100000000000.0 steps in 85.07
total episode rewards is -40.0
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'value_loss': 0.3394185394716139, '_timestamp': 1721953315.9314504}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'policy_loss': 0.007923395592176046, '_timestamp': 1721953315.9328194}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6370799779891968, '_timestamp': 1721953315.932907}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1610638052225113, '_timestamp': 1721953315.9334052}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26024580001831055, '_timestamp': 1721953315.9337733}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'ratio': 0.8780773282051086, '_timestamp': 1721953315.9338799}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953315.9340131}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953315.9348164}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.06761574745178, '_timestamp': 1721953315.9348762}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953315.9359388}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953315.9365017}).
wandb: WARNING (User provided step: 5954 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953315.9370492}).
Env Football Algo jrpo Exp base_JRPO updates 6121/100000000000.0 steps in 87.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'value_loss': 0.34378873583472647, '_timestamp': 1721953403.7521827}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014316365798392022, '_timestamp': 1721953403.7523491}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7769099223613739, '_timestamp': 1721953403.752416}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14743363857269287, '_timestamp': 1721953403.7525072}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3564648926258087, '_timestamp': 1721953403.7527835}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'ratio': 0.8690602779388428, '_timestamp': 1721953403.7528915}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953403.7530425}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953403.7535257}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.81410813331604, '_timestamp': 1721953403.753587}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953403.7542343}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953403.7547588}).
wandb: WARNING (User provided step: 6121 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953403.7552967}).
Env Football Algo jrpo Exp base_JRPO updates 8212/100000000000.0 steps in 82.01
total episode rewards is -40.0
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'value_loss': 0.31438845095224677, '_timestamp': 1721953485.7671652}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'policy_loss': 0.028766310133505613, '_timestamp': 1721953485.7673414}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8826077898343404, '_timestamp': 1721953485.7674062}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07867931574583054, '_timestamp': 1721953485.7674987}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26698148250579834, '_timestamp': 1721953485.7677562}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'ratio': 0.787071168422699, '_timestamp': 1721953485.7678597}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953485.7679994}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953485.7682939}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.01070761680603, '_timestamp': 1721953485.7683527}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953485.7688982}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953485.7693155}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953485.769748}).
Env Football Algo jrpo Exp base_JRPO updates 4799/100000000000.0 steps in 63.95
total episode rewards is -80.0
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'value_loss': 0.6047075115392605, '_timestamp': 1721953549.7204936}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03479944970381136, '_timestamp': 1721953549.7206511}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8491510796546936, '_timestamp': 1721953549.720717}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29549771547317505, '_timestamp': 1721953549.7208047}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5054799318313599, '_timestamp': 1721953549.7210424}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'ratio': 1.3333348035812378, '_timestamp': 1721953549.7211437}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721953549.7212706}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953549.7213604}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'Episode_Time': 63.94982075691223, '_timestamp': 1721953549.7215247}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953549.722001}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953549.7223861}).
wandb: WARNING (User provided step: 4799 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953549.7227817}).
Env Football Algo jrpo Exp base_JRPO updates 7734/100000000000.0 steps in 90.68
total episode rewards is -40.0
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'value_loss': 0.322831179931527, '_timestamp': 1721953640.399464}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021634564358973877, '_timestamp': 1721953640.3996377}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9469744265079498, '_timestamp': 1721953640.3997052}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1937464326620102, '_timestamp': 1721953640.3997977}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19409950077533722, '_timestamp': 1721953640.4000816}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'ratio': 0.9307742714881897, '_timestamp': 1721953640.4001865}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953640.4004362}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953640.4005313}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.67573690414429, '_timestamp': 1721953640.4005883}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953640.4011369}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953640.40157}).
wandb: WARNING (User provided step: 7734 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953640.40202}).
Env Football Algo jrpo Exp base_JRPO updates 6785/100000000000.0 steps in 59.72
total episode rewards is -80.0
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'value_loss': 0.6230584649617473, '_timestamp': 1721953700.1201408}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04301579183821256, '_timestamp': 1721953700.1203177}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0108447670936584, '_timestamp': 1721953700.1203842}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28513801097869873, '_timestamp': 1721953700.120477}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5621466040611267, '_timestamp': 1721953700.120724}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'ratio': 0.7409123182296753, '_timestamp': 1721953700.120825}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721953700.1209605}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953700.12118}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'Episode_Time': 59.71706795692444, '_timestamp': 1721953700.1212416}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953700.121706}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953700.1220276}).
wandb: WARNING (User provided step: 6785 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953700.1223729}).
Env Football Algo jrpo Exp base_JRPO updates 9467/100000000000.0 steps in 92.54
total episode rewards is -40.0
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'value_loss': 0.3398244831385091, '_timestamp': 1721953792.6669014}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021634000982545937, '_timestamp': 1721953792.6670928}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2002313105265299, '_timestamp': 1721953792.6671643}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14943671226501465, '_timestamp': 1721953792.6672719}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2686100900173187, '_timestamp': 1721953792.667563}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'ratio': 0.7836213111877441, '_timestamp': 1721953792.6676793}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953792.6685874}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953792.6686912}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.54368162155151, '_timestamp': 1721953792.6687484}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953792.6692736}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953792.6696672}).
wandb: WARNING (User provided step: 9467 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953792.6700597}).
Env Football Algo jrpo Exp base_JRPO updates 9713/100000000000.0 steps in 88.37
total episode rewards is -40.0
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'value_loss': 0.3031888715499857, '_timestamp': 1721953881.0417523}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0056917324460422, '_timestamp': 1721953881.0419219}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2681161427497865, '_timestamp': 1721953881.0419884}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17522495985031128, '_timestamp': 1721953881.042081}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4624670147895813, '_timestamp': 1721953881.0423353}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'ratio': 0.8953753113746643, '_timestamp': 1721953881.042436}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721953881.042565}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953881.042832}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.37070274353027, '_timestamp': 1721953881.0428908}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953881.0433404}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953881.0436888}).
wandb: WARNING (User provided step: 9713 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953881.0440593}).
Env Football Algo jrpo Exp base_JRPO updates 5406/100000000000.0 steps in 51.89
total episode rewards is -100.0
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'value_loss': 0.7476556403376162, '_timestamp': 1721953932.9374511}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009918301154878767, '_timestamp': 1721953932.9376228}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.164093840122223, '_timestamp': 1721953932.9376898}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6031565070152283, '_timestamp': 1721953932.937783}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.855623722076416, '_timestamp': 1721953932.9380534}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'ratio': 0.9222151637077332, '_timestamp': 1721953932.938157}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721953932.9382904}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953932.9388304}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'Episode_Time': 51.892457008361816, '_timestamp': 1721953932.938891}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953932.9392323}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953932.939475}).
wandb: WARNING (User provided step: 5406 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953932.939714}).
Env Football Algo jrpo Exp base_JRPO updates 5211/100000000000.0 steps in 65.78
total episode rewards is -110.0
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'value_loss': 0.8118570039918025, '_timestamp': 1721953998.718384}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'policy_loss': 0.017403375963525227, '_timestamp': 1721953998.7185714}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.184050255616506, '_timestamp': 1721953998.718641}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.618506908416748, '_timestamp': 1721953998.718744}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.8372023105621338, '_timestamp': 1721953998.7190242}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'ratio': 0.8772582411766052, '_timestamp': 1721953998.7191331}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721953998.7192705}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721953998.720022}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'Episode_Time': 65.77781701087952, '_timestamp': 1721953998.7200851}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721953998.7206771}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721953998.7210975}).
wandb: WARNING (User provided step: 5211 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721953998.7214987}).
Env Football Algo jrpo Exp base_JRPO updates 7965/100000000000.0 steps in 89.17
total episode rewards is -40.0
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'value_loss': 0.3199935083727663, '_timestamp': 1721954087.900744}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02312575033730051, '_timestamp': 1721954087.90205}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2335453009605408, '_timestamp': 1721954087.902125}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1440054476261139, '_timestamp': 1721954087.9026134}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.41127362847328186, '_timestamp': 1721954087.903048}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'ratio': 0.8613796234130859, '_timestamp': 1721954087.9031627}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954087.9032981}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954087.9035006}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.17281746864319, '_timestamp': 1721954087.9035602}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954087.9045496}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954087.9050138}).
wandb: WARNING (User provided step: 7965 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954087.905476}).
Env Football Algo jrpo Exp base_JRPO updates 5075/100000000000.0 steps in 90.68
total episode rewards is -70.0
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'value_loss': 0.5415691662424554, '_timestamp': 1721954178.586913}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01737903640275666, '_timestamp': 1721954178.5871298}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1343288691838582, '_timestamp': 1721954178.5871964}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3040301203727722, '_timestamp': 1721954178.5873284}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4923079013824463, '_timestamp': 1721954178.5875952}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'ratio': 0.8361698389053345, '_timestamp': 1721954178.5876956}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721954178.5881803}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954178.5882747}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.6804780960083, '_timestamp': 1721954178.588331}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954178.5890915}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954178.589657}).
wandb: WARNING (User provided step: 5075 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954178.5902114}).
Env Football Algo jrpo Exp base_JRPO updates 6902/100000000000.0 steps in 81.01
total episode rewards is -40.0
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'value_loss': 0.33324650605830053, '_timestamp': 1721954259.6004806}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'policy_loss': 0.023722716809716077, '_timestamp': 1721954259.6006835}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2048525365193685, '_timestamp': 1721954259.6007533}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.140680730342865, '_timestamp': 1721954259.6008456}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.32081788778305054, '_timestamp': 1721954259.6010578}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'ratio': 0.8276474475860596, '_timestamp': 1721954259.6014183}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954259.6015766}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954259.60167}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.00936436653137, '_timestamp': 1721954259.6017275}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954259.6023667}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954259.602852}).
wandb: WARNING (User provided step: 6902 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954259.603364}).
Env Football Algo jrpo Exp base_JRPO updates 7580/100000000000.0 steps in 83.03
total episode rewards is -70.0
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'value_loss': 0.5295102680567652, '_timestamp': 1721954342.6306326}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016874862348971266, '_timestamp': 1721954342.6308508}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.228961655298869, '_timestamp': 1721954342.6309178}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22051627933979034, '_timestamp': 1721954342.6310127}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5761555433273315, '_timestamp': 1721954342.631282}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'ratio': 0.8490073084831238, '_timestamp': 1721954342.6313832}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721954342.6315145}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954342.6318285}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.02618479728699, '_timestamp': 1721954342.6318872}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954342.6323845}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954342.6327598}).
wandb: WARNING (User provided step: 7580 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954342.6331432}).
Env Football Algo jrpo Exp base_JRPO updates 5316/100000000000.0 steps in 91.50
total episode rewards is -20.0
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'value_loss': 0.34728933684295044, '_timestamp': 1721954434.1405406}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004500337586505338, '_timestamp': 1721954434.1418817}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2078238773345946, '_timestamp': 1721954434.1419585}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.530102014541626, '_timestamp': 1721954434.1424806}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3674943745136261, '_timestamp': 1721954434.1428578}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'ratio': 0.9300056099891663, '_timestamp': 1721954434.1429656}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721954434.1437538}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954434.1439912}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.50092887878418, '_timestamp': 1721954434.1440508}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.38351920693928127, '_timestamp': 1721954434.145219}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'train_goal': 0.30824039653035934, '_timestamp': 1721954434.145799}).
wandb: WARNING (User provided step: 5316 is less than current step: 15000. Dropping entry: {'train_WDL': -0.38351920693928127, '_timestamp': 1721954434.1463723}).
Env Football Algo jrpo Exp base_JRPO updates 5542/100000000000.0 steps in 60.54
total episode rewards is -90.0
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'value_loss': 0.6883176147999863, '_timestamp': 1721954494.686164}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006776906180505951, '_timestamp': 1721954494.686344}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3619003478686016, '_timestamp': 1721954494.6864123}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48018860816955566, '_timestamp': 1721954494.6865134}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7613708972930908, '_timestamp': 1721954494.68678}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'ratio': 0.9214442372322083, '_timestamp': 1721954494.6868877}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721954494.6870217}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954494.6874413}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'Episode_Time': 60.538856506347656, '_timestamp': 1721954494.6875036}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954494.688001}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954494.6883655}).
wandb: WARNING (User provided step: 5542 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954494.6887343}).
Env Football Algo jrpo Exp base_JRPO updates 3526/100000000000.0 steps in 59.58
total episode rewards is -120.0
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'value_loss': 1.021330767571926, '_timestamp': 1721954554.2702713}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004998798159649595, '_timestamp': 1721954554.270436}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3404069050153096, '_timestamp': 1721954554.270501}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7141528129577637, '_timestamp': 1721954554.2705908}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.217145562171936, '_timestamp': 1721954554.2708535}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'ratio': 0.9298181533813477, '_timestamp': 1721954554.2709558}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -120.0, '_timestamp': 1721954554.2712088}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954554.271303}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'Episode_Time': 59.58056664466858, '_timestamp': 1721954554.27136}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3301643889879184, '_timestamp': 1721954554.2718058}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'train_goal': 0.3349178055060408, '_timestamp': 1721954554.272162}).
wandb: WARNING (User provided step: 3526 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3301643889879184, '_timestamp': 1721954554.272496}).
Env Football Algo jrpo Exp base_JRPO updates 3863/100000000000.0 steps in 56.31
total episode rewards is -80.0
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'value_loss': 0.5956162804986039, '_timestamp': 1721954610.5867357}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01638273847832655, '_timestamp': 1721954610.5868926}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2991641529401143, '_timestamp': 1721954610.5869586}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.312406063079834, '_timestamp': 1721954610.5870457}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5219143033027649, '_timestamp': 1721954610.587303}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'ratio': 0.885429322719574, '_timestamp': 1721954610.5874038}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721954610.5875354}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954610.5877447}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.31324338912964, '_timestamp': 1721954610.5878034}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954610.5882785}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954610.588648}).
wandb: WARNING (User provided step: 3863 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954610.5890179}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'value_loss': 0.3409956655527155, '_timestamp': 1721954700.9868562}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013072600028826854, '_timestamp': 1721954700.9870222}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3532164986928303, '_timestamp': 1721954700.9870877}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3365192413330078, '_timestamp': 1721954700.9871764}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20368963479995728, '_timestamp': 1721954700.9874308}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'ratio': 0.8890464305877686, '_timestamp': 1721954700.9875348}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954700.9878275}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954700.9879203}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.39710807800293, '_timestamp': 1721954700.987986}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954700.988677}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954700.989249}).
wandb: WARNING (User provided step: 4793 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954700.9898496}).
Env Football Algo jrpo Exp base_JRPO updates 4793/100000000000.0 steps in 90.40
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 5669/100000000000.0 steps in 63.01
total episode rewards is -60.0
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'value_loss': 0.46180908533434073, '_timestamp': 1721954763.9998164}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'policy_loss': -0.01762515075512662, '_timestamp': 1721954764.0081418}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4247480257352194, '_timestamp': 1721954764.0082977}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.35145461559295654, '_timestamp': 1721954764.0084164}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.380422979593277, '_timestamp': 1721954764.0087802}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'ratio': 0.8361204862594604, '_timestamp': 1721954764.0089037}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721954764.0090508}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954764.0091596}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'Episode_Time': 63.0088632106781, '_timestamp': 1721954764.0092235}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954764.0097516}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954764.0101345}).
wandb: WARNING (User provided step: 5669 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954764.0105035}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'value_loss': 0.2684473995740215, '_timestamp': 1721954859.0702958}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01012110018307188, '_timestamp': 1721954859.0705473}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4812114032109578, '_timestamp': 1721954859.0706332}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3542386293411255, '_timestamp': 1721954859.070764}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21441765129566193, '_timestamp': 1721954859.071077}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'ratio': 0.7260199785232544, '_timestamp': 1721954859.07189}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721954859.0804942}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954859.0806983}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'Episode_Time': 95.058424949646, '_timestamp': 1721954859.0807662}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954859.0814817}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954859.0819485}).
wandb: WARNING (User provided step: 7947 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954859.082408}).
Env Football Algo jrpo Exp base_JRPO updates 7947/100000000000.0 steps in 95.06
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 6742/100000000000.0 steps in 95.35
total episode rewards is -40.0
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'value_loss': 0.31563874006892245, '_timestamp': 1721954954.4342697}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010391285729128867, '_timestamp': 1721954954.4345644}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4589745386441548, '_timestamp': 1721954954.4346485}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2906235456466675, '_timestamp': 1721954954.4347854}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2631138861179352, '_timestamp': 1721954954.4351454}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'ratio': 0.7774803638458252, '_timestamp': 1721954954.4352624}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721954954.4354055}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721954954.435505}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'Episode_Time': 95.35076856613159, '_timestamp': 1721954954.4358516}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721954954.436559}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721954954.4370856}).
wandb: WARNING (User provided step: 6742 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721954954.4376152}).
Env Football Algo jrpo Exp base_JRPO updates 6810/100000000000.0 steps in 75.53
total episode rewards is -60.0
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'value_loss': 0.46034086001416047, '_timestamp': 1721955029.973099}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00505336157977581, '_timestamp': 1721955029.9732668}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4912288252512613, '_timestamp': 1721955029.9733338}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24697245657444, '_timestamp': 1721955029.9734213}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.37860146164894104, '_timestamp': 1721955029.973682}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'ratio': 0.7318249344825745, '_timestamp': 1721955029.9737866}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721955029.97392}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955029.9741867}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'Episode_Time': 75.53444337844849, '_timestamp': 1721955029.9742458}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955029.9747224}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955029.9750934}).
wandb: WARNING (User provided step: 6810 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955029.9754732}).
Env Football Algo jrpo Exp base_JRPO updates 9093/100000000000.0 steps in 90.35
total episode rewards is -40.0
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'value_loss': 0.3290255024842918, '_timestamp': 1721955120.3301487}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'policy_loss': 0.031361575769260526, '_timestamp': 1721955120.3303196}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4429528355598449, '_timestamp': 1721955120.330385}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2503030300140381, '_timestamp': 1721955120.3304737}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3085439205169678, '_timestamp': 1721955120.3307474}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'ratio': 0.6055708527565002, '_timestamp': 1721955120.3308568}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955120.3312905}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955120.3313868}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.35337424278259, '_timestamp': 1721955120.3314445}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955120.3325865}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955120.333173}).
wandb: WARNING (User provided step: 9093 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955120.333566}).
Env Football Algo jrpo Exp base_JRPO updates 6666/100000000000.0 steps in 88.40
total episode rewards is -10.0
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'value_loss': 0.2913725743877391, '_timestamp': 1721955208.7332084}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0022112705987334873, '_timestamp': 1721955208.73338}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5073109944661458, '_timestamp': 1721955208.7334487}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32672181725502014, '_timestamp': 1721955208.7335408}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3857933580875397, '_timestamp': 1721955208.7338102}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'ratio': 0.7676586508750916, '_timestamp': 1721955208.7339149}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721955208.7340536}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955208.7343545}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.3988196849823, '_timestamp': 1721955208.734415}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2877369810415167, '_timestamp': 1721955208.7351837}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'train_goal': 0.35613150947924166, '_timestamp': 1721955208.7356732}).
wandb: WARNING (User provided step: 6666 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2877369810415167, '_timestamp': 1721955208.7361846}).
Env Football Algo jrpo Exp base_JRPO updates 4356/100000000000.0 steps in 85.12
total episode rewards is -40.0
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'value_loss': 0.35103728878311813, '_timestamp': 1721955293.8612201}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0001992334673802058, '_timestamp': 1721955293.8613908}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4924178576469422, '_timestamp': 1721955293.8614578}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22145989537239075, '_timestamp': 1721955293.8615491}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.351801335811615, '_timestamp': 1721955293.8618066}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'ratio': 0.8552977442741394, '_timestamp': 1721955293.8619094}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955293.8620305}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955293.8621218}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.12235641479492, '_timestamp': 1721955293.862179}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955293.862877}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955293.8634624}).
wandb: WARNING (User provided step: 4356 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955293.8672185}).
Env Football Algo jrpo Exp base_JRPO updates 7872/100000000000.0 steps in 87.07
total episode rewards is -40.0
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'value_loss': 0.32032374895410615, '_timestamp': 1721955380.9381096}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02324001187866088, '_timestamp': 1721955380.9382672}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.60859748284022, '_timestamp': 1721955380.9383337}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16539205610752106, '_timestamp': 1721955380.9384253}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29955944418907166, '_timestamp': 1721955380.938674}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'ratio': 0.6643360257148743, '_timestamp': 1721955380.938776}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955380.9389076}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955380.938997}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.06998491287231, '_timestamp': 1721955380.9391632}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955380.9396875}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955380.9401257}).
wandb: WARNING (User provided step: 7872 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955380.9405708}).
Env Football Algo jrpo Exp base_JRPO updates 5163/100000000000.0 steps in 74.88
total episode rewards is -50.0
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'value_loss': 0.3926821354147978, '_timestamp': 1721955455.8171163}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012372420002551128, '_timestamp': 1721955455.817299}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.594317851861318, '_timestamp': 1721955455.8173656}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22086220979690552, '_timestamp': 1721955455.8174603}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29136618971824646, '_timestamp': 1721955455.8177288}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'ratio': 0.7910150289535522, '_timestamp': 1721955455.817834}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721955455.8179677}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955455.8184328}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.87551689147949, '_timestamp': 1721955455.8184924}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955455.8190024}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955455.8193955}).
wandb: WARNING (User provided step: 5163 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955455.8198004}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'value_loss': 0.3394420437712688, '_timestamp': 1721955538.470457}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02353788814196984, '_timestamp': 1721955538.470628}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6251171294848124, '_timestamp': 1721955538.4706938}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.25609445571899414, '_timestamp': 1721955538.4707851}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.35416460037231445, '_timestamp': 1721955538.4710727}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'ratio': 0.8627013564109802, '_timestamp': 1721955538.471178}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955538.4713116}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955538.4715817}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.6496102809906, '_timestamp': 1721955538.4716403}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955538.4724467}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955538.4730334}).
wandb: WARNING (User provided step: 4852 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955538.473635}).
Env Football Algo jrpo Exp base_JRPO updates 4852/100000000000.0 steps in 82.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'value_loss': 0.300937360637278, '_timestamp': 1721955626.1787076}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021408093825448303, '_timestamp': 1721955626.1789002}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6079642430941263, '_timestamp': 1721955626.178971}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19799751043319702, '_timestamp': 1721955626.1790717}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2819887399673462, '_timestamp': 1721955626.1793416}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'ratio': 0.8482205271720886, '_timestamp': 1721955626.1794474}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721955626.1795805}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955626.1799212}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.70416688919067, '_timestamp': 1721955626.180013}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955626.1807346}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955626.1813152}).
wandb: WARNING (User provided step: 5591 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955626.1818848}).
Env Football Algo jrpo Exp base_JRPO updates 5591/100000000000.0 steps in 87.70
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 4866/100000000000.0 steps in 72.94
total episode rewards is -10.0
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'value_loss': 0.41103837300091983, '_timestamp': 1721955699.124085}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00902710487668325, '_timestamp': 1721955699.1242557}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5253520568211874, '_timestamp': 1721955699.124322}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4091357886791229, '_timestamp': 1721955699.124413}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.42851415276527405, '_timestamp': 1721955699.1246731}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'ratio': 0.7552823424339294, '_timestamp': 1721955699.128381}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721955699.128734}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955699.1288629}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.94117665290833, '_timestamp': 1721955699.1295857}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.4508990318118949, '_timestamp': 1721955699.1303632}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'train_goal': 0.7254495159059474, '_timestamp': 1721955699.130824}).
wandb: WARNING (User provided step: 4866 is less than current step: 15000. Dropping entry: {'train_WDL': 0.4508990318118949, '_timestamp': 1721955699.1312678}).
Env Football Algo jrpo Exp base_JRPO updates 5151/100000000000.0 steps in 56.97
total episode rewards is -100.0
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'value_loss': 0.7746083246916533, '_timestamp': 1721955756.1042874}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016753578886661367, '_timestamp': 1721955756.104474}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6083679254849752, '_timestamp': 1721955756.1045434}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4334166646003723, '_timestamp': 1721955756.1046398}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.750318169593811, '_timestamp': 1721955756.104922}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'ratio': 0.8256849646568298, '_timestamp': 1721955756.1050308}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -100.0, '_timestamp': 1721955756.105165}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955756.1052608}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.97213816642761, '_timestamp': 1721955756.1057222}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955756.1063263}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955756.106685}).
wandb: WARNING (User provided step: 5151 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955756.1070495}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'value_loss': 0.275835885189008, '_timestamp': 1721955848.5432775}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0019410216740410153, '_timestamp': 1721955848.54461}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.710999941031138, '_timestamp': 1721955848.5446868}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.471709668636322, '_timestamp': 1721955848.5451767}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18004243075847626, '_timestamp': 1721955848.5455444}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'ratio': 0.7907318472862244, '_timestamp': 1721955848.5456545}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721955848.5457885}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955848.546598}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.43046474456787, '_timestamp': 1721955848.5466592}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.24788909892879646, '_timestamp': 1721955848.5476818}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'train_goal': 0.37605545053560174, '_timestamp': 1721955848.5482068}).
wandb: WARNING (User provided step: 7065 is less than current step: 15000. Dropping entry: {'train_WDL': -0.24788909892879646, '_timestamp': 1721955848.5487034}).
Env Football Algo jrpo Exp base_JRPO updates 7065/100000000000.0 steps in 92.43
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 6104/100000000000.0 steps in 92.36
total episode rewards is -20.0
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'value_loss': 0.3110895280757298, '_timestamp': 1721955940.9135518}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0026387127756606786, '_timestamp': 1721955940.9137368}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6025219217936197, '_timestamp': 1721955940.9138057}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4481373727321625, '_timestamp': 1721955940.9139025}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.34503862261772156, '_timestamp': 1721955940.9141665}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'ratio': 0.8093889951705933, '_timestamp': 1721955940.9142745}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721955940.914406}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955940.9144995}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.36394834518433, '_timestamp': 1721955940.9151413}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.33318345323741005, '_timestamp': 1721955940.9160202}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'train_goal': 0.333408273381295, '_timestamp': 1721955940.9165685}).
wandb: WARNING (User provided step: 6104 is less than current step: 15000. Dropping entry: {'train_WDL': -0.33318345323741005, '_timestamp': 1721955940.9171133}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'value_loss': 0.5907333165500313, '_timestamp': 1721955984.359776}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00942045265789299, '_timestamp': 1721955984.3600268}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6150000842412313, '_timestamp': 1721955984.3600962}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5642921328544617, '_timestamp': 1721955984.3602314}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5697934627532959, '_timestamp': 1721955984.3605201}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'ratio': 2.0976667404174805, '_timestamp': 1721955984.3606272}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721955984.3607624}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721955984.3608556}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'Episode_Time': 43.44099521636963, '_timestamp': 1721955984.361514}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721955984.3622994}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721955984.3625357}).
wandb: WARNING (User provided step: 3854 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721955984.3627653}).
Env Football Algo jrpo Exp base_JRPO updates 3854/100000000000.0 steps in 43.44
total episode rewards is -80.0
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'value_loss': 0.8360030492643515, '_timestamp': 1721956040.5922453}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03497300936549436, '_timestamp': 1721956040.5934396}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5819696855545045, '_timestamp': 1721956040.5935133}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6530259847640991, '_timestamp': 1721956040.593997}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0747394561767578, '_timestamp': 1721956040.5943675}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'ratio': 0.8282053470611572, '_timestamp': 1721956040.5944796}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721956040.5946085}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956040.5948107}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.223814725875854, '_timestamp': 1721956040.5956013}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5303344867358708, '_timestamp': 1721956040.5965037}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'train_goal': 0.7651672433679354, '_timestamp': 1721956040.5968285}).
wandb: WARNING (User provided step: 4065 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5303344867358708, '_timestamp': 1721956040.5971513}).
Env Football Algo jrpo Exp base_JRPO updates 4065/100000000000.0 steps in 56.22
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 7511/100000000000.0 steps in 83.14
total episode rewards is -40.0
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'value_loss': 0.3162607758181791, '_timestamp': 1721956123.7414641}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01793433788504141, '_timestamp': 1721956123.7416291}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6290233222643535, '_timestamp': 1721956123.7416968}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.20756219327449799, '_timestamp': 1721956123.741789}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21457454562187195, '_timestamp': 1721956123.7420607}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'ratio': 0.7624181509017944, '_timestamp': 1721956123.7421632}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956123.7423022}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956123.7423935}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.14308214187622, '_timestamp': 1721956123.7427979}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956123.743394}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956123.7438464}).
wandb: WARNING (User provided step: 7511 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956123.7443383}).
Env Football Algo jrpo Exp base_JRPO updates 4442/100000000000.0 steps in 67.47
total episode rewards is -80.0
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'value_loss': 0.6231785613546769, '_timestamp': 1721956191.2137926}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'policy_loss': -0.006713979361423602, '_timestamp': 1721956191.2140682}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6686330445607502, '_timestamp': 1721956191.2141438}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.9020945429801941, '_timestamp': 1721956191.2143543}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5340861678123474, '_timestamp': 1721956191.2146597}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'ratio': 0.559967577457428, '_timestamp': 1721956191.2147765}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721956191.2149186}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956191.2158012}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'Episode_Time': 67.46817326545715, '_timestamp': 1721956191.2158687}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956191.2167852}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956191.2171977}).
wandb: WARNING (User provided step: 4442 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956191.2175827}).
Env Football Algo jrpo Exp base_JRPO updates 7854/100000000000.0 steps in 84.34
total episode rewards is -30.0
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'value_loss': 0.30634581902374824, '_timestamp': 1721956275.56828}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05580318881974866, '_timestamp': 1721956275.569646}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9059907285372417, '_timestamp': 1721956275.5697215}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19894994795322418, '_timestamp': 1721956275.5702293}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19788947701454163, '_timestamp': 1721956275.5706084}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'ratio': 0.7034794092178345, '_timestamp': 1721956275.5707197}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721956275.5708628}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956275.571877}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.3445770740509, '_timestamp': 1721956275.5719426}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956275.5733259}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956275.5737965}).
wandb: WARNING (User provided step: 7854 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956275.5742693}).
Env Football Algo jrpo Exp base_JRPO updates 10402/100000000000.0 steps in 90.89
total episode rewards is -30.0
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'value_loss': 0.24936366950006536, '_timestamp': 1721956366.4646294}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'policy_loss': 0.046226649954175324, '_timestamp': 1721956366.4648116}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9979670763015747, '_timestamp': 1721956366.464876}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22345960140228271, '_timestamp': 1721956366.465032}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1664307713508606, '_timestamp': 1721956366.4652517}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'ratio': 0.620583713054657, '_timestamp': 1721956366.4653513}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721956366.4654756}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956366.465746}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.889315366745, '_timestamp': 1721956366.4658031}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956366.4662254}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956366.4665403}).
wandb: WARNING (User provided step: 10402 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956366.4668572}).
Env Football Algo jrpo Exp base_JRPO updates 7130/100000000000.0 steps in 85.70
total episode rewards is -60.0
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'value_loss': 0.4613412583526224, '_timestamp': 1721956452.1709633}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05092036160097147, '_timestamp': 1721956452.172015}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9865528806050619, '_timestamp': 1721956452.1720881}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16540956497192383, '_timestamp': 1721956452.172484}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2489636242389679, '_timestamp': 1721956452.1728055}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'ratio': 0.6192436218261719, '_timestamp': 1721956452.1729107}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721956452.1732419}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956452.1734161}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.69872212409973, '_timestamp': 1721956452.173476}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956452.1743038}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956452.174704}).
wandb: WARNING (User provided step: 7130 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956452.1751084}).
Env Football Algo jrpo Exp base_JRPO updates 7936/100000000000.0 steps in 85.08
total episode rewards is -40.0
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'value_loss': 0.34402618996449746, '_timestamp': 1721956537.253297}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03981880812207237, '_timestamp': 1721956537.2534776}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.0832167609532672, '_timestamp': 1721956537.2535443}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1314309537410736, '_timestamp': 1721956537.253642}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26882511377334595, '_timestamp': 1721956537.253901}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'ratio': 1.0539344549179077, '_timestamp': 1721956537.2540045}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956537.2543976}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956537.2544937}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.07733058929443, '_timestamp': 1721956537.2545524}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956537.255193}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956537.2556686}).
wandb: WARNING (User provided step: 7936 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956537.256163}).
Env Football Algo jrpo Exp base_JRPO updates 7113/100000000000.0 steps in 92.33
total episode rewards is -40.0
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'value_loss': 0.3760671995962427, '_timestamp': 1721956629.5866075}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'policy_loss': 0.031000782942865044, '_timestamp': 1721956629.5867777}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.059362537066142, '_timestamp': 1721956629.5868454}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1261717528104782, '_timestamp': 1721956629.5869362}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3423808515071869, '_timestamp': 1721956629.5871987}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'ratio': 0.9208717942237854, '_timestamp': 1721956629.5873022}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956629.5875905}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956629.587682}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.3294939994812, '_timestamp': 1721956629.58774}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956629.5883608}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956629.5888522}).
wandb: WARNING (User provided step: 7113 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956629.589342}).
Env Football Algo jrpo Exp base_JRPO updates 6458/100000000000.0 steps in 92.68
total episode rewards is -40.0
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'value_loss': 0.35047778925703216, '_timestamp': 1721956722.2745533}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'policy_loss': 0.036356333593527475, '_timestamp': 1721956722.2747207}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9539157978693644, '_timestamp': 1721956722.2747865}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17171651124954224, '_timestamp': 1721956722.2748768}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1744801104068756, '_timestamp': 1721956722.2751288}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'ratio': 0.9299003481864929, '_timestamp': 1721956722.275234}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956722.275577}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956722.2756724}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.6842520236969, '_timestamp': 1721956722.2757294}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956722.2763844}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956722.2768834}).
wandb: WARNING (User provided step: 6458 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956722.2774167}).
Env Football Algo jrpo Exp base_JRPO updates 5641/100000000000.0 steps in 80.05
total episode rewards is -40.0
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'value_loss': 0.358382985307835, '_timestamp': 1721956802.3308227}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04370052841841243, '_timestamp': 1721956802.331008}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8130662846565246, '_timestamp': 1721956802.3310776}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.20743754506111145, '_timestamp': 1721956802.3311813}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2005472630262375, '_timestamp': 1721956802.33146}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'ratio': 0.8418957591056824, '_timestamp': 1721956802.3315642}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721956802.3322294}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956802.3323355}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.05253839492798, '_timestamp': 1721956802.3323927}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956802.333369}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956802.3339481}).
wandb: WARNING (User provided step: 5641 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956802.3345199}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'value_loss': 0.6182174395707747, '_timestamp': 1721956877.3205671}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'policy_loss': 0.06339063417942574, '_timestamp': 1721956877.3207343}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5195836162567138, '_timestamp': 1721956877.3207984}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.23623354732990265, '_timestamp': 1721956877.320888}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.654899537563324, '_timestamp': 1721956877.3211462}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'ratio': 0.699295163154602, '_timestamp': 1721956877.3213878}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721956877.3215244}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956877.321617}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'Episode_Time': 74.98501086235046, '_timestamp': 1721956877.3216739}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956877.3222322}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956877.32267}).
wandb: WARNING (User provided step: 4371 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956877.3231266}).
Env Football Algo jrpo Exp base_JRPO updates 4371/100000000000.0 steps in 74.99
total episode rewards is -60.0
Env Football Algo jrpo Exp base_JRPO updates 2173/100000000000.0 steps in 25.25
total episode rewards is -160.0
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'value_loss': 1.1798285017410914, '_timestamp': 1721956902.572965}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'policy_loss': 0.10692996669754697, '_timestamp': 1721956902.5732188}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4066960263252257, '_timestamp': 1721956902.5732884}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.732855498790741, '_timestamp': 1721956902.5734587}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0823577642440796, '_timestamp': 1721956902.57372}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'ratio': 0.7620579600334167, '_timestamp': 1721956902.573825}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721956902.5742147}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956902.574351}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'Episode_Time': 25.248157739639282, '_timestamp': 1721956902.5744083}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956902.574643}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956902.574781}).
wandb: WARNING (User provided step: 2173 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956902.574913}).
Env Football Algo jrpo Exp base_JRPO updates 3609/100000000000.0 steps in 42.15
total episode rewards is -140.0
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'value_loss': 1.0230092305876315, '_timestamp': 1721956944.7260892}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07194682233821367, '_timestamp': 1721956944.7273853}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5013812923431396, '_timestamp': 1721956944.727463}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.34982359409332275, '_timestamp': 1721956944.7279377}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0024014711380005, '_timestamp': 1721956944.7282956}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'ratio': 0.741637110710144, '_timestamp': 1721956944.7283993}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -140.0, '_timestamp': 1721956944.7291262}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956944.729341}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'Episode_Time': 42.14547538757324, '_timestamp': 1721956944.7294006}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956944.7301672}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956944.7304275}).
wandb: WARNING (User provided step: 3609 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956944.7306874}).
Env Football Algo jrpo Exp base_JRPO updates 1389/100000000000.0 steps in 29.61
total episode rewards is -200.0
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'value_loss': 1.4504514003793398, '_timestamp': 1721956974.339472}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'policy_loss': 0.09703433971192377, '_timestamp': 1721956974.3396406}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.672191035747528, '_timestamp': 1721956974.3397076}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3941739499568939, '_timestamp': 1721956974.3398023}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.240934133529663, '_timestamp': 1721956974.3401039}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'ratio': 0.7758062481880188, '_timestamp': 1721956974.3402107}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -200.0, '_timestamp': 1721956974.3405092}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721956974.34082}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'Episode_Time': 29.607919454574585, '_timestamp': 1721956974.3408794}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721956974.3411484}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721956974.3413084}).
wandb: WARNING (User provided step: 1389 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721956974.3414633}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'value_loss': 1.2290870881577334, '_timestamp': 1721957017.912631}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07698772841598839, '_timestamp': 1721957017.9128547}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6009743515650432, '_timestamp': 1721957017.912923}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2929253578186035, '_timestamp': 1721957017.9130619}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.1700527667999268, '_timestamp': 1721957017.913337}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'ratio': 0.6629801392555237, '_timestamp': 1721957017.9135787}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -170.0, '_timestamp': 1721957017.9137182}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957017.9138105}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'Episode_Time': 43.56997990608215, '_timestamp': 1721957017.9138684}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957017.9141605}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957017.9143567}).
wandb: WARNING (User provided step: 3318 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957017.914555}).
Env Football Algo jrpo Exp base_JRPO updates 3318/100000000000.0 steps in 43.57
total episode rewards is -170.0
Env Football Algo jrpo Exp base_JRPO updates 1862/100000000000.0 steps in 26.46
total episode rewards is -190.0
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'value_loss': 1.345484613577525, '_timestamp': 1721957044.3794773}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'policy_loss': 0.11651858799780408, '_timestamp': 1721957044.3806565}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5272700794537861, '_timestamp': 1721957044.3807292}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30904173851013184, '_timestamp': 1721957044.3811858}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.1645760536193848, '_timestamp': 1721957044.3815293}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'ratio': 0.5662268400192261, '_timestamp': 1721957044.3821867}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -190.0, '_timestamp': 1721957044.382327}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957044.3825245}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'Episode_Time': 26.459532260894775, '_timestamp': 1721957044.3825836}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957044.3832343}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957044.383393}).
wandb: WARNING (User provided step: 1862 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957044.383546}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'value_loss': 1.5144786729415258, '_timestamp': 1721957075.2246642}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07153359186719171, '_timestamp': 1721957075.2248292}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6600932995478312, '_timestamp': 1721957075.2248952}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2186945676803589, '_timestamp': 1721957075.224987}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0877469778060913, '_timestamp': 1721957075.2252529}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'ratio': 0.4536082148551941, '_timestamp': 1721957075.2253547}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -200.0, '_timestamp': 1721957075.2257135}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957075.225807}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'Episode_Time': 30.8400936126709, '_timestamp': 1721957075.2258646}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.33975346687211094, '_timestamp': 1721957075.2261918}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'train_goal': 0.33012326656394453, '_timestamp': 1721957075.226407}).
wandb: WARNING (User provided step: 1759 is less than current step: 15000. Dropping entry: {'train_WDL': -0.33975346687211094, '_timestamp': 1721957075.2266214}).
Env Football Algo jrpo Exp base_JRPO updates 1759/100000000000.0 steps in 30.84
total episode rewards is -200.0
Env Football Algo jrpo Exp base_JRPO updates 7324/100000000000.0 steps in 89.61
total episode rewards is -80.0
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'value_loss': 0.6058253547797601, '_timestamp': 1721957164.8352587}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'policy_loss': 0.025206512830530603, '_timestamp': 1721957164.8354473}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.331713667710622, '_timestamp': 1721957164.8355172}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21165770292282104, '_timestamp': 1721957164.8356225}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7567095756530762, '_timestamp': 1721957164.8359036}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'ratio': 0.5466797947883606, '_timestamp': 1721957164.8368013}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721957164.8369572}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957164.837062}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.60777926445007, '_timestamp': 1721957164.8371193}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957164.8377607}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957164.8382125}).
wandb: WARNING (User provided step: 7324 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957164.8386402}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'value_loss': 0.8223552260299524, '_timestamp': 1721957203.7745354}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'policy_loss': 0.08798488977559221, '_timestamp': 1721957203.775803}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7368851041793822, '_timestamp': 1721957203.7758777}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21324431896209717, '_timestamp': 1721957203.7763865}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6848291754722595, '_timestamp': 1721957203.7767005}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'ratio': 0.3250509202480316, '_timestamp': 1721957203.7776387}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721957203.777758}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957203.7779725}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'Episode_Time': 38.93006610870361, '_timestamp': 1721957203.7780323}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3562005277044855, '_timestamp': 1721957203.7787566}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'train_goal': 0.32189973614775724, '_timestamp': 1721957203.7790146}).
wandb: WARNING (User provided step: 2973 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3562005277044855, '_timestamp': 1721957203.779271}).
Env Football Algo jrpo Exp base_JRPO updates 2973/100000000000.0 steps in 38.93
total episode rewards is -90.0
Env Football Algo jrpo Exp base_JRPO updates 3087/100000000000.0 steps in 28.87
total episode rewards is -160.0
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'value_loss': 1.2841467808683713, '_timestamp': 1721957232.6552093}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'policy_loss': 0.11301705664237185, '_timestamp': 1721957232.6554096}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5759841028849284, '_timestamp': 1721957232.6554773}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.33386683464050293, '_timestamp': 1721957232.6555746}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0398824214935303, '_timestamp': 1721957232.655869}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'ratio': 0.44370269775390625, '_timestamp': 1721957232.6562002}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721957232.65634}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957232.6564348}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'Episode_Time': 28.874953269958496, '_timestamp': 1721957232.656493}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957232.6568406}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957232.6570067}).
wandb: WARNING (User provided step: 3087 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957232.657163}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'value_loss': 1.4014525958895683, '_timestamp': 1721957283.7325656}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'policy_loss': 0.09926794224884361, '_timestamp': 1721957283.732739}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6055793849627178, '_timestamp': 1721957283.732809}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30080291628837585, '_timestamp': 1721957283.732907}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.143560528755188, '_timestamp': 1721957283.7331808}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'ratio': 0.6694879531860352, '_timestamp': 1721957283.7336185}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -180.0, '_timestamp': 1721957283.7337604}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957283.733854}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'Episode_Time': 51.07457375526428, '_timestamp': 1721957283.7339098}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957283.7342098}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957283.7344422}).
wandb: WARNING (User provided step: 3798 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957283.7346404}).
Env Football Algo jrpo Exp base_JRPO updates 3798/100000000000.0 steps in 51.07
total episode rewards is -180.0
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'value_loss': 0.8413118441899617, '_timestamp': 1721957339.8651805}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015936130962024134, '_timestamp': 1721957339.8653605}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6296543224652609, '_timestamp': 1721957339.8654327}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.41270700097084045, '_timestamp': 1721957339.8655746}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7338529825210571, '_timestamp': 1721957339.866502}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'ratio': 0.7395236492156982, '_timestamp': 1721957339.8666134}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721957339.866754}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957339.867666}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.12933278083801, '_timestamp': 1721957339.8677287}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957339.868294}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957339.8686414}).
wandb: WARNING (User provided step: 4617 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957339.8694546}).
Env Football Algo jrpo Exp base_JRPO updates 4617/100000000000.0 steps in 56.13
total episode rewards is -110.0
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'value_loss': 0.4051980849231283, '_timestamp': 1721957432.1415985}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'policy_loss': 0.08415160162374377, '_timestamp': 1721957432.1418166}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5437237938245139, '_timestamp': 1721957432.1418831}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.35897716879844666, '_timestamp': 1721957432.142008}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25863030552864075, '_timestamp': 1721957432.1425254}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'ratio': 0.7348302602767944, '_timestamp': 1721957432.1426306}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957432.1427596}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957432.1428485}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.27114224433899, '_timestamp': 1721957432.1429045}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957432.1436946}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957432.1442845}).
wandb: WARNING (User provided step: 4751 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957432.1448894}).
Env Football Algo jrpo Exp base_JRPO updates 4751/100000000000.0 steps in 92.27
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 7153/100000000000.0 steps in 85.28
total episode rewards is -40.0
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'value_loss': 0.3426575898875793, '_timestamp': 1721957517.4271638}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'policy_loss': 0.12009850340584914, '_timestamp': 1721957517.427363}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5723386955261232, '_timestamp': 1721957517.4274318}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2386353611946106, '_timestamp': 1721957517.42753}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1864691823720932, '_timestamp': 1721957517.4278052}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'ratio': 0.6449359059333801, '_timestamp': 1721957517.4279172}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957517.4281077}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957517.4287748}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.28125476837158, '_timestamp': 1721957517.4288504}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957517.4295876}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957517.4301748}).
wandb: WARNING (User provided step: 7153 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957517.4307835}).
Env Football Algo jrpo Exp base_JRPO updates 5051/100000000000.0 steps in 88.41
total episode rewards is -40.0
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'value_loss': 0.3240724598802626, '_timestamp': 1721957605.8465536}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'policy_loss': 0.11164845644496381, '_timestamp': 1721957605.8467205}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4709837603569031, '_timestamp': 1721957605.846784}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.34288084506988525, '_timestamp': 1721957605.8468728}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3081839680671692, '_timestamp': 1721957605.847117}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'ratio': 0.5361639857292175, '_timestamp': 1721957605.8473215}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957605.847454}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957605.8475456}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.41463303565979, '_timestamp': 1721957605.8476017}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957605.848291}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957605.8488646}).
wandb: WARNING (User provided step: 5051 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957605.8494523}).
Env Football Algo jrpo Exp base_JRPO updates 6947/100000000000.0 steps in 91.05
total episode rewards is -40.0
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'value_loss': 0.37295243370036285, '_timestamp': 1721957696.9040067}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'policy_loss': 0.08228360590835412, '_timestamp': 1721957696.9053102}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5592036390304564, '_timestamp': 1721957696.9053843}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13703815639019012, '_timestamp': 1721957696.905915}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2162134051322937, '_timestamp': 1721957696.906281}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'ratio': 0.4554237425327301, '_timestamp': 1721957696.906388}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721957696.9065194}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957696.9072964}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.04813265800476, '_timestamp': 1721957696.907358}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957696.9084196}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957696.9089003}).
wandb: WARNING (User provided step: 6947 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957696.9093935}).
Env Football Algo jrpo Exp base_JRPO updates 4763/100000000000.0 steps in 71.12
total episode rewards is -80.0
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'value_loss': 0.613966712616384, '_timestamp': 1721957768.0261059}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'policy_loss': 0.07294337062397972, '_timestamp': 1721957768.0263488}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6023642134666443, '_timestamp': 1721957768.0264497}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13207870721817017, '_timestamp': 1721957768.0265563}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3992316424846649, '_timestamp': 1721957768.0268285}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'ratio': 0.861619770526886, '_timestamp': 1721957768.0273676}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721957768.027513}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957768.027614}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'Episode_Time': 71.1156907081604, '_timestamp': 1721957768.0276716}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957768.028379}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957768.0288885}).
wandb: WARNING (User provided step: 4763 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957768.029405}).
Env Football Algo jrpo Exp base_JRPO updates 4790/100000000000.0 steps in 52.66
total episode rewards is -150.0
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'value_loss': 1.05252312588195, '_timestamp': 1721957820.6980374}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'policy_loss': 0.12906442078839367, '_timestamp': 1721957820.698226}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1993374756971995, '_timestamp': 1721957820.698293}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3844296336174011, '_timestamp': 1721957820.6983824}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7050290107727051, '_timestamp': 1721957820.6986234}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'ratio': 0.20809534192085266, '_timestamp': 1721957820.6987255}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -150.0, '_timestamp': 1721957820.6988547}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957820.6989443}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'Episode_Time': 52.662437438964844, '_timestamp': 1721957820.6991253}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957820.699564}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957820.699768}).
wandb: WARNING (User provided step: 4790 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957820.6999745}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'value_loss': 0.9315607969462871, '_timestamp': 1721957855.354067}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'policy_loss': 0.08630301547547181, '_timestamp': 1721957855.3542762}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2424879813194274, '_timestamp': 1721957855.3543673}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.15071354806423187, '_timestamp': 1721957855.3544815}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.9701679944992065, '_timestamp': 1721957855.3547826}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'ratio': 0.32753968238830566, '_timestamp': 1721957855.3549097}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -130.0, '_timestamp': 1721957855.355347}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957855.3554585}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'Episode_Time': 34.653217792510986, '_timestamp': 1721957855.3555307}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957855.3558328}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957855.356089}).
wandb: WARNING (User provided step: 3417 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957855.3562987}).
Env Football Algo jrpo Exp base_JRPO updates 3417/100000000000.0 steps in 34.65
total episode rewards is -130.0
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'value_loss': 1.1133747294793526, '_timestamp': 1721957888.3469043}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'policy_loss': 0.06537373988467152, '_timestamp': 1721957888.3470688}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1259374980131784, '_timestamp': 1721957888.3471344}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1912415623664856, '_timestamp': 1721957888.3472261}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 1.0951638221740723, '_timestamp': 1721957888.3475256}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'ratio': 0.710791289806366, '_timestamp': 1721957888.347635}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -160.0, '_timestamp': 1721957888.3477683}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957888.3512442}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'Episode_Time': 32.989707469940186, '_timestamp': 1721957888.3514013}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957888.3518293}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957888.3520827}).
wandb: WARNING (User provided step: 2684 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957888.3523207}).
Env Football Algo jrpo Exp base_JRPO updates 2684/100000000000.0 steps in 32.99
total episode rewards is -160.0
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'value_loss': 0.7809719706823428, '_timestamp': 1721957955.12978}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03872467534422564, '_timestamp': 1721957955.1300423}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9454332371552785, '_timestamp': 1721957955.1301105}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2018909901380539, '_timestamp': 1721957955.1302361}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.7745729684829712, '_timestamp': 1721957955.130501}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'ratio': 0.6009505987167358, '_timestamp': 1721957955.130712}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -110.0, '_timestamp': 1721957955.1308448}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721957955.130937}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'Episode_Time': 66.77625441551208, '_timestamp': 1721957955.1309967}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721957955.1316624}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721957955.1321895}).
wandb: WARNING (User provided step: 4116 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721957955.1326182}).
Env Football Algo jrpo Exp base_JRPO updates 4116/100000000000.0 steps in 66.78
total episode rewards is -110.0
Env Football Algo jrpo Exp base_JRPO updates 8357/100000000000.0 steps in 82.78
total episode rewards is -30.0
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'value_loss': 0.2550668774793545, '_timestamp': 1721958037.9099638}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02596895065003385, '_timestamp': 1721958037.910141}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0992766372362772, '_timestamp': 1721958037.9102113}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.9041224122047424, '_timestamp': 1721958037.9103107}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2707052528858185, '_timestamp': 1721958037.9106512}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'ratio': 0.6492293477058411, '_timestamp': 1721958037.9107575}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958037.9115229}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958037.911622}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.7762930393219, '_timestamp': 1721958037.9116817}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958037.912234}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958037.9126656}).
wandb: WARNING (User provided step: 8357 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958037.913116}).
Env Football Algo jrpo Exp base_JRPO updates 8625/100000000000.0 steps in 92.63
total episode rewards is -40.0
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'value_loss': 0.33693184996644654, '_timestamp': 1721958130.5406783}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'policy_loss': 0.001960625892970711, '_timestamp': 1721958130.5408535}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1612998151779175, '_timestamp': 1721958130.540931}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5892860293388367, '_timestamp': 1721958130.541027}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2751557528972626, '_timestamp': 1721958130.541294}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'ratio': 0.8298517465591431, '_timestamp': 1721958130.5414007}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958130.5419216}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958130.542019}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.62670969963074, '_timestamp': 1721958130.542076}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958130.542662}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958130.5430675}).
wandb: WARNING (User provided step: 8625 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958130.5434926}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'value_loss': 0.32515739751358824, '_timestamp': 1721958221.2718694}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0026667475079496703, '_timestamp': 1721958221.2721536}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9189866109689077, '_timestamp': 1721958221.272227}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5960110425949097, '_timestamp': 1721958221.2723694}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3190348148345947, '_timestamp': 1721958221.2726667}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'ratio': 0.8861942887306213, '_timestamp': 1721958221.2727733}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958221.2733824}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958221.2734823}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.72672772407532, '_timestamp': 1721958221.273542}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958221.2742095}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958221.2745717}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958221.274946}).
Env Football Algo jrpo Exp base_JRPO updates 9456/100000000000.0 steps in 90.73
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 14199/100000000000.0 steps in 90.84
total episode rewards is -10.0
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'value_loss': 0.07254694327091177, '_timestamp': 1721958312.120037}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'policy_loss': 0.000709114314619607, '_timestamp': 1721958312.1202295}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7433605138460795, '_timestamp': 1721958312.1202993}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2279292345046997, '_timestamp': 1721958312.120401}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14845243096351624, '_timestamp': 1721958312.120871}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'ratio': 0.7717194557189941, '_timestamp': 1721958312.1209834}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721958312.1211264}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958312.121227}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.84381151199341, '_timestamp': 1721958312.1218128}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958312.122056}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958312.122189}).
wandb: WARNING (User provided step: 14199 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958312.1223152}).
Env Football Algo jrpo Exp base_JRPO updates 6670/100000000000.0 steps in 77.85
total episode rewards is -50.0
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'value_loss': 0.42479702666401864, '_timestamp': 1721958389.972292}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015081061523330087, '_timestamp': 1721958389.9724736}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.5758841160933177, '_timestamp': 1721958389.9725492}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3367711305618286, '_timestamp': 1721958389.972647}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4562014937400818, '_timestamp': 1721958389.972905}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'ratio': 0.9021984934806824, '_timestamp': 1721958389.9730122}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721958389.973432}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958389.9735286}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.84917044639587, '_timestamp': 1721958389.9735863}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958389.9742408}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958389.9746585}).
wandb: WARNING (User provided step: 6670 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958389.975088}).
Env Football Algo jrpo Exp base_JRPO updates 10888/100000000000.0 steps in 89.97
total episode rewards is -30.0
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'value_loss': 0.22738065080096323, '_timestamp': 1721958479.945585}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014426008179822626, '_timestamp': 1721958479.945796}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8022385307153066, '_timestamp': 1721958479.9458659}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39822056889533997, '_timestamp': 1721958479.9459786}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3820505738258362, '_timestamp': 1721958479.946246}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'ratio': 0.6938329935073853, '_timestamp': 1721958479.9463491}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958479.9464793}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958479.947152}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.9695508480072, '_timestamp': 1721958479.9472136}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958479.9477458}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958479.948086}).
wandb: WARNING (User provided step: 10888 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958479.948394}).
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 88.72
total episode rewards is 0.0
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'value_loss': 0.21988058551835518, '_timestamp': 1721958653.372421}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'policy_loss': 0.003701393367276372, '_timestamp': 1721958653.3725872}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9424048527081808, '_timestamp': 1721958653.3726535}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28213149309158325, '_timestamp': 1721958653.372749}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17537517845630646, '_timestamp': 1721958653.3730142}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'ratio': 0.7180969715118408, '_timestamp': 1721958653.3731165}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958653.3732486}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958653.3733406}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.70269846916199, '_timestamp': 1721958653.3733976}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958653.3740268}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958653.3743598}).
wandb: WARNING (User provided step: 10408 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958653.3746846}).
Env Football Algo jrpo Exp base_JRPO updates 10408/100000000000.0 steps in 84.70
total episode rewards is -30.0
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'value_loss': 0.2931325293549647, '_timestamp': 1721958744.6219878}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'policy_loss': -0.007030672931189959, '_timestamp': 1721958744.6221504}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9936722973982494, '_timestamp': 1721958744.6222165}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.23931171000003815, '_timestamp': 1721958744.6223066}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1923859566450119, '_timestamp': 1721958744.622554}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'ratio': 0.7957390546798706, '_timestamp': 1721958744.622664}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721958744.6227973}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958744.6228902}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.24602937698364, '_timestamp': 1721958744.6229494}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958744.6234581}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958744.6238682}).
wandb: WARNING (User provided step: 8345 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958744.6243126}).
Env Football Algo jrpo Exp base_JRPO updates 8345/100000000000.0 steps in 91.25
total episode rewards is -40.0
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'value_loss': 0.06810163340026823, '_timestamp': 1721958830.2855308}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'policy_loss': -0.007946760590615061, '_timestamp': 1721958830.2857077}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9583868948618571, '_timestamp': 1721958830.2857757}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2062814086675644, '_timestamp': 1721958830.2858694}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15687929093837738, '_timestamp': 1721958830.28614}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'ratio': 0.6150221228599548, '_timestamp': 1721958830.2862487}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721958830.2863832}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958830.2864752}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.66040849685669, '_timestamp': 1721958830.2865329}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958830.2868156}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958830.2869987}).
wandb: WARNING (User provided step: 13006 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958830.2871802}).
Env Football Algo jrpo Exp base_JRPO updates 13006/100000000000.0 steps in 85.66
total episode rewards is -10.0
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'value_loss': 0.22566061414778232, '_timestamp': 1721958913.53303}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011833242614908765, '_timestamp': 1721958913.5332253}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0526759831110637, '_timestamp': 1721958913.5332973}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2575931251049042, '_timestamp': 1721958913.5334044}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3073018193244934, '_timestamp': 1721958913.5336847}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'ratio': 0.8429213762283325, '_timestamp': 1721958913.533797}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721958913.5339339}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721958913.5340378}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.24494791030884, '_timestamp': 1721958913.5341005}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721958913.5346808}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721958913.5350995}).
wandb: WARNING (User provided step: 8544 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721958913.5355232}).
Env Football Algo jrpo Exp base_JRPO updates 8544/100000000000.0 steps in 83.24
total episode rewards is -30.0
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'value_loss': 0.2779156975712006, '_timestamp': 1721959003.9193323}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'policy_loss': -0.010718180576319961, '_timestamp': 1721959003.9194965}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0711144781112671, '_timestamp': 1721959003.9195623}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16589488089084625, '_timestamp': 1721959003.91965}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18273155391216278, '_timestamp': 1721959003.9199054}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'ratio': 0.8307374119758606, '_timestamp': 1721959003.920024}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959003.920156}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959003.9202487}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.38297843933105, '_timestamp': 1721959003.9203072}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959003.9208953}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959003.921382}).
wandb: WARNING (User provided step: 6865 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959003.9218786}).
Env Football Algo jrpo Exp base_JRPO updates 6865/100000000000.0 steps in 90.38
total episode rewards is -40.0
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'value_loss': 0.2798286974344713, '_timestamp': 1721959090.3706398}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006046308560374503, '_timestamp': 1721959090.3708305}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.053975830078125, '_timestamp': 1721959090.3708992}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1123916283249855, '_timestamp': 1721959090.3710349}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.27535971999168396, '_timestamp': 1721959090.3713028}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'ratio': 0.688088059425354, '_timestamp': 1721959090.3714118}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959090.3715582}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959090.371657}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.4477801322937, '_timestamp': 1721959090.3717163}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959090.372247}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959090.372612}).
wandb: WARNING (User provided step: 11770 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959090.3729663}).
Env Football Algo jrpo Exp base_JRPO updates 11770/100000000000.0 steps in 86.45
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 10336/100000000000.0 steps in 86.55
total episode rewards is -30.0
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'value_loss': 0.21215771871541317, '_timestamp': 1721959176.928354}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009739853028246823, '_timestamp': 1721959176.9296334}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0606377092997232, '_timestamp': 1721959176.9297051}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1611436903476715, '_timestamp': 1721959176.930184}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2223973423242569, '_timestamp': 1721959176.9305341}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'ratio': 0.7203273773193359, '_timestamp': 1721959176.9306407}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721959176.9307725}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959176.930978}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.549471616745, '_timestamp': 1721959176.9310381}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959176.931864}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959176.9322166}).
wandb: WARNING (User provided step: 10336 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959176.9325578}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'value_loss': 0.14351691640214995, '_timestamp': 1721959266.5022395}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'policy_loss': -0.003654229248835084, '_timestamp': 1721959266.5025625}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0538978068033855, '_timestamp': 1721959266.5026329}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2111898809671402, '_timestamp': 1721959266.5027342}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14554299414157867, '_timestamp': 1721959266.5029929}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'ratio': 0.6408767104148865, '_timestamp': 1721959266.5030954}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721959266.5033808}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959266.5034757}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.56559991836548, '_timestamp': 1721959266.5035317}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959266.5060272}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959266.5063279}).
wandb: WARNING (User provided step: 11634 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959266.5066187}).
Env Football Algo jrpo Exp base_JRPO updates 11634/100000000000.0 steps in 89.57
total episode rewards is -20.0
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'value_loss': 0.13718255323416087, '_timestamp': 1721959355.9823031}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00497379796889921, '_timestamp': 1721959355.9825203}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1061948561668395, '_timestamp': 1721959355.9825904}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12146265804767609, '_timestamp': 1721959355.9826863}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.27187973260879517, '_timestamp': 1721959355.982963}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'ratio': 0.703467845916748, '_timestamp': 1721959355.9830692}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721959355.9833133}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959355.9834232}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.47463750839233, '_timestamp': 1721959355.983485}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959355.988473}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959355.9887512}).
wandb: WARNING (User provided step: 12927 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959355.9890532}).
Env Football Algo jrpo Exp base_JRPO updates 12927/100000000000.0 steps in 89.47
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 9568/100000000000.0 steps in 81.91
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'value_loss': 0.2718096855849338, '_timestamp': 1721959437.9046187}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'policy_loss': -0.01334199236870821, '_timestamp': 1721959437.9047947}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1013743917147318, '_timestamp': 1721959437.904862}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13451704382896423, '_timestamp': 1721959437.9049575}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2403310388326645, '_timestamp': 1721959437.9052296}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'ratio': 0.6631975173950195, '_timestamp': 1721959437.9053314}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959437.905468}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959437.9055603}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.9146375656128, '_timestamp': 1721959437.905616}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959437.906081}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959437.9064395}).
wandb: WARNING (User provided step: 9568 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959437.9068086}).
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 10382/100000000000.0 steps in 89.92
total episode rewards is -30.0
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'value_loss': 0.22303432679812735, '_timestamp': 1721959527.828032}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009144888478137242, '_timestamp': 1721959527.8282328}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.154825587272644, '_timestamp': 1721959527.8283007}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30158355832099915, '_timestamp': 1721959527.828392}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4184190034866333, '_timestamp': 1721959527.82865}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'ratio': 0.7638800144195557, '_timestamp': 1721959527.8287563}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721959527.8288853}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959527.829016}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.92035269737244, '_timestamp': 1721959527.8290741}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959527.8298056}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959527.830127}).
wandb: WARNING (User provided step: 10382 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959527.8304453}).
Env Football Algo jrpo Exp base_JRPO updates 4752/100000000000.0 steps in 67.23
total episode rewards is -70.0
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'value_loss': 0.47985579929624994, '_timestamp': 1721959595.063891}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'policy_loss': -0.017438193869311364, '_timestamp': 1721959595.0642207}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2060326806704202, '_timestamp': 1721959595.064295}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40382540225982666, '_timestamp': 1721959595.0644512}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4786466956138611, '_timestamp': 1721959595.0647366}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'ratio': 0.88736891746521, '_timestamp': 1721959595.0648384}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721959595.0649714}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959595.0650702}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'Episode_Time': 67.23232412338257, '_timestamp': 1721959595.0651271}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959595.065716}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959595.0661662}).
wandb: WARNING (User provided step: 4752 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959595.0667129}).
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 85.95
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 8999/100000000000.0 steps in 90.69
total episode rewards is -40.0
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'value_loss': 0.27386104862050464, '_timestamp': 1721959771.719774}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01535577532214423, '_timestamp': 1721959771.7201045}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1566163730621337, '_timestamp': 1721959771.7201812}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2707987129688263, '_timestamp': 1721959771.7203155}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21773244440555573, '_timestamp': 1721959771.7205882}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'ratio': 0.7244056463241577, '_timestamp': 1721959771.720692}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959771.7209506}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959771.72105}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.69020414352417, '_timestamp': 1721959771.7211084}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959771.7223134}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959771.7230196}).
wandb: WARNING (User provided step: 8999 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959771.7234297}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'value_loss': 0.353394735896339, '_timestamp': 1721959850.6249232}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01499504012754187, '_timestamp': 1721959850.625144}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1583469343185424, '_timestamp': 1721959850.6252115}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16491498053073883, '_timestamp': 1721959850.6253648}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.45628851652145386, '_timestamp': 1721959850.6256514}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'ratio': 0.73036128282547, '_timestamp': 1721959850.6257598}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721959850.625899}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959850.6260097}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.90021300315857, '_timestamp': 1721959850.6260726}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959850.6266265}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959850.6269727}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959850.6273582}).
Env Football Algo jrpo Exp base_JRPO updates 9456/100000000000.0 steps in 78.90
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 8230/100000000000.0 steps in 90.56
total episode rewards is -40.0
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'value_loss': 0.2933174082854142, '_timestamp': 1721959941.1940389}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004581451757209531, '_timestamp': 1721959941.1943905}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1507203388214111, '_timestamp': 1721959941.1944659}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17502461373806, '_timestamp': 1721959941.1945565}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4442877173423767, '_timestamp': 1721959941.1948338}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'ratio': 0.8126387000083923, '_timestamp': 1721959941.1949382}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721959941.1950817}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721959941.1951764}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.56462025642395, '_timestamp': 1721959941.1952348}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721959941.195909}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721959941.1963391}).
wandb: WARNING (User provided step: 8230 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721959941.1967733}).
Env Football Algo jrpo Exp base_JRPO updates 7655/100000000000.0 steps in 87.49
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'value_loss': 0.2141988612463077, '_timestamp': 1721960028.6846328}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00537138261347233, '_timestamp': 1721960028.6847992}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1508245984713237, '_timestamp': 1721960028.6848667}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2583892345428467, '_timestamp': 1721960028.684958}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2379896342754364, '_timestamp': 1721960028.685219}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'ratio': 0.8400243520736694, '_timestamp': 1721960028.6853235}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960028.6854522}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960028.6855452}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.4867992401123, '_timestamp': 1721960028.6856055}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960028.6861615}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960028.6866107}).
wandb: WARNING (User provided step: 7655 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960028.687071}).
total episode rewards is -30.0
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'value_loss': 0.37112945432464284, '_timestamp': 1721960105.315716}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0037948996274887272, '_timestamp': 1721960105.3158822}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1276598485310871, '_timestamp': 1721960105.3159652}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2882639765739441, '_timestamp': 1721960105.3160553}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26262572407722473, '_timestamp': 1721960105.3162956}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'ratio': 0.7572404742240906, '_timestamp': 1721960105.3163953}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721960105.3165247}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960105.3166144}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'Episode_Time': 76.62769722938538, '_timestamp': 1721960105.3166697}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960105.317249}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960105.3177247}).
wandb: WARNING (User provided step: 6702 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960105.3182223}).
Env Football Algo jrpo Exp base_JRPO updates 6702/100000000000.0 steps in 76.63
total episode rewards is -50.0
Env Football Algo jrpo Exp base_JRPO updates 14226/100000000000.0 steps in 87.51
total episode rewards is -30.0
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'value_loss': 0.21307439221534877, '_timestamp': 1721960192.8253827}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03211359693901614, '_timestamp': 1721960192.8255525}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0449161342779796, '_timestamp': 1721960192.82562}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3741356134414673, '_timestamp': 1721960192.8257163}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20533666014671326, '_timestamp': 1721960192.825982}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'ratio': 0.6560773253440857, '_timestamp': 1721960192.8260903}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960192.8262246}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960192.8263166}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.50635528564453, '_timestamp': 1721960192.8263779}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960192.8265896}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960192.8267162}).
wandb: WARNING (User provided step: 14226 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960192.826838}).
Env Football Algo jrpo Exp base_JRPO updates 10337/100000000000.0 steps in 87.28
total episode rewards is -40.0
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'value_loss': 0.28482297019353914, '_timestamp': 1721960280.1113226}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013221780639141797, '_timestamp': 1721960280.1114814}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.161457397143046, '_timestamp': 1721960280.1115463}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11546660214662552, '_timestamp': 1721960280.1116364}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17235104739665985, '_timestamp': 1721960280.1118908}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'ratio': 0.7159995436668396, '_timestamp': 1721960280.1120114}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960280.1121492}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960280.1122398}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.28362345695496, '_timestamp': 1721960280.1122973}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960280.1127112}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960280.1131048}).
wandb: WARNING (User provided step: 10337 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960280.1134276}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'value_loss': 0.15482248112151864, '_timestamp': 1721960357.358096}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0026864050338432813, '_timestamp': 1721960357.3582554}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1720159753163655, '_timestamp': 1721960357.3583236}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1755920648574829, '_timestamp': 1721960357.3584123}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.07876273989677429, '_timestamp': 1721960357.3586614}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'ratio': 1.129210114479065, '_timestamp': 1721960357.3587673}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721960357.358899}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960357.3589911}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.24377822875977, '_timestamp': 1721960357.3590508}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960357.3594527}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960357.3597658}).
wandb: WARNING (User provided step: 10589 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960357.3600934}).
Env Football Algo jrpo Exp base_JRPO updates 10589/100000000000.0 steps in 77.24
total episode rewards is -20.0
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'value_loss': 0.2970890862067851, '_timestamp': 1721960447.149465}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'policy_loss': 0.001016884135606233, '_timestamp': 1721960447.1496546}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1715900826454162, '_timestamp': 1721960447.1497266}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2129484862089157, '_timestamp': 1721960447.1498268}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3255951702594757, '_timestamp': 1721960447.1500862}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'ratio': 0.8396469354629517, '_timestamp': 1721960447.150203}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721960447.1503322}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960447.1504269}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.78825759887695, '_timestamp': 1721960447.1504822}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960447.1511195}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960447.1516023}).
wandb: WARNING (User provided step: 6964 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960447.1521416}).
Env Football Algo jrpo Exp base_JRPO updates 6964/100000000000.0 steps in 89.79
total episode rewards is -40.0
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'value_loss': 0.49847081729754183, '_timestamp': 1721960499.349954}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005293121043941937, '_timestamp': 1721960499.350956}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.163482011159261, '_timestamp': 1721960499.351029}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.367075651884079, '_timestamp': 1721960499.3514452}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5633360147476196, '_timestamp': 1721960499.3517995}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'ratio': 0.867982804775238, '_timestamp': 1721960499.351907}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721960499.3520808}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960499.3522632}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'Episode_Time': 52.193167209625244, '_timestamp': 1721960499.3523223}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960499.3530877}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960499.3534176}).
wandb: WARNING (User provided step: 4416 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960499.3537245}).
Env Football Algo jrpo Exp base_JRPO updates 4416/100000000000.0 steps in 52.19
total episode rewards is -70.0
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'value_loss': 0.21074195044774874, '_timestamp': 1721960588.985801}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03084716768547272, '_timestamp': 1721960588.9859698}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2101478322347006, '_timestamp': 1721960588.9860413}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1678171306848526, '_timestamp': 1721960588.9861355}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.11832371354103088, '_timestamp': 1721960588.9864035}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'ratio': 0.881367027759552, '_timestamp': 1721960588.986517}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960588.986647}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960588.9867415}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.63128161430359, '_timestamp': 1721960588.9868007}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960588.9870706}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960588.9872465}).
wandb: WARNING (User provided step: 13233 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960588.9874215}).
Env Football Algo jrpo Exp base_JRPO updates 13233/100000000000.0 steps in 89.63
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 11535/100000000000.0 steps in 84.00
total episode rewards is -30.0
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'value_loss': 0.21937230592263707, '_timestamp': 1721960672.9886172}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'policy_loss': 0.026769046544407805, '_timestamp': 1721960672.9888005}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.260132966041565, '_timestamp': 1721960672.9888687}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21865369379520416, '_timestamp': 1721960672.988967}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22727903723716736, '_timestamp': 1721960672.9892285}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'ratio': 0.708214282989502, '_timestamp': 1721960672.9893334}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960672.9894738}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960672.989609}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.00007128715515, '_timestamp': 1721960672.989668}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960672.9902806}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960672.990552}).
wandb: WARNING (User provided step: 11535 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960672.990816}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'value_loss': 0.4558008851855993, '_timestamp': 1721960745.2434375}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03472533447978397, '_timestamp': 1721960745.2436097}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2200456015268961, '_timestamp': 1721960745.2436788}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24435564875602722, '_timestamp': 1721960745.2437708}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4533858895301819, '_timestamp': 1721960745.2440598}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'ratio': 0.7885750532150269, '_timestamp': 1721960745.2441664}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721960745.2443092}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960745.2443995}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.25173664093018, '_timestamp': 1721960745.2444575}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960745.244917}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960745.2452025}).
wandb: WARNING (User provided step: 8376 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960745.2454925}).
Env Football Algo jrpo Exp base_JRPO updates 8376/100000000000.0 steps in 72.25
total episode rewards is -60.0
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'value_loss': 0.21758992399127844, '_timestamp': 1721960835.7621548}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013279691316808263, '_timestamp': 1721960835.7623281}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2191097259521484, '_timestamp': 1721960835.7623956}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14437629282474518, '_timestamp': 1721960835.762488}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22873136401176453, '_timestamp': 1721960835.7627478}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'ratio': 0.8862560987472534, '_timestamp': 1721960835.7628531}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960835.7629786}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960835.763071}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.51575756072998, '_timestamp': 1721960835.763127}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960835.7636452}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960835.7640784}).
wandb: WARNING (User provided step: 8541 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960835.764497}).
Env Football Algo jrpo Exp base_JRPO updates 8541/100000000000.0 steps in 90.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'value_loss': 0.21955109924446636, '_timestamp': 1721960923.880224}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00910794593093063, '_timestamp': 1721960923.8804507}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1590649048487345, '_timestamp': 1721960923.8805215}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12211847305297852, '_timestamp': 1721960923.880659}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2541370987892151, '_timestamp': 1721960923.8809052}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'ratio': 0.9401389956474304, '_timestamp': 1721960923.8810108}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721960923.881144}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721960923.8812404}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.11461091041565, '_timestamp': 1721960923.8812969}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721960923.8817801}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721960923.8821194}).
wandb: WARNING (User provided step: 9933 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721960923.8824759}).
Env Football Algo jrpo Exp base_JRPO updates 9933/100000000000.0 steps in 88.11
total episode rewards is -30.0
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'value_loss': 0.22659267261992985, '_timestamp': 1721961007.2392006}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013290904220193625, '_timestamp': 1721961007.2404857}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0349138430754343, '_timestamp': 1721961007.2405572}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14143164455890656, '_timestamp': 1721961007.2410321}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18563002347946167, '_timestamp': 1721961007.2413878}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'ratio': 0.9402597546577454, '_timestamp': 1721961007.2414908}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721961007.2416236}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961007.2418184}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.35065174102783, '_timestamp': 1721961007.2418754}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961007.24284}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961007.2433286}).
wandb: WARNING (User provided step: 7883 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961007.2437835}).
Env Football Algo jrpo Exp base_JRPO updates 7883/100000000000.0 steps in 83.35
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 90.27
total episode rewards is 0.0
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'value_loss': 0.14199902153261065, '_timestamp': 1721961185.0135803}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011950511708079526, '_timestamp': 1721961185.0137918}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0790306754906973, '_timestamp': 1721961185.0138636}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10674475878477097, '_timestamp': 1721961185.0139933}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23451220989227295, '_timestamp': 1721961185.0142493}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'ratio': 0.8932943940162659, '_timestamp': 1721961185.0143552}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961185.0144856}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961185.014581}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.49350833892822, '_timestamp': 1721961185.0146391}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961185.0150957}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961185.0154243}).
wandb: WARNING (User provided step: 10012 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961185.0157633}).
Env Football Algo jrpo Exp base_JRPO updates 10012/100000000000.0 steps in 87.49
total episode rewards is -20.0
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'value_loss': 0.24430395741384323, '_timestamp': 1721961268.917679}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00947513554400454, '_timestamp': 1721961268.918927}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0366914578278859, '_timestamp': 1721961268.9190023}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.275126188993454, '_timestamp': 1721961268.9194753}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.404023140668869, '_timestamp': 1721961268.919825}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'ratio': 0.9230890274047852, '_timestamp': 1721961268.9199355}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721961268.920109}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961268.92032}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.89624238014221, '_timestamp': 1721961268.920382}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.23932185569720069, '_timestamp': 1721961268.9214356}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'train_goal': 0.38033907215139967, '_timestamp': 1721961268.9219198}).
wandb: WARNING (User provided step: 7391 is less than current step: 15000. Dropping entry: {'train_WDL': -0.23932185569720069, '_timestamp': 1721961268.9224048}).
Env Football Algo jrpo Exp base_JRPO updates 7391/100000000000.0 steps in 83.90
total episode rewards is -10.0
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'value_loss': 0.14299356777856398, '_timestamp': 1721961358.2523594}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'policy_loss': -0.012553377424289162, '_timestamp': 1721961358.2525427}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2702121257781982, '_timestamp': 1721961358.252613}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10448481142520905, '_timestamp': 1721961358.2527127}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3752819895744324, '_timestamp': 1721961358.2529778}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'ratio': 0.616963803768158, '_timestamp': 1721961358.2530894}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961358.2532246}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961358.2533176}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.32898831367493, '_timestamp': 1721961358.2533758}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961358.2537634}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961358.2540348}).
wandb: WARNING (User provided step: 11252 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961358.254314}).
Env Football Algo jrpo Exp base_JRPO updates 11252/100000000000.0 steps in 89.33
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 12336/100000000000.0 steps in 89.32
total episode rewards is -10.0
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'value_loss': 0.07940096516239767, '_timestamp': 1721961447.5761445}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015134828221052886, '_timestamp': 1721961447.5775328}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2544774651527404, '_timestamp': 1721961447.5776079}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.20276181399822235, '_timestamp': 1721961447.578158}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29953545331954956, '_timestamp': 1721961447.5821295}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'ratio': 0.4693882465362549, '_timestamp': 1721961447.5822754}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721961447.5824742}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961447.582759}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.31525087356567, '_timestamp': 1721961447.582822}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961447.5838196}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961447.5840626}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961447.584402}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'value_loss': 0.14224991488736122, '_timestamp': 1721961535.1234484}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'policy_loss': -0.018868620798069363, '_timestamp': 1721961535.1236444}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9155197616418203, '_timestamp': 1721961535.1237128}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2289520502090454, '_timestamp': 1721961535.123816}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2756589353084564, '_timestamp': 1721961535.1241298}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'ratio': 0.2559507489204407, '_timestamp': 1721961535.124237}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721961535.1243699}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961535.124462}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.53806900978088, '_timestamp': 1721961535.1245193}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961535.1251354}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961535.1254117}).
wandb: WARNING (User provided step: 11515 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961535.1257818}).
Env Football Algo jrpo Exp base_JRPO updates 11515/100000000000.0 steps in 87.54
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 12403/100000000000.0 steps in 90.43
total episode rewards is -10.0
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'value_loss': 0.07239444602901737, '_timestamp': 1721961625.5590243}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009400891853147186, '_timestamp': 1721961625.5591927}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.41674896160761515, '_timestamp': 1721961625.5592604}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.34893763065338135, '_timestamp': 1721961625.5593495}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.08890465646982193, '_timestamp': 1721961625.5596108}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'ratio': 0.20037394762039185, '_timestamp': 1721961625.559716}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721961625.5598543}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961625.5599632}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.43247556686401, '_timestamp': 1721961625.5600245}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961625.5604312}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961625.560675}).
wandb: WARNING (User provided step: 12403 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961625.560926}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'value_loss': 0.3016618987731636, '_timestamp': 1721961709.2385166}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'policy_loss': 0.06257425985347558, '_timestamp': 1721961709.2386947}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8371010847886403, '_timestamp': 1721961709.2387607}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2010071575641632, '_timestamp': 1721961709.2388546}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.317110151052475, '_timestamp': 1721961709.2391279}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'ratio': 0.6102422475814819, '_timestamp': 1721961709.239234}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721961709.2393699}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961709.2394624}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.67659187316895, '_timestamp': 1721961709.2395217}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961709.2400599}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961709.24047}).
wandb: WARNING (User provided step: 8540 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961709.2408907}).
Env Football Algo jrpo Exp base_JRPO updates 8540/100000000000.0 steps in 83.68
total episode rewards is -40.0
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'value_loss': 0.44931259951864677, '_timestamp': 1721961792.6855345}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'policy_loss': 0.030846902418876804, '_timestamp': 1721961792.6857119}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.7709180223941803, '_timestamp': 1721961792.6857915}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10174728184938431, '_timestamp': 1721961792.6858912}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5158134698867798, '_timestamp': 1721961792.6861866}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'ratio': 0.6125788688659668, '_timestamp': 1721961792.6863055}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721961792.686448}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961792.6865516}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.44355535507202, '_timestamp': 1721961792.6866183}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961792.6871588}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961792.6876018}).
wandb: WARNING (User provided step: 7666 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961792.6880772}).
Env Football Algo jrpo Exp base_JRPO updates 7666/100000000000.0 steps in 83.44
total episode rewards is -60.0
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'value_loss': 0.5909535662084818, '_timestamp': 1721961876.709885}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009905737240915187, '_timestamp': 1721961876.7100568}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.41830189565817516, '_timestamp': 1721961876.7101247}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13960769772529602, '_timestamp': 1721961876.7102206}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5727030038833618, '_timestamp': 1721961876.7104628}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'ratio': 0.8695529103279114, '_timestamp': 1721961876.7106037}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -80.0, '_timestamp': 1721961876.7107348}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961876.710827}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.020987033844, '_timestamp': 1721961876.7108853}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961876.7115178}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961876.7120073}).
wandb: WARNING (User provided step: 6088 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961876.7124887}).
Env Football Algo jrpo Exp base_JRPO updates 6088/100000000000.0 steps in 84.02
total episode rewards is -80.0
Env Football Algo jrpo Exp base_JRPO updates 8749/100000000000.0 steps in 81.86
total episode rewards is -30.0
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'value_loss': 0.26635455422103405, '_timestamp': 1721961958.5772655}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'policy_loss': 0.015645515427847083, '_timestamp': 1721961958.577439}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.051796221335729, '_timestamp': 1721961958.5775044}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32071730494499207, '_timestamp': 1721961958.577598}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3592877686023712, '_timestamp': 1721961958.5778759}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'ratio': 0.6782692074775696, '_timestamp': 1721961958.577977}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721961958.5781076}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721961958.5781984}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.86365389823914, '_timestamp': 1721961958.5782537}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721961958.5787847}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721961958.579187}).
wandb: WARNING (User provided step: 8749 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721961958.5796022}).
Env Football Algo jrpo Exp base_JRPO updates 10304/100000000000.0 steps in 91.13
total episode rewards is -20.0
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'value_loss': 0.32331860239307086, '_timestamp': 1721962049.7164617}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'policy_loss': 0.09128975608075658, '_timestamp': 1721962049.7166307}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0633123421669006, '_timestamp': 1721962049.7166996}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10881131887435913, '_timestamp': 1721962049.7167957}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2866396903991699, '_timestamp': 1721962049.7170706}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'ratio': 0.15471144020557404, '_timestamp': 1721962049.7171733}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721962049.7173078}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962049.7174008}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.13178300857544, '_timestamp': 1721962049.7174573}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.21805792163543442, '_timestamp': 1721962049.7179022}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'train_goal': 0.3909710391822828, '_timestamp': 1721962049.7184277}).
wandb: WARNING (User provided step: 10304 is less than current step: 15000. Dropping entry: {'train_WDL': -0.21805792163543442, '_timestamp': 1721962049.7189798}).
Env Football Algo jrpo Exp base_JRPO updates 11410/100000000000.0 steps in 88.98
total episode rewards is -30.0
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'value_loss': 0.23241541864971318, '_timestamp': 1721962138.6972897}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'policy_loss': 0.06624165078392252, '_timestamp': 1721962138.6975088}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.561624432404836, '_timestamp': 1721962138.6975782}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3091874420642853, '_timestamp': 1721962138.6976948}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2152225524187088, '_timestamp': 1721962138.6979601}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'ratio': 0.1759478896856308, '_timestamp': 1721962138.698069}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721962138.698222}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962138.6983418}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.97658681869507, '_timestamp': 1721962138.6984131}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962138.699127}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962138.6994755}).
wandb: WARNING (User provided step: 11410 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962138.6997592}).
Env Football Algo jrpo Exp base_JRPO updates 10626/100000000000.0 steps in 84.32
total episode rewards is -40.0
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'value_loss': 0.3054715697964033, '_timestamp': 1721962223.0199902}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03540478035070312, '_timestamp': 1721962223.020384}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3228148198127747, '_timestamp': 1721962223.0204544}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14114095270633698, '_timestamp': 1721962223.0206387}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23342280089855194, '_timestamp': 1721962223.0209234}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'ratio': 0.22781172394752502, '_timestamp': 1721962223.0210307}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962223.0211596}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962223.0212855}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.31852674484253, '_timestamp': 1721962223.0213523}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962223.0218573}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962223.022159}).
wandb: WARNING (User provided step: 10626 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962223.022465}).
Env Football Algo jrpo Exp base_JRPO updates 5411/100000000000.0 steps in 90.36
total episode rewards is -40.0
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'value_loss': 0.3339484004676342, '_timestamp': 1721962313.3857777}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'policy_loss': -0.002122137317395148, '_timestamp': 1721962313.3859696}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8071169726053874, '_timestamp': 1721962313.3860452}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09101197123527527, '_timestamp': 1721962313.3861496}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17804521322250366, '_timestamp': 1721962313.3863742}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'ratio': 0.5786876082420349, '_timestamp': 1721962313.3864772}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962313.386604}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962313.3866997}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.36247396469116, '_timestamp': 1721962313.3867562}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962313.3874552}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962313.388154}).
wandb: WARNING (User provided step: 5411 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962313.3887541}).
Env Football Algo jrpo Exp base_JRPO updates 9476/100000000000.0 steps in 86.32
total episode rewards is -10.0
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'value_loss': 0.2489649189139406, '_timestamp': 1721962399.7179866}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03361423840513453, '_timestamp': 1721962399.7192996}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2634382017453512, '_timestamp': 1721962399.7193766}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09461281448602676, '_timestamp': 1721962399.7198775}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2656400203704834, '_timestamp': 1721962399.7202232}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'ratio': 0.3644244074821472, '_timestamp': 1721962399.7203367}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721962399.7204642}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962399.7206607}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.32337784767151, '_timestamp': 1721962399.7207196}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.005068790731354091, '_timestamp': 1721962399.7216613}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'train_goal': 0.49746560463432293, '_timestamp': 1721962399.7220533}).
wandb: WARNING (User provided step: 9476 is less than current step: 15000. Dropping entry: {'train_WDL': -0.005068790731354091, '_timestamp': 1721962399.7224228}).
Env Football Algo jrpo Exp base_JRPO updates 9064/100000000000.0 steps in 83.47
total episode rewards is 0.0
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'value_loss': 0.297466151881963, '_timestamp': 1721962483.1916692}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04330549569878106, '_timestamp': 1721962483.1918545}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2276025056838988, '_timestamp': 1721962483.191927}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.08210854232311249, '_timestamp': 1721962483.1920545}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3328922390937805, '_timestamp': 1721962483.1923463}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'ratio': 0.32227030396461487, '_timestamp': 1721962483.1924524}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721962483.1925945}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962483.1926966}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.46836733818054, '_timestamp': 1721962483.1927576}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.24797843665768193, '_timestamp': 1721962483.193689}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'train_goal': 0.623989218328841, '_timestamp': 1721962483.1941457}).
wandb: WARNING (User provided step: 9064 is less than current step: 15000. Dropping entry: {'train_WDL': 0.24797843665768193, '_timestamp': 1721962483.194826}).
Env Football Algo jrpo Exp base_JRPO updates 7598/100000000000.0 steps in 90.89
total episode rewards is 30.0
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'value_loss': 0.2807389216994246, '_timestamp': 1721962574.0833158}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'policy_loss': 0.056375232242280617, '_timestamp': 1721962574.0834937}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0243970568974812, '_timestamp': 1721962574.083563}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.25252479314804077, '_timestamp': 1721962574.08366}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14163917303085327, '_timestamp': 1721962574.0839345}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'ratio': 0.4948921799659729, '_timestamp': 1721962574.0840569}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 30.0, '_timestamp': 1721962574.0841918}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962574.0842814}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.88767457008362, '_timestamp': 1721962574.0843394}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721962574.0853279}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721962574.0857623}).
wandb: WARNING (User provided step: 7598 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721962574.0861886}).
Env Football Algo jrpo Exp base_JRPO updates 9508/100000000000.0 steps in 86.89
total episode rewards is -10.0
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'value_loss': 0.24860178128505747, '_timestamp': 1721962660.9749122}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010550581108254846, '_timestamp': 1721962660.975087}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.20223770459493, '_timestamp': 1721962660.975153}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11930292099714279, '_timestamp': 1721962660.9752474}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19277316331863403, '_timestamp': 1721962660.9755273}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'ratio': 0.4078119993209839, '_timestamp': 1721962660.975636}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721962660.9757717}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962660.9758666}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.88735818862915, '_timestamp': 1721962660.9759262}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.07938820101966497, '_timestamp': 1721962660.9765456}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'train_goal': 0.5396941005098325, '_timestamp': 1721962660.976906}).
wandb: WARNING (User provided step: 9508 is less than current step: 15000. Dropping entry: {'train_WDL': 0.07938820101966497, '_timestamp': 1721962660.977268}).
Env Football Algo jrpo Exp base_JRPO updates 5089/100000000000.0 steps in 82.76
total episode rewards is 0.0
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'value_loss': 0.2931320078174273, '_timestamp': 1721962743.7374556}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012327816177469988, '_timestamp': 1721962743.7376437}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.6900547456741333, '_timestamp': 1721962743.737713}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.11727147549390793, '_timestamp': 1721962743.7378175}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2045595496892929, '_timestamp': 1721962743.7381024}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'ratio': 0.601699948310852, '_timestamp': 1721962743.7382097}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721962743.7383413}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962743.7384398}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.75933957099915, '_timestamp': 1721962743.738498}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.051155282009888, '_timestamp': 1721962743.739269}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'train_goal': 0.525577641004944, '_timestamp': 1721962743.73986}).
wandb: WARNING (User provided step: 5089 is less than current step: 15000. Dropping entry: {'train_WDL': 0.051155282009888, '_timestamp': 1721962743.740482}).
Env Football Algo jrpo Exp base_JRPO updates 6419/100000000000.0 steps in 87.81
total episode rewards is -40.0
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'value_loss': 0.3431701337794463, '_timestamp': 1721962831.5556598}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'policy_loss': -0.003935241336002946, '_timestamp': 1721962831.5558305}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8293847362200419, '_timestamp': 1721962831.5558958}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06220318749547005, '_timestamp': 1721962831.5560064}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19169719517230988, '_timestamp': 1721962831.5562744}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'ratio': 0.5367119908332825, '_timestamp': 1721962831.5563817}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721962831.5565116}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962831.5566041}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.8143150806427, '_timestamp': 1721962831.556661}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721962831.5572565}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721962831.557785}).
wandb: WARNING (User provided step: 6419 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721962831.5583086}).
Env Football Algo jrpo Exp base_JRPO updates 10339/100000000000.0 steps in 85.50
total episode rewards is 0.0
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'value_loss': 0.30728293739259244, '_timestamp': 1721962917.0576258}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'policy_loss': 0.06330970962221424, '_timestamp': 1721962917.0577996}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1842509130636851, '_timestamp': 1721962917.057868}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07078483700752258, '_timestamp': 1721962917.0579593}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3149106502532959, '_timestamp': 1721962917.0582213}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'ratio': 0.18385906517505646, '_timestamp': 1721962917.058325}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721962917.058458}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962917.0585458}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.49818325042725, '_timestamp': 1721962917.058602}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.1997425445183437, '_timestamp': 1721962917.0590346}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'train_goal': 0.40012872774082814, '_timestamp': 1721962917.059351}).
wandb: WARNING (User provided step: 10339 is less than current step: 15000. Dropping entry: {'train_WDL': -0.1997425445183437, '_timestamp': 1721962917.0596666}).
Env Football Algo jrpo Exp base_JRPO updates 7348/100000000000.0 steps in 80.02
total episode rewards is 0.0
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'value_loss': 0.322607301051418, '_timestamp': 1721962997.0819056}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04279771996254567, '_timestamp': 1721962997.0821178}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.04155055642128, '_timestamp': 1721962997.0821884}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06158716231584549, '_timestamp': 1721962997.0822964}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.12427477538585663, '_timestamp': 1721962997.082626}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'ratio': 0.427432119846344, '_timestamp': 1721962997.0827637}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721962997.0829108}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721962997.0830126}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.01545119285583, '_timestamp': 1721962997.0830832}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.19419759539989545, '_timestamp': 1721962997.08385}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_goal': 0.5970987976999478, '_timestamp': 1721962997.0844553}).
wandb: WARNING (User provided step: 7348 is less than current step: 15000. Dropping entry: {'train_WDL': 0.19419759539989545, '_timestamp': 1721962997.0849364}).
Env Football Algo jrpo Exp base_JRPO updates 6257/100000000000.0 steps in 81.04
total episode rewards is -30.0
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'value_loss': 0.37443929264321923, '_timestamp': 1721963078.1281226}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012562301172874869, '_timestamp': 1721963078.1283104}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9320099898179373, '_timestamp': 1721963078.1283765}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09568913280963898, '_timestamp': 1721963078.1284728}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2651177942752838, '_timestamp': 1721963078.1287303}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'ratio': 0.4616507589817047, '_timestamp': 1721963078.1288316}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963078.1289632}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963078.1290555}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.04184889793396, '_timestamp': 1721963078.129116}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.704509701101206, '_timestamp': 1721963078.1297104}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'train_goal': 0.14774514944939696, '_timestamp': 1721963078.1301827}).
wandb: WARNING (User provided step: 6257 is less than current step: 15000. Dropping entry: {'train_WDL': -0.704509701101206, '_timestamp': 1721963078.1306596}).
Env Football Algo jrpo Exp base_JRPO updates 9108/100000000000.0 steps in 80.08
total episode rewards is 20.0
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'value_loss': 0.15233309488122662, '_timestamp': 1721963158.2110243}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009477806026116014, '_timestamp': 1721963158.2112045}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1575710105895995, '_timestamp': 1721963158.2112708}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3628320097923279, '_timestamp': 1721963158.2113695}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16689854860305786, '_timestamp': 1721963158.211624}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'ratio': 0.5352081656455994, '_timestamp': 1721963158.2117312}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721963158.2118633}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963158.2119813}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.07950472831726, '_timestamp': 1721963158.2120404}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721963158.2130284}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721963158.213584}).
wandb: WARNING (User provided step: 9108 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721963158.213955}).
Env Football Algo jrpo Exp base_JRPO updates 7243/100000000000.0 steps in 82.87
total episode rewards is -30.0
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'value_loss': 0.314581967163831, '_timestamp': 1721963241.0828223}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02921950523760946, '_timestamp': 1721963241.0829887}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2626174799601237, '_timestamp': 1721963241.083055}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19455699622631073, '_timestamp': 1721963241.0831468}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26308321952819824, '_timestamp': 1721963241.0836065}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'ratio': 0.3671923279762268, '_timestamp': 1721963241.0837102}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963241.083842}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963241.0839376}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.86806559562683, '_timestamp': 1721963241.0840082}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.5985045513654096, '_timestamp': 1721963241.084499}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'train_goal': 0.20074772431729518, '_timestamp': 1721963241.0848992}).
wandb: WARNING (User provided step: 7243 is less than current step: 15000. Dropping entry: {'train_WDL': -0.5985045513654096, '_timestamp': 1721963241.085298}).
Env Football Algo jrpo Exp base_JRPO updates 9243/100000000000.0 steps in 85.08
total episode rewards is -30.0
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'value_loss': 0.2375696854184692, '_timestamp': 1721963326.1688235}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'policy_loss': 0.031851025086749966, '_timestamp': 1721963326.168991}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.379577984015147, '_timestamp': 1721963326.1692283}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17034512758255005, '_timestamp': 1721963326.1693175}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15203632414340973, '_timestamp': 1721963326.1695669}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'ratio': 0.45282360911369324, '_timestamp': 1721963326.1696665}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963326.1697958}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963326.1698859}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.08232474327087, '_timestamp': 1721963326.1699436}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963326.1704195}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963326.1707985}).
wandb: WARNING (User provided step: 9243 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963326.171175}).
Env Football Algo jrpo Exp base_JRPO updates 6134/100000000000.0 steps in 84.95
total episode rewards is -40.0
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'value_loss': 0.3325472853674243, '_timestamp': 1721963411.1270244}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03265441980872614, '_timestamp': 1721963411.127199}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5524153017997742, '_timestamp': 1721963411.1272671}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13528719544410706, '_timestamp': 1721963411.1273642}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17535027861595154, '_timestamp': 1721963411.1276298}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'ratio': 0.5258898138999939, '_timestamp': 1721963411.1277325}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963411.1278656}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963411.127977}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.95487213134766, '_timestamp': 1721963411.1280372}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963411.1286917}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963411.1291795}).
wandb: WARNING (User provided step: 6134 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963411.129721}).
Env Football Algo jrpo Exp base_JRPO updates 10695/100000000000.0 steps in 90.97
total episode rewards is -30.0
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'value_loss': 0.22465855544801647, '_timestamp': 1721963502.0998285}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04101921687618111, '_timestamp': 1721963502.100007}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6186134084065755, '_timestamp': 1721963502.1000748}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06879530847072601, '_timestamp': 1721963502.1001673}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19342675805091858, '_timestamp': 1721963502.1004279}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'ratio': 0.5017461776733398, '_timestamp': 1721963502.100532}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721963502.1006527}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963502.1007445}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.96914005279541, '_timestamp': 1721963502.1008024}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963502.1011856}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963502.1014833}).
wandb: WARNING (User provided step: 10695 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963502.1017878}).
Env Football Algo jrpo Exp base_JRPO updates 10692/100000000000.0 steps in 86.36
total episode rewards is -20.0
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'value_loss': 0.14629118078853934, '_timestamp': 1721963588.4606142}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02620376430878726, '_timestamp': 1721963588.460815}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6622116017341613, '_timestamp': 1721963588.4608812}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07394812256097794, '_timestamp': 1721963588.460975}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13757161796092987, '_timestamp': 1721963588.4612596}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'ratio': 0.8852524757385254, '_timestamp': 1721963588.461365}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721963588.4614859}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963588.461607}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.35766315460205, '_timestamp': 1721963588.4616642}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963588.4620986}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963588.4623914}).
wandb: WARNING (User provided step: 10692 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963588.4626977}).
Env Football Algo jrpo Exp base_JRPO updates 6505/100000000000.0 steps in 67.71
total episode rewards is -50.0
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'value_loss': 0.36556298342494603, '_timestamp': 1721963656.1733172}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014424392407527194, '_timestamp': 1721963656.173537}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6660593064626057, '_timestamp': 1721963656.1736078}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14023657143115997, '_timestamp': 1721963656.1737134}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3505364954471588, '_timestamp': 1721963656.1740267}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'ratio': 0.8410893678665161, '_timestamp': 1721963656.1741354}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721963656.174276}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963656.1743805}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'Episode_Time': 67.70942068099976, '_timestamp': 1721963656.1744397}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963656.175024}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963656.1753833}).
wandb: WARNING (User provided step: 6505 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963656.1757476}).
Env Football Algo jrpo Exp base_JRPO updates 7842/100000000000.0 steps in 78.16
total episode rewards is -70.0
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'value_loss': 0.5210314827614153, '_timestamp': 1721963734.3363492}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'policy_loss': 0.024538200252864045, '_timestamp': 1721963734.336522}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6995544664065043, '_timestamp': 1721963734.3365898}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29969921708106995, '_timestamp': 1721963734.336684}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5573126077651978, '_timestamp': 1721963734.3369045}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'ratio': 0.8326366543769836, '_timestamp': 1721963734.3370092}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721963734.337142}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963734.3372397}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'Episode_Time': 78.15944814682007, '_timestamp': 1721963734.3372989}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963734.337919}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963734.3382711}).
wandb: WARNING (User provided step: 7842 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963734.3386273}).
Env Football Algo jrpo Exp base_JRPO updates 4762/100000000000.0 steps in 84.26
total episode rewards is -40.0
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'value_loss': 0.3002756508474704, '_timestamp': 1721963818.596457}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0012740832066144019, '_timestamp': 1721963818.5966485}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6902572663625082, '_timestamp': 1721963818.596718}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.14231304824352264, '_timestamp': 1721963818.5968199}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.10730260610580444, '_timestamp': 1721963818.5970914}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'ratio': 0.9352028369903564, '_timestamp': 1721963818.5971985}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963818.5973346}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963818.5974684}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.2568781375885, '_timestamp': 1721963818.5975266}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963818.598602}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963818.5994208}).
wandb: WARNING (User provided step: 4762 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963818.600074}).
Env Football Algo jrpo Exp base_JRPO updates 10259/100000000000.0 steps in 89.24
total episode rewards is -40.0
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'value_loss': 0.28730629981107386, '_timestamp': 1721963907.8419971}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008772911842679604, '_timestamp': 1721963907.842176}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7663259998957317, '_timestamp': 1721963907.842244}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1221093237400055, '_timestamp': 1721963907.8423433}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3103315532207489, '_timestamp': 1721963907.842587}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'ratio': 0.9424515962600708, '_timestamp': 1721963907.842692}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721963907.8428211}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963907.8429155}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.2407009601593, '_timestamp': 1721963907.8429751}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721963907.843458}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721963907.8438113}).
wandb: WARNING (User provided step: 10259 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721963907.8441515}).
Env Football Algo jrpo Exp base_JRPO updates 9648/100000000000.0 steps in 87.03
total episode rewards is -20.0
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'value_loss': 0.33737861982119893, '_timestamp': 1721963994.8789358}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'policy_loss': 0.019504894668546817, '_timestamp': 1721963994.8792317}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8055593784650166, '_timestamp': 1721963994.8793015}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.34992364048957825, '_timestamp': 1721963994.8794591}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.31016308069229126, '_timestamp': 1721963994.8798118}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'ratio': 0.9930353164672852, '_timestamp': 1721963994.8799245}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721963994.8800824}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721963994.8801808}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.03270483016968, '_timestamp': 1721963994.8802397}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.05642750373692078, '_timestamp': 1721963994.8810184}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'train_goal': 0.5282137518684604, '_timestamp': 1721963994.8814502}).
wandb: WARNING (User provided step: 9648 is less than current step: 15000. Dropping entry: {'train_WDL': 0.05642750373692078, '_timestamp': 1721963994.8818371}).
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 81.28
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 5136/100000000000.0 steps in 90.57
total episode rewards is -40.0
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'value_loss': 0.3116981143535425, '_timestamp': 1721964166.738026}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014327554687818822, '_timestamp': 1721964166.7382386}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7856478786468506, '_timestamp': 1721964166.7383087}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.42904454469680786, '_timestamp': 1721964166.7384317}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.36434054374694824, '_timestamp': 1721964166.738671}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'ratio': 0.95944744348526, '_timestamp': 1721964166.7387724}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721964166.738897}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964166.7389867}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.57246422767639, '_timestamp': 1721964166.7390475}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964166.7398188}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964166.7404013}).
wandb: WARNING (User provided step: 5136 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964166.7409923}).
Env Football Algo jrpo Exp base_JRPO updates 13195/100000000000.0 steps in 87.35
total episode rewards is -10.0
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'value_loss': 0.07309784519001065, '_timestamp': 1721964254.0925045}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'policy_loss': 0.011298184864087185, '_timestamp': 1721964254.0927439}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8356767853101095, '_timestamp': 1721964254.0928187}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10138331353664398, '_timestamp': 1721964254.0929604}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14085720479488373, '_timestamp': 1721964254.093268}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'ratio': 0.9195328950881958, '_timestamp': 1721964254.0933807}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721964254.093524}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964254.0936275}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.3503487110138, '_timestamp': 1721964254.0936897}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964254.0941105}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964254.0943017}).
wandb: WARNING (User provided step: 13195 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964254.0944846}).
Env Football Algo jrpo Exp base_JRPO updates 12987/100000000000.0 steps in 91.56
total episode rewards is -20.0
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'value_loss': 0.15245632551823898, '_timestamp': 1721964345.6506429}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'policy_loss': 0.002610188974843671, '_timestamp': 1721964345.6508837}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7930432653427124, '_timestamp': 1721964345.6509528}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17729608714580536, '_timestamp': 1721964345.6510873}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17495813965797424, '_timestamp': 1721964345.6513517}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'ratio': 0.9364362955093384, '_timestamp': 1721964345.6514537}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964345.651681}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964345.6517751}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.55501294136047, '_timestamp': 1721964345.6518333}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964345.6523857}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964345.6525743}).
wandb: WARNING (User provided step: 12987 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964345.6527586}).
Env Football Algo jrpo Exp base_JRPO updates 6982/100000000000.0 steps in 61.03
total episode rewards is -70.0
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'value_loss': 0.5373781522487601, '_timestamp': 1721964406.6879861}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004460448241055322, '_timestamp': 1721964406.688202}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.778570986588796, '_timestamp': 1721964406.6882696}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5364317297935486, '_timestamp': 1721964406.688367}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6630353331565857, '_timestamp': 1721964406.6886468}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'ratio': 0.9430583119392395, '_timestamp': 1721964406.6887534}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721964406.689035}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964406.6891334}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'Episode_Time': 61.03428316116333, '_timestamp': 1721964406.689193}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964406.6898055}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964406.6901014}).
wandb: WARNING (User provided step: 6982 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964406.6903963}).
Env Football Algo jrpo Exp base_JRPO updates 12522/100000000000.0 steps in 89.87
total episode rewards is -10.0
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'value_loss': 0.08023025598105353, '_timestamp': 1721964496.5610428}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0008226541464682668, '_timestamp': 1721964496.5612173}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.839069628715515, '_timestamp': 1721964496.5612833}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4767630696296692, '_timestamp': 1721964496.5613773}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.10655346512794495, '_timestamp': 1721964496.5616171}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'ratio': 0.9526039958000183, '_timestamp': 1721964496.5617168}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721964496.5618436}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964496.561932}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.86988186836243, '_timestamp': 1721964496.5619876}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964496.5622795}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964496.5624895}).
wandb: WARNING (User provided step: 12522 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964496.5627005}).
Env Football Algo jrpo Exp base_JRPO updates 10156/100000000000.0 steps in 82.87
total episode rewards is -30.0
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'value_loss': 0.22392677018496518, '_timestamp': 1721964579.4376907}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00044753707906541727, '_timestamp': 1721964579.4378629}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8219292481740317, '_timestamp': 1721964579.4379318}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4369353950023651, '_timestamp': 1721964579.4380279}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.279083251953125, '_timestamp': 1721964579.4383068}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'ratio': 0.5071134567260742, '_timestamp': 1721964579.438412}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721964579.4385552}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964579.4386477}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.87399363517761, '_timestamp': 1721964579.4387054}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964579.4391813}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964579.439511}).
wandb: WARNING (User provided step: 10156 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964579.43985}).
Env Football Algo jrpo Exp base_JRPO updates 10147/100000000000.0 steps in 87.45
total episode rewards is -20.0
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'value_loss': 0.17534010164206848, '_timestamp': 1721964666.8936496}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'policy_loss': -0.01548221723428772, '_timestamp': 1721964666.893843}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6389695620536804, '_timestamp': 1721964666.8939078}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2636632025241852, '_timestamp': 1721964666.8939986}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.12661463022232056, '_timestamp': 1721964666.8942351}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'ratio': 0.3540184199810028, '_timestamp': 1721964666.8943365}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964666.89458}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964666.894675}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.45288634300232, '_timestamp': 1721964666.8947325}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964666.8953376}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964666.8956711}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964666.8960164}).
Env Football Algo jrpo Exp base_JRPO updates 8226/100000000000.0 steps in 92.45
total episode rewards is -20.0
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'value_loss': 0.3199244431902965, '_timestamp': 1721964759.347181}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0016108204366173595, '_timestamp': 1721964759.3473616}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.706282213528951, '_timestamp': 1721964759.347432}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19230808317661285, '_timestamp': 1721964759.3475285}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.33709272742271423, '_timestamp': 1721964759.3478057}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'ratio': 0.4508817791938782, '_timestamp': 1721964759.3479116}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721964759.3480668}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964759.3481605}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.45017576217651, '_timestamp': 1721964759.3482184}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.14289932093297902, '_timestamp': 1721964759.3488176}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'train_goal': 0.42855033953351046, '_timestamp': 1721964759.3492327}).
wandb: WARNING (User provided step: 8226 is less than current step: 15000. Dropping entry: {'train_WDL': -0.14289932093297902, '_timestamp': 1721964759.349663}).
Env Football Algo jrpo Exp base_JRPO updates 14017/100000000000.0 steps in 87.12
total episode rewards is -10.0
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'value_loss': 0.07253030612754326, '_timestamp': 1721964846.4703104}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004728851980374505, '_timestamp': 1721964846.470478}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9768308345476786, '_timestamp': 1721964846.470545}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17594191431999207, '_timestamp': 1721964846.4706368}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19444917142391205, '_timestamp': 1721964846.4708974}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'ratio': 0.18692336976528168, '_timestamp': 1721964846.4709995}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721964846.471134}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964846.4712248}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.11959838867188, '_timestamp': 1721964846.4712813}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964846.4714968}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964846.47163}).
wandb: WARNING (User provided step: 14017 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964846.4717607}).
Env Football Algo jrpo Exp base_JRPO updates 9407/100000000000.0 steps in 88.47
total episode rewards is -30.0
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'value_loss': 0.23971744527419409, '_timestamp': 1721964934.9471407}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'policy_loss': -0.02401431386722834, '_timestamp': 1721964934.9473753}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8157782379786174, '_timestamp': 1721964934.9474468}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2868538498878479, '_timestamp': 1721964934.947584}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29334843158721924, '_timestamp': 1721964934.9478586}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'ratio': 0.38585954904556274, '_timestamp': 1721964934.9479852}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721964934.9481273}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721964934.9482293}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.47446632385254, '_timestamp': 1721964934.9482865}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721964934.9487846}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721964934.9491613}).
wandb: WARNING (User provided step: 9407 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721964934.9495368}).
Env Football Algo jrpo Exp base_JRPO updates 8801/100000000000.0 steps in 91.65
total episode rewards is -30.0
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'value_loss': 0.24881609694411358, '_timestamp': 1721965026.5983694}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'policy_loss': -0.02736502868278573, '_timestamp': 1721965026.5985937}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7976214869817098, '_timestamp': 1721965026.5986633}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3250895142555237, '_timestamp': 1721965026.5987663}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.26669782400131226, '_timestamp': 1721965026.5990613}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'ratio': 0.410547137260437, '_timestamp': 1721965026.5991669}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965026.5993023}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965026.5993953}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.64789581298828, '_timestamp': 1721965026.5994534}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965026.6000478}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965026.6004572}).
wandb: WARNING (User provided step: 8801 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965026.600866}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'value_loss': 0.3455818408479293, '_timestamp': 1721965112.03437}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0061608252239724, '_timestamp': 1721965112.0345585}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.739221818447113, '_timestamp': 1721965112.0346289}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.20362938940525055, '_timestamp': 1721965112.0347285}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.31372153759002686, '_timestamp': 1721965112.0349545}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'ratio': 0.5042637586593628, '_timestamp': 1721965112.0350583}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965112.0351853}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965112.035315}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.43238687515259, '_timestamp': 1721965112.035381}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3704524709870909, '_timestamp': 1721965112.036185}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'train_goal': 0.31477376450645456, '_timestamp': 1721965112.0366993}).
wandb: WARNING (User provided step: 7331 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3704524709870909, '_timestamp': 1721965112.0372531}).
Env Football Algo jrpo Exp base_JRPO updates 7331/100000000000.0 steps in 85.43
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8475/100000000000.0 steps in 86.90
total episode rewards is -40.0
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'value_loss': 0.3115384508979817, '_timestamp': 1721965198.9402716}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'policy_loss': -0.021497028354836707, '_timestamp': 1721965198.9404588}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.759847449461619, '_timestamp': 1721965198.9405293}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2506956458091736, '_timestamp': 1721965198.940632}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19120508432388306, '_timestamp': 1721965198.9409246}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'ratio': 0.4145658314228058, '_timestamp': 1721965198.941032}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721965198.941156}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965198.9412527}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.90179920196533, '_timestamp': 1721965198.9413126}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965198.941886}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965198.942327}).
wandb: WARNING (User provided step: 8475 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965198.9427557}).
Env Football Algo jrpo Exp base_JRPO updates 11230/100000000000.0 steps in 90.08
total episode rewards is -20.0
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'value_loss': 0.1510929878304402, '_timestamp': 1721965289.0274496}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'policy_loss': -0.021289615444839, '_timestamp': 1721965289.0276287}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8369112960497538, '_timestamp': 1721965289.0276976}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3005375862121582, '_timestamp': 1721965289.0277903}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13847368955612183, '_timestamp': 1721965289.028038}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'ratio': 0.2566094696521759, '_timestamp': 1721965289.028146}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965289.028279}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965289.0283768}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.08370971679688, '_timestamp': 1721965289.028435}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965289.0288062}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965289.0290759}).
wandb: WARNING (User provided step: 11230 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965289.0293555}).
Env Football Algo jrpo Exp base_JRPO updates 8995/100000000000.0 steps in 81.76
total episode rewards is -30.0
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'value_loss': 0.24880794572333495, '_timestamp': 1721965370.787449}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'policy_loss': -0.02774763209745288, '_timestamp': 1721965370.7876246}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9083259097735088, '_timestamp': 1721965370.7876923}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.27461501955986023, '_timestamp': 1721965370.7877839}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25418621301651, '_timestamp': 1721965370.7880733}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'ratio': 0.40475794672966003, '_timestamp': 1721965370.7881808}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965370.788315}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965370.78841}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.75723433494568, '_timestamp': 1721965370.788467}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965370.7889636}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965370.7893336}).
wandb: WARNING (User provided step: 8995 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965370.7897205}).
Env Football Algo jrpo Exp base_JRPO updates 11648/100000000000.0 steps in 89.95
total episode rewards is -30.0
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'value_loss': 0.2339873955460886, '_timestamp': 1721965460.73833}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'policy_loss': -0.014068315849193217, '_timestamp': 1721965460.7384992}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8935254780451456, '_timestamp': 1721965460.738567}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3125874698162079, '_timestamp': 1721965460.738656}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3229685425758362, '_timestamp': 1721965460.7389078}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'ratio': 0.23534932732582092, '_timestamp': 1721965460.7390099}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965460.7391396}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965460.739227}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.94760203361511, '_timestamp': 1721965460.7392852}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965460.7396257}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965460.7398796}).
wandb: WARNING (User provided step: 11648 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965460.740146}).
Env Football Algo jrpo Exp base_JRPO updates 11219/100000000000.0 steps in 91.46
total episode rewards is -20.0
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'value_loss': 0.17228309984008472, '_timestamp': 1721965552.202098}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'policy_loss': -0.021499102880091717, '_timestamp': 1721965552.2023478}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9871010041236878, '_timestamp': 1721965552.2024193}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.346841424703598, '_timestamp': 1721965552.2025518}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2345455437898636, '_timestamp': 1721965552.2028291}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'ratio': 0.2712315618991852, '_timestamp': 1721965552.202939}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965552.2030709}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965552.2031662}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.46096563339233, '_timestamp': 1721965552.2032285}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965552.2036436}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965552.2039266}).
wandb: WARNING (User provided step: 11219 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965552.2043784}).
Env Football Algo jrpo Exp base_JRPO updates 14180/100000000000.0 steps in 88.94
total episode rewards is -10.0
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'value_loss': 0.07448572093310456, '_timestamp': 1721965641.1431935}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0046890558575978505, '_timestamp': 1721965641.1434565}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'dist_entropy': 2.1004859654108685, '_timestamp': 1721965641.1435282}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2595154345035553, '_timestamp': 1721965641.143668}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.12239090353250504, '_timestamp': 1721965641.1439743}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'ratio': 0.09992889314889908, '_timestamp': 1721965641.1440837}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721965641.1442223}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965641.1443172}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.9376928806305, '_timestamp': 1721965641.144379}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965641.1446455}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965641.1447797}).
wandb: WARNING (User provided step: 14180 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965641.1449103}).
Env Football Algo jrpo Exp base_JRPO updates 11719/100000000000.0 steps in 80.64
total episode rewards is -20.0
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'value_loss': 0.17042856289694708, '_timestamp': 1721965721.7863963}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'policy_loss': -0.020529911330280204, '_timestamp': 1721965721.7865605}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.908854893843333, '_timestamp': 1721965721.7866247}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5490953922271729, '_timestamp': 1721965721.7867126}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18372970819473267, '_timestamp': 1721965721.7869613}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'ratio': 0.23288089036941528, '_timestamp': 1721965721.7870626}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965721.7871845}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965721.7872753}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.64055943489075, '_timestamp': 1721965721.7873318}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965721.78765}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965721.787886}).
wandb: WARNING (User provided step: 11719 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965721.788139}).
Env Football Algo jrpo Exp base_JRPO updates 8772/100000000000.0 steps in 88.23
total episode rewards is -10.0
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'value_loss': 0.28146970793604853, '_timestamp': 1721965810.0219967}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0032186038885265588, '_timestamp': 1721965810.0221605}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6778884347279865, '_timestamp': 1721965810.0222275}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7363468408584595, '_timestamp': 1721965810.0223167}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.32076603174209595, '_timestamp': 1721965810.0225859}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'ratio': 0.41023993492126465, '_timestamp': 1721965810.0226886}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721965810.0228112}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965810.0229053}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.23291254043579, '_timestamp': 1721965810.022965}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.31021194605009633, '_timestamp': 1721965810.023468}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'train_goal': 0.3448940269749518, '_timestamp': 1721965810.0238597}).
wandb: WARNING (User provided step: 8772 is less than current step: 15000. Dropping entry: {'train_WDL': -0.31021194605009633, '_timestamp': 1721965810.0242689}).
Env Football Algo jrpo Exp base_JRPO updates 11623/100000000000.0 steps in 83.14
total episode rewards is -20.0
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'value_loss': 0.1785490988443295, '_timestamp': 1721965893.1633294}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'policy_loss': -0.02734751231657962, '_timestamp': 1721965893.1634939}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.859351134300232, '_timestamp': 1721965893.1635594}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4595332443714142, '_timestamp': 1721965893.163649}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20969922840595245, '_timestamp': 1721965893.1638498}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'ratio': 0.23299828171730042, '_timestamp': 1721965893.1639695}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721965893.1640918}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965893.1641831}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.1378161907196, '_timestamp': 1721965893.16424}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965893.1645722}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965893.1648214}).
wandb: WARNING (User provided step: 11623 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965893.1650655}).
Env Football Algo jrpo Exp base_JRPO updates 12521/100000000000.0 steps in 84.51
total episode rewards is -30.0
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'value_loss': 0.2396790047114094, '_timestamp': 1721965977.6744184}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011918584867574585, '_timestamp': 1721965977.6745958}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9095152449607848, '_timestamp': 1721965977.6746616}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.337825745344162, '_timestamp': 1721965977.6747515}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2612191438674927, '_timestamp': 1721965977.6750166}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'ratio': 0.289146363735199, '_timestamp': 1721965977.6751192}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721965977.6752508}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721965977.6753423}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.50839591026306, '_timestamp': 1721965977.675398}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721965977.6756988}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721965977.675909}).
wandb: WARNING (User provided step: 12521 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721965977.676143}).
Env Football Algo jrpo Exp base_JRPO updates 6035/100000000000.0 steps in 92.15
total episode rewards is -20.0
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'value_loss': 0.41413923596342406, '_timestamp': 1721966069.829673}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015262662621680648, '_timestamp': 1721966069.8299186}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.770585334300995, '_timestamp': 1721966069.8300028}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30114829540252686, '_timestamp': 1721966069.8301373}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21030330657958984, '_timestamp': 1721966069.8304367}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'ratio': 0.6408125758171082, '_timestamp': 1721966069.8305597}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721966069.8307147}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966069.8308241}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.15256714820862, '_timestamp': 1721966069.830891}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3430005577244841, '_timestamp': 1721966069.831765}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'train_goal': 0.32849972113775794, '_timestamp': 1721966069.83244}).
wandb: WARNING (User provided step: 6035 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3430005577244841, '_timestamp': 1721966069.8331087}).
Env Football Algo jrpo Exp base_JRPO updates 11239/100000000000.0 steps in 86.71
total episode rewards is -30.0
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'value_loss': 0.2665620330472787, '_timestamp': 1721966156.542219}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'policy_loss': -0.023563747481433285, '_timestamp': 1721966156.5424492}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6689315978686015, '_timestamp': 1721966156.5425217}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.44361528754234314, '_timestamp': 1721966156.542656}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1528337448835373, '_timestamp': 1721966156.5429273}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'ratio': 0.2500610649585724, '_timestamp': 1721966156.543035}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966156.5431705}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966156.5432706}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.70788621902466, '_timestamp': 1721966156.5433285}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966156.5437422}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966156.5441735}).
wandb: WARNING (User provided step: 11239 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966156.5444639}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'value_loss': 0.3024378132820129, '_timestamp': 1721966241.5450659}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'policy_loss': -0.03405611668538768, '_timestamp': 1721966241.5452287}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.865982407728831, '_timestamp': 1721966241.5452948}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48589056730270386, '_timestamp': 1721966241.545385}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18513993918895721, '_timestamp': 1721966241.5456493}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'ratio': 0.30348894000053406, '_timestamp': 1721966241.5457551}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966241.5458882}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966241.5459907}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.99987292289734, '_timestamp': 1721966241.546048}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966241.5465198}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966241.5468445}).
wandb: WARNING (User provided step: 10375 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966241.547167}).
Env Football Algo jrpo Exp base_JRPO updates 10375/100000000000.0 steps in 85.00
total episode rewards is -30.0
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'value_loss': 0.3297295545041561, '_timestamp': 1721966329.7046783}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'policy_loss': -0.03671189591683591, '_timestamp': 1721966329.7048495}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.8521820068359376, '_timestamp': 1721966329.7049153}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4650641083717346, '_timestamp': 1721966329.7050045}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.37639787793159485, '_timestamp': 1721966329.7052739}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'ratio': 0.3198590576648712, '_timestamp': 1721966329.7053754}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966329.705512}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966329.7056038}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.15626955032349, '_timestamp': 1721966329.7056615}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966329.7063131}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966329.7099273}).
wandb: WARNING (User provided step: 10325 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966329.7102835}).
Env Football Algo jrpo Exp base_JRPO updates 10325/100000000000.0 steps in 88.16
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 12417/100000000000.0 steps in 88.37
total episode rewards is -30.0
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'value_loss': 0.27420146284004054, '_timestamp': 1721966418.079701}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015576951678764696, '_timestamp': 1721966418.0798936}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6736524041493734, '_timestamp': 1721966418.0799952}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4883847236633301, '_timestamp': 1721966418.0801063}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19525815546512604, '_timestamp': 1721966418.0803854}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'ratio': 0.17155338823795319, '_timestamp': 1721966418.0804935}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966418.0806332}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966418.0807283}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.36851859092712, '_timestamp': 1721966418.0807862}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966418.0811346}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966418.0813506}).
wandb: WARNING (User provided step: 12417 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966418.08157}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'value_loss': 0.3457317229111989, '_timestamp': 1721966505.706048}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'policy_loss': -0.04948086051309171, '_timestamp': 1721966505.7062092}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6776942610740662, '_timestamp': 1721966505.706276}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6905678510665894, '_timestamp': 1721966505.7063656}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2302088439464569, '_timestamp': 1721966505.7066066}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'ratio': 0.2994762063026428, '_timestamp': 1721966505.7067077}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721966505.7068357}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966505.7069244}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.6236310005188, '_timestamp': 1721966505.706986}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966505.7075193}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966505.707822}).
wandb: WARNING (User provided step: 10550 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966505.7082849}).
Env Football Algo jrpo Exp base_JRPO updates 10550/100000000000.0 steps in 87.62
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6180/100000000000.0 steps in 84.51
total episode rewards is -40.0
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'value_loss': 0.7551154335339864, '_timestamp': 1721966590.2196078}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'policy_loss': -0.05861687118599851, '_timestamp': 1721966590.2197733}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6834544841448467, '_timestamp': 1721966590.219837}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.45234188437461853, '_timestamp': 1721966590.2199264}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2746855616569519, '_timestamp': 1721966590.2201972}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'ratio': 0.5632562637329102, '_timestamp': 1721966590.2203012}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721966590.2204318}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966590.220527}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.5103964805603, '_timestamp': 1721966590.2205837}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966590.2212145}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966590.2217238}).
wandb: WARNING (User provided step: 6180 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966590.2222602}).
Env Football Algo jrpo Exp base_JRPO updates 9894/100000000000.0 steps in 83.92
total episode rewards is -30.0
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'value_loss': 0.5263712831338246, '_timestamp': 1721966674.1384578}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'policy_loss': -0.05355487813397, '_timestamp': 1721966674.138622}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6896877678235371, '_timestamp': 1721966674.1386855}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5783520340919495, '_timestamp': 1721966674.1387734}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16266721487045288, '_timestamp': 1721966674.1390448}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'ratio': 0.3310713768005371, '_timestamp': 1721966674.1391485}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966674.139273}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966674.1393678}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.91517663002014, '_timestamp': 1721966674.1394274}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966674.139874}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966674.140233}).
wandb: WARNING (User provided step: 9894 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966674.1405776}).
Env Football Algo jrpo Exp base_JRPO updates 8555/100000000000.0 steps in 86.25
total episode rewards is -30.0
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'value_loss': 0.6352193961540858, '_timestamp': 1721966760.386685}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'policy_loss': -0.05946840782805036, '_timestamp': 1721966760.3868558}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7181720717748006, '_timestamp': 1721966760.386923}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6348824501037598, '_timestamp': 1721966760.3870158}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1269972175359726, '_timestamp': 1721966760.387282}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'ratio': 0.4210701286792755, '_timestamp': 1721966760.3873851}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721966760.3875182}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966760.3876212}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.24534034729004, '_timestamp': 1721966760.3876777}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966760.3882182}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966760.3886101}).
wandb: WARNING (User provided step: 8555 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966760.3890243}).
Env Football Algo jrpo Exp base_JRPO updates 6308/100000000000.0 steps in 77.45
total episode rewards is -50.0
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'value_loss': 0.8615367851654688, '_timestamp': 1721966837.8447282}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'policy_loss': -0.05763081211557922, '_timestamp': 1721966837.8450036}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7451446596781413, '_timestamp': 1721966837.845073}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6604806780815125, '_timestamp': 1721966837.8452017}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.216269388794899, '_timestamp': 1721966837.8454537}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'ratio': 0.48249295353889465, '_timestamp': 1721966837.8455546}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721966837.845828}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966837.8459544}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.4545648097992, '_timestamp': 1721966837.8460135}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966837.847121}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966837.847549}).
wandb: WARNING (User provided step: 6308 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966837.8480098}).
Env Football Algo jrpo Exp base_JRPO updates 5753/100000000000.0 steps in 56.98
total episode rewards is -90.0
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'value_loss': 0.8051011043787003, '_timestamp': 1721966894.837983}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'policy_loss': -0.03445586757113536, '_timestamp': 1721966894.8392844}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.815115249156952, '_timestamp': 1721966894.839357}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.38596874475479126, '_timestamp': 1721966894.8398416}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.702608585357666, '_timestamp': 1721966894.8402224}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'ratio': 0.3005698323249817, '_timestamp': 1721966894.8403301}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -90.0, '_timestamp': 1721966894.8404584}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966894.8406734}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'Episode_Time': 56.98383665084839, '_timestamp': 1721966894.8407333}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721966894.8415112}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721966894.841811}).
wandb: WARNING (User provided step: 5753 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721966894.842098}).
Env Football Algo jrpo Exp base_JRPO updates 9523/100000000000.0 steps in 88.68
total episode rewards is -10.0
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'value_loss': 0.4342371815443039, '_timestamp': 1721966983.5238926}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'policy_loss': 0.13314134339491526, '_timestamp': 1721966983.5240817}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6009529980023702, '_timestamp': 1721966983.5241485}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7136743068695068, '_timestamp': 1721966983.5242434}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3204452097415924, '_timestamp': 1721966983.5245028}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'ratio': 0.3897002637386322, '_timestamp': 1721966983.524607}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721966983.524739}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721966983.524838}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.68088722229004, '_timestamp': 1721966983.5249329}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.07577140770494796, '_timestamp': 1721966983.5255568}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'train_goal': 0.537885703852474, '_timestamp': 1721966983.5259104}).
wandb: WARNING (User provided step: 9523 is less than current step: 15000. Dropping entry: {'train_WDL': 0.07577140770494796, '_timestamp': 1721966983.5262663}).
Env Football Algo jrpo Exp base_JRPO updates 10070/100000000000.0 steps in 86.11
total episode rewards is -30.0
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'value_loss': 0.40579608221848806, '_timestamp': 1721967069.636507}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'policy_loss': 0.11143900884936253, '_timestamp': 1721967069.636768}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8662456957499186, '_timestamp': 1721967069.6368377}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5506638288497925, '_timestamp': 1721967069.6369405}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3204112946987152, '_timestamp': 1721967069.6372263}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'ratio': 0.32122817635536194, '_timestamp': 1721967069.6373334}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721967069.6377118}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967069.6378505}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.10901069641113, '_timestamp': 1721967069.637911}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967069.6392095}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967069.639591}).
wandb: WARNING (User provided step: 10070 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967069.6399665}).
Env Football Algo jrpo Exp base_JRPO updates 10802/100000000000.0 steps in 88.00
total episode rewards is -20.0
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'value_loss': 0.28381926581263545, '_timestamp': 1721967157.6496754}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'policy_loss': 0.13528878511705747, '_timestamp': 1721967157.6508145}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.8715253595511119, '_timestamp': 1721967157.6508837}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.46002981066703796, '_timestamp': 1721967157.6513078}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19844986498355865, '_timestamp': 1721967157.651717}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'ratio': 0.4804837703704834, '_timestamp': 1721967157.6518216}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721967157.6519709}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967157.6521564}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.00409173965454, '_timestamp': 1721967157.6522534}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967157.6530066}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967157.6533344}).
wandb: WARNING (User provided step: 10802 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967157.6536798}).
Env Football Algo jrpo Exp base_JRPO updates 8902/100000000000.0 steps in 92.18
total episode rewards is -10.0
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'value_loss': 0.43949857662121455, '_timestamp': 1721967249.8323274}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'policy_loss': 0.12214994914208849, '_timestamp': 1721967249.8326335}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1836534158388774, '_timestamp': 1721967249.8327055}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5619488954544067, '_timestamp': 1721967249.832845}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21303124725818634, '_timestamp': 1721967249.833131}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'ratio': 0.5734449028968811, '_timestamp': 1721967249.8332396}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721967249.833517}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967249.8338087}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.17737650871277, '_timestamp': 1721967249.8338687}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.025910134470318136, '_timestamp': 1721967249.8350475}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'train_goal': 0.48704493276484095, '_timestamp': 1721967249.83577}).
wandb: WARNING (User provided step: 8902 is less than current step: 15000. Dropping entry: {'train_WDL': -0.025910134470318136, '_timestamp': 1721967249.8365371}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'value_loss': 0.1603212204327186, '_timestamp': 1721967332.8432338}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02369911077529347, '_timestamp': 1721967332.8445444}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1816283011436461, '_timestamp': 1721967332.844619}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5951535105705261, '_timestamp': 1721967332.845113}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18095341324806213, '_timestamp': 1721967332.8454702}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'ratio': 0.5084549784660339, '_timestamp': 1721967332.8455777}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721967332.8457115}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967332.846121}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.00091671943665, '_timestamp': 1721967332.8461816}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967332.8471575}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967332.8473969}).
wandb: WARNING (User provided step: 12270 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967332.847628}).
Env Football Algo jrpo Exp base_JRPO updates 12270/100000000000.0 steps in 83.00
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 7543/100000000000.0 steps in 87.34
total episode rewards is 0.0
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'value_loss': 0.5608642631769181, '_timestamp': 1721967420.192936}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'policy_loss': 0.10672192452747065, '_timestamp': 1721967420.193117}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4046926712989807, '_timestamp': 1721967420.1931853}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5375422835350037, '_timestamp': 1721967420.1932812}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13008640706539154, '_timestamp': 1721967420.1935024}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'ratio': 0.5732439160346985, '_timestamp': 1721967420.1936066}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721967420.193733}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967420.1938639}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.34448456764221, '_timestamp': 1721967420.1939228}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5638996915649725, '_timestamp': 1721967420.1946857}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'train_goal': 0.7819498457824863, '_timestamp': 1721967420.1951911}).
wandb: WARNING (User provided step: 7543 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5638996915649725, '_timestamp': 1721967420.1956449}).
Env Football Algo jrpo Exp base_JRPO updates 4940/100000000000.0 steps in 93.39
total episode rewards is 0.0
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'value_loss': 0.6106799597541491, '_timestamp': 1721967513.5934954}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0789735277746028, '_timestamp': 1721967513.5949497}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5411078985532125, '_timestamp': 1721967513.5950565}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6306824684143066, '_timestamp': 1721967513.5956025}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2082028090953827, '_timestamp': 1721967513.596002}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'ratio': 0.6767418384552002, '_timestamp': 1721967513.596136}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721967513.5962903}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967513.596514}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'Episode_Time': 93.39119696617126, '_timestamp': 1721967513.596575}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.13737574552683895, '_timestamp': 1721967513.59811}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'train_goal': 0.5686878727634195, '_timestamp': 1721967513.598763}).
wandb: WARNING (User provided step: 4940 is less than current step: 15000. Dropping entry: {'train_WDL': 0.13737574552683895, '_timestamp': 1721967513.5993812}).
Env Football Algo jrpo Exp base_JRPO updates 12691/100000000000.0 steps in 84.42
total episode rewards is -30.0
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'value_loss': 0.28522511944174767, '_timestamp': 1721967598.0194595}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013173468219029018, '_timestamp': 1721967598.0196729}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5269580698013305, '_timestamp': 1721967598.0197418}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3755606412887573, '_timestamp': 1721967598.0198388}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24579058587551117, '_timestamp': 1721967598.0201735}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'ratio': 0.46735408902168274, '_timestamp': 1721967598.020283}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721967598.0204186}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967598.020643}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.41913390159607, '_timestamp': 1721967598.0207033}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721967598.0212736}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721967598.0214841}).
wandb: WARNING (User provided step: 12691 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721967598.0216885}).
Env Football Algo jrpo Exp base_JRPO updates 9911/100000000000.0 steps in 91.53
total episode rewards is 0.0
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'value_loss': 0.34614982863267263, '_timestamp': 1721967689.5543036}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'policy_loss': 0.09603803996151934, '_timestamp': 1721967689.5544908}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5650213686625163, '_timestamp': 1721967689.5545616}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6413528323173523, '_timestamp': 1721967689.5546603}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13787028193473816, '_timestamp': 1721967689.5549579}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'ratio': 0.585324764251709, '_timestamp': 1721967689.5550659}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721967689.5552037}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967689.555305}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.53150153160095, '_timestamp': 1721967689.555364}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.13932010218117508, '_timestamp': 1721967689.5563614}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'train_goal': 0.5696600510905876, '_timestamp': 1721967689.5567663}).
wandb: WARNING (User provided step: 9911 is less than current step: 15000. Dropping entry: {'train_WDL': 0.13932010218117508, '_timestamp': 1721967689.5571363}).
Env Football Algo jrpo Exp base_JRPO updates 4248/100000000000.0 steps in 60.01
total episode rewards is -50.0
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'value_loss': 0.8038726772864659, '_timestamp': 1721967749.5725951}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'policy_loss': 0.029410016029917944, '_timestamp': 1721967749.5728116}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5959656286239623, '_timestamp': 1721967749.5728827}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.551287829875946, '_timestamp': 1721967749.5729773}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5276448726654053, '_timestamp': 1721967749.5732224}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'ratio': 0.44121241569519043, '_timestamp': 1721967749.573331}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -50.0, '_timestamp': 1721967749.5748405}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967749.575194}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'Episode_Time': 60.01456093788147, '_timestamp': 1721967749.5752554}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.9996851385390428, '_timestamp': 1721967749.575919}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'train_goal': 0.00015743073047858942, '_timestamp': 1721967749.5766475}).
wandb: WARNING (User provided step: 4248 is less than current step: 15000. Dropping entry: {'train_WDL': -0.9996851385390428, '_timestamp': 1721967749.5770712}).
Env Football Algo jrpo Exp base_JRPO updates 5727/100000000000.0 steps in 92.03
total episode rewards is -20.0
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'value_loss': 0.36595033772289753, '_timestamp': 1721967841.6130683}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'policy_loss': 0.08295406800073882, '_timestamp': 1721967841.6133142}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.637168599764506, '_timestamp': 1721967841.6133838}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.448693186044693, '_timestamp': 1721967841.6134787}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25260689854621887, '_timestamp': 1721967841.6137867}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'ratio': 0.686111569404602, '_timestamp': 1721967841.6138914}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721967841.6141806}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967841.614317}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'Episode_Time': 92.03470540046692, '_timestamp': 1721967841.6143782}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3613717243610482, '_timestamp': 1721967841.6156228}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'train_goal': 0.3193141378194759, '_timestamp': 1721967841.6162024}).
wandb: WARNING (User provided step: 5727 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3613717243610482, '_timestamp': 1721967841.616796}).
Env Football Algo jrpo Exp base_JRPO updates 9733/100000000000.0 steps in 93.10
total episode rewards is 0.0
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'value_loss': 0.16733253991231323, '_timestamp': 1721967934.7205572}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0510256342512245, '_timestamp': 1721967934.720805}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6627119088172913, '_timestamp': 1721967934.7208767}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3619341254234314, '_timestamp': 1721967934.7210143}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15155106782913208, '_timestamp': 1721967934.7212834}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'ratio': 0.743080735206604, '_timestamp': 1721967934.7254367}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721967934.7257562}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721967934.726109}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'Episode_Time': 93.10255002975464, '_timestamp': 1721967934.726173}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.12625783178279856, '_timestamp': 1721967934.72721}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'train_goal': 0.5631289158913992, '_timestamp': 1721967934.7278569}).
wandb: WARNING (User provided step: 9733 is less than current step: 15000. Dropping entry: {'train_WDL': 0.12625783178279856, '_timestamp': 1721967934.728481}).
Env Football Algo jrpo Exp base_JRPO updates 7561/100000000000.0 steps in 79.66
total episode rewards is -20.0
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'value_loss': 0.3087220906404157, '_timestamp': 1721968014.3917394}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'policy_loss': 0.021156745238695294, '_timestamp': 1721968014.3931046}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6862797888120016, '_timestamp': 1721968014.393179}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2559260129928589, '_timestamp': 1721968014.3936815}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14692403376102448, '_timestamp': 1721968014.394049}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'ratio': 0.7498154640197754, '_timestamp': 1721968014.3941567}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721968014.3942952}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968014.3945112}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.65718221664429, '_timestamp': 1721968014.3945718}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.21467939239145045, '_timestamp': 1721968014.3960137}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'train_goal': 0.39266030380427475, '_timestamp': 1721968014.3965273}).
wandb: WARNING (User provided step: 7561 is less than current step: 15000. Dropping entry: {'train_WDL': -0.21467939239145045, '_timestamp': 1721968014.3970451}).
Env Football Algo jrpo Exp base_JRPO updates 8212/100000000000.0 steps in 91.46
total episode rewards is -30.0
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'value_loss': 0.22931524278130383, '_timestamp': 1721968105.8557634}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'policy_loss': 0.05142868076004864, '_timestamp': 1721968105.8560398}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.774835684299469, '_timestamp': 1721968105.8561094}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.468313604593277, '_timestamp': 1721968105.8562455}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13158845901489258, '_timestamp': 1721968105.856525}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'ratio': 0.8819361329078674, '_timestamp': 1721968105.8566277}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721968105.8567688}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968105.8568625}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.45741724967957, '_timestamp': 1721968105.8570168}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968105.857935}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968105.858594}).
wandb: WARNING (User provided step: 8212 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968105.8590953}).
Env Football Algo jrpo Exp base_JRPO updates 7397/100000000000.0 steps in 89.31
total episode rewards is -10.0
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'value_loss': 0.2330798521110167, '_timestamp': 1721968195.1772084}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'policy_loss': 0.023011370555420095, '_timestamp': 1721968195.1784377}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.697017195224762, '_timestamp': 1721968195.1785078}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.25938719511032104, '_timestamp': 1721968195.1789756}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20995409786701202, '_timestamp': 1721968195.1792953}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'ratio': 0.6646682620048523, '_timestamp': 1721968195.1793983}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721968195.179531}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968195.1797345}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.31220483779907, '_timestamp': 1721968195.1798685}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.22767328686044982, '_timestamp': 1721968195.1807947}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'train_goal': 0.3861633565697751, '_timestamp': 1721968195.1813204}).
wandb: WARNING (User provided step: 7397 is less than current step: 15000. Dropping entry: {'train_WDL': -0.22767328686044982, '_timestamp': 1721968195.1817865}).
Env Football Algo jrpo Exp base_JRPO updates 9641/100000000000.0 steps in 82.08
total episode rewards is -30.0
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'value_loss': 0.22308775107453888, '_timestamp': 1721968277.2661495}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'policy_loss': 0.028014071344708402, '_timestamp': 1721968277.266331}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.761662842432658, '_timestamp': 1721968277.2663968}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13063794374465942, '_timestamp': 1721968277.2664876}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1330336481332779, '_timestamp': 1721968277.2667482}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'ratio': 0.730271577835083, '_timestamp': 1721968277.2668521}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721968277.2669868}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968277.2672374}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'Episode_Time': 82.08348989486694, '_timestamp': 1721968277.2672975}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968277.2677808}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968277.2681527}).
wandb: WARNING (User provided step: 9641 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968277.268557}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'value_loss': 0.2189476202405058, '_timestamp': 1721968363.7258506}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'policy_loss': 0.03720100277588548, '_timestamp': 1721968363.726015}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.9614284531275432, '_timestamp': 1721968363.7260787}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30806851387023926, '_timestamp': 1721968363.7261655}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.5697230100631714, '_timestamp': 1721968363.7264223}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'ratio': 0.7578707337379456, '_timestamp': 1721968363.7265263}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721968363.7266595}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968363.7267501}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.45562481880188, '_timestamp': 1721968363.7268808}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968363.7273908}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968363.7277594}).
wandb: WARNING (User provided step: 9094 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968363.728153}).
Env Football Algo jrpo Exp base_JRPO updates 9094/100000000000.0 steps in 86.46
total episode rewards is -30.0
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'value_loss': 0.2624317749438342, '_timestamp': 1721968449.8857937}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'policy_loss': 0.019940181490965186, '_timestamp': 1721968449.8859591}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.912811210155487, '_timestamp': 1721968449.886026}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.274487167596817, '_timestamp': 1721968449.8861156}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2232283055782318, '_timestamp': 1721968449.8863792}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'ratio': 0.7981947064399719, '_timestamp': 1721968449.8864846}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721968449.8866181}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968449.8868036}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.1566834449768, '_timestamp': 1721968449.8868618}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.16818960593946317, '_timestamp': 1721968449.8874109}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'train_goal': 0.4159051970302684, '_timestamp': 1721968449.887828}).
wandb: WARNING (User provided step: 7996 is less than current step: 15000. Dropping entry: {'train_WDL': -0.16818960593946317, '_timestamp': 1721968449.888293}).
Env Football Algo jrpo Exp base_JRPO updates 7996/100000000000.0 steps in 86.16
total episode rewards is -10.0
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'value_loss': 0.2908347101788968, '_timestamp': 1721968540.161013}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'policy_loss': 0.059811534724891924, '_timestamp': 1721968540.1613176}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7046684416135152, '_timestamp': 1721968540.1613896}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.32517898082733154, '_timestamp': 1721968540.1619496}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.16823352873325348, '_timestamp': 1721968540.162255}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'ratio': 0.819770097732544, '_timestamp': 1721968540.1623597}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968540.1624951}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968540.1627634}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.27151846885681, '_timestamp': 1721968540.162824}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968540.163509}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968540.163841}).
wandb: WARNING (User provided step: 10242 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968540.1641874}).
Env Football Algo jrpo Exp base_JRPO updates 10242/100000000000.0 steps in 90.27
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 8476/100000000000.0 steps in 85.29
total episode rewards is -10.0
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'value_loss': 0.263099015331051, '_timestamp': 1721968625.4545975}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'policy_loss': 0.027369236268180733, '_timestamp': 1721968625.454773}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6101857590675355, '_timestamp': 1721968625.4548392}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.29034310579299927, '_timestamp': 1721968625.45493}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.29756495356559753, '_timestamp': 1721968625.4551842}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'ratio': 0.8348003625869751, '_timestamp': 1721968625.4552882}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721968625.4554207}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968625.455514}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.28939414024353, '_timestamp': 1721968625.4558344}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.09227467811158799, '_timestamp': 1721968625.456456}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'train_goal': 0.453862660944206, '_timestamp': 1721968625.4568794}).
wandb: WARNING (User provided step: 8476 is less than current step: 15000. Dropping entry: {'train_WDL': -0.09227467811158799, '_timestamp': 1721968625.4572918}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'value_loss': 0.18499393168565195, '_timestamp': 1721968713.959038}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'policy_loss': 0.02206407952090861, '_timestamp': 1721968713.9592493}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.418363524278005, '_timestamp': 1721968713.9593196}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.19455447793006897, '_timestamp': 1721968713.9594216}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.203498974442482, '_timestamp': 1721968713.9597192}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'ratio': 0.8554325699806213, '_timestamp': 1721968713.959837}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721968713.9599855}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968713.9605794}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.50071024894714, '_timestamp': 1721968713.9606462}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968713.9615033}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968713.9619}).
wandb: WARNING (User provided step: 9931 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968713.9622836}).
Env Football Algo jrpo Exp base_JRPO updates 9931/100000000000.0 steps in 88.50
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 7827/100000000000.0 steps in 80.42
total episode rewards is -40.0
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'value_loss': 0.2968868280388415, '_timestamp': 1721968794.3919919}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00871905603732254, '_timestamp': 1721968794.3932314}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.450797115166982, '_timestamp': 1721968794.3933096}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.23594491183757782, '_timestamp': 1721968794.3937798}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20437733829021454, '_timestamp': 1721968794.3941214}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'ratio': 0.9583337903022766, '_timestamp': 1721968794.394231}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721968794.394364}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968794.3950307}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.42415857315063, '_timestamp': 1721968794.395093}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721968794.3963044}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721968794.3968322}).
wandb: WARNING (User provided step: 7827 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721968794.397295}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'value_loss': 0.16785182503207277, '_timestamp': 1721968882.3780088}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'policy_loss': 0.008149868621840141, '_timestamp': 1721968882.37819}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4535956422487895, '_timestamp': 1721968882.3782556}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40165334939956665, '_timestamp': 1721968882.3783534}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.28193891048431396, '_timestamp': 1721968882.3786266}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'ratio': 0.8776553273200989, '_timestamp': 1721968882.3787298}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721968882.3789847}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968882.3790781}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.97961831092834, '_timestamp': 1721968882.379137}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.12120046171604464, '_timestamp': 1721968882.379662}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'train_goal': 0.5606002308580224, '_timestamp': 1721968882.3800223}).
wandb: WARNING (User provided step: 9802 is less than current step: 15000. Dropping entry: {'train_WDL': 0.12120046171604464, '_timestamp': 1721968882.380366}).
Env Football Algo jrpo Exp base_JRPO updates 9802/100000000000.0 steps in 87.98
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 11138/100000000000.0 steps in 85.13
total episode rewards is 0.0
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'value_loss': 0.14794509066074776, '_timestamp': 1721968967.5213888}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01391174460547821, '_timestamp': 1721968967.522778}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5449145007133485, '_timestamp': 1721968967.5228508}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3681645095348358, '_timestamp': 1721968967.523371}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25924181938171387, '_timestamp': 1721968967.523748}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'ratio': 0.9221556782722473, '_timestamp': 1721968967.5238535}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721968967.5240185}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721968967.5246677}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.13462138175964, '_timestamp': 1721968967.5247302}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.5416882444329363, '_timestamp': 1721968967.5256803}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'train_goal': 0.7708441222164681, '_timestamp': 1721968967.5259683}).
wandb: WARNING (User provided step: 11138 is less than current step: 15000. Dropping entry: {'train_WDL': 0.5416882444329363, '_timestamp': 1721968967.5262496}).
Env Football Algo jrpo Exp base_JRPO updates 10192/100000000000.0 steps in 80.49
total episode rewards is -30.0
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'value_loss': 0.24407950916327537, '_timestamp': 1721969048.0175374}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'policy_loss': 0.01947058832583328, '_timestamp': 1721969048.0177004}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.525564617315928, '_timestamp': 1721969048.0177667}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16969826817512512, '_timestamp': 1721969048.0178566}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18333688378334045, '_timestamp': 1721969048.0181184}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'ratio': 0.8865586519241333, '_timestamp': 1721969048.0182214}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721969048.0183527}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969048.0186322}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.49034214019775, '_timestamp': 1721969048.0186923}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969048.0191875}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969048.0195081}).
wandb: WARNING (User provided step: 10192 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969048.019837}).
Env Football Algo jrpo Exp base_JRPO updates 10724/100000000000.0 steps in 87.47
total episode rewards is -10.0
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'value_loss': 0.22607209188863636, '_timestamp': 1721969135.4910252}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006778669392618516, '_timestamp': 1721969135.491313}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5749303754170736, '_timestamp': 1721969135.4914079}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.312305748462677, '_timestamp': 1721969135.4915545}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.342303991317749, '_timestamp': 1721969135.491841}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'ratio': 0.8866732120513916, '_timestamp': 1721969135.4919803}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721969135.4921255}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969135.4926987}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.47015929222107, '_timestamp': 1721969135.4927616}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2960710944808232, '_timestamp': 1721969135.493452}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'train_goal': 0.3519644527595884, '_timestamp': 1721969135.4937906}).
wandb: WARNING (User provided step: 10724 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2960710944808232, '_timestamp': 1721969135.4941373}).
Env Football Algo jrpo Exp base_JRPO updates 5004/100000000000.0 steps in 88.80
total episode rewards is 0.0
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'value_loss': 0.3123130486874531, '_timestamp': 1721969224.3001022}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0006587022073411693, '_timestamp': 1721969224.3002796}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5808071557680765, '_timestamp': 1721969224.3003457}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.33677417039871216, '_timestamp': 1721969224.300438}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4843716621398926, '_timestamp': 1721969224.3006992}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'ratio': 0.9257545471191406, '_timestamp': 1721969224.3008027}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721969224.300935}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969224.3011081}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.80475091934204, '_timestamp': 1721969224.3011668}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.1676670668267307, '_timestamp': 1721969224.3019156}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'train_goal': 0.5838335334133653, '_timestamp': 1721969224.3024962}).
wandb: WARNING (User provided step: 5004 is less than current step: 15000. Dropping entry: {'train_WDL': 0.1676670668267307, '_timestamp': 1721969224.303091}).
Env Football Algo jrpo Exp base_JRPO updates 5972/100000000000.0 steps in 80.10
total episode rewards is 0.0
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'value_loss': 0.34963977135485036, '_timestamp': 1721969304.3997946}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'policy_loss': 0.005158638973565151, '_timestamp': 1721969304.4000494}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5428364857037862, '_timestamp': 1721969304.4001205}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40638867020606995, '_timestamp': 1721969304.4002159}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20268690586090088, '_timestamp': 1721969304.4004793}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'ratio': 0.9305380582809448, '_timestamp': 1721969304.400586}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721969304.4012892}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969304.401392}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.09582138061523, '_timestamp': 1721969304.4014525}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.028577758085954807, '_timestamp': 1721969304.4028559}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'train_goal': 0.4857111209570226, '_timestamp': 1721969304.4037988}).
wandb: WARNING (User provided step: 5972 is less than current step: 15000. Dropping entry: {'train_WDL': -0.028577758085954807, '_timestamp': 1721969304.4043791}).
Env Football Algo jrpo Exp base_JRPO updates 9836/100000000000.0 steps in 91.29
total episode rewards is -20.0
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'value_loss': 0.34656231803198656, '_timestamp': 1721969395.7019444}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'policy_loss': 0.011372815568077689, '_timestamp': 1721969395.703263}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4916865921020508, '_timestamp': 1721969395.703338}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2818577289581299, '_timestamp': 1721969395.7038221}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.22640688717365265, '_timestamp': 1721969395.704186}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'ratio': 0.8983393311500549, '_timestamp': 1721969395.7042942}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969395.704468}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969395.7052464}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.29161500930786, '_timestamp': 1721969395.705311}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.6494965143299768, '_timestamp': 1721969395.7064292}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'train_goal': 0.17525174283501163, '_timestamp': 1721969395.7068212}).
wandb: WARNING (User provided step: 9836 is less than current step: 15000. Dropping entry: {'train_WDL': -0.6494965143299768, '_timestamp': 1721969395.7072537}).
Env Football Algo jrpo Exp base_JRPO updates 8958/100000000000.0 steps in 87.98
total episode rewards is -20.0
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'value_loss': 0.3159732356262005, '_timestamp': 1721969483.689085}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010546750709569702, '_timestamp': 1721969483.6892676}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4714782738685608, '_timestamp': 1721969483.6893368}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.22237277030944824, '_timestamp': 1721969483.6894307}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.25507938861846924, '_timestamp': 1721969483.6896873}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'ratio': 0.9124752283096313, '_timestamp': 1721969483.6898012}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969483.6901808}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969483.6902747}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.98097085952759, '_timestamp': 1721969483.690332}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.026812313803376366, '_timestamp': 1721969483.690938}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'train_goal': 0.48659384309831183, '_timestamp': 1721969483.6913242}).
wandb: WARNING (User provided step: 8958 is less than current step: 15000. Dropping entry: {'train_WDL': -0.026812313803376366, '_timestamp': 1721969483.6917126}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'value_loss': 0.17304342771375864, '_timestamp': 1721969567.5299225}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'policy_loss': 0.04533839943896358, '_timestamp': 1721969567.5301049}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.093270407517751, '_timestamp': 1721969567.5301752}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5020360946655273, '_timestamp': 1721969567.530271}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3680602014064789, '_timestamp': 1721969567.5305765}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'ratio': 1.0008330345153809, '_timestamp': 1721969567.5306816}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969567.5308158}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969567.5311906}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.83721208572388, '_timestamp': 1721969567.5312512}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969567.5317483}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969567.5321572}).
wandb: WARNING (User provided step: 11148 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969567.5324643}).
Env Football Algo jrpo Exp base_JRPO updates 11148/100000000000.0 steps in 83.84
total episode rewards is -20.0
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'value_loss': 0.3375315917135837, '_timestamp': 1721969656.6605325}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00949432166138043, '_timestamp': 1721969656.660742}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.298536020119985, '_timestamp': 1721969656.6608102}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.44116848707199097, '_timestamp': 1721969656.6609156}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.295261412858963, '_timestamp': 1721969656.6613367}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'ratio': 0.9262539744377136, '_timestamp': 1721969656.6620018}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 20.0, '_timestamp': 1721969656.662154}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969656.6622574}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.12687373161316, '_timestamp': 1721969656.6623166}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.24679582712369597, '_timestamp': 1721969656.6629288}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'train_goal': 0.623397913561848, '_timestamp': 1721969656.6633723}).
wandb: WARNING (User provided step: 8290 is less than current step: 15000. Dropping entry: {'train_WDL': 0.24679582712369597, '_timestamp': 1721969656.6637998}).
Env Football Algo jrpo Exp base_JRPO updates 8290/100000000000.0 steps in 89.13
total episode rewards is 20.0
Env Football Algo jrpo Exp base_JRPO updates 9516/100000000000.0 steps in 75.57
total episode rewards is -20.0
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'value_loss': 0.45491292818449436, '_timestamp': 1721969732.2432868}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0007963510416448117, '_timestamp': 1721969732.2444324}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3184568230311076, '_timestamp': 1721969732.2445064}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4610869884490967, '_timestamp': 1721969732.2447147}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.48554444313049316, '_timestamp': 1721969732.2450178}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'ratio': 0.9359092712402344, '_timestamp': 1721969732.2451282}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969732.25062}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969732.2508285}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'Episode_Time': 75.5698356628418, '_timestamp': 1721969732.2514143}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3411885245901639, '_timestamp': 1721969732.2522974}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'train_goal': 0.670594262295082, '_timestamp': 1721969732.2526028}).
wandb: WARNING (User provided step: 9516 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3411885245901639, '_timestamp': 1721969732.2528956}).
Env Football Algo jrpo Exp base_JRPO updates 10423/100000000000.0 steps in 85.72
total episode rewards is -20.0
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'value_loss': 0.15585957557409225, '_timestamp': 1721969817.9761546}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00901259316286693, '_timestamp': 1721969817.976335}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1645861713091532, '_timestamp': 1721969817.9764037}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06694363057613373, '_timestamp': 1721969817.9764993}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.07886690646409988, '_timestamp': 1721969817.9767854}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'ratio': 1.6042722463607788, '_timestamp': 1721969817.9768918}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721969817.9770288}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969817.9777167}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.7223789691925, '_timestamp': 1721969817.9777787}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721969817.9782202}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721969817.9785423}).
wandb: WARNING (User provided step: 10423 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721969817.978868}).
Env Football Algo jrpo Exp base_JRPO updates 9456/100000000000.0 steps in 88.14
total episode rewards is 0.0
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'value_loss': 0.3118876776836502, '_timestamp': 1721969906.1159344}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0032957985668084196, '_timestamp': 1721969906.1161885}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3100526801745096, '_timestamp': 1721969906.116262}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3392220437526703, '_timestamp': 1721969906.1163576}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2762022018432617, '_timestamp': 1721969906.1166286}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'ratio': 0.9428550601005554, '_timestamp': 1721969906.1167362}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721969906.1168768}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969906.1172762}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.13606381416321, '_timestamp': 1721969906.117339}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.13347763347763347, '_timestamp': 1721969906.1180127}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_goal': 0.5667388167388168, '_timestamp': 1721969906.1184335}).
wandb: WARNING (User provided step: 9456 is less than current step: 15000. Dropping entry: {'train_WDL': 0.13347763347763347, '_timestamp': 1721969906.1187942}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'value_loss': 0.07729683664845652, '_timestamp': 1721969987.2834141}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'policy_loss': 0.011553641753271221, '_timestamp': 1721969987.2835867}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2671277443567912, '_timestamp': 1721969987.2836516}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4630718529224396, '_timestamp': 1721969987.2837422}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.0669320672750473, '_timestamp': 1721969987.284028}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'ratio': 0.9335432052612305, '_timestamp': 1721969987.2842944}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721969987.2844288}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721969987.2845204}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.16354441642761, '_timestamp': 1721969987.2845776}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_goal_diff': 1.0, '_timestamp': 1721969987.2850928}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_goal': 1.0, '_timestamp': 1721969987.2853289}).
wandb: WARNING (User provided step: 12052 is less than current step: 15000. Dropping entry: {'train_WDL': 1.0, '_timestamp': 1721969987.2855482}).
Env Football Algo jrpo Exp base_JRPO updates 12052/100000000000.0 steps in 81.16
total episode rewards is 10.0
Env Football Algo jrpo Exp base_JRPO updates 11094/100000000000.0 steps in 85.70
total episode rewards is -30.0
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'value_loss': 0.22644344437537559, '_timestamp': 1721970072.9886198}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0015519931118857736, '_timestamp': 1721970072.9888966}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.433798520565033, '_timestamp': 1721970072.98897}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12944576144218445, '_timestamp': 1721970072.9891126}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3473999798297882, '_timestamp': 1721970072.9893973}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'ratio': 0.9246048927307129, '_timestamp': 1721970072.9895058}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721970072.9953642}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970072.9962418}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.70194029808044, '_timestamp': 1721970072.9963102}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970072.996958}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970072.9972878}).
wandb: WARNING (User provided step: 11094 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970072.9976013}).
Env Football Algo jrpo Exp base_JRPO updates 10340/100000000000.0 steps in 87.82
total episode rewards is -10.0
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'value_loss': 0.24287628337498365, '_timestamp': 1721970160.8276877}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0056746345695379815, '_timestamp': 1721970160.8290133}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4227720228830973, '_timestamp': 1721970160.829085}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.27475184202194214, '_timestamp': 1721970160.8295667}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1805393397808075, '_timestamp': 1721970160.8303297}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'ratio': 0.9465235471725464, '_timestamp': 1721970160.8304393}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721970160.830577}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970160.8307822}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.82384037971497, '_timestamp': 1721970160.830842}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.2575107296137339, '_timestamp': 1721970160.831757}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'train_goal': 0.628755364806867, '_timestamp': 1721970160.832097}).
wandb: WARNING (User provided step: 10340 is less than current step: 15000. Dropping entry: {'train_WDL': 0.2575107296137339, '_timestamp': 1721970160.8324142}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'value_loss': 0.2572045930154854, '_timestamp': 1721970240.4936059}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0029200796297906588, '_timestamp': 1721970240.493786}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4676061407725016, '_timestamp': 1721970240.4938552}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.09260345995426178, '_timestamp': 1721970240.4939525}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21198640763759613, '_timestamp': 1721970240.4942093}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'ratio': 0.9696522355079651, '_timestamp': 1721970240.4943135}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721970240.494671}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970240.4947662}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.66032719612122, '_timestamp': 1721970240.494825}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970240.4953928}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970240.4958346}).
wandb: WARNING (User provided step: 7758 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970240.4963267}).
Env Football Algo jrpo Exp base_JRPO updates 7758/100000000000.0 steps in 79.66
total episode rewards is -30.0
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'value_loss': 0.07446919604990399, '_timestamp': 1721970329.9073849}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'policy_loss': 0.012990442438361545, '_timestamp': 1721970329.9075897}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.409638074239095, '_timestamp': 1721970329.9076574}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06106602028012276, '_timestamp': 1721970329.9077594}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.04986587166786194, '_timestamp': 1721970329.9080074}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'ratio': 0.9177038669586182, '_timestamp': 1721970329.9082172}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721970329.9083478}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970329.908441}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.4099953174591, '_timestamp': 1721970329.9084973}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970329.9088392}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970329.9090695}).
wandb: WARNING (User provided step: 12336 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970329.9092944}).
Env Football Algo jrpo Exp base_JRPO updates 12336/100000000000.0 steps in 89.41
total episode rewards is -10.0
Env Football Algo jrpo Exp base_JRPO updates 12851/100000000000.0 steps in 91.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'value_loss': 0.24826108350845363, '_timestamp': 1721970421.432909}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'policy_loss': 0.014627216154282602, '_timestamp': 1721970421.4330895}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4680736629168192, '_timestamp': 1721970421.433159}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28233441710472107, '_timestamp': 1721970421.4332576}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2065434753894806, '_timestamp': 1721970421.4335291}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'ratio': 0.9340426921844482, '_timestamp': 1721970421.4336402}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721970421.434074}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970421.4341717}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.52280902862549, '_timestamp': 1721970421.4342318}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970421.434533}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970421.4347417}).
wandb: WARNING (User provided step: 12851 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970421.4350207}).
Env Football Algo jrpo Exp base_JRPO updates 6224/100000000000.0 steps in 77.45
total episode rewards is -10.0
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'value_loss': 0.41346444164635615, '_timestamp': 1721970498.881153}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0026762235638064643, '_timestamp': 1721970498.8813248}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5704999121030172, '_timestamp': 1721970498.8813915}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.31396016478538513, '_timestamp': 1721970498.8814845}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.308645099401474, '_timestamp': 1721970498.8817387}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'ratio': 0.971662700176239, '_timestamp': 1721970498.8819425}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721970498.8820708}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970498.8821602}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.44532179832458, '_timestamp': 1721970498.8822162}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.19671140128158626, '_timestamp': 1721970498.882866}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'train_goal': 0.5983557006407931, '_timestamp': 1721970498.8833501}).
wandb: WARNING (User provided step: 6224 is less than current step: 15000. Dropping entry: {'train_WDL': 0.19671140128158626, '_timestamp': 1721970498.8838491}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'value_loss': 0.1607832193186429, '_timestamp': 1721970586.7642741}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'policy_loss': 0.009454367968161629, '_timestamp': 1721970586.7644656}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4458453758557637, '_timestamp': 1721970586.7645347}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3992316722869873, '_timestamp': 1721970586.764634}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.17664454877376556, '_timestamp': 1721970586.7649646}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'ratio': 0.9213945865631104, '_timestamp': 1721970586.7650745}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721970586.7659197}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970586.766019}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.87948513031006, '_timestamp': 1721970586.7660787}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.39095619406500237, '_timestamp': 1721970586.7666094}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'train_goal': 0.6954780970325012, '_timestamp': 1721970586.766939}).
wandb: WARNING (User provided step: 10754 is less than current step: 15000. Dropping entry: {'train_WDL': 0.39095619406500237, '_timestamp': 1721970586.767265}).
Env Football Algo jrpo Exp base_JRPO updates 10754/100000000000.0 steps in 87.88
total episode rewards is 0.0
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'value_loss': 0.15043478971662505, '_timestamp': 1721970670.7164433}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'policy_loss': 0.018600318178844947, '_timestamp': 1721970670.7166216}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5716465838750204, '_timestamp': 1721970670.7166915}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28104567527770996, '_timestamp': 1721970670.716785}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15334586799144745, '_timestamp': 1721970670.7170486}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'ratio': 0.9681240320205688, '_timestamp': 1721970670.7171543}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721970670.7178075}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970670.7179132}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.94837284088135, '_timestamp': 1721970670.717974}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970670.7184455}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970670.7187796}).
wandb: WARNING (User provided step: 10239 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970670.7191231}).
Env Football Algo jrpo Exp base_JRPO updates 10239/100000000000.0 steps in 83.95
total episode rewards is -20.0
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'value_loss': 0.2264059635034452, '_timestamp': 1721970754.2716682}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0010027633412149346, '_timestamp': 1721970754.2719178}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5825279966990153, '_timestamp': 1721970754.272002}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1870126575231552, '_timestamp': 1721970754.2721493}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.19875597953796387, '_timestamp': 1721970754.2724583}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'ratio': 0.9591612815856934, '_timestamp': 1721970754.2725635}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721970754.273397}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970754.2735143}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.55121493339539, '_timestamp': 1721970754.2735727}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970754.2740405}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970754.2743595}).
wandb: WARNING (User provided step: 10699 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970754.2746854}).
Env Football Algo jrpo Exp base_JRPO updates 10699/100000000000.0 steps in 83.55
total episode rewards is -30.0
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'value_loss': 0.49315199656256786, '_timestamp': 1721970818.4364028}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'policy_loss': 0.017924173088686074, '_timestamp': 1721970818.4366224}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6715606983502707, '_timestamp': 1721970818.436694}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.30549803376197815, '_timestamp': 1721970818.4368207}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.587462842464447, '_timestamp': 1721970818.4370904}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'ratio': 0.8875982761383057, '_timestamp': 1721970818.4376817}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -60.0, '_timestamp': 1721970818.4378195}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970818.4379132}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'Episode_Time': 64.16050267219543, '_timestamp': 1721970818.4379692}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970818.438456}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970818.4388177}).
wandb: WARNING (User provided step: 4451 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970818.439242}).
Env Football Algo jrpo Exp base_JRPO updates 4451/100000000000.0 steps in 64.16
total episode rewards is -60.0
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'value_loss': 0.07725170321684952, '_timestamp': 1721970898.8725154}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'policy_loss': 0.015484253584509134, '_timestamp': 1721970898.8727067}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.759695417881012, '_timestamp': 1721970898.8727753}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.21566763520240784, '_timestamp': 1721970898.8728726}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21903738379478455, '_timestamp': 1721970898.8731394}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'ratio': 0.6916469931602478, '_timestamp': 1721970898.8732414}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721970898.8735995}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970898.8736978}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.43215322494507, '_timestamp': 1721970898.8737552}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721970898.8740819}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721970898.8742886}).
wandb: WARNING (User provided step: 12716 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721970898.874493}).
Env Football Algo jrpo Exp base_JRPO updates 12716/100000000000.0 steps in 80.43
total episode rewards is -10.0
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'value_loss': 0.34448971875205947, '_timestamp': 1721970987.967765}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0019382160895717487, '_timestamp': 1721970987.96915}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.733605392773946, '_timestamp': 1721970987.9692242}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3993885815143585, '_timestamp': 1721970987.9697378}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1977412849664688, '_timestamp': 1721970987.970119}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'ratio': 1.0427051782608032, '_timestamp': 1721970987.970224}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721970987.9708815}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721970987.9711015}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.08710527420044, '_timestamp': 1721970987.971161}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2920077034183919, '_timestamp': 1721970987.9723248}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'train_goal': 0.35399614829080406, '_timestamp': 1721970987.9731338}).
wandb: WARNING (User provided step: 6692 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2920077034183919, '_timestamp': 1721970987.9736376}).
Env Football Algo jrpo Exp base_JRPO updates 6692/100000000000.0 steps in 89.09
total episode rewards is -20.0
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'value_loss': 0.22770046019519213, '_timestamp': 1721971077.3017776}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'policy_loss': 0.010609860482315223, '_timestamp': 1721971077.3019378}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.7196549169222515, '_timestamp': 1721971077.3020036}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3486140966415405, '_timestamp': 1721971077.302093}).
Env Football Algo jrpo Exp base_JRPO updates 11681/100000000000.0 steps in 89.33
total episode rewards is -30.0
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'ratio': 0.9445858001708984, '_timestamp': 1721971077.302455}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721971077.3027844}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971077.3028772}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.3273332118988, '_timestamp': 1721971077.3029351}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971077.3034604}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971077.303709}).
wandb: WARNING (User provided step: 11681 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971077.3041089}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'value_loss': 0.15272523604682647, '_timestamp': 1721971157.8283114}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'policy_loss': 0.013152875201776625, '_timestamp': 1721971157.8284767}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6375426244735718, '_timestamp': 1721971157.8285432}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5954365730285645, '_timestamp': 1721971157.8286352}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20247338712215424, '_timestamp': 1721971157.8288867}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'ratio': 0.9365798234939575, '_timestamp': 1721971157.828988}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971157.8291216}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971157.8293364}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.52305507659912, '_timestamp': 1721971157.829397}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971157.8296018}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971157.8297293}).
wandb: WARNING (User provided step: 14195 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971157.829856}).
Env Football Algo jrpo Exp base_JRPO updates 14195/100000000000.0 steps in 80.52
total episode rewards is -20.0
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'value_loss': 0.30363763872698957, '_timestamp': 1721971239.432051}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004892311716297021, '_timestamp': 1721971239.4322283}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.6050788593292236, '_timestamp': 1721971239.4322968}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18153947591781616, '_timestamp': 1721971239.4323926}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23749437928199768, '_timestamp': 1721971239.4326704}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'ratio': 0.9611570239067078, '_timestamp': 1721971239.4327784}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721971239.4333029}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971239.4334004}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.60145998001099, '_timestamp': 1721971239.4334564}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971239.4339678}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971239.4343643}).
wandb: WARNING (User provided step: 8799 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971239.4347734}).
Env Football Algo jrpo Exp base_JRPO updates 8799/100000000000.0 steps in 81.60
total episode rewards is -40.0
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'value_loss': 0.1593355524590394, '_timestamp': 1721971327.2707028}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00870677142792071, '_timestamp': 1721971327.2708821}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5582811331748962, '_timestamp': 1721971327.2709517}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.16462375223636627, '_timestamp': 1721971327.2710526}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14325377345085144, '_timestamp': 1721971327.2713478}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'ratio': 0.9796715378761292, '_timestamp': 1721971327.271461}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971327.2715943}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971327.2724063}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.83510494232178, '_timestamp': 1721971327.2724729}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971327.2729528}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971327.273251}).
wandb: WARNING (User provided step: 10872 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971327.2735548}).
Env Football Algo jrpo Exp base_JRPO updates 10872/100000000000.0 steps in 87.84
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 83.22
total episode rewards is 0.0
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'value_loss': 0.2824601147188029, '_timestamp': 1721971493.588587}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0055481497512664645, '_timestamp': 1721971493.5887501}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5407104476292928, '_timestamp': 1721971493.58882}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6382808089256287, '_timestamp': 1721971493.588909}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.4589097201824188, '_timestamp': 1721971493.5891542}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'ratio': 0.9879314303398132, '_timestamp': 1721971493.5892577}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721971493.589395}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971493.5894876}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.09399032592773, '_timestamp': 1721971493.5895433}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2849382716049383, '_timestamp': 1721971493.5901346}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'train_goal': 0.3575308641975309, '_timestamp': 1721971493.590615}).
wandb: WARNING (User provided step: 6900 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2849382716049383, '_timestamp': 1721971493.5911126}).
Env Football Algo jrpo Exp base_JRPO updates 6900/100000000000.0 steps in 83.09
total episode rewards is -10.0
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'value_loss': 0.320574180688709, '_timestamp': 1721971581.1114867}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0034914763621054588, '_timestamp': 1721971581.1116636}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5136159825325013, '_timestamp': 1721971581.1117327}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.48799651861190796, '_timestamp': 1721971581.1118286}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.11751410365104675, '_timestamp': 1721971581.11212}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'ratio': 0.9662256240844727, '_timestamp': 1721971581.1122262}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721971581.1123605}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971581.112456}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.51955652236938, '_timestamp': 1721971581.1125147}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.39402798078930884, '_timestamp': 1721971581.113211}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'train_goal': 0.3029860096053456, '_timestamp': 1721971581.1137826}).
wandb: WARNING (User provided step: 5422 is less than current step: 15000. Dropping entry: {'train_WDL': -0.39402798078930884, '_timestamp': 1721971581.1143582}).
Env Football Algo jrpo Exp base_JRPO updates 5422/100000000000.0 steps in 87.52
total episode rewards is -20.0
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'value_loss': 0.2095852481527254, '_timestamp': 1721971666.0279129}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'policy_loss': -0.003785885422597251, '_timestamp': 1721971666.0289845}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5419867340723674, '_timestamp': 1721971666.029057}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.26223939657211304, '_timestamp': 1721971666.029451}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.08224322646856308, '_timestamp': 1721971666.0297759}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'ratio': 0.8451578617095947, '_timestamp': 1721971666.0298834}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721971666.0300121}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971666.030191}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.90898513793945, '_timestamp': 1721971666.0302498}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971666.0310676}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971666.0316963}).
wandb: WARNING (User provided step: 8072 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971666.032169}).
Env Football Algo jrpo Exp base_JRPO updates 8072/100000000000.0 steps in 84.91
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 6627/100000000000.0 steps in 86.29
total episode rewards is -40.0
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'value_loss': 0.3320001843230178, '_timestamp': 1721971752.3254669}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00537502387242057, '_timestamp': 1721971752.3256748}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5051076531410217, '_timestamp': 1721971752.3257477}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.28106221556663513, '_timestamp': 1721971752.3258653}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2567301392555237, '_timestamp': 1721971752.3261352}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'ratio': 0.9724107980728149, '_timestamp': 1721971752.3262408}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721971752.3264616}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971752.3265836}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.2922477722168, '_timestamp': 1721971752.3266447}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971752.3272681}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971752.3277686}).
wandb: WARNING (User provided step: 6627 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971752.3283007}).
Env Football Algo jrpo Exp base_JRPO updates 8998/100000000000.0 steps in 86.40
total episode rewards is 10.0
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'value_loss': 0.2555249174622198, '_timestamp': 1721971838.7307312}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'policy_loss': 0.00043439578230997235, '_timestamp': 1721971838.7320635}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4962777503331501, '_timestamp': 1721971838.732137}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5767080783843994, '_timestamp': 1721971838.732631}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15383559465408325, '_timestamp': 1721971838.7329898}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'ratio': 0.9579412341117859, '_timestamp': 1721971838.7330966}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721971838.733233}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971838.7334418}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.39610004425049, '_timestamp': 1721971838.7335}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.951682772409197, '_timestamp': 1721971838.7346916}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'train_goal': 0.9758413862045985, '_timestamp': 1721971838.7351053}).
wandb: WARNING (User provided step: 8998 is less than current step: 15000. Dropping entry: {'train_WDL': 0.951682772409197, '_timestamp': 1721971838.735622}).
Env Football Algo jrpo Exp base_JRPO updates 11494/100000000000.0 steps in 80.54
total episode rewards is -30.0
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'value_loss': 0.22681585597495238, '_timestamp': 1721971919.2761712}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0062749336349467435, '_timestamp': 1721971919.276386}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4796385582288105, '_timestamp': 1721971919.2764559}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6605899333953857, '_timestamp': 1721971919.2765536}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2263260930776596, '_timestamp': 1721971919.2768168}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'ratio': 0.970560610294342, '_timestamp': 1721971919.2769194}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721971919.2770462}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721971919.2771375}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.53960943222046, '_timestamp': 1721971919.2771933}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721971919.2777276}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721971919.2780073}).
wandb: WARNING (User provided step: 11494 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721971919.278285}).
Env Football Algo jrpo Exp base_JRPO updates 14856/100000000000.0 steps in 87.35
total episode rewards is -10.0
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'value_loss': 0.07613960684490545, '_timestamp': 1721972006.6314194}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'policy_loss': 0.006272174373734742, '_timestamp': 1721972006.6316452}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4704252481460571, '_timestamp': 1721972006.6317427}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5443539023399353, '_timestamp': 1721972006.6318557}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.24205555021762848, '_timestamp': 1721972006.6321938}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'ratio': 0.97079998254776, '_timestamp': 1721972006.6323528}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721972006.6325226}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972006.6326406}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.35228371620178, '_timestamp': 1721972006.6327038}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972006.6329021}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972006.6330054}).
wandb: WARNING (User provided step: 14856 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972006.633095}).
Env Football Algo jrpo Exp base_JRPO updates 14310/100000000000.0 steps in 84.38
total episode rewards is -20.0
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'value_loss': 0.15904006168401488, '_timestamp': 1721972091.0118535}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005236706410845121, '_timestamp': 1721972091.0121617}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4581304287910462, '_timestamp': 1721972091.0122328}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18452106416225433, '_timestamp': 1721972091.0123348}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2336510568857193, '_timestamp': 1721972091.01261}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'ratio': 0.9605854749679565, '_timestamp': 1721972091.0127125}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972091.0129893}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972091.0131261}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.37760186195374, '_timestamp': 1721972091.0131848}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972091.0138388}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972091.0139701}).
wandb: WARNING (User provided step: 14310 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972091.0140896}).
Env Football Algo jrpo Exp base_JRPO updates 10849/100000000000.0 steps in 81.42
total episode rewards is -40.0
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'value_loss': 0.3056547285243869, '_timestamp': 1721972172.4396427}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0006169638817664235, '_timestamp': 1721972172.4409215}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4485166954994202, '_timestamp': 1721972172.440997}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.7157662510871887, '_timestamp': 1721972172.4414978}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2086658924818039, '_timestamp': 1721972172.441862}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'ratio': 0.9614381194114685, '_timestamp': 1721972172.441969}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721972172.4421065}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972172.4423044}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.41979718208313, '_timestamp': 1721972172.4423687}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972172.443246}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972172.4435556}).
wandb: WARNING (User provided step: 10849 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972172.4438608}).
Env Football Algo jrpo Exp base_JRPO updates 8905/100000000000.0 steps in 90.01
total episode rewards is -10.0
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'value_loss': 0.24871897650882602, '_timestamp': 1721972262.4554193}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'policy_loss': -0.003986174981109798, '_timestamp': 1721972262.4555912}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.483064002195994, '_timestamp': 1721972262.4556613}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.4284161925315857, '_timestamp': 1721972262.4557588}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14017529785633087, '_timestamp': 1721972262.4560354}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'ratio': 0.9224922060966492, '_timestamp': 1721972262.4561448}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721972262.4562833}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972262.4563766}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.01066327095032, '_timestamp': 1721972262.4564376}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.045447087776866284, '_timestamp': 1721972262.4569516}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'train_goal': 0.4772764561115669, '_timestamp': 1721972262.4573348}).
wandb: WARNING (User provided step: 8905 is less than current step: 15000. Dropping entry: {'train_WDL': -0.045447087776866284, '_timestamp': 1721972262.4577289}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'value_loss': 0.24665394493378698, '_timestamp': 1721972349.193645}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0010421516136072265, '_timestamp': 1721972349.1938343}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4993977165222168, '_timestamp': 1721972349.1939034}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5684496760368347, '_timestamp': 1721972349.194001}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15533947944641113, '_timestamp': 1721972349.1942785}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'ratio': 0.9670208692550659, '_timestamp': 1721972349.194389}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721972349.1945155}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972349.1946099}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.73489284515381, '_timestamp': 1721972349.1946661}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.0012087722327749958, '_timestamp': 1721972349.195424}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'train_goal': 0.4993956138836125, '_timestamp': 1721972349.1958487}).
wandb: WARNING (User provided step: 9209 is less than current step: 15000. Dropping entry: {'train_WDL': -0.0012087722327749958, '_timestamp': 1721972349.1962364}).
Env Football Algo jrpo Exp base_JRPO updates 9209/100000000000.0 steps in 86.73
total episode rewards is -10.0
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'value_loss': 0.28527372968072695, '_timestamp': 1721972430.6176789}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'policy_loss': 0.002374349534511566, '_timestamp': 1721972430.61826}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.479861184755961, '_timestamp': 1721972430.6183324}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6350242495536804, '_timestamp': 1721972430.6185658}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.087564617395401, '_timestamp': 1721972430.6188574}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'ratio': 0.981401801109314, '_timestamp': 1721972430.6189666}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 10.0, '_timestamp': 1721972430.6190996}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972430.6192372}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.41838526725769, '_timestamp': 1721972430.6192997}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3692198245198008, '_timestamp': 1721972430.6202166}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'train_goal': 0.6846099122599004, '_timestamp': 1721972430.620717}).
wandb: WARNING (User provided step: 6566 is less than current step: 15000. Dropping entry: {'train_WDL': 0.3692198245198008, '_timestamp': 1721972430.621218}).
Env Football Algo jrpo Exp base_JRPO updates 6566/100000000000.0 steps in 81.42
total episode rewards is 10.0
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'value_loss': 0.15083441062519948, '_timestamp': 1721972516.9841292}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'policy_loss': -0.004896868198023488, '_timestamp': 1721972516.9843009}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5244661172231038, '_timestamp': 1721972516.9843655}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.231138214468956, '_timestamp': 1721972516.9844546}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.12343868613243103, '_timestamp': 1721972516.9847162}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'ratio': 0.887666642665863, '_timestamp': 1721972516.9848208}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972516.9849546}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972516.985044}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.36191725730896, '_timestamp': 1721972516.985099}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972516.9853163}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972516.985451}).
wandb: WARNING (User provided step: 13959 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972516.985585}).
Env Football Algo jrpo Exp base_JRPO updates 13959/100000000000.0 steps in 86.36
total episode rewards is -20.0
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'value_loss': 0.528084768584619, '_timestamp': 1721972556.1434495}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0016302911541424693, '_timestamp': 1721972556.1436095}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4519384129842123, '_timestamp': 1721972556.1436758}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.6520161628723145, '_timestamp': 1721972556.143762}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.6825519800186157, '_timestamp': 1721972556.1440432}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'ratio': 0.9992730021476746, '_timestamp': 1721972556.1441479}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -70.0, '_timestamp': 1721972556.144269}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972556.1443582}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'Episode_Time': 39.156901121139526, '_timestamp': 1721972556.1444154}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972556.1446733}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972556.144857}).
wandb: WARNING (User provided step: 3956 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972556.1450374}).
Env Football Algo jrpo Exp base_JRPO updates 3956/100000000000.0 steps in 39.16
total episode rewards is -70.0
Env Football Algo jrpo Exp base_JRPO updates 11285/100000000000.0 steps in 83.48
total episode rewards is -20.0
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'value_loss': 0.15314890370937065, '_timestamp': 1721972639.625135}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'policy_loss': 0.016409078282304108, '_timestamp': 1721972639.625303}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5176282223065694, '_timestamp': 1721972639.6253684}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3686211407184601, '_timestamp': 1721972639.6254566}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.20492079854011536, '_timestamp': 1721972639.6257162}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'ratio': 0.9391833543777466, '_timestamp': 1721972639.6258204}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972639.6259527}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972639.626043}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'Episode_Time': 83.47936201095581, '_timestamp': 1721972639.6261003}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721972639.6264596}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721972639.6267269}).
wandb: WARNING (User provided step: 11285 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721972639.6270025}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'value_loss': 0.33973221527917, '_timestamp': 1721972730.7698927}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004892851160548162, '_timestamp': 1721972730.7701075}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.49216113169988, '_timestamp': 1721972730.7701788}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.5351268649101257, '_timestamp': 1721972730.7703207}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1441311240196228, '_timestamp': 1721972730.7705781}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'ratio': 0.9828708171844482, '_timestamp': 1721972730.7706833}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972730.770827}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972730.770924}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.14178538322449, '_timestamp': 1721972730.7709854}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.42465477270436447, '_timestamp': 1721972730.7717333}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'train_goal': 0.28767261364781777, '_timestamp': 1721972730.7723289}).
wandb: WARNING (User provided step: 5079 is less than current step: 15000. Dropping entry: {'train_WDL': -0.42465477270436447, '_timestamp': 1721972730.7729309}).
Env Football Algo jrpo Exp base_JRPO updates 5079/100000000000.0 steps in 91.14
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 6737/100000000000.0 steps in 81.19
total episode rewards is -20.0
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'value_loss': 0.3386398418736644, '_timestamp': 1721972811.971746}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0007156898251438785, '_timestamp': 1721972811.9727435}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5343358985582987, '_timestamp': 1721972811.972817}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2574807405471802, '_timestamp': 1721972811.9732125}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21747232973575592, '_timestamp': 1721972811.9735508}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'ratio': 0.9575419425964355, '_timestamp': 1721972811.9736583}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972811.9737813}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972811.9739552}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.19425320625305, '_timestamp': 1721972811.974015}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3055790874984872, '_timestamp': 1721972811.974929}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'train_goal': 0.34721045625075636, '_timestamp': 1721972811.9754405}).
wandb: WARNING (User provided step: 6737 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3055790874984872, '_timestamp': 1721972811.9759424}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'value_loss': 0.31638976764089116, '_timestamp': 1721972897.440754}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'policy_loss': 0.004851111677077522, '_timestamp': 1721972897.4409564}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5262950698534647, '_timestamp': 1721972897.441025}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.40339428186416626, '_timestamp': 1721972897.4411275}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18992604315280914, '_timestamp': 1721972897.4414074}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'ratio': 0.9611033201217651, '_timestamp': 1721972897.4415112}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721972897.4416451}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972897.4417412}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.46344876289368, '_timestamp': 1721972897.4418}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.3521095402426806, '_timestamp': 1721972897.4425764}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_goal': 0.3239452298786597, '_timestamp': 1721972897.4431257}).
wandb: WARNING (User provided step: 6017 is less than current step: 15000. Dropping entry: {'train_WDL': -0.3521095402426806, '_timestamp': 1721972897.443683}).
Env Football Algo jrpo Exp base_JRPO updates 6017/100000000000.0 steps in 85.46
total episode rewards is -20.0
Env Football Algo jrpo Exp base_JRPO updates 8903/100000000000.0 steps in 88.78
total episode rewards is -10.0
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'value_loss': 0.23380775335244836, '_timestamp': 1721972986.228494}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'policy_loss': 0.0070786258723819625, '_timestamp': 1721972986.229756}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5800692796707154, '_timestamp': 1721972986.2298276}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.482975572347641, '_timestamp': 1721972986.2303112}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21277420222759247, '_timestamp': 1721972986.2306368}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'ratio': 0.95377117395401, '_timestamp': 1721972986.2307389}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721972986.2308733}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721972986.2310905}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.77883577346802, '_timestamp': 1721972986.231148}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.03788748564867968, '_timestamp': 1721972986.2322829}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'train_goal': 0.48105625717566014, '_timestamp': 1721972986.2326777}).
wandb: WARNING (User provided step: 8903 is less than current step: 15000. Dropping entry: {'train_WDL': -0.03788748564867968, '_timestamp': 1721972986.2330658}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'value_loss': 0.39458964434374744, '_timestamp': 1721973058.9352062}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0005702941433992236, '_timestamp': 1721973058.9353728}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5547011796633403, '_timestamp': 1721973058.9354417}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2738407850265503, '_timestamp': 1721973058.935533}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.23462539911270142, '_timestamp': 1721973058.9357963}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'ratio': 0.9549564719200134, '_timestamp': 1721973058.935899}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721973058.9360633}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973058.9361541}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'Episode_Time': 72.70104765892029, '_timestamp': 1721973058.9362113}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.0955191256830601, '_timestamp': 1721973058.9366925}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'train_goal': 0.54775956284153, '_timestamp': 1721973058.936999}).
wandb: WARNING (User provided step: 8570 is less than current step: 15000. Dropping entry: {'train_WDL': 0.0955191256830601, '_timestamp': 1721973058.9373076}).
Env Football Algo jrpo Exp base_JRPO updates 8570/100000000000.0 steps in 72.70
total episode rewards is -30.0
Env Football Algo jrpo Exp base_JRPO updates 7082/100000000000.0 steps in 85.59
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'value_loss': 0.3345399066879569, '_timestamp': 1721973144.5261662}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013194308694995318, '_timestamp': 1721973144.5263488}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.5327266081174216, '_timestamp': 1721973144.5264199}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1964283138513565, '_timestamp': 1721973144.5265203}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14564251899719238, '_timestamp': 1721973144.526805}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'ratio': 0.9752745032310486, '_timestamp': 1721973144.5269108}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973144.5270312}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973144.5271788}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.58802032470703, '_timestamp': 1721973144.5272388}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.2523364485981308, '_timestamp': 1721973144.5278783}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'train_goal': 0.37383177570093457, '_timestamp': 1721973144.5283804}).
wandb: WARNING (User provided step: 7082 is less than current step: 15000. Dropping entry: {'train_WDL': -0.2523364485981308, '_timestamp': 1721973144.5288434}).
total episode rewards is -20.0
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'value_loss': 0.3434048342918201, '_timestamp': 1721973233.953363}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011248776277328338, '_timestamp': 1721973233.9535265}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.51939036210378, '_timestamp': 1721973233.953595}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.24228401482105255, '_timestamp': 1721973233.9536855}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.14333797991275787, '_timestamp': 1721973233.953935}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'ratio': 0.9878054261207581, '_timestamp': 1721973233.9540374}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721973233.954171}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973233.9542627}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.42374014854431, '_timestamp': 1721973233.954323}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973233.954806}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973233.9551919}).
wandb: WARNING (User provided step: 8954 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973233.955582}).
Env Football Algo jrpo Exp base_JRPO updates 8954/100000000000.0 steps in 89.42
total episode rewards is -40.0
Env Football Algo jrpo Exp base_JRPO updates 9948/100000000000.0 steps in 80.41
total episode rewards is -10.0
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'value_loss': 0.24225332759534163, '_timestamp': 1721973314.3682172}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'policy_loss': -0.009706939901479927, '_timestamp': 1721973314.3683848}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4895702989896138, '_timestamp': 1721973314.3684502}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.31586307287216187, '_timestamp': 1721973314.3685393}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.0745515450835228, '_timestamp': 1721973314.3688064}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'ratio': 1.0065841674804688, '_timestamp': 1721973314.3689075}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721973314.3690352}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973314.3691263}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'Episode_Time': 80.4116461277008, '_timestamp': 1721973314.3691828}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.1611243072050673, '_timestamp': 1721973314.3697095}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'train_goal': 0.5805621536025336, '_timestamp': 1721973314.3700397}).
wandb: WARNING (User provided step: 9948 is less than current step: 15000. Dropping entry: {'train_WDL': 0.1611243072050673, '_timestamp': 1721973314.3703685}).
Env Football Algo jrpo Exp base_JRPO updates 12372/100000000000.0 steps in 87.52
total episode rewards is -20.0
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'value_loss': 0.1568148556422481, '_timestamp': 1721973401.887103}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0077924216655083, '_timestamp': 1721973401.8872666}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4683238855997722, '_timestamp': 1721973401.8873355}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.17575757205486298, '_timestamp': 1721973401.887428}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13969440758228302, '_timestamp': 1721973401.887684}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'ratio': 0.9568824768066406, '_timestamp': 1721973401.8877878}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973401.8879197}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973401.888032}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.51598954200745, '_timestamp': 1721973401.8880913}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973401.8883991}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973401.8886182}).
wandb: WARNING (User provided step: 12372 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973401.8888376}).
Env Football Algo jrpo Exp base_JRPO updates 7707/100000000000.0 steps in 89.35
total episode rewards is -30.0
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'value_loss': 0.24369260120001854, '_timestamp': 1721973491.2383108}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011065054790427287, '_timestamp': 1721973491.2384717}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.430741020043691, '_timestamp': 1721973491.2385366}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.18457067012786865, '_timestamp': 1721973491.2386253}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21697083115577698, '_timestamp': 1721973491.2388716}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'ratio': 0.9907761812210083, '_timestamp': 1721973491.238972}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721973491.2391014}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973491.2391887}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.34877514839172, '_timestamp': 1721973491.2392435}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973491.2400966}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973491.2405317}).
wandb: WARNING (User provided step: 7707 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973491.2409832}).
Env Football Algo jrpo Exp base_JRPO updates 8122/100000000000.0 steps in 79.87
total episode rewards is -10.0
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'value_loss': 0.27501465391003876, '_timestamp': 1721973571.1130106}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0066796996135963125, '_timestamp': 1721973571.1131873}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4361475785573323, '_timestamp': 1721973571.1132562}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3404623866081238, '_timestamp': 1721973571.1133535}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.13600276410579681, '_timestamp': 1721973571.1136096}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'ratio': 0.993768036365509, '_timestamp': 1721973571.113714}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721973571.1138442}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973571.1139383}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'Episode_Time': 79.87118124961853, '_timestamp': 1721973571.113998}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'train_goal_diff': -0.1392846757778424, '_timestamp': 1721973571.1146014}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'train_goal': 0.4303576621110788, '_timestamp': 1721973571.1150408}).
wandb: WARNING (User provided step: 8122 is less than current step: 15000. Dropping entry: {'train_WDL': -0.1392846757778424, '_timestamp': 1721973571.1154704}).
Env Football Algo jrpo Exp base_JRPO updates 12814/100000000000.0 steps in 88.68
total episode rewards is -20.0
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'value_loss': 0.15702809167628098, '_timestamp': 1721973659.7973516}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005860044280998409, '_timestamp': 1721973659.797532}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.4012234298388164, '_timestamp': 1721973659.7975981}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12387503683567047, '_timestamp': 1721973659.7976942}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21050481498241425, '_timestamp': 1721973659.7979622}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'ratio': 0.9332379102706909, '_timestamp': 1721973659.7980642}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721973659.7981946}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973659.7982898}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.68090534210205, '_timestamp': 1721973659.798348}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973659.7986238}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973659.7988803}).
wandb: WARNING (User provided step: 12814 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973659.799075}).
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 84.41
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 78.86
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 10147/100000000000.0 steps in 91.73
total episode rewards is -30.0
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'value_loss': 0.2354496290292203, '_timestamp': 1721973914.8043845}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'policy_loss': -0.00719605266310585, '_timestamp': 1721973914.8045998}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3832794642448425, '_timestamp': 1721973914.80467}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.39572569727897644, '_timestamp': 1721973914.8047662}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2143395096063614, '_timestamp': 1721973914.8050318}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'ratio': 0.9829235076904297, '_timestamp': 1721973914.8051417}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721973914.805284}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721973914.8053796}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'Episode_Time': 91.73171257972717, '_timestamp': 1721973914.8054428}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721973914.8059638}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721973914.806297}).
wandb: WARNING (User provided step: 10147 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721973914.8066363}).
Env Football Algo jrpo Exp base_JRPO updates 15000/100000000000.0 steps in 89.18
total episode rewards is 0.0
Env Football Algo jrpo Exp base_JRPO updates 9618/100000000000.0 steps in 77.60
total episode rewards is -30.0
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'value_loss': 0.24493947035477806, '_timestamp': 1721974081.5972774}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0019393146971560782, '_timestamp': 1721974081.5974483}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2740677603085835, '_timestamp': 1721974081.5975175}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.2898614704608917, '_timestamp': 1721974081.5976148}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.36456626653671265, '_timestamp': 1721974081.597873}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'ratio': 0.9300208687782288, '_timestamp': 1721974081.5979757}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974081.5981069}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974081.5982032}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'Episode_Time': 77.60386395454407, '_timestamp': 1721974081.5982602}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974081.5990062}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974081.5994222}).
wandb: WARNING (User provided step: 9618 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974081.59979}).
Env Football Algo jrpo Exp base_JRPO updates 14385/100000000000.0 steps in 90.22
total episode rewards is -10.0
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'value_loss': 0.07833514259885609, '_timestamp': 1721974171.8236547}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005423015642960915, '_timestamp': 1721974171.8238695}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.3528789178530376, '_timestamp': 1721974171.823938}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07131532579660416, '_timestamp': 1721974171.8240647}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18999381363391876, '_timestamp': 1721974171.8243208}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'ratio': 0.9170985221862793, '_timestamp': 1721974171.824423}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721974171.8245559}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974171.8246484}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.22296357154846, '_timestamp': 1721974171.8247077}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974171.8249125}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974171.8250363}).
wandb: WARNING (User provided step: 14385 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974171.8251538}).
Env Football Algo jrpo Exp base_JRPO updates 8670/100000000000.0 steps in 86.23
total episode rewards is -40.0
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'value_loss': 0.3189755257545039, '_timestamp': 1721974258.0573719}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0121338857266043, '_timestamp': 1721974258.058504}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.273162182966868, '_timestamp': 1721974258.0585732}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.23399676382541656, '_timestamp': 1721974258.0589957}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3465125560760498, '_timestamp': 1721974258.059305}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'ratio': 0.9572635889053345, '_timestamp': 1721974258.0594084}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974258.0595388}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974258.0597115}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.22693252563477, '_timestamp': 1721974258.05977}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974258.0606358}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974258.061041}).
wandb: WARNING (User provided step: 8670 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974258.061451}).
Env Football Algo jrpo Exp base_JRPO updates 12530/100000000000.0 steps in 90.70
total episode rewards is -20.0
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'value_loss': 0.15468847628556734, '_timestamp': 1721974348.7643292}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'policy_loss': -0.010851835974802574, '_timestamp': 1721974348.7645154}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2252322665850321, '_timestamp': 1721974348.7645898}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10685596615076065, '_timestamp': 1721974348.764693}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.10715804249048233, '_timestamp': 1721974348.7649934}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'ratio': 0.9544910788536072, '_timestamp': 1721974348.7651143}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721974348.7652657}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974348.7653642}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'Episode_Time': 90.7019431591034, '_timestamp': 1721974348.7654436}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974348.7657871}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974348.7660153}).
wandb: WARNING (User provided step: 12530 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974348.7662382}).
Env Football Algo jrpo Exp base_JRPO updates 11539/100000000000.0 steps in 86.78
total episode rewards is -30.0
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'value_loss': 0.23651177466720885, '_timestamp': 1721974435.5534945}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013781158602796495, '_timestamp': 1721974435.554778}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1839366626739503, '_timestamp': 1721974435.5548522}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.10598768293857574, '_timestamp': 1721974435.555319}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.43470972776412964, '_timestamp': 1721974435.555676}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'ratio': 0.993281900882721, '_timestamp': 1721974435.5557835}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974435.5559697}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974435.5562184}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.78142929077148, '_timestamp': 1721974435.5562813}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974435.5572114}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974435.5575092}).
wandb: WARNING (User provided step: 11539 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974435.5578094}).
Env Football Algo jrpo Exp base_JRPO updates 7711/100000000000.0 steps in 87.65
total episode rewards is -40.0
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'value_loss': 0.32646828164656955, '_timestamp': 1721974523.2109442}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'policy_loss': -0.017771098187367898, '_timestamp': 1721974523.2112198}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.136830449104309, '_timestamp': 1721974523.2112892}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.12918327748775482, '_timestamp': 1721974523.2114284}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18060307204723358, '_timestamp': 1721974523.2117043}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'ratio': 0.9660879969596863, '_timestamp': 1721974523.211811}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721974523.2119708}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974523.2120724}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'Episode_Time': 87.65190720558167, '_timestamp': 1721974523.2121358}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974523.2127278}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974523.2131722}).
wandb: WARNING (User provided step: 7711 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974523.2136278}).
Env Football Algo jrpo Exp base_JRPO updates 14048/100000000000.0 steps in 84.19
total episode rewards is -10.0
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'value_loss': 0.07864973562109905, '_timestamp': 1721974607.4077911}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'policy_loss': -0.005665417079968999, '_timestamp': 1721974607.4079967}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1901664312680562, '_timestamp': 1721974607.4080725}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.06980405002832413, '_timestamp': 1721974607.408173}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.21738505363464355, '_timestamp': 1721974607.4084}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'ratio': 0.8795350193977356, '_timestamp': 1721974607.408508}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721974607.408639}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974607.4087374}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.19330072402954, '_timestamp': 1721974607.4087982}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974607.4090514}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974607.4091926}).
wandb: WARNING (User provided step: 14048 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974607.4093287}).
Env Football Algo jrpo Exp base_JRPO updates 10238/100000000000.0 steps in 88.70
total episode rewards is -30.0
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'value_loss': 0.24814606375157988, '_timestamp': 1721974696.110846}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'policy_loss': -0.015185639039070034, '_timestamp': 1721974696.1110308}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.1050243878364563, '_timestamp': 1721974696.1110992}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.108770452439785, '_timestamp': 1721974696.111198}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.11832994222640991, '_timestamp': 1721974696.1114676}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'ratio': 0.953467845916748, '_timestamp': 1721974696.111573}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721974696.1117063}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974696.1117997}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'Episode_Time': 88.70054244995117, '_timestamp': 1721974696.11186}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974696.112511}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974696.1128345}).
wandb: WARNING (User provided step: 10238 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974696.1133413}).
Env Football Algo jrpo Exp base_JRPO updates 14270/100000000000.0 steps in 85.00
total episode rewards is -10.0
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'value_loss': 0.08575963066631327, '_timestamp': 1721974781.1212585}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'policy_loss': -0.0036606769448068615, '_timestamp': 1721974781.1226816}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.2017638103167216, '_timestamp': 1721974781.122753}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.07836750894784927, '_timestamp': 1721974781.123294}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.06409011781215668, '_timestamp': 1721974781.1236842}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'ratio': 0.8547405004501343, '_timestamp': 1721974781.1237936}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721974781.123988}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974781.1242118}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.00141716003418, '_timestamp': 1721974781.12427}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974781.1249275}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974781.1250575}).
wandb: WARNING (User provided step: 14270 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974781.1251829}).
Env Football Algo jrpo Exp base_JRPO updates 10079/100000000000.0 steps in 81.85
total episode rewards is -20.0
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'value_loss': 0.16666355128448535, '_timestamp': 1721974862.9798763}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'policy_loss': -0.011163801147292058, '_timestamp': 1721974862.9800754}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0419424414634704, '_timestamp': 1721974862.980145}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1684838831424713, '_timestamp': 1721974862.9802356}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.3926472067832947, '_timestamp': 1721974862.9804924}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'ratio': 0.921029806137085, '_timestamp': 1721974862.980595}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721974862.9807246}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974862.9808166}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'Episode_Time': 81.85392332077026, '_timestamp': 1721974862.980873}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974862.9813168}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974862.9816422}).
wandb: WARNING (User provided step: 10079 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974862.981977}).
Env Football Algo jrpo Exp base_JRPO updates 13343/100000000000.0 steps in 89.50
total episode rewards is -20.0
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'value_loss': 0.15728586107109246, '_timestamp': 1721974952.4845526}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'policy_loss': 0.027293466880267563, '_timestamp': 1721974952.4847524}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9998763545354208, '_timestamp': 1721974952.4848256}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.8993515372276306, '_timestamp': 1721974952.484932}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.18851658701896667, '_timestamp': 1721974952.4852111}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'ratio': 0.8248140215873718, '_timestamp': 1721974952.4853227}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -20.0, '_timestamp': 1721974952.4854598}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721974952.4855592}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.50163435935974, '_timestamp': 1721974952.4856186}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721974952.485906}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721974952.486089}).
wandb: WARNING (User provided step: 13343 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721974952.4862638}).
Env Football Algo jrpo Exp base_JRPO updates 10479/100000000000.0 steps in 85.89
total episode rewards is -10.0
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'value_loss': 0.2422836960143468, '_timestamp': 1721975038.3760655}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'policy_loss': -0.007684230159308451, '_timestamp': 1721975038.3762343}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0199222826957703, '_timestamp': 1721975038.3763034}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.3331337869167328, '_timestamp': 1721975038.3763995}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.49266883730888367, '_timestamp': 1721975038.376618}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'ratio': 0.9318398237228394, '_timestamp': 1721975038.3767245}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -10.0, '_timestamp': 1721975038.376854}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975038.3769498}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.88889575004578, '_timestamp': 1721975038.3770084}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.28422915284229155, '_timestamp': 1721975038.3775291}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'train_goal': 0.6421145764211458, '_timestamp': 1721975038.3778427}).
wandb: WARNING (User provided step: 10479 is less than current step: 15000. Dropping entry: {'train_WDL': 0.28422915284229155, '_timestamp': 1721975038.3781457}).
Env Football Algo jrpo Exp base_JRPO updates 10327/100000000000.0 steps in 84.55
total episode rewards is -40.0
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'value_loss': 0.3110547261229173, '_timestamp': 1721975122.9268441}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'policy_loss': -0.013381372864435737, '_timestamp': 1721975122.9271078}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'dist_entropy': 0.9994205037752787, '_timestamp': 1721975122.9271839}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.13559868931770325, '_timestamp': 1721975122.9273202}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.15233008563518524, '_timestamp': 1721975122.9275775}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'ratio': 0.9549840688705444, '_timestamp': 1721975122.9276867}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -40.0, '_timestamp': 1721975122.9278188}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975122.9279647}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'Episode_Time': 84.54756879806519, '_timestamp': 1721975122.928025}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975122.9286635}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975122.9289885}).
wandb: WARNING (User provided step: 10327 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975122.9293191}).
Env Football Algo jrpo Exp base_JRPO updates 8968/100000000000.0 steps in 89.44
total episode rewards is -30.0
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'value_loss': 0.2511260480200872, '_timestamp': 1721975212.3769221}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'policy_loss': -0.014986011559425, '_timestamp': 1721975212.3784692}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0332398307323456, '_timestamp': 1721975212.3785455}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.1026715338230133, '_timestamp': 1721975212.3790553}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.1195514053106308, '_timestamp': 1721975212.3794289}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'ratio': 0.9306817650794983, '_timestamp': 1721975212.3795393}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721975212.379676}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975212.3798952}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'Episode_Time': 89.4416937828064, '_timestamp': 1721975212.379971}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975212.3811622}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975212.381588}).
wandb: WARNING (User provided step: 8968 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975212.3820157}).
Env Football Algo jrpo Exp base_JRPO updates 8956/100000000000.0 steps in 85.52
total episode rewards is -30.0
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'value_loss': 0.244740511153747, '_timestamp': 1721975297.9028208}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'policy_loss': -0.01380963485687971, '_timestamp': 1721975297.902981}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.053429644902547, '_timestamp': 1721975297.9030483}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.08612606674432755, '_timestamp': 1721975297.9031398}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.2668936848640442, '_timestamp': 1721975297.9033988}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'ratio': 0.940907895565033, '_timestamp': 1721975297.9035003}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'total_episode_rewards': -30.0, '_timestamp': 1721975297.904848}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975297.9050019}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'Episode_Time': 85.52000713348389, '_timestamp': 1721975297.9050705}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'train_goal_diff': -1.0, '_timestamp': 1721975297.905684}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'train_goal': 0.0, '_timestamp': 1721975297.9060938}).
wandb: WARNING (User provided step: 8956 is less than current step: 15000. Dropping entry: {'train_WDL': -1.0, '_timestamp': 1721975297.9064903}).
Env Football Algo jrpo Exp base_JRPO updates 10669/100000000000.0 steps in 86.81
total episode rewards is 0.0
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'value_loss': 0.16411834000221764, '_timestamp': 1721975384.716427}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'policy_loss': -0.008016182126302738, '_timestamp': 1721975384.716596}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'dist_entropy': 1.0751845741271973, '_timestamp': 1721975384.7166605}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'actor_grad_norm': 0.43605276942253113, '_timestamp': 1721975384.7167547}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'critic_grad_norm': 0.35454055666923523, '_timestamp': 1721975384.7170038}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'ratio': 0.8521991968154907, '_timestamp': 1721975384.7171044}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'total_episode_rewards': 0.0, '_timestamp': 1721975384.717233}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'Difficulty_level': 1, '_timestamp': 1721975384.717326}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'Episode_Time': 86.80909419059753, '_timestamp': 1721975384.7173836}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'train_goal_diff': 0.3659662895405218, '_timestamp': 1721975384.7178795}).
wandb: WARNING (User provided step: 10669 is less than current step: 15000. Dropping entry: {'train_goal': 0.6829831447702609, '_timestamp': 1721975384.7181888}).
