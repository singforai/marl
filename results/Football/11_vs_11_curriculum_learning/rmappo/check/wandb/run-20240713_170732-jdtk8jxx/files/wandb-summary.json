{"value_loss": 0.28943370779355365, "_timestamp": 1720858515.971913, "policy_loss": -0.004903039485130497, "dist_entropy": 2.8467965920766196, "actor_grad_norm": 0.059874601662158966, "critic_grad_norm": 0.3222728967666626, "ratio": 1.0001754760742188, "average_episode_rewards": -20.00000048428774, "train_possession_rate": 0.30933333333333335, "_runtime": 463.71446800231934, "_step": 57000, "train_goal_diff": -2.0, "train_goal": 0.0, "train_WDL": -1.0, "_wandb": {"runtime": 468}}