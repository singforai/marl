{"value_loss": 0.38839942272752526, "_timestamp": 1720867288.2683382, "policy_loss": -0.011258666540961713, "dist_entropy": 2.7822077528635663, "actor_grad_norm": 0.26791152358055115, "critic_grad_norm": 0.12658441066741943, "ratio": 1.0259792804718018, "average_episode_rewards": -21.999999415129423, "train_possession_rate": 0.2877333333333333, "_runtime": 8729.49970817566, "_step": 5520000, "train_goal_diff": -2.1, "train_goal": 0.0, "train_WDL": -0.9, "eval_goal": 0.0, "eval_WDL": -0.95, "eval_goal_diff": -2.2, "eval_possession_rate": 0.4324, "_wandb": {"runtime": 8744}}