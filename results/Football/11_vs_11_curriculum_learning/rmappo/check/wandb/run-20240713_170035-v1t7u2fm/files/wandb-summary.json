{"value_loss": 1.2130270719528198, "_timestamp": 1720857857.8068497, "policy_loss": -0.033823619193087025, "dist_entropy": 2.9291293462117514, "actor_grad_norm": 0.31993231177330017, "critic_grad_norm": 1.8682594299316406, "ratio": 1.0047730207443237, "average_episode_rewards": -40.00000096857548, "train_goal_diff": -0.5, "train_goal": 0.25, "train_WDL": -0.5, "train_possession_rate": 0.23, "_runtime": 222.13645482063293, "_step": 27000, "_wandb": {"runtime": 232}}