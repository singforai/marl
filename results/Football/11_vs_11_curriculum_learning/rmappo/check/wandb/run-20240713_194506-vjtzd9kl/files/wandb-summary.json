{"value_loss": 0.32567863022287685, "_timestamp": 1720870465.4965565, "policy_loss": -0.024134051815296213, "dist_entropy": 2.896570987701416, "actor_grad_norm": 0.2631237208843231, "critic_grad_norm": 0.23203308880329132, "ratio": 1.0066782236099243, "average_episode_rewards": -20.00000048428774, "train_possession_rate": 0.2848666666666667, "_runtime": 2958.629151582718, "_step": 2280000, "train_goal_diff": -2.5, "train_goal": 0.15, "train_WDL": -0.95, "eval_goal": 0.0, "eval_WDL": -0.9, "eval_goal_diff": -2.25, "eval_possession_rate": 0.18901666666666664, "_wandb": {"runtime": 3024}}