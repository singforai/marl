{"value_loss": 0.5234567546347777, "_timestamp": 1720950173.9201512, "policy_loss": -0.023294459773266378, "dist_entropy": 2.542953651746114, "actor_grad_norm": 0.3518489599227905, "critic_grad_norm": 0.18355026841163635, "ratio": 1.0410346984863281, "average_episode_rewards": -22.999999579042196, "train_possession_rate": 0.27713333333333334, "_runtime": 79522.1371421814, "_step": 21870000, "train_goal_diff": -2.3, "train_goal": 0.0, "train_WDL": -0.8, "eval_goal": 0.05, "eval_WDL": -0.9, "eval_goal_diff": -1.6, "eval_possession_rate": 0.44556666666666667}