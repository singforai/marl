{"value_loss": 0.38262118093669417, "_timestamp": 1720950159.207145, "policy_loss": -0.011721124830461728, "dist_entropy": 2.5895576508839926, "actor_grad_norm": 0.30776137113571167, "critic_grad_norm": 0.1556360125541687, "ratio": 1.040420413017273, "average_episode_rewards": -20.00000048428774, "train_possession_rate": 0.27016666666666667, "_runtime": 79507.41751408577, "_step": 22170000, "train_goal_diff": -2.2, "train_goal": 0.0, "train_WDL": -1.0, "eval_goal": 0.0, "eval_WDL": -0.95, "eval_goal_diff": -2.15, "eval_possession_rate": 0.44386666666666663}