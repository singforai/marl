{"value_loss": 0.4655825360616048, "_timestamp": 1720950222.7703774, "policy_loss": -0.01626784524890051, "dist_entropy": 2.6083007526397703, "actor_grad_norm": 0.2862483859062195, "critic_grad_norm": 0.13013248145580292, "ratio": 1.0403181314468384, "average_episode_rewards": -25.000001303851604, "train_possession_rate": 0.2740333333333333, "_runtime": 79570.99216151237, "_step": 21990000, "train_goal_diff": -2.3, "train_goal": 0.0, "train_WDL": -0.9, "eval_goal": 0.35, "eval_WDL": -0.6, "eval_goal_diff": -1.5, "eval_possession_rate": 0.5067666666666667}