{"value_loss": 0.5512439096470674, "_timestamp": 1720950039.8164628, "policy_loss": -0.01053470529402451, "dist_entropy": 2.6330286184946696, "actor_grad_norm": 0.27626872062683105, "critic_grad_norm": 0.11278123408555984, "ratio": 1.0324978828430176, "average_episode_rewards": -22.999999579042196, "train_possession_rate": 0.2773, "_runtime": 79388.10858678818, "_step": 21870000, "train_goal_diff": -2.3, "train_goal": 0.1, "train_WDL": -1.0, "eval_goal": 0.3, "eval_WDL": -0.8, "eval_goal_diff": -1.6, "eval_possession_rate": 0.4495}