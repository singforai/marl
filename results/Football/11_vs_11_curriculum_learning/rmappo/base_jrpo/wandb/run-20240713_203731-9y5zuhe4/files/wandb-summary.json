{"value_loss": 0.4645946043233077, "_timestamp": 1720950146.340495, "policy_loss": -0.017801142604439518, "dist_entropy": 2.6596091588338218, "actor_grad_norm": 0.2776646018028259, "critic_grad_norm": 0.13032862544059753, "ratio": 1.0385555028915405, "average_episode_rewards": -21.999999415129423, "train_possession_rate": 0.26936666666666664, "_runtime": 79494.55122613907, "_step": 22170000, "train_goal_diff": -1.6, "train_goal": 0.4, "train_WDL": -0.6, "eval_goal": 0.1, "eval_WDL": -0.9, "eval_goal_diff": -1.8, "eval_possession_rate": 0.43753333333333333}