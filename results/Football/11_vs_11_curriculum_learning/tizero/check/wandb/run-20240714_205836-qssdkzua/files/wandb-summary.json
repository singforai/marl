{"value_loss": 0.438526181379954, "_timestamp": 1720958530.9555752, "policy_loss": -0.05656853217482573, "dist_entropy": 2.9217094580332437, "actor_grad_norm": 0.39008432626724243, "critic_grad_norm": 1.6090867519378662, "ratio": 1.1579511165618896, "average_episode_rewards": -40.00000096857548, "train_possession_rate": 0.6966666666666667, "_runtime": 214.9079782962799, "_step": 21000, "train_goal_diff": -3.0, "train_goal": 0.0, "train_WDL": -1.0, "_wandb": {"runtime": 219}}