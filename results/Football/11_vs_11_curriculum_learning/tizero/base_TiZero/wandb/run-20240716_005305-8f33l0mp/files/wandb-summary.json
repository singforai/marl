{"value_loss": 0.3419381936391195, "_timestamp": 1721104787.9521725, "policy_loss": -0.0451813704178979, "dist_entropy": 2.734947609901428, "actor_grad_norm": 0.262461394071579, "critic_grad_norm": 1.0431188344955444, "ratio": 1.256798267364502, "average_episode_rewards": -21.800000220537186, "Episode_Time": 143.71040797233582, "train_possession_rate": 0.6691866666666667, "_runtime": 46002.44928240776, "_step": 24900000, "train_goal_diff": -2.14, "train_goal": 0.02, "train_WDL": -0.92, "eval_goal": 0.0, "eval_WDL": -0.9, "eval_goal_diff": -2.3, "_wandb": {"runtime": 46228}}