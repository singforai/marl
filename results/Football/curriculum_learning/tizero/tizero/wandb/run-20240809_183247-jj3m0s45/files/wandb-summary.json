{"value_loss": 0.5241541266441345, "_timestamp": 1723196636.4830093, "policy_loss": 0.20890679955482483, "dist_entropy": 2.944349241256714, "actor_grad_norm": 0.0610508993268013, "critic_grad_norm": 0.33539488911628723, "ratio": 0.7054928541183472, "episode_length": 1058.2, "total_episode_rewards": -26.749000549316406, "Episode_Time": 59.603660345077515, "difficulty_level": 1, "level_stack": 0, "train_goal_diff": -0.7, "train_goal": 0.0, "train_WDL": 0.0, "_runtime": 669.3760364055634, "_step": 10681}