{"value_loss": 0.5272650564213593, "_timestamp": 1722583528.5950885, "policy_loss": -0.02810979111333533, "dist_entropy": 1.288472596804301, "actor_grad_norm": 0.42310336232185364, "critic_grad_norm": 0.3875882029533386, "ratio": 0.9279761910438538, "episode_length": 982.0, "total_episode_rewards": -59.97570037841797, "Difficulty_level": 1, "Episode_Time": 54.66205143928528, "train_goal_diff": -0.6, "train_goal": 0.2, "train_WDL": -0.6, "_runtime": 2354.317988395691, "_step": 51189}