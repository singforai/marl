{"value_loss": 0.6282113352417946, "_timestamp": 1723461655.4364977, "policy_loss": 0.22171257280744613, "dist_entropy": 1.4660167336463927, "actor_grad_norm": 0.7409481406211853, "critic_grad_norm": 0.5775508880615234, "ratio": 0.4637087881565094, "episode_length": 594.3, "total_episode_rewards": -30.0, "Episode_Time": 14.999571561813354, "difficulty_level": 1, "level_stack": 0, "train_goal_diff": -0.3, "train_goal": 0.2, "train_WDL": 0.2, "_runtime": 453.22447776794434, "_step": 23420}