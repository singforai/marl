
사용 가능한 CPU Thread: 24
{'value_loss': 0.6572821444272995, 'policy_loss': 0.02827521974919364, 'dist_entropy': 2.9441679239273073, 'actor_grad_norm': tensor(0.2144), 'critic_grad_norm': tensor(1.3849), 'ratio': tensor(0.7205)}
Env Football Algo tizero Exp check updates 1080/100000000000.0 steps in 28.37
total episode rewards is -27.927998860677082
{'value_loss': 0.5218938367068767, 'policy_loss': 0.06384944829158484, 'dist_entropy': 2.9430415868759154, 'actor_grad_norm': tensor(0.2236), 'critic_grad_norm': tensor(0.6968), 'ratio': tensor(0.5756)}
Env Football Algo tizero Exp check updates 1943/100000000000.0 steps in 30.20
total episode rewards is 23.40599822998047
{'value_loss': 0.5188085757195949, 'policy_loss': 0.07100679338327609, 'dist_entropy': 2.9417311429977415, 'actor_grad_norm': tensor(0.2291), 'critic_grad_norm': tensor(0.5950), 'ratio': tensor(0.6229)}
Env Football Algo tizero Exp check updates 2876/100000000000.0 steps in 23.34
total episode rewards is -6.698998769124349
{'value_loss': 0.6938424646481871, 'policy_loss': 0.01770368586294353, 'dist_entropy': 2.9415172719955445, 'actor_grad_norm': tensor(0.2543), 'critic_grad_norm': tensor(0.6573), 'ratio': tensor(0.5566)}
Env Football Algo tizero Exp check updates 3711/100000000000.0 steps in 29.31
total episode rewards is 64.7009989420573
Traceback (most recent call last):
  File "/home/uosai/Desktop/marl/onpolicy/train_grf.py", line 238, in <module>
    main(args = sys.argv[1:])
  File "/home/uosai/Desktop/marl/onpolicy/train_grf.py", line 229, in main
    runner.run()
  File "/home/uosai/Desktop/marl/onpolicy/runner/shared/football_runner.py", line 64, in run
    values, actions, action_log_probs, rnn_states, rnn_states_critic, actions_env, enemy_rnn_states = self.collect(step)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/uosai/Desktop/marl/onpolicy/runner/shared/football_runner.py", line 201, in collect
    enemy_actions, enemy_rnn_states = self.opponent_policy.act(
  File "/home/uosai/Desktop/marl/onpolicy/algorithms/tizero/algorithm/TiZeroPolicy.py", line 129, in act
    actions, _, rnn_states_actor = self.actor(obs, rnn_states_actor, masks, available_actions, deterministic)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/marl/onpolicy/algorithms/tizero/algorithm/r_actor_critic.py", line 82, in forward
    obs_output, rnn_states = self.obs_encoder(obs, rnn_states, masks)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/marl/onpolicy/algorithms/utils/input_encoder.py", line 381, in forward
    actor_features = self.input_encoder(obs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/marl/onpolicy/algorithms/utils/input_encoder.py", line 316, in forward
    match_state_output = self.match_state_encoder(match_state_vec)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/marl/onpolicy/algorithms/utils/input_encoder.py", line 109, in forward
    output = self.first_mlp(x)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/container.py", line 215, in forward
    input = module(input)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1518, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1527, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 101, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/uosai/Desktop/miniconda3/envs/marl/lib/python3.9/site-packages/torch/nn/functional.py", line 1471, in relu
    result = torch.relu(input)
KeyboardInterrupt