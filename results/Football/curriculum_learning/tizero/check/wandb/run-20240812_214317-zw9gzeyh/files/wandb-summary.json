{"value_loss": 0.2122572034597397, "_timestamp": 1723466644.5375414, "policy_loss": 0.08616673648357391, "dist_entropy": 0.7290810108184814, "actor_grad_norm": 0.06351064890623093, "critic_grad_norm": 0.671055257320404, "ratio": 0.4469228684902191, "episode_length": 496.1, "total_episode_rewards": -10.0, "Episode_Time": 6.381211042404175, "difficulty_level": 1, "level_stack": 0, "train_goal_diff": -0.1, "train_goal": 0.0, "train_WDL": 0.0, "_runtime": 47.08927249908447, "_step": 2632}