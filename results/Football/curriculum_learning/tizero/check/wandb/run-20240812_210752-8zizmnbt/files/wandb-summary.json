{"value_loss": 0.19194951057434081, "_timestamp": 1723464598.3073924, "policy_loss": 0.12441821992397309, "dist_entropy": 1.1855884552001954, "actor_grad_norm": 0.03223438188433647, "critic_grad_norm": 0.22880308330059052, "ratio": 0.5161449313163757, "episode_length": 471.9, "total_episode_rewards": -10.0, "Episode_Time": 6.872578144073486, "difficulty_level": 1, "level_stack": 0, "train_goal_diff": -0.1, "train_goal": 0.0, "train_WDL": 0.0, "_runtime": 126.03512144088745, "_step": 7435}